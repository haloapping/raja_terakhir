{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13fc63c4-da08-43a8-9972-2615d377d1fa",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "313363b9-24d1-4b87-87cd-a0b7dd5fc128",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pytz\n",
    "import torch\n",
    "import timeit\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from itertools import chain\n",
    "from time import time\n",
    "from torch import nn, optim\n",
    "from torchmetrics import F1Score\n",
    "from torch.optim import lr_scheduler\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from polyglot.mapping import Embedding, CaseExpander, DigitExpander"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b49405-006a-4a45-ae79-0e22f6a7172e",
   "metadata": {},
   "source": [
    "# Hyperparameters Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68709d29-24a1-45bf-b549-804952fd1db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hyperparams:\n",
    "     def __init__(\n",
    "        self,\n",
    "        context_size=79,\n",
    "        input_size_left_context=64,\n",
    "        input_size_oov_context=20,\n",
    "        input_size_right_context=64,\n",
    "        batch_size=32,\n",
    "        num_hidden_layer=1,\n",
    "        hidden_size=128,\n",
    "        output_size=3611,\n",
    "        shuffle=True,\n",
    "        lr=0.001,\n",
    "        batch_first=True,\n",
    "        bidirectional=True,\n",
    "        init_wb_with_kaiming_normal=True,\n",
    "        n_epoch=20,\n",
    "        patience=20,\n",
    "        device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    ):\n",
    "        self.context_size = context_size\n",
    "        self.input_size_left_context = input_size_left_context\n",
    "        self.input_size_oov_context = input_size_oov_context\n",
    "        self.input_size_right_context = input_size_right_context\n",
    "        self.batch_size = batch_size\n",
    "        self.num_hidden_layer = num_hidden_layer\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.shuffle = shuffle\n",
    "        self.lr = lr\n",
    "        self.batch_first = batch_first\n",
    "        self.bidirectional = bidirectional\n",
    "        self.init_wb_with_kaiming_normal = init_wb_with_kaiming_normal\n",
    "        self.n_epoch = n_epoch\n",
    "        self.patience = patience\n",
    "        self.device = device\n",
    "        \n",
    "hyperparams = Hyperparams()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f750b1-d4a7-4a2a-9fe1-369a61f28a2b",
   "metadata": {},
   "source": [
    "# Prepare Feature Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f241f20b-fb34-4db2-b887-1687f137b141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left context shape: (16562, 71)\n",
      "OOV context shape: (16562, 28)\n",
      "Right context shape: (16562, 79)\n",
      "Actual lable shape: (16562,)\n"
     ]
    }
   ],
   "source": [
    "def convert_doc_to_idxs(docs, dict_vocabs):\n",
    "    doc_to_idx = []\n",
    "    \n",
    "    for doc in docs:\n",
    "        doc_to_idx.append([dict_vocabs[token] for token in doc])\n",
    "        \n",
    "    return np.array(doc_to_idx)\n",
    "\n",
    "# Left context\n",
    "left_context = open(f\"../../datasets/features/{hyperparams.context_size}_context/left_context_with_pad.pkl\", \"rb\")\n",
    "left_context = pickle.load(left_context)\n",
    "left_context_to_idx = open(f\"../../datasets/features/{hyperparams.context_size}_context/token2idx_left_context.pkl\", \"rb\")\n",
    "left_context_to_idx = pickle.load(left_context_to_idx)\n",
    "doc_left_context_to_idx = convert_doc_to_idxs(left_context, left_context_to_idx)\n",
    "\n",
    "# OOV context\n",
    "oov_context = open(f\"../../datasets/features/{hyperparams.context_size}_context/oov_context_with_pad.pkl\", \"rb\")\n",
    "oov_context = pickle.load(oov_context)\n",
    "oov_context_to_idx = open(f\"../../datasets/features/{hyperparams.context_size}_context/token2idx_oov_context.pkl\", \"rb\")\n",
    "oov_context_to_idx = pickle.load(oov_context_to_idx)\n",
    "doc_oov_context_to_idx = convert_doc_to_idxs(oov_context, oov_context_to_idx)\n",
    "\n",
    "# Right context\n",
    "right_context = open(f\"../../datasets/features/{hyperparams.context_size}_context/right_context_with_pad.pkl\", \"rb\")\n",
    "right_context = pickle.load(right_context)\n",
    "right_context_to_idx = open(f\"../../datasets/features/{hyperparams.context_size}_context/token2idx_right_context.pkl\", \"rb\")\n",
    "right_context_to_idx = pickle.load(right_context_to_idx)\n",
    "doc_right_context_to_idx = convert_doc_to_idxs(right_context, right_context_to_idx)\n",
    "\n",
    "# Actual labels\n",
    "labels_context = open(f\"../../datasets/features/{hyperparams.context_size}_context/lables.pkl\", \"rb\")\n",
    "labels_context = pickle.load(labels_context)\n",
    "labels_to_idx = open(f\"../../datasets/features/{hyperparams.context_size}_context/lable_vocabs.pkl\", \"rb\")\n",
    "labels_to_idx = pickle.load(labels_to_idx)\n",
    "doc_labels_to_idx = convert_doc_to_idxs(labels_context, labels_to_idx).flatten()\n",
    "\n",
    "print(f\"Left context shape: {doc_left_context_to_idx.shape}\")\n",
    "print(f\"OOV context shape: {doc_oov_context_to_idx.shape}\")\n",
    "print(f\"Right context shape: {doc_right_context_to_idx.shape}\")\n",
    "print(f\"Actual lable shape: {doc_labels_to_idx.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe386c1f-3e1d-4589-b18e-42e4bc4055ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to Tensor\n",
    "left_contexts = torch.LongTensor(doc_left_context_to_idx)\n",
    "oov_contexts = torch.LongTensor(doc_oov_context_to_idx)\n",
    "right_contexts = torch.LongTensor(doc_right_context_to_idx)\n",
    "actual_labels = torch.LongTensor(doc_labels_to_idx)\n",
    "dataset = TensorDataset(left_contexts, oov_contexts, right_contexts, actual_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8806cc8-c1d1-450a-833d-f25375c52949",
   "metadata": {},
   "source": [
    "# Char and Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86595b81-a95e-4469-acad-49b9ed2c9662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word Embedding\n",
    "word_embeddings = Embedding.load(\"../../word_embeddings/polyglot/idn_embeddings.tar.bz2\")\n",
    "word_embeddings.apply_expansion(DigitExpander)\n",
    "word_embeddings.apply_expansion(CaseExpander)\n",
    "\n",
    "left_vocabs = open(f\"../../datasets/features/{hyperparams.context_size}_context/left_context_vocabs.pkl\", \"rb\")\n",
    "left_vocabs = pickle.load(left_vocabs)\n",
    "\n",
    "right_vocabs = open(f\"../../datasets/features/{hyperparams.context_size}_context/right_context_vocabs.pkl\", \"rb\")\n",
    "right_vocabs = pickle.load(right_vocabs)\n",
    "\n",
    "left_word_embedding_dict = {left_context_to_idx[vocab] : word_embeddings[vocab] for vocab in left_vocabs}\n",
    "right_word_embedding_dict = {right_context_to_idx[vocab] : word_embeddings[vocab] for vocab in right_vocabs}\n",
    "\n",
    "# Char Embedding\n",
    "char_embedding_dict = open(\"../../word_embeddings/chars_embedding/char_embeddings.pkl\", \"rb\")\n",
    "char_embedding_dict = pickle.load(char_embedding_dict)\n",
    "\n",
    "# Context embedding\n",
    "left_context_embedding = nn.Embedding.from_pretrained(torch.FloatTensor(np.array(list(left_word_embedding_dict.values()))), padding_idx=left_vocabs.index(\"<PAD>\"), freeze=True)\n",
    "oov_context_embedding = nn.Embedding.from_pretrained(torch.FloatTensor(np.array(list(char_embedding_dict.values()))), padding_idx=list(char_embedding_dict.keys()).index(\"PAD\"), freeze=True)\n",
    "right_context_embedding = nn.Embedding.from_pretrained(torch.FloatTensor(np.array(list(right_word_embedding_dict.values()))), padding_idx=right_vocabs.index(\"<PAD>\"), freeze=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593ddcfe-1525-41ae-bf02-c9ebf3d957aa",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "998fb38d-da64-4b4c-9371-75e06ebfc8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=hyperparams.batch_size, shuffle=hyperparams.shuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5be550-2f41-41b4-9df4-ac67744041c5",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed852446-c649-4727-b9ff-64375cf7e966",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Comick(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size_left_context=hyperparams.input_size_left_context,\n",
    "        input_size_oov_context=hyperparams.input_size_oov_context,\n",
    "        input_size_right_context=hyperparams.input_size_right_context,\n",
    "        hidden_size=hyperparams.hidden_size,\n",
    "        num_layers=hyperparams.num_hidden_layer,\n",
    "        output_size=hyperparams.output_size,\n",
    "        batch_first=hyperparams.batch_first,\n",
    "        bidirectional=hyperparams.bidirectional,\n",
    "        init_wb_with_kaiming_normal=hyperparams.init_wb_with_kaiming_normal\n",
    "    ):\n",
    "        super(Comick, self).__init__()\n",
    "        \n",
    "        self.input_size_left_context = input_size_left_context\n",
    "        self.input_size_oov_context = input_size_oov_context\n",
    "        self.input_size_right_context = input_size_right_context\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.output_size = output_size\n",
    "        self.batch_first = batch_first\n",
    "        self.bidirectional = bidirectional\n",
    "        \n",
    "        self.bilstm_left_context_feature = nn.LSTM(\n",
    "            input_size = self.input_size_left_context,\n",
    "            hidden_size = self.hidden_size,\n",
    "            num_layers = self.num_layers,\n",
    "            batch_first = self.batch_first,\n",
    "            bidirectional = self.bidirectional\n",
    "        )\n",
    "        \n",
    "        self.bilstm_oov_context_feature = nn.LSTM(\n",
    "            input_size = self.input_size_oov_context,\n",
    "            hidden_size = self.hidden_size,\n",
    "            num_layers = self.num_layers,\n",
    "            batch_first = self.batch_first,\n",
    "            bidirectional = self.bidirectional\n",
    "        )\n",
    "        \n",
    "        self.bilstm_right_context_feature = nn.LSTM(\n",
    "            input_size = self.input_size_right_context,\n",
    "            hidden_size = self.hidden_size,\n",
    "            num_layers = self.num_layers,\n",
    "            batch_first = self.batch_first,\n",
    "            bidirectional = self.bidirectional\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(2 * self.hidden_size, 64),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "        self.oov_embedding = nn.Linear(in_features=3 * 64, out_features=64)\n",
    "        \n",
    "        self.embedding = np.empty((output_size, 64), dtype=np.float32)\n",
    "        \n",
    "        self.prob = nn.Sequential(\n",
    "            nn.Linear(64, self.output_size),\n",
    "            nn.LogSoftmax(dim=1)\n",
    "        )\n",
    "                \n",
    "        if init_wb_with_kaiming_normal:\n",
    "            self.init_wb()\n",
    "            \n",
    "    def init_wb(self):\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, (nn.Linear, nn.LSTM)):\n",
    "                for name, param in module.named_parameters():\n",
    "                    if \"weight\" in name:\n",
    "                        nn.init.kaiming_normal_(param)\n",
    "                    else:\n",
    "                        nn.init.kaiming_normal_(param.reshape(1, -1))\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_left_context,\n",
    "        input_oov_context,\n",
    "        input_right_context,\n",
    "        idxs_target,\n",
    "        hidden_left_context=None,\n",
    "        hidden_oov_context=None,\n",
    "        hidden_right_context=None,\n",
    "    ):\n",
    "        # BiLSTM left, oov, and right context\n",
    "        output_left_context, (hidden_left_context, memory_left_context) = self.bilstm_left_context_feature(input_left_context, hidden_left_context)\n",
    "        output_oov_context, (hidden_oov_context, memory_oov_context) = self.bilstm_oov_context_feature(input_oov_context, hidden_oov_context)\n",
    "        output_right_context, (hidden_right_context, memory_right_context) = self.bilstm_right_context_feature(input_right_context, hidden_right_context)\n",
    "                \n",
    "        # Concate hidden (forward and backward hidden BiLSTM)\n",
    "        hidden_left_bidirectional = torch.cat((hidden_left_context[0], hidden_left_context[-1]), dim=1)\n",
    "        hidden_oov_bidirectional = torch.cat((hidden_oov_context[0], hidden_oov_context[-1]), dim=1)\n",
    "        hidden_right_bidirectional = torch.cat((hidden_right_context[0], hidden_right_context[-1]), dim=1)\n",
    "        \n",
    "        # Fully connected\n",
    "        output_left_fc = self.fc(hidden_left_bidirectional)\n",
    "        output_oov_fc = self.fc(hidden_oov_bidirectional)\n",
    "        output_right_fc = self.fc(hidden_right_bidirectional)\n",
    "        \n",
    "        # Concate output left, oov, and right context feature\n",
    "        output = torch.cat((output_left_fc, output_oov_fc, output_right_fc), dim=1)\n",
    "        \n",
    "        # OOV embedding\n",
    "        output = self.oov_embedding(output)\n",
    "                \n",
    "        # save OOV embedding\n",
    "        self.embedding[idxs_target.tolist()] = output.cpu().detach().numpy()\n",
    "        \n",
    "        # Projection OOV embedding\n",
    "        prob = self.prob(output)\n",
    "        \n",
    "        return prob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992eb40b-9062-47f1-9703-65e80d6cb07d",
   "metadata": {},
   "source": [
    "# Model, Optimizer, Criterion, Metric, and Learning Rate Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b08d05fc-0bb5-426e-aa7b-eb930ba9f06b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Comick(\n",
       "  (bilstm_left_context_feature): LSTM(64, 128, batch_first=True, bidirectional=True)\n",
       "  (bilstm_oov_context_feature): LSTM(20, 128, batch_first=True, bidirectional=True)\n",
       "  (bilstm_right_context_feature): LSTM(64, 128, batch_first=True, bidirectional=True)\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (1): Tanh()\n",
       "  )\n",
       "  (oov_embedding): Linear(in_features=192, out_features=64, bias=True)\n",
       "  (prob): Sequential(\n",
       "    (0): Linear(in_features=64, out_features=3611, bias=True)\n",
       "    (1): LogSoftmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Comick().to(hyperparams.device)\n",
    "model.prob[0].requires_grad_ = False # disable gradient for projection layer\n",
    "optimizer = optim.Adam(model.parameters(), lr=hyperparams.lr)\n",
    "criterion = nn.NLLLoss(ignore_index=list(char_embedding_dict.keys()).index(\"PAD\")).to(hyperparams.device)\n",
    "metric = F1Score(ignore_index=list(char_embedding_dict.keys()).index(\"PAD\")).to(hyperparams.device)\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.5)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d463d75-dd43-4b45-9eec-8f4aca21b018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "814,427\n"
     ]
    }
   ],
   "source": [
    "print(f\"{sum([param.numel() for param in model.parameters() if param.requires_grad_]):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "494a567d-acbc-46c2-adc8-b9a512366c17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4.6195900e-38,  4.5686534e-41, -4.6195900e-38, ...,\n",
       "         4.5685133e-41,  1.0835681e-40,  0.0000000e+00],\n",
       "       [-1.2199597e+30,  4.5685133e-41, -1.9804599e+30, ...,\n",
       "         4.5685133e-41, -1.9805566e+30,  4.5685133e-41],\n",
       "       [ 1.0837222e-40,  0.0000000e+00, -1.2199863e+30, ...,\n",
       "         0.0000000e+00, -1.2200153e+30,  4.5685133e-41],\n",
       "       ...,\n",
       "       [-1.4088867e+29,  4.5685133e-41, -1.9456041e+30, ...,\n",
       "         4.5685133e-41, -1.9457008e+30,  4.5685133e-41],\n",
       "       [ 1.1442583e-40,  0.0000000e+00, -1.4089199e+29, ...,\n",
       "         0.0000000e+00, -1.4089562e+29,  4.5685133e-41],\n",
       "       [-1.9458072e+30,  4.5685133e-41,  1.1444124e-40, ...,\n",
       "         4.5685133e-41,  1.1445526e-40,  0.0000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b39ba3-b103-44da-ae1e-34fd12ad2d2f",
   "metadata": {},
   "source": [
    "# Training Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c51a3a6-a4af-425f-aa1f-34ffe9ff8248",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_step(dataloader, model, optimizer, criterion, metric, scheduler=None, path_name=None):\n",
    "    model.train()\n",
    "    \n",
    "    batch_losses = []\n",
    "    batch_metric_scores = []\n",
    "    \n",
    "    for batch, (input_left_context, input_oov_context, input_right_context, actual_label) in enumerate(tqdm(dataloader), 1):\n",
    "        # Forward Propagation\n",
    "        prob = model(\n",
    "            left_context_embedding(input_left_context).to(hyperparams.device),\n",
    "            oov_context_embedding(input_oov_context).to(hyperparams.device),\n",
    "            right_context_embedding(input_right_context).to(hyperparams.device),\n",
    "            actual_label.to(hyperparams.device)\n",
    "        )\n",
    "                \n",
    "        loss = criterion(prob, actual_label.to(hyperparams.device))\n",
    "        metric_score = metric(prob.argmax(dim=1), actual_label.to(hyperparams.device))\n",
    "        metric_score = metric.compute()\n",
    "        \n",
    "        if scheduler is not None:\n",
    "            scheduler.step(loss)\n",
    "        \n",
    "        batch_losses.append(loss.item())\n",
    "        batch_metric_scores.append(metric_score)\n",
    "        \n",
    "        if batch % 50 == 0 or batch == len(dataloader):\n",
    "            batch_name = \"Batch-\" + str(batch)\n",
    "            print(f\"{batch_name.ljust(9)}: {str(criterion).split('(')[0]}={(loss.item()):.4f} | {str(metric).split('(')[0]}={(metric_score):.4f}\")\n",
    "            with open(f\"../../logs/comick/{hyperparams.context_size}_contexts/{path_name}/training_history.txt\", \"a\") as f:\n",
    "                f.write(f\"{batch_name.ljust(9)}: {str(criterion).split('(')[0]}={(loss.item()):.4f} | {str(metric).split('(')[0]}={(metric_score):.4f}\\n\")\n",
    "\n",
    "        # Backward Propagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    return batch_losses, batch_metric_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3043a1-39cb-4b38-8024-54f909a565a9",
   "metadata": {},
   "source": [
    "# Looping Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e139244-b036-4d45-beca-1de5bd7b5e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH-1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c97e9968cfee44d597cff34a82ca1332",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=4.6678 | F1Score=0.2700\n",
      "Batch-100: NLLLoss=5.5524 | F1Score=0.2891\n",
      "Batch-150: NLLLoss=5.4879 | F1Score=0.3125\n",
      "Batch-200: NLLLoss=4.3875 | F1Score=0.3391\n",
      "Batch-250: NLLLoss=4.1270 | F1Score=0.3638\n",
      "Batch-300: NLLLoss=4.0027 | F1Score=0.3818\n",
      "Batch-350: NLLLoss=4.4085 | F1Score=0.3981\n",
      "Batch-400: NLLLoss=3.9453 | F1Score=0.4097\n",
      "Batch-450: NLLLoss=4.0325 | F1Score=0.4197\n",
      "Batch-500: NLLLoss=3.5535 | F1Score=0.4310\n",
      "Batch-518: NLLLoss=2.7161 | F1Score=0.4342\n",
      "\n",
      "Mean NLLLoss: 4.5361 | Mean F1Score: 0.3545\n",
      "==================================================\n",
      "\n",
      "EPOCH-2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d3cb800d7e5422388b0a6327bd5e292",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=2.9692 | F1Score=0.5752\n",
      "Batch-100: NLLLoss=2.4787 | F1Score=0.5798\n",
      "Batch-150: NLLLoss=3.8593 | F1Score=0.5826\n",
      "Batch-200: NLLLoss=2.3253 | F1Score=0.5913\n",
      "Batch-250: NLLLoss=2.9453 | F1Score=0.6013\n",
      "Batch-300: NLLLoss=2.9772 | F1Score=0.6103\n",
      "Batch-350: NLLLoss=3.4423 | F1Score=0.6158\n",
      "Batch-400: NLLLoss=1.6546 | F1Score=0.6233\n",
      "Batch-450: NLLLoss=2.7593 | F1Score=0.6295\n",
      "Batch-500: NLLLoss=3.3187 | F1Score=0.6340\n",
      "Batch-518: NLLLoss=2.5120 | F1Score=0.6364\n",
      "\n",
      "Yeah 🎉😄! Model improved.\n",
      "Mean NLLLoss: 2.7052 | Mean F1Score: 0.6019\n",
      "==================================================\n",
      "\n",
      "EPOCH-3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cecf98d0db924666b27090897762f937",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=2.2622 | F1Score=0.7238\n",
      "Batch-100: NLLLoss=2.5266 | F1Score=0.7222\n",
      "Batch-150: NLLLoss=2.4284 | F1Score=0.7229\n",
      "Batch-200: NLLLoss=0.7482 | F1Score=0.7269\n",
      "Batch-250: NLLLoss=2.8145 | F1Score=0.7299\n",
      "Batch-300: NLLLoss=2.7017 | F1Score=0.7321\n",
      "Batch-350: NLLLoss=1.6597 | F1Score=0.7346\n",
      "Batch-400: NLLLoss=2.4260 | F1Score=0.7378\n",
      "Batch-450: NLLLoss=2.6186 | F1Score=0.7410\n",
      "Batch-500: NLLLoss=1.0252 | F1Score=0.7458\n",
      "Batch-518: NLLLoss=1.8554 | F1Score=0.7474\n",
      "\n",
      "Yeah 🎉😄! Model improved.\n",
      "Mean NLLLoss: 1.7794 | Mean F1Score: 0.7307\n",
      "==================================================\n",
      "\n",
      "EPOCH-4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "212909b5015349e8abdf19b790892ef9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=1.2865 | F1Score=0.8062\n",
      "Batch-100: NLLLoss=1.3516 | F1Score=0.8056\n",
      "Batch-150: NLLLoss=1.3854 | F1Score=0.8042\n",
      "Batch-200: NLLLoss=1.8251 | F1Score=0.8078\n",
      "Batch-250: NLLLoss=1.6852 | F1Score=0.8125\n",
      "Batch-300: NLLLoss=0.8051 | F1Score=0.8139\n",
      "Batch-350: NLLLoss=0.6391 | F1Score=0.8144\n",
      "Batch-400: NLLLoss=1.0886 | F1Score=0.8160\n",
      "Batch-450: NLLLoss=2.0925 | F1Score=0.8170\n",
      "Batch-500: NLLLoss=1.0179 | F1Score=0.8190\n",
      "Batch-518: NLLLoss=1.0733 | F1Score=0.8187\n",
      "\n",
      "Yeah 🎉😄! Model improved.\n",
      "Mean NLLLoss: 1.1521 | Mean F1Score: 0.8105\n",
      "==================================================\n",
      "\n",
      "EPOCH-5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d1153689cc74ebd83c8d7a5f24969b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=1.3601 | F1Score=0.8775\n",
      "Batch-100: NLLLoss=0.6692 | F1Score=0.8754\n",
      "Batch-150: NLLLoss=0.8687 | F1Score=0.8738\n",
      "Batch-200: NLLLoss=1.9284 | F1Score=0.8746\n",
      "Batch-250: NLLLoss=0.5142 | F1Score=0.8742\n",
      "Batch-300: NLLLoss=1.0022 | F1Score=0.8751\n",
      "Batch-350: NLLLoss=0.6435 | F1Score=0.8732\n",
      "Batch-400: NLLLoss=0.6988 | F1Score=0.8749\n",
      "Batch-450: NLLLoss=0.5449 | F1Score=0.8743\n",
      "Batch-500: NLLLoss=0.7643 | F1Score=0.8736\n",
      "Batch-518: NLLLoss=0.7497 | F1Score=0.8733\n",
      "\n",
      "Yeah 🎉😄! Model improved.\n",
      "Mean NLLLoss: 0.6849 | Mean F1Score: 0.8757\n",
      "==================================================\n",
      "\n",
      "EPOCH-6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbda345669144f93906819075e288bec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=0.4915 | F1Score=0.9600\n",
      "Batch-100: NLLLoss=0.3824 | F1Score=0.9581\n",
      "Batch-150: NLLLoss=0.4301 | F1Score=0.9546\n",
      "Batch-200: NLLLoss=0.5256 | F1Score=0.9495\n",
      "Batch-250: NLLLoss=0.2498 | F1Score=0.9465\n",
      "Batch-300: NLLLoss=0.3641 | F1Score=0.9467\n",
      "Batch-350: NLLLoss=0.5729 | F1Score=0.9445\n",
      "Batch-400: NLLLoss=0.4196 | F1Score=0.9441\n",
      "Batch-450: NLLLoss=0.5113 | F1Score=0.9414\n",
      "Batch-500: NLLLoss=0.6565 | F1Score=0.9393\n",
      "Batch-518: NLLLoss=0.6211 | F1Score=0.9382\n",
      "\n",
      "Yeah 🎉😄! Model improved.\n",
      "Mean NLLLoss: 0.3389 | Mean F1Score: 0.9489\n",
      "==================================================\n",
      "\n",
      "EPOCH-7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e4194988a534fbcbc6a3f171763cda8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=0.2349 | F1Score=0.9887\n",
      "Batch-100: NLLLoss=0.0432 | F1Score=0.9881\n",
      "Batch-150: NLLLoss=0.0258 | F1Score=0.9890\n",
      "Batch-200: NLLLoss=0.0995 | F1Score=0.9892\n",
      "Batch-250: NLLLoss=0.0226 | F1Score=0.9893\n",
      "Batch-300: NLLLoss=0.0501 | F1Score=0.9890\n",
      "Batch-350: NLLLoss=0.0565 | F1Score=0.9883\n",
      "Batch-400: NLLLoss=0.1590 | F1Score=0.9877\n",
      "Batch-450: NLLLoss=0.2208 | F1Score=0.9872\n",
      "Batch-500: NLLLoss=0.2222 | F1Score=0.9865\n",
      "Batch-518: NLLLoss=0.4356 | F1Score=0.9859\n",
      "\n",
      "Yeah 🎉😄! Model improved.\n",
      "Mean NLLLoss: 0.1178 | Mean F1Score: 0.9885\n",
      "==================================================\n",
      "\n",
      "EPOCH-8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abe119d510954e879dc63e73c4a9f8e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=0.0383 | F1Score=0.9981\n",
      "Batch-100: NLLLoss=0.0558 | F1Score=0.9972\n",
      "Batch-150: NLLLoss=0.0453 | F1Score=0.9970\n",
      "Batch-200: NLLLoss=0.0435 | F1Score=0.9966\n",
      "Batch-250: NLLLoss=0.0218 | F1Score=0.9971\n",
      "Batch-300: NLLLoss=0.0182 | F1Score=0.9974\n",
      "Batch-350: NLLLoss=0.0190 | F1Score=0.9973\n",
      "Batch-400: NLLLoss=0.0104 | F1Score=0.9972\n",
      "Batch-450: NLLLoss=0.0254 | F1Score=0.9973\n",
      "Batch-500: NLLLoss=0.0437 | F1Score=0.9973\n",
      "Batch-518: NLLLoss=0.0245 | F1Score=0.9974\n",
      "\n",
      "Yeah 🎉😄! Model improved.\n",
      "Mean NLLLoss: 0.0402 | Mean F1Score: 0.9972\n",
      "==================================================\n",
      "\n",
      "EPOCH-9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c9dbbe31ce043788996c508fe18f328",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=0.0113 | F1Score=0.9994\n",
      "Batch-100: NLLLoss=0.0079 | F1Score=0.9994\n",
      "Batch-150: NLLLoss=0.0157 | F1Score=0.9992\n",
      "Batch-200: NLLLoss=0.0084 | F1Score=0.9991\n",
      "Batch-250: NLLLoss=0.0075 | F1Score=0.9991\n",
      "Batch-300: NLLLoss=0.0377 | F1Score=0.9992\n",
      "Batch-350: NLLLoss=0.0047 | F1Score=0.9991\n",
      "Batch-400: NLLLoss=0.0043 | F1Score=0.9991\n",
      "Batch-450: NLLLoss=0.0143 | F1Score=0.9992\n",
      "Batch-500: NLLLoss=0.0089 | F1Score=0.9992\n",
      "Batch-518: NLLLoss=0.0099 | F1Score=0.9992\n",
      "\n",
      "Yeah 🎉😄! Model improved.\n",
      "Mean NLLLoss: 0.0123 | Mean F1Score: 0.9992\n",
      "==================================================\n",
      "\n",
      "EPOCH-10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cbdbd5813d545edacecffcac3efaa82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=0.0103 | F1Score=0.9994\n",
      "Batch-100: NLLLoss=0.0070 | F1Score=0.9997\n",
      "Batch-150: NLLLoss=0.0034 | F1Score=0.9998\n",
      "Batch-200: NLLLoss=0.0048 | F1Score=0.9996\n",
      "Batch-250: NLLLoss=0.0039 | F1Score=0.9996\n",
      "Batch-300: NLLLoss=0.0047 | F1Score=0.9996\n",
      "Batch-350: NLLLoss=0.0305 | F1Score=0.9995\n",
      "Batch-400: NLLLoss=0.0077 | F1Score=0.9993\n",
      "Batch-450: NLLLoss=0.0092 | F1Score=0.9993\n",
      "Batch-500: NLLLoss=0.0093 | F1Score=0.9993\n",
      "Batch-518: NLLLoss=0.0034 | F1Score=0.9993\n",
      "\n",
      "Yeah 🎉😄! Model improved.\n",
      "Mean NLLLoss: 0.0083 | Mean F1Score: 0.9995\n",
      "==================================================\n",
      "\n",
      "EPOCH-11\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e59b41146b94a6e8559e2fe21c86f37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=0.0038 | F1Score=0.9994\n",
      "Batch-100: NLLLoss=0.0039 | F1Score=0.9997\n",
      "Batch-150: NLLLoss=0.0029 | F1Score=0.9996\n",
      "Batch-200: NLLLoss=0.0023 | F1Score=0.9995\n",
      "Batch-250: NLLLoss=0.0028 | F1Score=0.9996\n",
      "Batch-300: NLLLoss=0.0031 | F1Score=0.9996\n",
      "Batch-350: NLLLoss=0.0042 | F1Score=0.9996\n",
      "Batch-400: NLLLoss=0.0045 | F1Score=0.9995\n",
      "Batch-450: NLLLoss=0.0076 | F1Score=0.9996\n",
      "Batch-500: NLLLoss=0.0049 | F1Score=0.9995\n",
      "Batch-518: NLLLoss=0.0031 | F1Score=0.9995\n",
      "\n",
      "Yeah 🎉😄! Model improved.\n",
      "Mean NLLLoss: 0.0053 | Mean F1Score: 0.9996\n",
      "==================================================\n",
      "\n",
      "EPOCH-12\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef5fb59ec96a42a28c805e5a962eaacc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=0.1830 | F1Score=0.9981\n",
      "Batch-100: NLLLoss=0.0020 | F1Score=0.9991\n",
      "Batch-150: NLLLoss=0.0057 | F1Score=0.9991\n",
      "Batch-200: NLLLoss=0.0021 | F1Score=0.9991\n",
      "Batch-250: NLLLoss=0.0011 | F1Score=0.9992\n",
      "Batch-300: NLLLoss=0.0023 | F1Score=0.9993\n",
      "Batch-350: NLLLoss=0.0016 | F1Score=0.9994\n",
      "Batch-400: NLLLoss=0.0024 | F1Score=0.9995\n",
      "Batch-450: NLLLoss=0.0028 | F1Score=0.9995\n",
      "Batch-500: NLLLoss=0.0029 | F1Score=0.9996\n",
      "Batch-518: NLLLoss=0.0042 | F1Score=0.9996\n",
      "\n",
      "Yeah 🎉😄! Model improved.\n",
      "Mean NLLLoss: 0.0052 | Mean F1Score: 0.9990\n",
      "==================================================\n",
      "\n",
      "EPOCH-13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0202b477905f42de8a53db77fa9a4aa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=0.0012 | F1Score=1.0000\n",
      "Batch-100: NLLLoss=0.0021 | F1Score=0.9997\n",
      "Batch-150: NLLLoss=0.0010 | F1Score=0.9998\n",
      "Batch-200: NLLLoss=0.0023 | F1Score=0.9998\n",
      "Batch-250: NLLLoss=0.0030 | F1Score=0.9999\n",
      "Batch-300: NLLLoss=0.0030 | F1Score=0.9999\n",
      "Batch-350: NLLLoss=0.0038 | F1Score=0.9998\n",
      "Batch-400: NLLLoss=0.0010 | F1Score=0.9998\n",
      "Batch-450: NLLLoss=0.0028 | F1Score=0.9997\n",
      "Batch-500: NLLLoss=0.0014 | F1Score=0.9997\n",
      "Batch-518: NLLLoss=0.0018 | F1Score=0.9996\n",
      "\n",
      "Yeah 🎉😄! Model improved.\n",
      "Mean NLLLoss: 0.0034 | Mean F1Score: 0.9998\n",
      "==================================================\n",
      "\n",
      "EPOCH-14\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0225afadb6454a0d8ba94339027352a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=0.0011 | F1Score=1.0000\n",
      "Batch-100: NLLLoss=0.0015 | F1Score=1.0000\n",
      "Batch-150: NLLLoss=0.0020 | F1Score=0.9999\n",
      "Batch-200: NLLLoss=0.0038 | F1Score=0.9996\n",
      "Batch-250: NLLLoss=0.0041 | F1Score=0.9993\n",
      "Batch-300: NLLLoss=0.0029 | F1Score=0.9994\n",
      "Batch-350: NLLLoss=0.2525 | F1Score=0.9951\n",
      "Batch-400: NLLLoss=0.5604 | F1Score=0.9761\n",
      "Batch-450: NLLLoss=0.8718 | F1Score=0.9625\n",
      "Batch-500: NLLLoss=0.3811 | F1Score=0.9554\n",
      "Batch-518: NLLLoss=0.3357 | F1Score=0.9534\n",
      "\n",
      "Huft 😥! Model not improved.\n",
      "Mean NLLLoss: 0.1817 | Mean F1Score: 0.9897\n",
      "Patience = 1/20❗\n",
      "==================================================\n",
      "\n",
      "EPOCH-15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30ee684ece314e56a1757ac730c2758f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=0.1434 | F1Score=0.9613\n",
      "Batch-100: NLLLoss=0.0387 | F1Score=0.9583\n",
      "Batch-150: NLLLoss=0.1775 | F1Score=0.9599\n",
      "Batch-200: NLLLoss=0.0554 | F1Score=0.9632\n",
      "Batch-250: NLLLoss=0.0262 | F1Score=0.9642\n",
      "Batch-300: NLLLoss=0.1364 | F1Score=0.9627\n",
      "Batch-350: NLLLoss=0.0296 | F1Score=0.9646\n",
      "Batch-400: NLLLoss=0.1031 | F1Score=0.9657\n",
      "Batch-450: NLLLoss=0.0435 | F1Score=0.9675\n",
      "Batch-500: NLLLoss=0.0051 | F1Score=0.9687\n",
      "Batch-518: NLLLoss=0.3494 | F1Score=0.9688\n",
      "\n",
      "Yeah 🎉😄! Model improved.\n",
      "Mean NLLLoss: 0.1352 | Mean F1Score: 0.9632\n",
      "==================================================\n",
      "\n",
      "EPOCH-16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5c132f92b4c47979dbfaba6fec87ae9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=0.0040 | F1Score=0.9972\n",
      "Batch-100: NLLLoss=0.0074 | F1Score=0.9970\n",
      "Batch-150: NLLLoss=0.0079 | F1Score=0.9980\n",
      "Batch-200: NLLLoss=0.0050 | F1Score=0.9980\n",
      "Batch-250: NLLLoss=0.0100 | F1Score=0.9982\n",
      "Batch-300: NLLLoss=0.0043 | F1Score=0.9982\n",
      "Batch-350: NLLLoss=0.0132 | F1Score=0.9983\n",
      "Batch-400: NLLLoss=0.0152 | F1Score=0.9985\n",
      "Batch-450: NLLLoss=0.0066 | F1Score=0.9985\n",
      "Batch-500: NLLLoss=0.0067 | F1Score=0.9986\n",
      "Batch-518: NLLLoss=0.0023 | F1Score=0.9986\n",
      "\n",
      "Yeah 🎉😄! Model improved.\n",
      "Mean NLLLoss: 0.0101 | Mean F1Score: 0.9979\n",
      "==================================================\n",
      "\n",
      "EPOCH-17\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "849fd71a2c4a4e45882fc214bed509b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=0.0069 | F1Score=0.9994\n",
      "Batch-100: NLLLoss=0.0006 | F1Score=0.9997\n",
      "Batch-150: NLLLoss=0.0027 | F1Score=0.9998\n",
      "Batch-200: NLLLoss=0.0069 | F1Score=0.9998\n",
      "Batch-250: NLLLoss=0.0010 | F1Score=0.9997\n",
      "Batch-300: NLLLoss=0.0038 | F1Score=0.9997\n",
      "Batch-350: NLLLoss=0.0018 | F1Score=0.9998\n",
      "Batch-400: NLLLoss=0.0050 | F1Score=0.9998\n",
      "Batch-450: NLLLoss=0.0033 | F1Score=0.9997\n",
      "Batch-500: NLLLoss=0.0038 | F1Score=0.9997\n",
      "Batch-518: NLLLoss=0.0025 | F1Score=0.9998\n",
      "\n",
      "Yeah 🎉😄! Model improved.\n",
      "Mean NLLLoss: 0.0030 | Mean F1Score: 0.9997\n",
      "==================================================\n",
      "\n",
      "EPOCH-18\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "845ee9fb85ec44f3baee8057077d7ddb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=0.0009 | F1Score=1.0000\n",
      "Batch-100: NLLLoss=0.0008 | F1Score=1.0000\n",
      "Batch-150: NLLLoss=0.0014 | F1Score=1.0000\n",
      "Batch-200: NLLLoss=0.0013 | F1Score=0.9998\n",
      "Batch-250: NLLLoss=0.0022 | F1Score=0.9999\n",
      "Batch-300: NLLLoss=0.0015 | F1Score=0.9999\n",
      "Batch-350: NLLLoss=0.0322 | F1Score=0.9997\n",
      "Batch-400: NLLLoss=0.0004 | F1Score=0.9997\n",
      "Batch-450: NLLLoss=0.0006 | F1Score=0.9997\n",
      "Batch-500: NLLLoss=0.0013 | F1Score=0.9997\n",
      "Batch-518: NLLLoss=0.0008 | F1Score=0.9997\n",
      "\n",
      "Yeah 🎉😄! Model improved.\n",
      "Mean NLLLoss: 0.0021 | Mean F1Score: 0.9999\n",
      "==================================================\n",
      "\n",
      "EPOCH-19\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ff4d47c2bfb4e33b58e678db0203049",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=0.0007 | F1Score=1.0000\n",
      "Batch-100: NLLLoss=0.0019 | F1Score=1.0000\n",
      "Batch-150: NLLLoss=0.0004 | F1Score=1.0000\n",
      "Batch-200: NLLLoss=0.0005 | F1Score=1.0000\n",
      "Batch-250: NLLLoss=0.0013 | F1Score=0.9999\n",
      "Batch-300: NLLLoss=0.0014 | F1Score=0.9999\n",
      "Batch-350: NLLLoss=0.0010 | F1Score=0.9999\n",
      "Batch-400: NLLLoss=0.0003 | F1Score=0.9999\n",
      "Batch-450: NLLLoss=0.0006 | F1Score=0.9999\n",
      "Batch-500: NLLLoss=0.0008 | F1Score=0.9999\n",
      "Batch-518: NLLLoss=0.0012 | F1Score=0.9999\n",
      "\n",
      "Yeah 🎉😄! Model improved.\n",
      "Mean NLLLoss: 0.0012 | Mean F1Score: 0.9999\n",
      "==================================================\n",
      "\n",
      "EPOCH-20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2630cd51886f4d2492d33c57ebab85e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=0.0008 | F1Score=1.0000\n",
      "Batch-100: NLLLoss=0.0009 | F1Score=0.9997\n",
      "Batch-150: NLLLoss=0.0004 | F1Score=0.9996\n",
      "Batch-200: NLLLoss=0.0011 | F1Score=0.9997\n",
      "Batch-250: NLLLoss=0.0007 | F1Score=0.9997\n",
      "Batch-300: NLLLoss=0.0005 | F1Score=0.9998\n",
      "Batch-350: NLLLoss=0.0011 | F1Score=0.9998\n",
      "Batch-400: NLLLoss=0.0007 | F1Score=0.9998\n",
      "Batch-450: NLLLoss=0.0010 | F1Score=0.9998\n",
      "Batch-500: NLLLoss=0.0007 | F1Score=0.9998\n",
      "Batch-518: NLLLoss=0.0003 | F1Score=0.9998\n",
      "\n",
      "Yeah 🎉😄! Model improved.\n",
      "Mean NLLLoss: 0.0009 | Mean F1Score: 0.9998\n",
      "==================================================\n",
      "\n",
      "TRAINING SUMMARY\n",
      "Best NLLLoss      : 0.0009\n",
      "Best F1Score      : 0.9998\n",
      "Training duration : 36.747 minutes.\n",
      "Training date     : 2022-10-11 19:39:04.399657+08:00\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def looping_step(dataloader, model, optimizer, criterion, metric, n_epoch=hyperparams.n_epoch, patience=hyperparams.patience, monitor=\"loss\"):    \n",
    "    start_time = time()\n",
    "    \n",
    "    epoch_losses = []\n",
    "    epoch_metric_scores = []\n",
    "    patience_counter = 0\n",
    "    \n",
    "    now = datetime.now(pytz.timezone(\"Asia/Ujung_Pandang\"))\n",
    "    path_name = now.strftime(\"%m-%d-%Y_%H-%M-%S\")\n",
    "    os.makedirs(f\"../../logs/comick/{hyperparams.context_size}_contexts/{path_name}\")\n",
    "    \n",
    "    # Hyperparameters\n",
    "    with open(f\"../../logs/comick/{hyperparams.context_size}_contexts/{path_name}/training_history.txt\", \"a\") as f:\n",
    "        f.write(f\"HYPERPARAMETERS\\n\")\n",
    "        f.write(f\"{'-' * 50}\\n\")\n",
    "        for name, value in vars(hyperparams).items():\n",
    "            f.write(f\"{name}: {value}\\n\")\n",
    "        \n",
    "        f.write(\"\\n\\nTRAINING PROGRESS\\n\")\n",
    "        f.write(f\"{'-' * 50}\\n\")\n",
    "    \n",
    "    # Training Progress\n",
    "    for epoch in range(1, n_epoch + 1):\n",
    "        print(f\"EPOCH-{epoch}\")\n",
    "        with open(f\"../../logs/comick/{hyperparams.context_size}_contexts/{path_name}/training_history.txt\", \"a\") as f:\n",
    "            f.write(f\"EPOCH-{epoch}\\n\")\n",
    "        \n",
    "        batch_losses, batch_metric_scores = training_step(dataloader, model, optimizer, criterion, metric, path_name=path_name)\n",
    "        epoch_loss = torch.mean(torch.FloatTensor(batch_losses))\n",
    "\n",
    "        epoch_loss = torch.mean(torch.FloatTensor(batch_losses))\n",
    "        epoch_losses.append(epoch_loss.item())\n",
    "\n",
    "        epoch_metric_score = torch.mean(torch.FloatTensor(batch_metric_scores))\n",
    "        epoch_metric_scores.append(epoch_metric_score.item())\n",
    "        \n",
    "        with open(f\"../../logs/comick/{hyperparams.context_size}_contexts/{path_name}/training_history.txt\", \"a\") as f:\n",
    "            if monitor == \"loss\":\n",
    "                if epoch == 1:\n",
    "                    best_state_dict = model.state_dict()\n",
    "                    best_loss = (epoch_loss)\n",
    "                    best_metric = (epoch_metric_score)\n",
    "                    \n",
    "                    print(f\"\\nMean {str(criterion).split('(')[0]}: {(epoch_loss):.4f} | Mean {str(metric).split('(')[0]}: {(epoch_metric_score):.4f}\")\n",
    "                    \n",
    "                    f.write(f\"\\nMean {str(criterion).split('(')[0]}: {(epoch_loss):.4f} | Mean {str(metric).split('(')[0]}: {(epoch_metric_score):.4f}\\n\")\n",
    "                elif epoch_losses[-1] < epoch_losses[-2]:\n",
    "                    best_state_dict = model.state_dict()\n",
    "                    best_loss = (epoch_loss)\n",
    "                    best_metric = (epoch_metric_score)\n",
    "                    \n",
    "                    print(\"\\nYeah 🎉😄! Model improved.\")\n",
    "                    print(f\"Mean {str(criterion).split('(')[0]}: {(epoch_loss):.4f} | Mean {str(metric).split('(')[0]}: {(epoch_metric_score):.4f}\")\n",
    "                    \n",
    "                    f.write(\"\\nYeah 🎉😄! Model improved.\\n\")\n",
    "                    f.write(f\"Mean {str(criterion).split('(')[0]}: {(epoch_loss):.4f} | Mean {str(metric).split('(')[0]}: {(epoch_metric_score):.4f}\\n\")\n",
    "                else:\n",
    "                    patience_counter += 1\n",
    "                    \n",
    "                    print(\"\\nHuft 😥! Model not improved.\")\n",
    "                    print(f\"Mean {str(criterion).split('(')[0]}: {(epoch_loss):.4f} | Mean {str(metric).split('(')[0]}: {(epoch_metric_score):.4f}\")\n",
    "                    print(f\"Patience = {patience_counter}/{patience}❗\")\n",
    "                    \n",
    "                    f.write(\"\\nHuft 😥! Model not improved.\\n\")\n",
    "                    f.write(f\"Mean {str(criterion).split('(')[0]}: {(epoch_loss):.4f} | Mean {str(metric).split('(')[0]}: {(epoch_metric_score):.4f}\\n\")                    \n",
    "                    f.write(f\"Patience = {patience_counter}/{patience}❗\\n\")\n",
    "            else:\n",
    "                if epoch == 1:\n",
    "                    best_state_dict = model.state_dict()\n",
    "                    best_loss = (epoch_loss)\n",
    "                    best_metric = (epoch_metric_score)\n",
    "                    \n",
    "                    print(f\"\\nMean {str(criterion).split('(')[0]}: {(epoch_loss):.4f} | Mean {str(metric).split('(')[0]}: {(epoch_metric_score):.4f}\")\n",
    "                    \n",
    "                    f.write(f\"\\nMean {str(criterion).split('(')[0]}: {(epoch_loss):.4f} | Mean {str(metric).split('(')[0]}: {(epoch_metric_score):.4f}\\n\")\n",
    "                elif epoch_metric_scores[-1] > epoch_metric_scores[-2]:\n",
    "                    best_state_dict = model.state_dict()\n",
    "                    best_loss = (epoch_loss)\n",
    "                    best_metric = (epoch_metric_score)\n",
    "                    \n",
    "                    print(\"\\nYeah 🎉😄! Model improved.\")\n",
    "                    print(f\"Mean {str(criterion).split('(')[0]}: {(epoch_loss):.4f} | Mean Mean {str(metric).split('(')[0]}: {(epoch_metric_score):.4f}\")\n",
    "                    \n",
    "                    f.write(\"\\nYeah 🎉😄! Model improved.\\n\")\n",
    "                    f.write(f\"Mean {str(criterion).split('(')[0]}: {(epoch_loss):.4f} | Mean {str(metric).split('(')[0]}: {(epoch_metric_score):.4f}\\n\")\n",
    "                else:\n",
    "                    patience_counter += 1\n",
    "                    \n",
    "                    print(\"\\nHuft 😥! Model not improved.\")\n",
    "                    print(f\"Mean {str(criterion).split('(')[0]}: {(epoch_loss):.4f} | Mean {str(metric).split('(')[0]}: {(epoch_metric_score):.4f}\\n\")\n",
    "                    print(f\"Patience = {patience_counter}/{patience}❗\\n\")\n",
    "                    \n",
    "                    f.write(\"\\nHuft 😥! Model not improved.\\n\")\n",
    "                    f.write(f\"Mean {str(criterion).split('(')[0]}: {(epoch_loss):.4f} | Mean {str(metric).split('(')[0]}: {(epoch_metric_score):.4f}\\n\")\n",
    "                    f.write(f\"Patience = {patience_counter}/{patience}❗\\n\")\n",
    "                    \n",
    "            print(\"=\" * 50, end=\"\\n\\n\")\n",
    "            f.write(f\"{'=' * 50}\\n\\n\")\n",
    "            \n",
    "            if patience_counter == patience:\n",
    "                print(f\"Early stopping, patience = {patience_counter}/{patience}❗\\n\")\n",
    "                f.write(f\"Early stopping, patience = {patience_counter}/{patience}❗\\n\")\n",
    "                break\n",
    "        \n",
    "        metric.reset()\n",
    "    \n",
    "    finish_time = time()\n",
    "    \n",
    "    # Training plot \n",
    "    fig, (ax_loss, ax_metric_score) = plt.subplots(nrows=1, ncols=2, figsize=(15, 5))\n",
    "\n",
    "    fig.suptitle(f\"Training with context size = {hyperparams.context_size}\")\n",
    "\n",
    "    ax_loss.set_title(\"Loss\")\n",
    "    ax_loss.set_xlabel(\"Epoch\")\n",
    "    ax_loss.set_ylabel(\"Score\")\n",
    "    ax_loss.plot(epoch_losses, \"green\")\n",
    "    ax_loss.grid()\n",
    "\n",
    "    ax_metric_score.set_title(\"F1 Score\")\n",
    "    ax_metric_score.set_xlabel(\"Epoch\")\n",
    "    ax_metric_score.set_ylabel(\"Score\")\n",
    "    ax_metric_score.plot(epoch_metric_scores, \"orange\")\n",
    "    ax_metric_score.grid()\n",
    "\n",
    "    plt.savefig(f\"../../logs/comick/{hyperparams.context_size}_contexts/{path_name}/training_plot.jpg\", dpi=200)                        \n",
    "    \n",
    "    print(\"TRAINING SUMMARY\")\n",
    "    criterion_name = \"Best \" + str(criterion).split('(')[0]\n",
    "    metric_name = \"Best \" + str(metric).split('(')[0]\n",
    "    \n",
    "    print(f\"{criterion_name.ljust(18)}: {best_loss:.4f}\")\n",
    "    print(f\"{metric_name.ljust(18)}: {best_metric:.4f}\")\n",
    "    print(f\"{'Training duration'.ljust(18)}: {((finish_time - start_time) / 60):.3f} minutes.\")\n",
    "    print(f\"{'Training date'.ljust(18)}: {now}\")\n",
    "    \n",
    "    with open(f\"../../logs/comick/{hyperparams.context_size}_contexts/{path_name}/training_history.txt\", \"a\") as f:\n",
    "        f.write(\"\\nTRAINING SUMMARY\\n\")\n",
    "        f.write(f\"{'-' * 50}\\n\")\n",
    "        f.write(f\"{criterion_name.ljust(18)}: {best_loss:.4f}\\n\")\n",
    "        f.write(f\"{metric_name.ljust(18)}: {best_metric:.4f}\\n\")\n",
    "        f.write(f\"{'Training duration'.ljust(18)}: {((finish_time - start_time) / 60):.3f} minutes.\\n\")\n",
    "        f.write(f\"{'Training date'.ljust(18)}: {now}\\n\")\n",
    "    \n",
    "    # Save epoch losses, epoch metric scores, model, state dict, and oov embedding dict\n",
    "    filename_model_params = f\"../../logs/comick/{hyperparams.context_size}_contexts/{path_name}/model_params.pth\"\n",
    "    filename_oov_embedding_dict = open(f\"../../logs/comick/{hyperparams.context_size}_contexts/{path_name}/oov_embedding_dict.pkl\", \"ab\")\n",
    "    \n",
    "    pd.DataFrame(\n",
    "        data={\n",
    "            \"epoch\": list(range(1, len(epoch_losses) + 1)),\n",
    "            \"loss\": epoch_losses\n",
    "        }\n",
    "    ).to_csv(f\"../../logs/comick/{hyperparams.context_size}_contexts/{path_name}/epoch_losses.csv\", index=False)\n",
    "    \n",
    "    pd.DataFrame(\n",
    "        data={\n",
    "            \"epoch\": list(range(1, len(epoch_metric_scores) + 1)),\n",
    "            \"f1_score\": epoch_metric_scores\n",
    "        }\n",
    "    ).to_csv(f\"../../logs/comick/{hyperparams.context_size}_contexts/{path_name}/epoch_metric_scores.csv\", index=False)\n",
    "    \n",
    "    torch.save(best_state_dict, filename_model_params)\n",
    "    pickle.dump({token : embedding for token, embedding in zip(list(labels_to_idx.keys()), model.embedding)}, filename_oov_embedding_dict)\n",
    "    \n",
    "    return epoch_losses, epoch_metric_scores\n",
    "\n",
    "epoch_losses, epoch_metric_scores = looping_step(dataloader, model, optimizer, criterion, metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfef50c-e71c-4288-a9f3-6fd8831033b0",
   "metadata": {},
   "source": [
    "# END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92debcb3-d6ea-4299-a3e9-37be5b63d2b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.88485795, -3.2273695 ,  0.28837246, ..., -1.500096  ,\n",
       "        -0.4721673 ,  5.962238  ],\n",
       "       [-2.2189875 ,  3.4459896 , -2.0817409 , ...,  2.3434176 ,\n",
       "        -4.7441225 ,  3.5739758 ],\n",
       "       [-2.9355183 , -0.41798598, -1.3048999 , ...,  9.925539  ,\n",
       "        -3.568224  , -6.23039   ],\n",
       "       ...,\n",
       "       [ 6.45844   , -1.5894524 ,  2.990764  , ...,  1.544313  ,\n",
       "        -1.6937437 , -0.01078879],\n",
       "       [ 0.19107032, -0.8977425 ,  5.1170073 , ..., -6.5612803 ,\n",
       "         4.7654657 ,  3.7947006 ],\n",
       "       [-1.7708272 , -0.09179287, -2.7237394 , ...,  3.9349575 ,\n",
       "        -4.716484  , -0.2576896 ]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27ce78c3-ac2c-4a84-a8e8-4d8e85d26563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('bilstm_left_context_feature.weight_ih_l0',\n",
       "              tensor([[ 0.0028, -0.0497,  0.5100,  ..., -0.3477,  0.3091,  0.1202],\n",
       "                      [ 0.0294, -0.0808,  0.0107,  ..., -0.0161, -0.0950, -0.0701],\n",
       "                      [ 0.1427, -0.1713,  0.1106,  ..., -0.1606, -0.0752, -0.0594],\n",
       "                      ...,\n",
       "                      [ 0.2979, -0.0584,  0.0009,  ..., -0.1208,  0.0621, -0.1685],\n",
       "                      [ 0.0495, -0.2009,  0.2793,  ..., -0.2290,  0.4574, -0.2754],\n",
       "                      [ 0.2883, -0.2180,  0.0797,  ..., -0.0828,  0.3293, -0.5595]])),\n",
       "             ('bilstm_left_context_feature.weight_hh_l0',\n",
       "              tensor([[-0.0476, -0.2417,  0.2973,  ..., -0.3268, -0.0044, -0.2318],\n",
       "                      [ 0.1909, -0.1913, -0.0052,  ...,  0.1024,  0.0999,  0.0192],\n",
       "                      [-0.0827,  0.0865,  0.0017,  ..., -0.1065, -0.1961,  0.0388],\n",
       "                      ...,\n",
       "                      [-0.1662,  0.0515,  0.0176,  ..., -0.2628, -0.0523,  0.2461],\n",
       "                      [ 0.0791,  0.0792,  0.2179,  ...,  0.0443, -0.0633, -0.2225],\n",
       "                      [-0.0970, -0.1517, -0.1976,  ..., -0.1655, -0.0233, -0.1676]])),\n",
       "             ('bilstm_left_context_feature.bias_ih_l0',\n",
       "              tensor([-0.1583, -0.0774, -0.2106, -0.1155, -0.1747, -0.1348, -0.1880, -0.1475,\n",
       "                      -0.2195,  0.0525, -0.1002, -0.1528, -0.2297, -0.1980, -0.0629, -0.0133,\n",
       "                      -0.1220, -0.1600, -0.1800, -0.1755, -0.1495, -0.1066, -0.1018, -0.0567,\n",
       "                      -0.0806, -0.0798, -0.1760, -0.1367, -0.0756, -0.1153, -0.2249, -0.0757,\n",
       "                      -0.1453, -0.2390, -0.1294, -0.1277, -0.1238, -0.1001, -0.0052, -0.1019,\n",
       "                      -0.1418, -0.2207, -0.2356,  0.0128, -0.2775, -0.2274, -0.1258, -0.3508,\n",
       "                      -0.1192, -0.1374, -0.1353, -0.2055, -0.2261, -0.1909, -0.2717, -0.2381,\n",
       "                      -0.0200, -0.1863, -0.1751, -0.2086, -0.2568,  0.0137,  0.0184, -0.0493,\n",
       "                      -0.0775,  0.0116, -0.0498, -0.1235,  0.0200, -0.2135, -0.2565, -0.1016,\n",
       "                      -0.1557, -0.0725, -0.1179, -0.2253, -0.0753, -0.0420, -0.0944, -0.1155,\n",
       "                      -0.1842, -0.1786, -0.2669, -0.0517, -0.0568, -0.0915, -0.1064, -0.2820,\n",
       "                      -0.0675, -0.0233, -0.3219, -0.1432, -0.0518, -0.0422, -0.1515, -0.0918,\n",
       "                      -0.0403, -0.0663, -0.1937, -0.0595, -0.1630, -0.2532, -0.0511, -0.0005,\n",
       "                      -0.1673, -0.1420, -0.2252, -0.1770, -0.0573, -0.0662, -0.2257, -0.1369,\n",
       "                      -0.0480, -0.1516, -0.1490, -0.1586, -0.1137, -0.2185, -0.0923, -0.1572,\n",
       "                      -0.1930, -0.2084, -0.1856, -0.1313, -0.0668, -0.1971, -0.0687, -0.2131,\n",
       "                      -0.1972, -0.0579, -0.1473, -0.1168, -0.0558,  0.0272, -0.0297, -0.0941,\n",
       "                      -0.2027, -0.2136,  0.0723, -0.1136, -0.1292, -0.0888, -0.1506, -0.1397,\n",
       "                      -0.1633, -0.0362, -0.0993, -0.1042, -0.0909, -0.1328, -0.0711, -0.0167,\n",
       "                      -0.1759, -0.0692, -0.1905, -0.1392, -0.2222, -0.1058, -0.1761, -0.1112,\n",
       "                      -0.1300, -0.0951, -0.0703, -0.1088, -0.1391, -0.2346, -0.1918, -0.2350,\n",
       "                      -0.0772, -0.2612, -0.1697, -0.0971, -0.1530, -0.2294, -0.1923, -0.2493,\n",
       "                      -0.0029, -0.0749, -0.1304, -0.1580, -0.1213, -0.1692, -0.1491, -0.1161,\n",
       "                      -0.0826, -0.0619, -0.2222, -0.1818, -0.1923, -0.1175, -0.1418, -0.0697,\n",
       "                      -0.1854, -0.0988, -0.1243, -0.0508, -0.0770, -0.0663, -0.1034,  0.0241,\n",
       "                      -0.0730, -0.0531, -0.1451, -0.2240, -0.0781, -0.0586, -0.1638, -0.0409,\n",
       "                      -0.1794, -0.0327, -0.1647, -0.0622, -0.1545, -0.1427, -0.0553, -0.1878,\n",
       "                      -0.1082, -0.0845,  0.0600, -0.1423, -0.1762, -0.1319, -0.0967, -0.0808,\n",
       "                      -0.1216, -0.0357, -0.0606, -0.0773, -0.1747, -0.1449,  0.0379, -0.1257,\n",
       "                      -0.0419, -0.1839, -0.1061,  0.0705, -0.1010, -0.0213, -0.2176, -0.0911,\n",
       "                      -0.1029, -0.1057, -0.2237, -0.0270, -0.0617, -0.1656, -0.1983, -0.2525,\n",
       "                      -0.0493, -0.2314, -0.2509, -0.0985, -0.1357, -0.0379, -0.2044, -0.2376,\n",
       "                       0.0609,  0.1130, -0.0727,  0.0388,  0.0147,  0.0647,  0.1209,  0.0570,\n",
       "                      -0.0172, -0.0246, -0.0467,  0.0029,  0.0138,  0.0770,  0.0210, -0.0278,\n",
       "                      -0.0360, -0.0302, -0.0334,  0.0269,  0.0480,  0.2623, -0.1713,  0.0336,\n",
       "                      -0.0180,  0.0377, -0.0210,  0.0596,  0.0295, -0.0378, -0.0368,  0.1501,\n",
       "                      -0.0030,  0.0440, -0.0090, -0.0590, -0.0308,  0.0686,  0.0438, -0.0074,\n",
       "                       0.0399,  0.1069, -0.0150,  0.0384, -0.0378,  0.0389,  0.0074, -0.0188,\n",
       "                       0.0401, -0.0223, -0.0118, -0.0045,  0.0359, -0.0751, -0.0150,  0.0230,\n",
       "                       0.0186,  0.0589,  0.0524,  0.0090,  0.0523, -0.0429, -0.0361,  0.0419,\n",
       "                      -0.0845,  0.0712,  0.0714,  0.0465,  0.0194,  0.0542, -0.0434, -0.0733,\n",
       "                       0.1133,  0.0488, -0.0626,  0.0193, -0.0244, -0.0917, -0.0319,  0.0215,\n",
       "                      -0.0241, -0.0611,  0.0240,  0.0135, -0.0748, -0.0246, -0.0499, -0.0332,\n",
       "                       0.1041, -0.0733,  0.0237, -0.1211, -0.1127, -0.0208, -0.0111, -0.0484,\n",
       "                      -0.0056,  0.1320,  0.0439, -0.0345,  0.0481, -0.0280, -0.0607, -0.0096,\n",
       "                      -0.0227,  0.0728, -0.0568,  0.0462,  0.0346,  0.0045,  0.0087, -0.0921,\n",
       "                       0.1331,  0.0127, -0.0681, -0.0318,  0.0100, -0.0618,  0.0056, -0.0386,\n",
       "                      -0.1135, -0.0760, -0.0886,  0.0663, -0.0828,  0.0325, -0.0989,  0.0017,\n",
       "                      -0.1498, -0.1310, -0.2104, -0.1242, -0.1303, -0.1557, -0.1083, -0.1099,\n",
       "                      -0.2035, -0.1564, -0.0501, -0.0262, -0.1408, -0.2405, -0.2536, -0.0810,\n",
       "                      -0.1797, -0.0868, -0.1998, -0.2783, -0.1974, -0.1270, -0.1187, -0.1519,\n",
       "                      -0.2423,  0.0392, -0.1761, -0.2113, -0.2292, -0.1595, -0.0586, -0.2139,\n",
       "                      -0.1067, -0.1462, -0.1258, -0.1282, -0.1285, -0.0896, -0.0495, -0.2735,\n",
       "                      -0.1143, -0.2154, -0.1196, -0.1017, -0.1033, -0.1025, -0.1816, -0.3326,\n",
       "                      -0.1414, -0.0575, -0.1885, -0.1320, -0.2586, -0.1833, -0.2290, -0.1756,\n",
       "                      -0.0878, -0.2428, -0.1323, -0.1308, -0.2279, -0.0902, -0.0457, -0.0285,\n",
       "                      -0.0645, -0.0389, -0.0811, -0.1345, -0.1609, -0.0723, -0.1462, -0.0870,\n",
       "                      -0.0788, -0.1246, -0.1055, -0.1750, -0.1283, -0.0767, -0.1567, -0.2644,\n",
       "                      -0.2148, -0.1405, -0.0849, -0.0146, -0.1125, -0.0475, -0.0874, -0.1720,\n",
       "                      -0.3083, -0.1070, -0.1131, -0.1890, -0.1696, -0.1198, -0.1300, -0.2332,\n",
       "                      -0.0825, -0.1737, -0.2644, -0.1933, -0.1461, -0.2679, -0.1370, -0.0898,\n",
       "                      -0.0483, -0.0633, -0.1323, -0.0642, -0.1298, -0.0878, -0.0212, -0.2054,\n",
       "                      -0.2510, -0.0539,  0.0963, -0.2884, -0.0823, -0.0337, -0.1702, -0.1723,\n",
       "                      -0.0950, -0.1513, -0.1130, -0.3228, -0.0500, -0.2577, -0.1656, -0.1813])),\n",
       "             ('bilstm_left_context_feature.bias_hh_l0',\n",
       "              tensor([-1.5488e-01, -1.4918e-01, -1.7913e-01, -1.5178e-01, -1.3879e-01,\n",
       "                       5.0097e-02, -1.4566e-01, -1.1874e-01, -2.3597e-01, -9.7187e-02,\n",
       "                      -1.2326e-01, -4.5918e-02, -8.9046e-02, -9.7799e-02, -1.4168e-01,\n",
       "                      -2.0322e-01, -2.0830e-01, -2.3508e-01, -6.5780e-02, -2.2424e-01,\n",
       "                      -2.3007e-01, -1.8719e-01, -1.9251e-01, -1.5331e-01, -1.9641e-01,\n",
       "                      -5.8596e-02, -1.9263e-01, -2.5223e-01, -2.2808e-01, -1.5333e-01,\n",
       "                      -1.9168e-01, -1.2973e-01, -2.1874e-01, -2.6359e-01, -1.0538e-01,\n",
       "                      -1.1245e-01, -9.4523e-02, -1.2176e-01, -2.2039e-01, -8.9864e-02,\n",
       "                      -1.6706e-01, -2.4873e-01, -1.9121e-01, -9.2224e-02, -6.0502e-02,\n",
       "                      -2.0119e-01, -1.7753e-01, -9.3195e-02,  1.1713e-01, -1.7569e-01,\n",
       "                      -1.5126e-01, -1.4486e-01, -2.8398e-01, -2.8565e-01, -2.7886e-01,\n",
       "                      -1.8001e-01, -5.5032e-02, -1.5983e-01, -1.8676e-01, -1.5364e-01,\n",
       "                      -1.7635e-01, -8.1476e-02, -1.3533e-01, -1.2183e-01, -1.7747e-01,\n",
       "                       9.3432e-03, -1.0812e-01, -9.1544e-02, -4.9427e-02, -1.5016e-01,\n",
       "                      -1.2386e-01, -9.1003e-02, -1.7638e-01,  8.5430e-05, -1.9958e-01,\n",
       "                      -2.9003e-01,  4.5959e-02, -2.7743e-02, -1.7114e-01, -2.0228e-01,\n",
       "                      -2.7588e-01, -1.7282e-01, -2.7930e-01, -1.4503e-01, -9.3737e-02,\n",
       "                      -4.5062e-02, -1.6096e-01, -1.7434e-01, -1.7877e-01, -1.0817e-01,\n",
       "                      -7.2972e-02, -7.4248e-02, -1.5043e-01, -1.9648e-01, -4.6731e-02,\n",
       "                      -3.6156e-02, -6.0540e-02, -8.7485e-02, -2.6556e-01, -1.5933e-01,\n",
       "                      -1.1062e-01, -2.8900e-01, -1.2416e-01, -1.6307e-01, -8.8054e-02,\n",
       "                      -1.3687e-01, -1.4243e-01, -1.5035e-01, -2.1754e-01, -1.1955e-01,\n",
       "                      -2.1770e-01, -6.7346e-02, -8.3855e-02, -2.1443e-01, -7.9257e-02,\n",
       "                      -1.2328e-01, -5.6042e-02, -8.2286e-02, -1.6268e-01, -1.4385e-01,\n",
       "                      -8.0565e-02, -1.4809e-01, -1.6457e-01, -1.3835e-01, -1.0724e-01,\n",
       "                      -8.8528e-02, -2.3184e-01, -1.2969e-01, -1.4507e-01, -1.2252e-01,\n",
       "                      -2.2317e-01, -1.1191e-01, -1.8762e-01, -3.8290e-02, -7.9294e-02,\n",
       "                      -1.4542e-01, -1.6821e-01, -9.9386e-02, -1.2197e-01, -1.7114e-01,\n",
       "                      -1.2639e-01, -1.4365e-01, -1.8830e-02, -7.6285e-02, -4.9883e-03,\n",
       "                      -1.6264e-01, -1.5268e-01, -2.1022e-02, -1.7703e-01, -9.5881e-02,\n",
       "                      -1.2086e-01, -1.1916e-01, -1.3188e-01,  1.2205e-02, -2.1306e-01,\n",
       "                      -1.8368e-01, -2.1342e-01, -1.1854e-01, -2.1998e-01, -4.3787e-02,\n",
       "                      -1.7818e-01, -1.2154e-01, -1.9562e-01, -1.5751e-01, -1.0917e-01,\n",
       "                      -1.2828e-01, -2.0228e-02, -1.2515e-01,  1.4916e-02, -8.2465e-02,\n",
       "                      -3.6515e-02, -1.3030e-01, -2.2113e-01, -1.7082e-01, -4.8167e-02,\n",
       "                      -2.9854e-02, -1.0907e-01, -1.5133e-01, -9.7080e-02, -1.8265e-01,\n",
       "                      -2.0282e-01, -1.9974e-01,  4.5418e-03, -1.1840e-01, -1.5394e-01,\n",
       "                      -1.0148e-01, -1.9325e-01, -1.3961e-01, -1.6195e-01, -1.6967e-01,\n",
       "                      -1.5895e-01, -3.7421e-04, -1.4985e-01, -1.6881e-01, -1.6188e-01,\n",
       "                      -7.3768e-02, -1.3108e-01, -2.4771e-01, -8.2323e-02, -1.3254e-02,\n",
       "                      -1.4451e-01, -1.4733e-01, -1.2363e-01, -6.7189e-02, -1.1480e-01,\n",
       "                      -1.0025e-02, -2.0950e-01,  8.1514e-03, -2.1521e-01, -6.7151e-02,\n",
       "                      -1.5008e-01, -1.6013e-01, -1.2772e-01, -1.2179e-01, -2.6665e-02,\n",
       "                      -9.3707e-02, -2.0043e-01, -7.4665e-02, -7.7662e-02, -1.7049e-01,\n",
       "                      -1.0302e-01, -1.2295e-01, -8.6538e-02, -1.9575e-01, -1.2491e-01,\n",
       "                      -8.1760e-02,  3.0404e-03, -5.3431e-02, -9.2865e-02, -2.2405e-01,\n",
       "                      -1.5534e-02, -1.3148e-01,  8.6586e-02, -1.0885e-01, -2.3231e-01,\n",
       "                      -9.5681e-02, -8.4342e-02, -1.4389e-01, -1.3648e-01, -7.1411e-02,\n",
       "                      -2.0426e-01, -2.5487e-02,  6.7672e-03, -1.3314e-01, -5.7937e-02,\n",
       "                      -1.7170e-01, -9.0836e-02, -6.5108e-02, -1.7901e-01, -7.1558e-02,\n",
       "                      -1.1267e-01, -4.8182e-02, -7.2285e-02, -2.7648e-01, -1.0359e-01,\n",
       "                      -1.4268e-01, -4.6922e-02,  5.3655e-02,  1.2156e-02, -7.4525e-03,\n",
       "                      -8.2189e-02, -7.3622e-02, -5.0966e-02, -1.9983e-02, -1.3679e-02,\n",
       "                       2.5109e-02,  1.1261e-02,  2.7932e-02, -3.6796e-02,  7.6000e-02,\n",
       "                       8.2071e-03,  5.0389e-02,  5.1718e-02, -5.4715e-02,  3.7175e-02,\n",
       "                       1.0705e-01, -3.2034e-02, -4.9349e-02, -1.2259e-02,  1.4137e-02,\n",
       "                      -4.0474e-02,  5.6661e-02,  4.7748e-02,  2.0122e-02, -4.3802e-02,\n",
       "                       6.0609e-03, -5.4073e-02,  1.9987e-01, -4.7914e-02, -7.1313e-02,\n",
       "                       8.6684e-03,  1.4585e-02, -6.8517e-02,  5.8182e-02,  2.0635e-02,\n",
       "                      -8.6051e-04,  2.4442e-03, -1.4750e-01,  5.8414e-03, -2.1890e-02,\n",
       "                       2.2224e-02, -8.5737e-02,  1.1691e-01, -6.5283e-03, -3.7747e-03,\n",
       "                      -8.9844e-03,  5.1377e-03,  1.1717e-01, -3.3725e-02,  1.2021e-01,\n",
       "                       7.7348e-02, -1.2167e-01, -7.8146e-02,  9.6626e-02,  6.0974e-03,\n",
       "                       4.0688e-02, -5.2386e-02,  6.9389e-02,  7.2964e-03, -8.6792e-02,\n",
       "                       4.2477e-02,  1.1835e-02, -1.2295e-01, -9.4764e-02, -5.9383e-02,\n",
       "                       1.0321e-01, -3.4278e-02,  1.7339e-01, -7.5581e-02, -2.0506e-02,\n",
       "                       6.1592e-02, -2.2652e-02,  2.4837e-02,  6.7111e-03, -9.4190e-02,\n",
       "                       4.5772e-02,  4.7886e-02, -4.2933e-02,  7.1713e-02,  6.0813e-02,\n",
       "                       1.0258e-02,  2.4005e-02, -4.2182e-02, -7.6012e-02,  3.9730e-02,\n",
       "                      -4.6661e-02,  2.0103e-02,  9.0014e-02, -6.5257e-02, -7.4510e-02,\n",
       "                       6.0768e-02,  6.3721e-02,  4.1571e-02, -3.9727e-02, -6.3045e-02,\n",
       "                       9.7067e-02, -3.0450e-02,  1.0210e-01,  3.1015e-02, -6.7592e-02,\n",
       "                       4.4132e-02, -7.7364e-02, -1.0551e-02,  1.3335e-02, -8.8731e-03,\n",
       "                       3.5174e-02,  3.2968e-02, -1.0109e-02, -7.4838e-02,  6.3384e-02,\n",
       "                      -5.2336e-02, -4.9324e-02, -2.1116e-02,  3.9603e-02, -5.8074e-02,\n",
       "                      -3.3305e-02, -2.7977e-02,  1.1669e-01,  1.0404e-01, -4.8199e-02,\n",
       "                       3.9029e-03, -4.9700e-02, -2.2736e-02,  5.6659e-02, -8.3640e-02,\n",
       "                      -1.9376e-01, -1.2938e-01, -1.9864e-01, -1.0559e-01, -1.3294e-01,\n",
       "                      -7.2156e-02, -2.1848e-01, -1.4919e-01, -8.6672e-02, -5.4256e-02,\n",
       "                      -2.8268e-02, -1.7489e-01, -2.4019e-01, -5.5192e-02, -1.6843e-01,\n",
       "                      -2.6671e-01, -3.6801e-03, -2.2613e-01, -1.6262e-01, -1.9828e-01,\n",
       "                      -3.3130e-02, -2.2196e-01, -6.8601e-02, -1.0334e-01, -5.0688e-02,\n",
       "                      -1.0084e-01, -2.7963e-01, -1.9813e-01, -1.9922e-01, -2.1341e-01,\n",
       "                      -1.9656e-01, -1.8534e-01, -8.1004e-02, -7.2367e-02, -1.5608e-01,\n",
       "                      -1.4885e-01, -1.0085e-01, -1.6778e-01, -1.2626e-01, -1.8158e-01,\n",
       "                      -1.6592e-01, -2.6153e-01, -1.3225e-01, -9.7698e-02, -1.5296e-01,\n",
       "                      -1.3339e-01, -1.7788e-01, -7.1669e-02, -7.7983e-02, -1.4043e-01,\n",
       "                      -1.3406e-01, -2.0620e-01, -8.5485e-02, -1.7404e-01, -1.2209e-01,\n",
       "                      -7.7557e-02, -2.1129e-01, -1.6658e-01, -1.9337e-01, -1.8648e-01,\n",
       "                      -1.4300e-01, -9.6722e-02, -1.8321e-01, -1.8720e-01, -1.3305e-01,\n",
       "                      -1.3196e-01, -1.1550e-01, -9.1029e-02, -2.5434e-01, -1.1646e-01,\n",
       "                      -9.3574e-02, -1.6707e-01, -1.0401e-01, -2.0997e-01, -2.7797e-01,\n",
       "                      -1.6157e-01, -8.3974e-02, -1.8493e-01, -2.7020e-01, -2.0888e-01,\n",
       "                      -2.8367e-02, -1.0520e-01, -1.0521e-01, -6.2826e-02, -1.5248e-01,\n",
       "                      -1.5555e-01, -2.1933e-01, -1.6084e-01, -9.8028e-02, -9.7880e-02,\n",
       "                      -9.8315e-02, -2.3474e-01, -1.2163e-01, -8.8032e-02, -6.0277e-02,\n",
       "                      -1.3553e-02, -1.9556e-01, -1.3156e-01, -2.0665e-01, -7.0230e-03,\n",
       "                      -1.8920e-01, -1.1555e-01, -2.2889e-01, -1.5049e-01, -1.7521e-01,\n",
       "                      -9.3409e-02, -1.2416e-01, -8.1828e-02, -1.4718e-01, -2.5106e-01,\n",
       "                      -4.3234e-02, -2.0848e-01, -1.5494e-01, -2.4541e-01, -1.8549e-01,\n",
       "                      -1.0082e-01, -1.9062e-01, -2.2697e-01, -1.6087e-01, -2.8625e-01,\n",
       "                      -1.1193e-01, -1.6231e-01, -1.1915e-01, -1.4464e-01, -2.3221e-01,\n",
       "                      -2.2312e-01, -2.6215e-01])),\n",
       "             ('bilstm_left_context_feature.weight_ih_l0_reverse',\n",
       "              tensor([[-6.2304e-02,  3.5787e-02,  1.6483e-01,  ..., -1.7808e-01,\n",
       "                        1.1887e-01,  7.2818e-02],\n",
       "                      [ 1.7359e-01,  1.5359e-01,  2.0849e-01,  ...,  1.0368e-01,\n",
       "                       -1.4565e-01,  3.4758e-01],\n",
       "                      [ 7.2378e-02, -4.8465e-03, -3.0289e-01,  ..., -3.1895e-01,\n",
       "                        6.5624e-02, -1.7433e-01],\n",
       "                      ...,\n",
       "                      [-1.6434e-01,  4.7865e-01, -5.6572e-02,  ...,  8.6021e-02,\n",
       "                       -3.3509e-01,  4.7794e-03],\n",
       "                      [-1.2886e-01, -2.6834e-02,  7.4145e-02,  ..., -1.6833e-01,\n",
       "                       -4.2825e-02, -1.2263e-02],\n",
       "                      [-1.1937e-02,  7.8523e-02,  2.0450e-01,  ..., -4.1906e-04,\n",
       "                        1.3710e-01,  5.3618e-04]])),\n",
       "             ('bilstm_left_context_feature.weight_hh_l0_reverse',\n",
       "              tensor([[ 0.1036,  0.1082, -0.2444,  ..., -0.1541,  0.0670, -0.0863],\n",
       "                      [-0.1942, -0.1763, -0.1540,  ..., -0.2473,  0.2702,  0.0271],\n",
       "                      [-0.1206,  0.0602,  0.2269,  ...,  0.0732, -0.0184, -0.0016],\n",
       "                      ...,\n",
       "                      [-0.1331, -0.0846, -0.2075,  ..., -0.1201, -0.0038,  0.0675],\n",
       "                      [ 0.0162, -0.1380,  0.0081,  ..., -0.2307, -0.2558, -0.2333],\n",
       "                      [ 0.0838, -0.0284, -0.1180,  ..., -0.2692, -0.0044, -0.0798]])),\n",
       "             ('bilstm_left_context_feature.bias_ih_l0_reverse',\n",
       "              tensor([ 1.0933e-01,  1.8026e-01,  1.2454e-01,  1.5350e-01,  5.4855e-02,\n",
       "                       7.2181e-02,  1.9708e-01,  6.7895e-02,  1.0486e-01,  1.7392e-01,\n",
       "                       5.8683e-02,  1.1557e-01,  2.4547e-01,  5.3115e-02, -1.0720e-01,\n",
       "                      -1.5892e-03,  1.3268e-01,  5.1515e-02,  1.5615e-02, -1.3659e-02,\n",
       "                       2.1693e-02,  1.3327e-02,  1.1440e-01,  9.9496e-02,  9.3419e-02,\n",
       "                       1.2183e-02,  1.3392e-01, -2.4613e-02,  1.0778e-01,  1.3762e-01,\n",
       "                      -1.1038e-01,  3.4273e-02,  1.3803e-01, -2.8886e-02,  1.2241e-01,\n",
       "                       1.0689e-01,  7.1208e-02,  4.3814e-02, -1.1872e-02,  1.5107e-01,\n",
       "                       1.0721e-03,  1.5977e-01, -5.6136e-02, -1.1209e-02,  2.5194e-01,\n",
       "                       5.6116e-02, -1.0725e-02, -2.0951e-02, -8.4780e-02, -9.6238e-02,\n",
       "                      -5.1622e-03, -3.5429e-03,  1.5987e-02,  1.3676e-01, -1.2563e-02,\n",
       "                      -4.9001e-02,  5.7223e-02,  7.3346e-02,  1.2539e-01,  9.2073e-02,\n",
       "                       3.7282e-02, -9.4415e-02, -1.4741e-02,  8.2782e-02,  6.1123e-02,\n",
       "                      -9.1959e-03,  1.0935e-01,  7.3691e-02,  9.7707e-02,  1.7199e-01,\n",
       "                       6.8923e-03,  1.2700e-01,  1.2386e-01, -9.7148e-02, -1.3986e-02,\n",
       "                       1.7857e-01,  8.6293e-03,  8.4847e-02,  1.4022e-01,  1.4060e-01,\n",
       "                      -4.9227e-02,  1.5657e-01,  4.9697e-04,  1.0094e-01,  1.0520e-01,\n",
       "                      -4.3176e-02, -4.5778e-02, -3.9161e-02, -6.4394e-02,  8.3255e-02,\n",
       "                      -4.2657e-02, -5.4909e-02,  2.0499e-01,  6.9785e-02,  6.4578e-03,\n",
       "                       1.4200e-01,  1.2271e-01,  1.6785e-01, -2.5470e-03, -6.2829e-02,\n",
       "                      -8.8923e-02,  1.4315e-01,  5.9338e-02,  6.2723e-02, -5.2949e-03,\n",
       "                      -1.0659e-01, -9.5812e-02, -1.5335e-01,  1.4516e-01,  6.1215e-02,\n",
       "                       2.7263e-01, -4.7834e-02, -1.0864e-02,  4.2253e-02,  1.3076e-01,\n",
       "                       1.0580e-01, -5.0106e-02, -1.6538e-02,  1.1561e-01, -2.2172e-02,\n",
       "                       1.5686e-01,  3.7555e-02,  7.0478e-02, -9.0216e-02, -2.7793e-02,\n",
       "                      -1.4449e-01, -1.5092e-01,  1.3539e-01, -4.1798e-02, -9.3169e-02,\n",
       "                       1.1302e-01, -4.3188e-02, -1.2720e-01,  1.1848e-01, -1.6143e-01,\n",
       "                      -2.6916e-02, -4.1298e-02, -1.8065e-01, -8.3258e-02, -5.3891e-02,\n",
       "                      -1.6565e-01, -1.6709e-01, -1.4955e-01, -2.4510e-03,  9.7854e-02,\n",
       "                      -5.3503e-02,  4.0552e-02, -1.5199e-02,  6.2925e-02,  1.9093e-01,\n",
       "                      -1.3749e-01, -6.6462e-02, -1.1636e-01, -2.6883e-01,  1.3814e-02,\n",
       "                      -2.6814e-01, -7.2614e-02, -1.7323e-01, -3.6409e-02, -1.1366e-02,\n",
       "                      -9.8239e-02,  2.8489e-02, -1.4070e-01, -1.5030e-02,  1.0266e-02,\n",
       "                      -1.0964e-01, -3.5302e-03, -4.6544e-02, -7.6590e-05, -2.6237e-01,\n",
       "                       1.7509e-02, -1.7967e-01, -2.9029e-02,  3.9062e-02, -1.5226e-01,\n",
       "                      -3.5312e-02, -3.7860e-02, -1.4511e-01,  7.1683e-02, -6.3506e-02,\n",
       "                       4.7971e-02, -1.0242e-01, -1.0018e-01, -7.8959e-02, -3.9469e-02,\n",
       "                      -1.5014e-01, -1.7002e-01, -1.3422e-01,  1.4602e-02, -2.3883e-01,\n",
       "                       6.4494e-03, -3.9644e-02, -7.3883e-02, -1.3379e-02, -9.6410e-02,\n",
       "                      -9.2648e-02, -5.7911e-02, -7.9691e-02, -8.6140e-02,  1.4052e-02,\n",
       "                      -7.4315e-03, -2.4152e-03, -1.0979e-01, -9.1506e-02, -3.9062e-03,\n",
       "                      -4.7177e-02, -3.8831e-02, -4.0402e-02, -8.0002e-03,  4.5796e-03,\n",
       "                       8.9301e-03, -5.3532e-02,  1.6292e-01,  8.6742e-03, -3.2879e-02,\n",
       "                      -1.2672e-01, -1.7118e-01, -1.0117e-01, -1.5469e-01, -1.3949e-02,\n",
       "                      -5.9792e-02, -2.6642e-01,  1.2292e-02, -1.7686e-01, -8.3591e-02,\n",
       "                      -1.0502e-01, -6.4184e-02,  1.4495e-01, -1.8278e-01, -4.5921e-02,\n",
       "                      -2.6674e-02, -3.8538e-02, -5.4101e-02, -2.3348e-02, -4.1315e-02,\n",
       "                      -2.2281e-03, -3.6881e-02, -8.8908e-02, -9.0248e-02,  8.7504e-03,\n",
       "                       2.0017e-02, -4.1667e-02, -4.1278e-02,  1.5954e-01, -1.4806e-01,\n",
       "                      -9.9909e-02, -3.6562e-02, -5.8827e-02, -1.0863e-01, -1.1251e-02,\n",
       "                      -1.2415e-01, -3.0422e-02, -8.0611e-02,  2.9908e-02, -7.9842e-02,\n",
       "                      -7.3859e-02, -2.4795e-03,  3.6622e-02, -1.3954e-01, -1.5175e-02,\n",
       "                       3.2471e-02,  3.0255e-02, -1.3541e-02,  5.9759e-02,  1.2435e-02,\n",
       "                       1.3168e-02, -8.1692e-02,  8.8788e-02,  1.1889e-01,  3.3570e-02,\n",
       "                      -8.4722e-03, -6.2156e-02,  3.7974e-02, -4.4127e-02, -4.8031e-02,\n",
       "                       1.8580e-02, -2.9559e-02,  9.4397e-02, -8.6543e-03, -9.0249e-02,\n",
       "                      -7.6440e-03,  2.9944e-02,  1.8597e-02, -8.3221e-02, -2.6555e-02,\n",
       "                       4.5393e-02, -1.1212e-01,  1.5788e-02, -4.4164e-02, -1.8365e-02,\n",
       "                      -7.5318e-02, -5.8788e-02, -7.6021e-02,  1.1838e-01, -7.3784e-02,\n",
       "                      -2.2545e-03, -6.8919e-02,  4.6412e-02, -1.7457e-02,  8.1752e-02,\n",
       "                      -1.7744e-02, -8.9051e-02,  1.7235e-02,  1.1231e-02, -5.3781e-03,\n",
       "                      -1.3649e-02,  4.6684e-03,  5.3448e-02, -2.3735e-02,  1.1398e-01,\n",
       "                      -9.2385e-02,  1.1157e-02,  9.4011e-02, -8.7313e-02,  9.6939e-02,\n",
       "                      -2.0979e-02,  3.9008e-02,  1.0134e-01,  3.4193e-02, -4.7164e-02,\n",
       "                      -4.0617e-02, -2.0698e-02, -7.2009e-02,  6.4093e-02, -1.1087e-01,\n",
       "                      -2.9757e-02, -2.0779e-02,  1.7785e-02, -6.9827e-02,  6.7598e-02,\n",
       "                       6.8647e-02,  2.7094e-02,  4.7374e-02, -1.9942e-02, -3.7792e-03,\n",
       "                       9.2252e-02, -7.2886e-02, -3.8818e-02, -2.4382e-02,  2.7069e-02,\n",
       "                       6.2089e-03,  7.5236e-03,  4.7387e-02,  1.2462e-02, -1.1082e-02,\n",
       "                      -1.0407e-02,  1.1579e-01, -1.7371e-02,  4.4905e-03, -1.2696e-02,\n",
       "                      -1.9804e-02, -6.4515e-02, -2.0885e-02, -1.1860e-01,  7.5862e-02,\n",
       "                      -5.4101e-02, -8.8795e-02, -3.3407e-02,  1.2975e-01,  1.1515e-02,\n",
       "                       2.4545e-02,  1.0743e-01, -4.7956e-02, -3.8426e-02,  9.3601e-02,\n",
       "                      -2.1396e-02, -8.3586e-02, -6.1330e-02,  7.7576e-02,  2.3731e-02,\n",
       "                       1.0311e-01,  6.7593e-02,  9.9796e-03, -5.1965e-02, -9.3510e-02,\n",
       "                       4.9322e-02, -3.6101e-02,  7.6008e-02,  4.6047e-02, -3.0576e-02,\n",
       "                      -6.4593e-02,  1.2861e-01,  6.2088e-02, -3.7896e-02,  1.6287e-01,\n",
       "                       1.6923e-01,  1.5905e-01,  4.7102e-02,  2.4921e-02, -7.5555e-02,\n",
       "                      -3.6144e-03,  1.5882e-01,  2.1646e-01,  9.0952e-02, -2.9699e-02,\n",
       "                       1.1455e-01,  1.4859e-01,  7.7897e-02,  6.7094e-02, -3.3405e-02,\n",
       "                       9.2765e-02,  1.8148e-01, -9.8082e-02,  4.1013e-02,  5.0091e-02,\n",
       "                       6.2556e-03,  3.5460e-02,  1.5540e-01,  6.3306e-02,  1.5465e-01,\n",
       "                       7.5797e-02,  4.4146e-02,  6.6076e-02,  2.4257e-02, -6.5747e-02,\n",
       "                       2.6780e-02,  1.4714e-01, -2.3996e-02,  3.2988e-02,  1.1151e-01,\n",
       "                       1.0176e-01, -9.0509e-02,  1.3013e-01, -1.2584e-02,  1.3553e-01,\n",
       "                       1.0674e-01,  2.4996e-02, -4.4651e-02,  1.1065e-01,  1.4426e-01,\n",
       "                       4.2158e-02,  9.2832e-02,  4.4237e-02, -1.3452e-04,  2.6858e-03,\n",
       "                       2.1657e-02,  7.5562e-02, -1.3375e-01,  6.1543e-02, -6.4454e-02,\n",
       "                       1.1978e-01, -4.9623e-02,  2.4253e-02,  2.2552e-01, -1.2272e-02,\n",
       "                      -7.8759e-02,  7.3980e-02,  1.9574e-02, -1.2594e-02,  9.7307e-02,\n",
       "                       1.1232e-01,  1.9871e-01,  2.3489e-02,  1.7705e-02, -3.0463e-02,\n",
       "                       4.2939e-02,  1.3562e-01, -3.1926e-03,  6.7786e-02,  1.4126e-01,\n",
       "                       7.4484e-02,  1.7644e-02,  5.3729e-02, -5.3038e-02,  1.3228e-01,\n",
       "                       1.0121e-01, -1.0798e-01,  6.8412e-02,  2.0139e-01, -8.0687e-02,\n",
       "                      -3.9367e-02, -1.0172e-01, -4.5899e-02,  1.5753e-01,  1.5367e-01,\n",
       "                      -1.9240e-02,  2.9177e-01, -1.3076e-01,  8.7344e-02, -1.0941e-01,\n",
       "                       5.3737e-02,  2.2307e-01, -1.4941e-02,  9.5805e-02, -1.1406e-01,\n",
       "                       7.0307e-02, -6.9492e-02,  2.5887e-02, -1.0319e-02, -1.0850e-01,\n",
       "                       9.4216e-02, -3.4275e-02,  2.2700e-02,  6.4819e-02,  2.2140e-01,\n",
       "                      -3.0638e-02,  4.9861e-02,  1.4127e-01,  6.5297e-02, -9.9822e-03,\n",
       "                      -2.9763e-02,  1.4642e-01, -2.2382e-02, -3.4432e-02,  6.0304e-02,\n",
       "                       8.2071e-02, -2.6933e-03, -6.4087e-02,  1.0839e-01, -3.5472e-02,\n",
       "                       3.2686e-02,  1.1499e-01])),\n",
       "             ('bilstm_left_context_feature.bias_hh_l0_reverse',\n",
       "              tensor([ 1.7506e-01,  5.6373e-02,  1.0872e-01,  1.0847e-01,  1.6750e-01,\n",
       "                       5.0986e-02,  1.2478e-01,  1.7796e-01,  1.3811e-01,  5.8503e-02,\n",
       "                       6.8248e-02,  1.2815e-01,  1.6685e-01,  4.7415e-02,  2.1997e-02,\n",
       "                       3.3424e-02,  1.2074e-01,  1.1792e-01, -2.7720e-02,  5.1715e-02,\n",
       "                       5.7594e-02, -2.7621e-02,  1.2474e-01,  5.9115e-02,  4.9518e-02,\n",
       "                       7.2857e-02, -1.2694e-02, -5.0975e-02,  5.6390e-02,  1.0972e-01,\n",
       "                      -9.0819e-02,  1.0832e-01,  2.4247e-01, -7.5651e-02,  1.8181e-01,\n",
       "                       1.1850e-01, -1.5409e-01, -2.5079e-03,  2.5448e-02,  1.4579e-01,\n",
       "                       6.9835e-02,  2.3706e-01,  1.7527e-01,  1.0905e-01,  1.8709e-01,\n",
       "                       4.3706e-02,  4.5821e-02, -4.5767e-02,  4.0320e-02, -6.6243e-02,\n",
       "                       3.2990e-02,  1.1022e-01, -5.3181e-03,  8.4481e-02, -1.3383e-02,\n",
       "                      -1.1154e-01,  2.3581e-02,  4.4771e-02,  1.1972e-01,  9.7225e-02,\n",
       "                       6.0472e-02, -4.4782e-02, -5.0369e-02,  9.9443e-02, -5.6397e-03,\n",
       "                      -1.4883e-02, -2.7056e-02,  1.2866e-01,  2.2932e-02, -3.1962e-02,\n",
       "                       6.1305e-02,  6.4301e-02,  5.2716e-02,  2.5604e-02,  1.2063e-01,\n",
       "                       1.0179e-01, -2.2694e-04,  7.7777e-02,  1.7523e-01, -6.2499e-03,\n",
       "                       5.6428e-02,  1.8070e-01, -3.7951e-03,  5.7708e-02,  2.1926e-01,\n",
       "                      -7.3215e-02, -9.1301e-02, -7.4120e-02, -1.2721e-01,  1.1602e-01,\n",
       "                       1.9119e-01, -5.0045e-02,  3.6422e-02, -7.4993e-02, -5.1363e-02,\n",
       "                      -7.8158e-02, -1.9392e-02,  2.0708e-01, -6.3071e-02, -1.2130e-01,\n",
       "                      -7.2230e-02,  1.2478e-01,  1.3838e-01,  2.6471e-02,  1.0034e-01,\n",
       "                      -3.4500e-02, -1.8590e-02, -1.6070e-01, -2.4433e-02,  7.4871e-02,\n",
       "                       2.1407e-01, -3.6169e-02, -3.1839e-02,  1.1327e-01,  1.1002e-01,\n",
       "                       8.6057e-02,  7.4905e-02, -3.1906e-02, -1.2369e-02, -5.7157e-02,\n",
       "                       2.9546e-02, -3.1969e-02, -4.1155e-03, -3.2661e-02,  5.7376e-02,\n",
       "                      -1.2619e-01, -5.9386e-02,  5.5970e-02, -1.2238e-01, -2.2222e-02,\n",
       "                       1.9236e-02,  2.3190e-02,  2.5892e-02, -2.3176e-02, -5.3589e-02,\n",
       "                      -5.9213e-02, -1.3885e-01, -9.4776e-02, -9.1833e-02, -1.0176e-01,\n",
       "                       1.8316e-02, -4.2945e-02, -4.2225e-02, -3.3047e-02, -1.5442e-01,\n",
       "                      -1.2814e-01,  6.5213e-02, -1.5932e-02,  2.7921e-02,  3.0289e-02,\n",
       "                      -1.8412e-01, -2.0446e-02, -1.2514e-02, -2.0696e-01,  5.2066e-03,\n",
       "                      -1.2444e-01,  8.7731e-02, -1.1822e-01, -8.2923e-02, -5.6603e-02,\n",
       "                      -1.5557e-01,  2.2119e-02, -6.5740e-02, -7.8921e-02, -1.3931e-03,\n",
       "                      -7.3837e-02, -8.6512e-02, -7.3250e-02,  8.3139e-02, -1.8524e-02,\n",
       "                      -6.3466e-02, -2.0381e-01, -1.8125e-01,  1.6977e-01, -7.2447e-02,\n",
       "                      -1.0715e-01, -4.4586e-02,  7.5320e-04, -4.5439e-02, -9.4810e-02,\n",
       "                      -1.1122e-01,  3.6397e-03,  3.9291e-03, -9.8208e-02, -5.6589e-02,\n",
       "                       1.5254e-02, -7.8404e-02,  4.0810e-02, -1.7737e-02, -1.2447e-01,\n",
       "                      -9.3563e-02,  6.0246e-02,  1.1430e-02, -1.4917e-01, -1.2805e-01,\n",
       "                      -2.7715e-02, -6.0191e-02, -7.1153e-02, -2.3629e-02, -2.1218e-02,\n",
       "                      -9.2236e-02,  1.8050e-02, -3.9171e-02, -9.9318e-02,  7.4434e-02,\n",
       "                       1.6741e-02, -1.7064e-01, -3.5541e-02, -1.0941e-01, -2.3130e-02,\n",
       "                       1.1503e-01,  4.5339e-02,  2.7727e-02, -1.4087e-01, -1.5881e-01,\n",
       "                      -1.6389e-01, -1.9358e-01, -7.8152e-02, -2.4622e-02, -3.5151e-02,\n",
       "                      -4.5822e-02, -2.0409e-01, -3.4445e-02, -1.3833e-01, -5.6358e-03,\n",
       "                      -1.4434e-01, -4.1572e-02,  1.7848e-01, -2.0448e-01, -1.3936e-01,\n",
       "                      -6.2653e-02, -1.2375e-01,  2.3595e-02,  4.9451e-02,  2.3248e-02,\n",
       "                       3.2106e-02, -3.5732e-02, -1.4360e-01,  2.6771e-02, -8.9724e-02,\n",
       "                      -4.7760e-02, -1.0159e-01, -2.8308e-02,  1.1370e-01,  7.6280e-03,\n",
       "                      -5.1298e-02, -5.1270e-02,  1.7706e-02, -1.9161e-01, -1.0238e-02,\n",
       "                       3.9056e-02,  3.1066e-02, -7.9975e-02, -1.5365e-01, -2.8330e-02,\n",
       "                      -2.2799e-03, -1.1096e-01,  6.6261e-02, -7.6829e-02, -9.3392e-02,\n",
       "                      -6.8565e-02, -1.5211e-01,  6.4483e-02,  1.1473e-02,  4.7984e-02,\n",
       "                       4.2272e-02, -5.8523e-03, -8.1138e-02,  4.8648e-02, -3.2880e-03,\n",
       "                      -1.8954e-02, -2.0225e-02, -5.3219e-02, -3.3629e-02, -3.7696e-02,\n",
       "                      -7.2548e-02, -3.6504e-02,  5.3614e-02,  1.0543e-02, -2.7318e-02,\n",
       "                      -3.7595e-02, -4.9219e-02, -7.8652e-02, -1.3331e-02,  1.3641e-01,\n",
       "                       3.0831e-02, -6.1836e-02,  8.5659e-02, -5.1797e-03, -1.6382e-02,\n",
       "                       6.5424e-02,  7.5266e-02, -3.2228e-02, -4.6591e-02,  1.2022e-01,\n",
       "                       2.7334e-02,  1.0105e-01,  5.6090e-02,  2.1186e-02,  1.8439e-02,\n",
       "                       2.5744e-02,  6.6987e-02, -1.4638e-01,  8.0462e-02,  2.5430e-02,\n",
       "                       1.6127e-02, -7.6928e-02, -5.7296e-02,  6.4289e-02,  5.1921e-02,\n",
       "                       1.0355e-01,  1.2260e-01, -3.8432e-02,  1.1084e-02,  6.3915e-02,\n",
       "                      -1.1628e-01, -5.0441e-02, -3.2902e-02, -1.2133e-01, -3.4635e-03,\n",
       "                       1.0271e-02, -5.4538e-02, -4.9762e-02, -5.1109e-02,  8.8622e-02,\n",
       "                      -2.6516e-03, -6.0191e-02,  5.9830e-02,  1.1571e-01, -5.4669e-02,\n",
       "                      -2.0194e-02,  5.9594e-02, -1.2067e-02, -5.5849e-02, -4.2414e-02,\n",
       "                       7.0423e-02, -3.2924e-03, -9.3231e-02, -6.4167e-02, -5.2999e-02,\n",
       "                      -1.5351e-01,  1.3655e-02,  5.5783e-02,  7.0370e-02,  2.3231e-02,\n",
       "                      -2.5141e-02,  2.4859e-03,  2.3283e-02,  3.7612e-02,  3.7522e-04,\n",
       "                      -8.4149e-02,  1.5224e-02, -3.6061e-02,  8.6773e-03, -9.9800e-02,\n",
       "                      -6.7821e-02, -3.4138e-02,  8.5574e-02,  6.1557e-02, -7.5029e-02,\n",
       "                       6.0439e-02, -1.1853e-01,  5.3343e-02,  3.4032e-02,  2.0716e-02,\n",
       "                       5.2143e-02, -9.1655e-02,  8.9482e-03,  1.1823e-01, -9.8008e-02,\n",
       "                       6.3374e-02, -1.2419e-02, -5.2897e-02, -4.8455e-02,  1.3012e-02,\n",
       "                       3.7718e-02, -1.2970e-01, -9.8071e-02, -1.3643e-01, -9.5751e-02,\n",
       "                       2.6462e-02,  9.0006e-02,  5.1518e-02,  4.5520e-02,  3.0581e-01,\n",
       "                       2.2670e-01,  8.5243e-02,  4.9003e-02,  2.3461e-02, -2.4958e-03,\n",
       "                       4.9948e-02,  1.0440e-01,  1.1376e-01,  1.8099e-01, -2.4085e-02,\n",
       "                       1.1316e-01,  2.8402e-02,  5.6527e-02,  1.4998e-01,  4.0566e-02,\n",
       "                       2.0850e-01,  2.0053e-01,  2.1953e-02,  1.5222e-01,  5.1353e-02,\n",
       "                      -1.0455e-01,  1.0693e-01, -1.9869e-02,  7.6361e-02,  1.6323e-01,\n",
       "                       1.2319e-01, -1.8260e-02,  2.4309e-02,  2.9950e-02, -2.9292e-02,\n",
       "                       1.2404e-01,  1.1438e-01,  2.7513e-02,  1.1670e-01,  1.2185e-01,\n",
       "                       6.5011e-02,  1.7816e-02,  8.0101e-02,  4.9245e-02, -8.6520e-02,\n",
       "                       6.8461e-02, -5.6348e-02, -2.7505e-02,  3.0496e-01,  2.0667e-01,\n",
       "                       3.7268e-02,  1.0522e-01, -1.0433e-01,  4.0684e-03, -4.3650e-02,\n",
       "                      -3.5926e-02,  9.0757e-02, -2.4465e-02, -6.5232e-03, -7.1632e-04,\n",
       "                      -3.3325e-02, -1.6985e-02,  1.6840e-02,  2.3900e-01, -6.6042e-02,\n",
       "                       6.4451e-02, -3.6100e-02,  1.5920e-01,  7.0601e-02, -9.4894e-02,\n",
       "                       4.5205e-02,  1.7092e-01, -8.8103e-02,  4.3644e-02,  6.4811e-02,\n",
       "                       1.1847e-01,  3.0270e-02, -2.6310e-02,  1.3305e-01,  2.4148e-01,\n",
       "                      -6.0551e-02,  1.8966e-02,  5.9549e-02, -8.7021e-02,  8.7746e-02,\n",
       "                       1.5554e-01, -1.1536e-01,  2.1649e-02,  1.6104e-01, -1.7011e-01,\n",
       "                      -6.8992e-04,  3.7230e-02,  4.8478e-02,  1.2155e-01,  5.1744e-02,\n",
       "                      -9.0799e-02,  2.4459e-01, -1.6062e-01,  2.0179e-02, -1.2397e-01,\n",
       "                       1.2436e-01,  9.6964e-02,  1.2585e-01, -3.7493e-02, -1.7164e-01,\n",
       "                      -1.7725e-03, -1.2156e-02,  6.5414e-02,  4.1893e-02,  8.0691e-02,\n",
       "                      -1.0603e-02,  8.3197e-02,  3.0717e-02,  5.1756e-02,  2.4408e-01,\n",
       "                      -4.6654e-02,  9.0909e-02,  1.5957e-01,  8.6306e-02, -9.0593e-03,\n",
       "                      -3.3894e-02,  8.3220e-02, -3.8999e-02, -9.8930e-03,  1.0190e-01,\n",
       "                       9.7697e-02, -8.8463e-02, -7.0000e-02,  1.0002e-01, -7.8545e-03,\n",
       "                      -1.0440e-01,  2.9246e-02])),\n",
       "             ('bilstm_oov_context_feature.weight_ih_l0',\n",
       "              tensor([[ 0.0703,  0.0733, -0.1520,  ...,  0.0581,  0.4036, -0.3828],\n",
       "                      [-0.3150,  0.5072,  0.0320,  ...,  0.3520, -0.1878,  0.0063],\n",
       "                      [ 0.3442, -0.0932, -0.0369,  ...,  0.1804,  0.0059, -0.1701],\n",
       "                      ...,\n",
       "                      [ 0.1935, -0.6110,  0.1898,  ...,  0.5174, -0.4504, -0.5282],\n",
       "                      [ 0.6045,  0.5346, -0.0546,  ..., -0.2443,  0.1403, -0.4537],\n",
       "                      [-0.0160, -0.1510, -0.5827,  ...,  0.0422,  0.1515,  0.0683]])),\n",
       "             ('bilstm_oov_context_feature.weight_hh_l0',\n",
       "              tensor([[ 0.1906,  0.1631, -0.1125,  ..., -0.4033, -0.1535, -0.0112],\n",
       "                      [-0.0730, -0.0277, -0.1386,  ...,  0.0498, -0.0556,  0.2150],\n",
       "                      [-0.3113, -0.0883, -0.0902,  ..., -0.2336,  0.2174,  0.0370],\n",
       "                      ...,\n",
       "                      [ 0.0477,  0.2563, -0.1436,  ..., -0.1066, -0.2415,  0.2951],\n",
       "                      [ 0.1377, -0.1515,  0.1433,  ..., -0.1610, -0.2479, -0.2731],\n",
       "                      [ 0.1727,  0.1550, -0.0987,  ...,  0.1510,  0.0527,  0.0482]])),\n",
       "             ('bilstm_oov_context_feature.bias_ih_l0',\n",
       "              tensor([-9.9523e-02, -6.9107e-02, -1.1278e-01, -1.5883e-01, -1.1625e-01,\n",
       "                      -4.0496e-02, -1.5024e-01, -5.3230e-02, -1.1006e-01, -2.0175e-02,\n",
       "                      -1.5868e-01, -1.1869e-01, -1.2998e-01, -1.7345e-01, -9.5601e-02,\n",
       "                      -7.6719e-02, -5.9658e-02, -1.2581e-01,  7.9224e-02, -1.3031e-01,\n",
       "                      -1.5536e-01, -1.9108e-01, -1.1086e-01, -1.3641e-02,  8.9278e-03,\n",
       "                      -1.6945e-01, -2.4517e-01, -1.6455e-01, -1.6848e-01, -1.5377e-01,\n",
       "                      -2.6836e-01, -7.0444e-02, -1.0169e-01, -1.7564e-01, -1.2331e-02,\n",
       "                      -6.2780e-02, -4.9917e-02, -1.0260e-02, -1.0524e-01, -1.2287e-01,\n",
       "                      -1.6191e-01, -1.5248e-01, -1.2408e-01, -4.4521e-02, -1.7146e-01,\n",
       "                      -1.4650e-01,  3.7647e-02, -5.8542e-02, -8.3763e-02, -7.9546e-02,\n",
       "                      -1.3874e-01, -2.0271e-01, -9.7042e-02, -2.5868e-01, -1.5509e-01,\n",
       "                      -1.3015e-01, -2.0540e-01, -5.7639e-02, -1.6946e-01,  2.7533e-02,\n",
       "                      -3.5834e-02,  1.2629e-01,  2.8035e-02, -8.1140e-02, -1.0963e-01,\n",
       "                      -1.6969e-01, -2.4685e-01,  7.2681e-02, -8.5346e-02,  1.6144e-02,\n",
       "                      -2.0593e-02, -1.5915e-01, -2.1870e-01, -9.3421e-03, -6.6611e-02,\n",
       "                      -1.6296e-01, -7.9098e-02, -6.5360e-02, -7.4601e-02, -8.9560e-02,\n",
       "                       3.4021e-02, -5.0483e-02, -9.4203e-02, -9.8778e-02,  3.5591e-02,\n",
       "                      -1.3463e-01, -5.2994e-02, -1.2151e-01, -1.4148e-01, -1.3769e-01,\n",
       "                      -1.0866e-01, -1.2754e-01, -2.3719e-01, -5.8878e-02, -2.5954e-01,\n",
       "                      -1.7598e-01,  7.8080e-02, -1.5916e-01, -2.1035e-01, -7.5111e-02,\n",
       "                      -3.1333e-03, -1.7883e-01, -1.1305e-01, -8.5607e-02, -1.4770e-01,\n",
       "                      -8.2191e-02, -1.6058e-01, -1.1167e-01, -2.5646e-01, -1.8239e-01,\n",
       "                       5.5280e-02, -9.2797e-02, -4.5450e-02, -1.4955e-02,  7.6400e-02,\n",
       "                      -1.0025e-01, -1.0682e-01, -1.9250e-01, -3.5652e-02, -2.0895e-01,\n",
       "                      -7.9781e-02, -9.2821e-02, -4.2500e-02, -5.5563e-02, -7.4452e-02,\n",
       "                      -3.2219e-02, -9.5371e-02, -1.8261e-01, -1.4178e-01, -3.1056e-02,\n",
       "                      -1.8427e-02, -1.8590e-01,  2.9814e-02,  7.7362e-02, -5.2210e-03,\n",
       "                      -1.6645e-02, -1.1875e-01, -1.5419e-01, -1.7806e-01, -1.4941e-01,\n",
       "                      -1.3102e-01, -7.4971e-02, -1.1128e-01,  7.7806e-02, -1.8017e-01,\n",
       "                       1.8447e-02,  1.7913e-01,  1.0714e-01, -1.6783e-01, -4.9338e-02,\n",
       "                      -5.2484e-02, -9.0080e-02,  1.6957e-01, -1.4558e-01, -2.4537e-01,\n",
       "                       2.9056e-02, -1.1464e-01,  1.5311e-01,  6.4283e-02, -2.8443e-02,\n",
       "                      -1.2626e-01, -1.0951e-01, -5.3342e-02, -9.1942e-02, -3.2316e-02,\n",
       "                      -1.8852e-01, -8.5620e-02, -1.0730e-01, -8.7268e-02, -1.4463e-02,\n",
       "                      -1.3042e-01, -2.2062e-01, -1.1251e-01, -1.2602e-01, -2.4453e-02,\n",
       "                      -9.4707e-03, -9.0983e-02, -2.4281e-02,  5.1294e-02,  5.0456e-02,\n",
       "                      -1.4461e-01,  4.7676e-02,  3.7681e-02,  4.1548e-02,  2.5394e-02,\n",
       "                      -2.7323e-01, -7.0200e-02, -2.9838e-02,  1.1754e-02,  1.6509e-01,\n",
       "                      -1.8255e-02,  1.2325e-02, -1.2247e-02,  1.7475e-01, -9.2731e-02,\n",
       "                       2.7503e-02, -1.0485e-01, -7.3738e-02, -5.7435e-02, -1.2754e-01,\n",
       "                      -1.4876e-01, -4.2799e-02,  7.2841e-02,  9.9660e-03,  2.0534e-02,\n",
       "                      -1.1578e-02, -1.3001e-01,  1.0265e-01,  8.8440e-02,  5.2360e-02,\n",
       "                      -1.4743e-01, -6.6955e-02,  1.9715e-01, -5.5606e-02,  1.5045e-01,\n",
       "                      -1.2694e-01,  1.4607e-02,  1.1054e-02, -1.7092e-01,  2.3206e-02,\n",
       "                      -3.5540e-03, -1.1426e-01, -7.2002e-02, -1.0294e-01,  2.4272e-02,\n",
       "                      -3.1750e-02, -2.3976e-01, -1.1543e-03,  1.7794e-01, -1.4991e-01,\n",
       "                      -9.0568e-04, -5.6728e-02, -1.3861e-02,  6.7174e-02, -4.4537e-02,\n",
       "                      -1.9641e-01, -5.7186e-03,  1.8138e-02, -1.5800e-02, -2.1271e-01,\n",
       "                       1.4529e-01, -2.1900e-02, -6.5547e-02, -1.4985e-02, -1.0671e-01,\n",
       "                       2.2843e-02, -7.9644e-02, -4.7830e-02, -4.4021e-02, -1.2523e-02,\n",
       "                      -3.4360e-02, -1.4897e-01, -8.7974e-02,  1.2874e-01, -2.0556e-01,\n",
       "                      -4.6897e-02, -1.1052e-01, -4.3254e-02,  2.0011e-01,  7.0123e-03,\n",
       "                       1.2027e-01,  2.5457e-02, -8.4210e-02, -6.5619e-02, -5.9400e-02,\n",
       "                       1.4922e-02,  5.4550e-02, -4.7641e-02, -5.8371e-02,  3.3523e-02,\n",
       "                      -1.6053e-01,  8.8266e-03,  1.1036e-01,  1.0558e-01,  5.9421e-02,\n",
       "                       1.1111e-02,  6.2543e-02, -1.8790e-02, -9.3595e-02,  7.8711e-02,\n",
       "                      -2.7674e-02,  6.0913e-02, -1.9030e-02, -5.5779e-03, -1.8619e-02,\n",
       "                       7.3607e-02, -7.2524e-02, -4.6241e-02, -1.1153e-01,  6.5061e-02,\n",
       "                       4.6550e-02, -2.1895e-02, -1.3339e-01, -1.2277e-02,  7.3101e-02,\n",
       "                      -5.7196e-02, -2.7460e-02, -2.6866e-01,  2.8242e-02,  7.9555e-02,\n",
       "                      -1.2514e-01, -7.0669e-02, -2.2784e-02,  2.6196e-02,  9.4347e-03,\n",
       "                      -6.6351e-02, -3.4676e-02,  7.2179e-02, -2.8229e-02, -2.7286e-02,\n",
       "                      -5.3549e-02, -1.7378e-02, -1.3953e-01, -2.9629e-02, -1.1385e-01,\n",
       "                      -3.4515e-02, -6.2230e-02, -1.6445e-02, -1.6476e-02,  1.2241e-01,\n",
       "                       3.9117e-02,  1.0316e-02, -1.0790e-02,  5.7189e-02,  2.8478e-02,\n",
       "                       5.9835e-02,  1.3594e-02, -4.8855e-02, -1.8692e-02,  4.7502e-02,\n",
       "                       2.1147e-02, -2.4123e-02,  7.3581e-02, -1.2436e-02, -6.5744e-02,\n",
       "                       6.6463e-02, -3.4284e-02, -8.1291e-02, -1.5889e-02,  2.2685e-02,\n",
       "                      -7.6599e-02,  2.9609e-02,  5.1744e-02,  5.6407e-02, -3.2084e-02,\n",
       "                       6.0686e-02, -1.1425e-02,  9.4996e-02, -2.9700e-02,  1.0966e-01,\n",
       "                       3.4513e-02, -1.1285e-02,  7.3442e-02, -4.3419e-02, -5.2223e-03,\n",
       "                      -1.0665e-01,  8.7316e-03,  8.7157e-02, -7.1930e-02, -7.9553e-02,\n",
       "                       3.6847e-02,  2.3082e-03,  5.9782e-02,  1.1432e-02, -9.4715e-02,\n",
       "                       1.6549e-01, -5.0538e-02, -2.6030e-02, -2.8268e-02,  1.1055e-01,\n",
       "                       4.8363e-03,  4.2136e-02,  8.4399e-02,  9.0303e-02, -3.0419e-02,\n",
       "                      -4.0833e-02,  4.6545e-02,  4.6340e-02,  1.2360e-01,  4.5516e-02,\n",
       "                       6.0880e-02,  1.5000e-02, -1.4653e-02, -8.0881e-02, -3.6095e-02,\n",
       "                       5.5568e-02, -1.9733e-01, -1.6581e-01, -8.7423e-02, -1.4381e-01,\n",
       "                      -1.3275e-01,  1.8028e-02, -2.4258e-01, -1.0429e-02, -1.8514e-01,\n",
       "                      -7.6022e-02, -1.6522e-01,  1.2168e-02, -3.9271e-02,  3.2318e-02,\n",
       "                      -7.6698e-02, -1.0115e-02, -1.4417e-02,  4.4317e-02, -3.9843e-03,\n",
       "                      -1.7360e-01, -1.7007e-01, -1.1461e-01,  2.5952e-02, -8.5528e-02,\n",
       "                      -2.4293e-01, -1.3370e-01, -1.5414e-01,  4.2797e-02, -5.8667e-03,\n",
       "                       4.3125e-02, -2.8659e-01,  1.5159e-02, -5.2032e-02, -7.1480e-02,\n",
       "                      -5.5645e-02, -1.8164e-01, -1.4427e-01, -3.1224e-03, -1.0563e-01,\n",
       "                      -1.0948e-01,  3.2948e-02, -2.1024e-01, -1.9577e-01, -1.3877e-01,\n",
       "                       9.7391e-02, -1.8911e-02, -1.3267e-01, -5.5366e-02, -1.2838e-01,\n",
       "                      -6.5909e-02, -1.7130e-01, -1.1502e-01, -1.5992e-01, -7.6295e-02,\n",
       "                      -1.1722e-01, -2.6516e-01, -2.9259e-02, -7.0462e-03, -1.9011e-01,\n",
       "                       1.0998e-01, -1.0615e-02, -9.2964e-03, -1.5442e-01, -1.0455e-01,\n",
       "                      -6.0716e-02,  8.4256e-02, -7.3192e-02,  1.7647e-02, -1.6618e-01,\n",
       "                      -1.2765e-02, -2.2351e-01, -1.7238e-01, -1.1060e-01, -6.7229e-02,\n",
       "                      -1.1392e-04, -2.3241e-01,  6.8442e-02,  6.2329e-02, -4.9351e-02,\n",
       "                       9.4466e-02, -1.8718e-01, -1.3415e-01,  6.5499e-02, -7.4503e-02,\n",
       "                      -1.3734e-01, -1.0837e-01, -7.4836e-03, -1.0838e-01, -8.6653e-02,\n",
       "                      -1.5823e-01, -2.2384e-01, -7.8199e-02, -7.3958e-02, -2.1203e-02,\n",
       "                       6.2711e-02, -1.3235e-01,  6.6613e-03, -9.5740e-02, -6.9418e-02,\n",
       "                      -1.3566e-01, -1.0929e-01, -4.6880e-02, -1.9757e-01,  9.4588e-02,\n",
       "                      -1.0156e-01, -2.5282e-02,  3.1000e-02, -1.1833e-01, -1.6750e-01,\n",
       "                      -3.9646e-02, -7.2526e-02, -1.1081e-01,  5.2861e-02, -1.5299e-01,\n",
       "                      -6.6319e-02, -8.5710e-02, -1.5356e-01, -6.6536e-02, -1.1309e-01,\n",
       "                      -9.2514e-02, -2.3094e-01, -2.5693e-01, -8.8409e-02, -6.0999e-02,\n",
       "                       1.1348e-02,  5.2533e-02])),\n",
       "             ('bilstm_oov_context_feature.bias_hh_l0',\n",
       "              tensor([-1.1207e-01, -4.1689e-02,  1.5308e-02, -9.4995e-02, -3.3414e-02,\n",
       "                      -5.9527e-02, -3.1593e-03,  2.6073e-03, -1.3855e-02,  6.3014e-02,\n",
       "                      -1.5062e-01, -1.5038e-01, -1.9586e-01, -1.5176e-01, -7.0658e-02,\n",
       "                       4.7594e-03, -1.0097e-01, -8.3211e-02, -2.5500e-02, -6.6196e-02,\n",
       "                      -6.3528e-02, -1.8463e-01, -1.0851e-01, -8.3236e-02,  3.4823e-02,\n",
       "                      -1.8583e-01, -2.0151e-01,  1.5124e-03, -1.4899e-01, -5.1220e-02,\n",
       "                      -1.9300e-01,  2.9087e-02, -1.3216e-01, -3.2907e-02, -1.0437e-01,\n",
       "                      -1.4239e-01, -6.2613e-02, -1.9695e-01, -3.5286e-02, -2.1782e-02,\n",
       "                       3.3065e-02, -1.0527e-01, -4.7928e-02, -5.5636e-02, -1.3748e-01,\n",
       "                      -2.1449e-01, -2.1798e-02, -4.8932e-02, -1.3776e-01, -1.4092e-02,\n",
       "                      -2.0313e-01, -5.8119e-02, -6.1202e-02, -1.0724e-01, -9.0500e-02,\n",
       "                       3.4813e-04,  6.2772e-02, -3.4899e-01, -2.2171e-01, -5.2688e-02,\n",
       "                      -1.3520e-01,  7.5976e-02, -1.0051e-01, -5.7257e-02,  1.4345e-03,\n",
       "                      -1.3727e-01, -1.1923e-01,  1.7427e-02,  8.2953e-02, -6.9250e-02,\n",
       "                      -1.3246e-01, -5.2857e-02, -9.2718e-02, -2.1319e-01,  1.1448e-01,\n",
       "                      -9.4176e-02, -3.0668e-02, -1.7586e-02, -8.9750e-03, -4.0219e-02,\n",
       "                      -5.5923e-02, -1.0071e-01, -3.2848e-02, -1.3186e-01, -8.1570e-02,\n",
       "                      -2.3935e-01, -1.7127e-01, -8.5247e-02, -5.2496e-02, -1.5322e-01,\n",
       "                       5.1329e-02, -8.0744e-02, -1.0007e-01, -1.2530e-01, -1.0631e-01,\n",
       "                      -1.3525e-01, -3.3396e-02, -8.5962e-02, -1.8066e-01, -1.1238e-01,\n",
       "                      -1.0426e-01, -1.3611e-01,  1.0553e-02, -1.4703e-01, -1.1564e-01,\n",
       "                      -1.1676e-02, -1.0845e-01, -1.4567e-01, -1.4431e-01, -1.4893e-01,\n",
       "                      -2.7507e-02, -1.3490e-01, -1.2471e-02, -7.6577e-02, -8.5105e-02,\n",
       "                      -7.2877e-02, -1.6416e-01, -7.0224e-02, -9.0254e-02, -8.1299e-02,\n",
       "                      -4.3995e-02, -1.4132e-01, -7.3011e-02, -1.6869e-01, -2.0719e-01,\n",
       "                      -6.6407e-02, -1.1808e-01, -1.0518e-01, -8.0622e-03, -1.1391e-01,\n",
       "                       1.9758e-03, -8.8793e-02,  7.8204e-02,  1.4025e-02,  4.8236e-03,\n",
       "                      -1.5223e-01, -4.5429e-02, -3.6271e-02, -8.2364e-02, -1.7913e-02,\n",
       "                      -9.1488e-02, -1.0251e-01, -9.6713e-02,  3.1932e-02, -1.9950e-02,\n",
       "                      -1.2543e-02, -1.6953e-02,  8.7145e-02, -2.8209e-02, -4.4557e-02,\n",
       "                       8.2756e-02, -2.4117e-02,  8.6688e-02,  7.0615e-02, -5.8214e-02,\n",
       "                       4.8483e-02, -1.2380e-01,  1.6258e-01,  9.2958e-02, -4.8430e-02,\n",
       "                      -1.0993e-01, -1.6365e-01, -8.0004e-02, -5.1885e-03, -1.0877e-01,\n",
       "                      -8.3978e-02, -1.0014e-01, -9.7838e-02, -1.5512e-01,  2.4940e-02,\n",
       "                      -3.2739e-02, -1.7232e-01, -1.2302e-01, -5.7032e-02,  6.5701e-02,\n",
       "                      -3.0770e-02, -5.3509e-02,  2.0311e-02, -1.4555e-01,  3.9734e-02,\n",
       "                      -1.2430e-02,  9.8924e-03, -1.3702e-01, -8.4033e-02, -1.0696e-01,\n",
       "                      -1.5595e-01, -1.7085e-01,  5.3899e-02, -8.4276e-02,  1.9201e-01,\n",
       "                      -5.7124e-02, -7.1896e-02, -7.5958e-03, -6.2070e-02, -4.1541e-02,\n",
       "                       7.9575e-02, -1.0769e-02,  1.2419e-02, -1.5561e-01, -1.3320e-01,\n",
       "                      -1.5256e-01, -9.6982e-02,  6.6169e-02, -1.2198e-02,  7.2381e-02,\n",
       "                      -2.6468e-01,  8.8867e-02,  1.3241e-01,  1.5589e-01,  2.2216e-03,\n",
       "                       1.4869e-03, -4.9980e-02,  1.9748e-01,  1.5645e-02, -8.8913e-02,\n",
       "                       2.7337e-02, -4.9053e-02, -1.1848e-01, -1.2925e-01, -1.4432e-01,\n",
       "                       4.3990e-02, -6.2966e-02, -9.8463e-02, -4.8875e-02,  3.9201e-02,\n",
       "                      -2.4726e-02, -4.3003e-02, -6.3783e-02, -1.1373e-01, -3.4070e-02,\n",
       "                      -8.7648e-02, -7.8981e-02,  1.7746e-02,  4.3057e-02, -7.0210e-02,\n",
       "                      -2.3785e-02, -8.7853e-02,  2.9887e-02, -1.2995e-01, -1.6102e-01,\n",
       "                       6.3519e-02, -6.8754e-02,  2.4852e-02, -8.5128e-02,  8.4137e-02,\n",
       "                      -1.4553e-01, -1.0526e-02, -8.5672e-02, -7.7441e-02,  9.2353e-03,\n",
       "                      -1.0596e-01, -1.1177e-01, -6.4261e-02,  4.0894e-02, -4.3994e-02,\n",
       "                      -1.5503e-02,  1.4994e-01,  2.3343e-02, -7.0363e-02, -2.0943e-01,\n",
       "                      -1.0377e-01,  7.0313e-02,  6.4164e-02, -2.0550e-02, -3.0059e-02,\n",
       "                       1.5081e-01,  1.6278e-02, -1.6579e-01,  1.7845e-02, -1.1870e-02,\n",
       "                       2.3598e-02, -1.3163e-01,  1.9105e-01,  5.4093e-02, -8.9903e-02,\n",
       "                       1.3092e-02, -6.9014e-02, -4.3535e-03, -3.0114e-02, -1.8651e-01,\n",
       "                      -6.5694e-02,  8.0377e-03,  7.3731e-02, -1.2525e-01, -3.5859e-02,\n",
       "                       9.1743e-02, -8.7243e-02, -4.9661e-02,  5.8971e-02, -1.2599e-01,\n",
       "                      -8.5238e-02, -7.0049e-02,  4.7426e-02,  4.9450e-02,  7.7224e-02,\n",
       "                      -2.2303e-01, -6.1843e-02, -1.1351e-01, -7.9476e-03, -1.3116e-01,\n",
       "                      -3.6410e-02, -1.2311e-01, -1.5522e-02,  2.2405e-02,  5.1411e-02,\n",
       "                      -4.0223e-02,  1.6461e-02,  8.2727e-02,  2.4625e-02, -3.5424e-03,\n",
       "                       1.2982e-02,  9.8287e-02, -9.2309e-02,  2.3384e-02,  2.9825e-02,\n",
       "                      -5.4864e-02, -1.2699e-01,  2.9894e-02,  2.9804e-02,  6.3770e-02,\n",
       "                      -5.9465e-03, -8.2183e-02,  3.8630e-03, -1.3067e-01,  3.4375e-03,\n",
       "                      -2.6005e-02, -1.4434e-02,  7.1405e-02, -2.1385e-02,  1.6338e-02,\n",
       "                      -8.6009e-02, -1.7239e-02, -5.0685e-02,  1.0476e-01,  9.1414e-02,\n",
       "                       1.8440e-01, -1.2223e-01, -6.5061e-02,  5.4112e-02,  4.4910e-02,\n",
       "                      -7.8396e-04,  8.0957e-02,  5.8381e-02, -4.2563e-02, -6.1662e-02,\n",
       "                       1.2561e-02,  1.4881e-02, -6.5341e-02, -2.5912e-02,  4.5976e-02,\n",
       "                      -6.9371e-02, -4.0891e-02,  3.6235e-02,  1.0581e-02,  9.0495e-02,\n",
       "                      -1.1022e-03,  9.9247e-02,  1.2455e-02, -1.6396e-02, -8.8950e-02,\n",
       "                       1.1637e-02, -7.0287e-02, -3.2099e-03, -3.3764e-03, -6.8607e-02,\n",
       "                       2.1914e-02,  5.0904e-02, -1.0317e-01,  1.0804e-01,  8.6739e-02,\n",
       "                       1.2225e-02, -1.1088e-01, -4.9076e-03,  2.3957e-04,  4.9970e-02,\n",
       "                       7.8931e-02,  6.2987e-02,  2.5353e-02,  5.7902e-02,  5.5100e-02,\n",
       "                      -9.4842e-02,  5.8911e-02,  2.3316e-02,  1.6849e-03, -8.6774e-02,\n",
       "                      -6.0546e-02, -1.7623e-02, -1.1746e-01, -6.9081e-02, -6.9883e-02,\n",
       "                      -1.1119e-01, -1.9345e-02, -1.5839e-01, -1.8558e-01, -1.2699e-01,\n",
       "                      -6.5228e-02, -1.4323e-01, -1.0064e-02,  6.2283e-02, -6.6988e-02,\n",
       "                       4.0764e-02,  2.2462e-02, -4.1658e-03, -2.8034e-02, -3.6675e-02,\n",
       "                      -6.8578e-02, -2.0866e-01, -8.7762e-02, -1.1487e-02, -1.3130e-01,\n",
       "                      -2.0106e-01, -1.7242e-02,  2.0162e-02,  3.2888e-02, -5.6168e-02,\n",
       "                      -9.7792e-02, -1.5859e-01, -1.4999e-01, -9.2575e-02, -1.0048e-01,\n",
       "                       5.4057e-03, -1.9765e-01,  1.1473e-02, -1.3626e-01, -3.4251e-02,\n",
       "                      -1.8008e-01, -6.4915e-02, -8.4822e-02, -1.4660e-01, -1.4413e-01,\n",
       "                       1.6679e-02, -2.5174e-02, -1.1083e-01,  1.5007e-02, -1.9514e-01,\n",
       "                      -1.2884e-01, -3.6844e-02, -1.4774e-01, -1.1555e-01, -1.8535e-01,\n",
       "                       4.6108e-02, -2.1627e-01, -7.7845e-02,  8.1227e-03, -1.4385e-01,\n",
       "                       1.1584e-01, -1.1648e-01, -7.9287e-02, -6.6799e-02, -1.0787e-01,\n",
       "                      -2.3210e-02,  7.4365e-02, -1.8464e-01, -1.0923e-01, -1.7479e-01,\n",
       "                      -7.3875e-02, -5.5710e-02, -1.7047e-01, -1.0763e-01, -1.2073e-01,\n",
       "                      -5.3623e-02, -1.0793e-01, -1.2046e-01,  9.5814e-02, -1.0313e-01,\n",
       "                      -1.0481e-02, -9.3030e-02, -9.4585e-02,  4.1518e-02, -3.4992e-02,\n",
       "                      -3.9517e-02, -7.2819e-02, -5.8389e-02, -2.0832e-01, -2.2347e-03,\n",
       "                      -5.1765e-02, -8.3373e-02, -1.4238e-01, -1.3861e-01, -6.5296e-02,\n",
       "                       8.8756e-02, -1.7397e-01, -5.0218e-02, -7.4108e-02, -1.1237e-01,\n",
       "                      -9.6037e-02, -2.6953e-02, -3.3237e-02, -9.5938e-02,  5.2329e-02,\n",
       "                      -8.0382e-02, -1.5315e-01, -5.8754e-02, -1.3309e-01, -1.0269e-01,\n",
       "                      -1.8015e-02, -6.3827e-02, -1.2656e-01, -1.3667e-01, -1.1016e-01,\n",
       "                      -7.6465e-02, -9.4171e-02, -1.5124e-01, -2.4442e-02, -3.9958e-02,\n",
       "                       1.1274e-01, -1.2073e-01, -2.3015e-01, -4.7620e-02, -8.4562e-02,\n",
       "                      -1.7014e-01, -7.5217e-02])),\n",
       "             ('bilstm_oov_context_feature.weight_ih_l0_reverse',\n",
       "              tensor([[-0.0447, -0.1827,  0.3729,  ...,  0.2135, -0.2199,  0.1934],\n",
       "                      [-0.2993, -0.1806, -0.1503,  ..., -0.4042,  0.2349, -0.0375],\n",
       "                      [ 0.3059,  0.1348,  0.5820,  ..., -0.4358, -0.2053,  0.1610],\n",
       "                      ...,\n",
       "                      [ 0.2059, -0.1073, -0.2576,  ...,  0.1902,  0.1718, -0.2822],\n",
       "                      [ 0.4014,  0.3075,  0.0063,  ...,  0.0673, -0.0177, -0.0724],\n",
       "                      [ 0.1854, -0.6922,  0.3670,  ...,  0.2774,  0.2770, -0.3415]])),\n",
       "             ('bilstm_oov_context_feature.weight_hh_l0_reverse',\n",
       "              tensor([[ 0.2067,  0.0818,  0.1154,  ..., -0.1103,  0.3700,  0.0174],\n",
       "                      [ 0.2121,  0.1548,  0.1406,  ...,  0.0029,  0.0873, -0.5134],\n",
       "                      [ 0.1820,  0.0635, -0.1098,  ..., -0.4417,  0.0261, -0.2182],\n",
       "                      ...,\n",
       "                      [-0.0501, -0.0961,  0.1921,  ..., -0.0471,  0.0137, -0.0119],\n",
       "                      [-0.1884,  0.0290,  0.0073,  ...,  0.1151,  0.2207, -0.3555],\n",
       "                      [ 0.1385,  0.0159,  0.0786,  ...,  0.2415,  0.1453,  0.0681]])),\n",
       "             ('bilstm_oov_context_feature.bias_ih_l0_reverse',\n",
       "              tensor([-5.7738e-02,  2.0797e-01,  2.7160e-02,  1.6976e-01,  2.0863e-01,\n",
       "                       6.6670e-02,  1.7309e-01,  1.6401e-01,  1.2087e-01, -7.5215e-03,\n",
       "                       1.9504e-01,  6.2455e-02,  1.4342e-01, -2.5733e-02,  1.4831e-01,\n",
       "                       1.2018e-01,  6.6879e-02,  2.8017e-01,  2.8106e-01,  1.1316e-01,\n",
       "                       1.2182e-01,  1.1689e-01,  3.1380e-01,  6.9858e-02,  3.8073e-03,\n",
       "                       4.2131e-02,  1.3851e-01,  3.1509e-01,  1.4430e-01,  6.6631e-02,\n",
       "                       1.5811e-01, -1.7028e-01,  3.0724e-01,  2.7705e-01,  1.3662e-01,\n",
       "                       3.4868e-01,  1.5407e-01, -6.3922e-02,  1.9811e-01,  1.2019e-01,\n",
       "                       1.6575e-01,  3.8534e-01, -6.1633e-02,  1.5108e-01,  1.3834e-01,\n",
       "                       3.1716e-02,  1.6010e-01,  4.1920e-02,  9.4306e-02,  5.8297e-03,\n",
       "                       1.6267e-01,  6.1320e-02,  1.2852e-01,  7.8181e-02,  1.8833e-02,\n",
       "                       2.2516e-01, -1.7944e-02,  2.2217e-01,  1.5599e-01,  2.7025e-02,\n",
       "                       6.2367e-02,  7.6781e-02,  1.2773e-01,  2.3671e-02,  1.2376e-01,\n",
       "                       2.7095e-01,  3.1078e-01,  3.2606e-01,  1.2927e-01,  4.4843e-02,\n",
       "                       2.4336e-01,  1.1456e-01,  1.8077e-01,  2.7129e-02,  1.4321e-01,\n",
       "                       1.1577e-01,  1.0910e-01,  5.5603e-02,  2.4735e-01,  1.8681e-02,\n",
       "                      -4.8023e-02,  1.0604e-01,  4.6547e-02,  2.3593e-01,  2.1274e-01,\n",
       "                       7.8111e-02,  2.1692e-01,  1.2609e-01,  2.9632e-02,  2.5217e-02,\n",
       "                      -1.0641e-02,  3.1771e-02,  1.0001e-01,  6.7012e-02,  2.2288e-01,\n",
       "                       1.5123e-01,  1.3673e-01,  1.0756e-01,  3.3936e-01,  2.5095e-01,\n",
       "                       7.4389e-02,  1.2056e-01,  2.1479e-01, -4.7034e-03,  5.7024e-02,\n",
       "                       4.1358e-02,  1.1360e-01,  8.2606e-02,  1.5821e-01,  2.3238e-01,\n",
       "                       4.9079e-02,  1.4361e-01, -2.4862e-02,  3.3665e-01,  2.5803e-01,\n",
       "                       1.7234e-01,  1.4705e-01,  8.2825e-03,  1.0003e-01,  1.0954e-01,\n",
       "                       1.8585e-01,  2.1988e-01,  1.9843e-01,  1.5296e-01,  2.9967e-01,\n",
       "                       2.9384e-01,  2.1063e-01,  1.1869e-01, -4.5301e-02,  7.5912e-02,\n",
       "                      -7.1397e-02,  1.0982e-01,  5.9459e-03,  1.7792e-01,  8.4198e-02,\n",
       "                      -1.1711e-01,  5.3867e-02,  1.8169e-03,  1.0842e-01, -7.1158e-02,\n",
       "                      -1.5320e-02,  4.6677e-02,  8.4160e-02,  6.3798e-02,  9.4519e-02,\n",
       "                      -1.0201e-01, -8.5770e-02, -1.1314e-01,  1.2176e-01, -7.0442e-02,\n",
       "                       1.7768e-02,  5.7634e-02, -2.8476e-02,  1.0611e-01,  7.3934e-03,\n",
       "                      -6.2708e-02,  5.1271e-02,  5.0603e-02,  5.2293e-02,  2.0613e-03,\n",
       "                       1.0105e-01,  1.4197e-01, -1.1797e-02,  1.9818e-01,  1.8483e-03,\n",
       "                      -6.5394e-03, -6.6165e-02,  5.2968e-02,  7.9097e-02,  8.6100e-02,\n",
       "                       1.3213e-01, -2.9890e-02,  6.3471e-02, -1.2550e-01,  3.9893e-03,\n",
       "                       1.3604e-01, -3.7846e-02,  8.6403e-02,  1.8148e-02,  1.3600e-02,\n",
       "                       4.0196e-02,  2.6939e-02,  1.2757e-02,  7.2319e-02,  4.8928e-02,\n",
       "                       7.6607e-02, -2.7380e-03,  9.1297e-02,  5.2470e-02,  2.5828e-02,\n",
       "                       9.0345e-03, -3.3629e-02, -8.6708e-03, -2.1991e-03, -9.1382e-02,\n",
       "                       1.1020e-01,  1.3567e-01,  1.3035e-01, -9.7863e-02, -1.3312e-01,\n",
       "                      -6.0651e-02, -7.7090e-02,  7.2786e-02,  6.4671e-02,  1.5953e-01,\n",
       "                       1.3763e-02, -1.0905e-01, -8.7144e-03,  4.2690e-02,  8.7893e-02,\n",
       "                       2.2982e-02, -1.2643e-01, -1.4026e-01, -1.3653e-01, -8.1374e-02,\n",
       "                       2.4722e-01, -8.1087e-02, -1.0002e-02, -5.2386e-03,  5.1782e-02,\n",
       "                       7.8683e-02, -4.3603e-02,  1.0679e-01,  6.9077e-02, -2.4418e-03,\n",
       "                      -2.9585e-02, -1.6044e-01, -1.5172e-01,  1.2027e-01,  1.7619e-01,\n",
       "                       2.3007e-01,  7.4418e-02,  9.3603e-02,  9.4765e-02,  8.3749e-02,\n",
       "                       1.8251e-02, -9.1750e-03,  8.0888e-02,  2.7003e-02,  6.8197e-02,\n",
       "                       4.2146e-02,  9.4268e-02,  6.4464e-02, -5.6342e-02,  4.6531e-02,\n",
       "                      -1.1714e-03,  3.8320e-02,  1.5066e-01,  6.2512e-02,  1.0494e-01,\n",
       "                      -2.0111e-02, -2.3269e-02,  3.3248e-02,  1.2990e-01,  1.3941e-02,\n",
       "                       1.0254e-01,  4.9907e-02, -4.4558e-02,  4.3130e-02, -6.9169e-04,\n",
       "                       2.9237e-02,  6.6328e-02,  1.0358e-01, -1.3289e-01, -2.9852e-02,\n",
       "                      -4.2529e-02, -1.3450e-01,  7.8466e-02,  4.4174e-02,  1.0204e-01,\n",
       "                       6.1988e-02, -1.4911e-01,  8.6625e-02,  5.6202e-03,  4.2108e-02,\n",
       "                      -2.7427e-02,  1.1332e-01, -4.5583e-03, -3.4175e-02,  1.0592e-01,\n",
       "                       6.0704e-02, -1.5439e-01, -1.4319e-02,  6.6833e-02,  8.2254e-02,\n",
       "                       7.1678e-02,  3.3446e-02,  4.0399e-02, -1.5273e-01, -3.1214e-02,\n",
       "                       5.7052e-02, -1.5369e-02,  2.4435e-02, -2.4820e-02, -1.0110e-01,\n",
       "                      -7.0365e-02,  3.8549e-02, -8.5127e-02, -1.9697e-02,  5.5223e-02,\n",
       "                      -4.8499e-02,  1.2501e-02, -1.3405e-03, -3.1434e-02,  1.0842e-01,\n",
       "                      -6.5904e-02,  6.9740e-02,  1.4171e-01, -6.9670e-02, -1.2111e-02,\n",
       "                      -9.0004e-02,  1.1002e-01,  4.3505e-02, -7.5766e-02, -2.2154e-02,\n",
       "                      -2.7456e-02,  1.2495e-02, -2.6526e-02,  7.0618e-02, -7.1934e-02,\n",
       "                      -2.6057e-02,  1.1271e-02, -1.9169e-02,  5.7284e-02,  9.1974e-02,\n",
       "                       1.0357e-01, -3.0646e-02,  2.3586e-02,  1.2156e-01,  2.9025e-03,\n",
       "                       8.5309e-02, -3.1601e-02,  1.0672e-01,  1.1245e-01,  3.2557e-02,\n",
       "                       9.5704e-02, -1.6999e-02,  2.1745e-01,  7.8536e-02, -5.7012e-03,\n",
       "                      -6.3309e-03, -3.4384e-02,  4.8273e-02,  2.2685e-02, -1.2482e-02,\n",
       "                      -6.1156e-02,  5.0571e-02, -3.7624e-02,  2.2949e-02, -8.0167e-02,\n",
       "                      -7.8248e-02, -1.7458e-02, -5.1284e-02,  1.5018e-02, -3.5137e-02,\n",
       "                       8.2007e-02, -2.0025e-02, -1.1948e-01, -8.6094e-02, -3.3048e-02,\n",
       "                      -6.2661e-03, -9.3852e-03, -7.3599e-02,  1.0964e-02,  1.1682e-02,\n",
       "                      -7.5397e-02,  9.4139e-02, -8.2551e-02, -4.9552e-02,  7.2400e-02,\n",
       "                      -4.6783e-02, -1.9807e-02, -1.7927e-01,  4.8641e-02,  5.5583e-02,\n",
       "                      -8.2903e-02, -9.5485e-02, -1.5090e-02, -1.3327e-02, -2.8184e-02,\n",
       "                      -3.1131e-03, -8.9292e-02, -2.8017e-04, -1.0390e-01, -2.8340e-02,\n",
       "                       1.6584e-01,  7.6423e-02, -5.6364e-03,  6.9750e-02,  5.0125e-02,\n",
       "                       2.4461e-01,  1.6222e-01,  1.0531e-01,  1.5252e-01,  1.3968e-01,\n",
       "                       4.5041e-02,  2.8914e-01, -3.8910e-02, -5.4091e-02,  2.2282e-01,\n",
       "                      -8.7198e-02,  1.8254e-01,  1.9963e-01,  4.4843e-01,  1.5561e-01,\n",
       "                       3.0886e-01,  2.8901e-01,  2.3569e-01,  2.1202e-02, -2.1488e-02,\n",
       "                       1.6652e-01,  3.1026e-01,  1.8186e-01,  2.6792e-02,  4.6760e-02,\n",
       "                       8.6823e-02,  3.4099e-01, -1.0427e-01,  1.2097e-01,  1.5035e-01,\n",
       "                       2.3867e-02, -7.7947e-03,  1.7531e-01,  1.4701e-01,  2.3509e-01,\n",
       "                       1.4995e-01,  1.1807e-02,  1.8115e-01, -6.9595e-02,  1.1628e-01,\n",
       "                       2.0990e-01, -6.4523e-02,  2.8285e-01,  8.3746e-02, -3.2830e-02,\n",
       "                       1.4407e-01,  3.8140e-02,  3.8152e-01,  1.6939e-01,  1.0083e-01,\n",
       "                      -3.4739e-02,  3.0962e-01,  2.1686e-01,  1.6732e-01, -7.1906e-02,\n",
       "                       2.7523e-01,  3.6579e-02,  1.4418e-01, -1.1680e-01,  2.0280e-01,\n",
       "                       2.2248e-01,  4.1273e-01,  7.9536e-02,  2.0506e-01,  2.5411e-01,\n",
       "                       1.4170e-01,  2.0813e-01,  8.8494e-02,  1.8605e-01,  2.9139e-01,\n",
       "                       2.1650e-01,  2.3578e-01,  2.4812e-01, -2.3446e-03,  1.9576e-01,\n",
       "                       1.0156e-01,  2.7799e-01,  1.9578e-01,  3.4351e-02,  1.5027e-01,\n",
       "                       2.9070e-01,  8.4231e-02,  4.1393e-02, -4.8043e-02, -9.4945e-02,\n",
       "                       2.9511e-01,  3.0263e-01,  8.5491e-02,  3.8923e-02,  1.5220e-01,\n",
       "                       2.9099e-01,  2.3686e-01,  3.5342e-01,  2.3583e-01,  1.3498e-01,\n",
       "                       6.5281e-02,  8.5968e-02,  1.3670e-01,  1.8984e-01,  4.7604e-02,\n",
       "                       2.0049e-01,  1.1274e-01,  1.9779e-01,  2.4176e-01,  1.9170e-01,\n",
       "                       1.9057e-01,  1.5078e-01,  1.6888e-01,  2.7823e-01,  1.3228e-01,\n",
       "                       3.2145e-01,  3.8934e-01,  1.3653e-01,  1.4938e-01,  2.3546e-01,\n",
       "                       1.1078e-01,  5.4770e-02,  1.3364e-01,  2.4852e-01,  2.1506e-01,\n",
       "                       1.6827e-01,  7.6689e-02])),\n",
       "             ('bilstm_oov_context_feature.bias_hh_l0_reverse',\n",
       "              tensor([-6.2881e-03,  1.1976e-01,  1.1709e-01,  9.1828e-02,  1.2758e-01,\n",
       "                       1.1088e-02,  1.0637e-01,  2.6962e-01,  2.7365e-01,  1.8123e-01,\n",
       "                       1.1980e-01, -4.0125e-02,  1.5164e-01, -4.7086e-02,  6.4061e-02,\n",
       "                       1.0214e-01,  1.3143e-01,  2.5426e-01,  3.1440e-01,  6.1160e-02,\n",
       "                       1.2065e-01,  1.8445e-01,  2.8254e-01,  1.4933e-01, -4.2922e-02,\n",
       "                       3.9475e-02,  8.0569e-02,  3.7819e-01,  1.8986e-01,  2.2673e-01,\n",
       "                       1.0551e-01,  9.9773e-04,  1.9525e-01,  1.7252e-01,  2.1151e-01,\n",
       "                       1.4345e-01,  1.2265e-01,  1.4644e-01,  1.9670e-01,  2.7214e-02,\n",
       "                       1.3015e-01,  1.5216e-01,  3.3496e-02,  5.3434e-02,  1.2194e-01,\n",
       "                      -5.1600e-02,  1.8835e-01,  1.9967e-01,  5.7543e-02, -2.9072e-02,\n",
       "                       1.6887e-01,  1.1533e-01,  2.1105e-01,  2.7538e-02,  1.7051e-04,\n",
       "                       1.3726e-01,  3.5589e-02,  2.4251e-01,  7.1528e-02,  9.2314e-02,\n",
       "                       8.7176e-02,  1.2268e-01,  1.7709e-01, -5.2860e-02,  7.6086e-02,\n",
       "                       2.8842e-01,  2.9274e-01,  3.2182e-01,  2.1954e-01,  1.9817e-02,\n",
       "                       2.4193e-01,  1.0243e-01,  2.5283e-01,  1.6906e-01,  1.1650e-01,\n",
       "                       2.4021e-01,  1.9205e-01,  6.3983e-02,  1.5731e-01,  2.3787e-01,\n",
       "                       1.1209e-01, -1.6537e-02,  1.7406e-01,  2.1704e-01,  7.5895e-02,\n",
       "                       2.9359e-01,  2.2242e-01, -2.6507e-02,  7.8762e-02,  3.6317e-02,\n",
       "                       5.8922e-02,  3.6056e-02,  5.4585e-02,  6.7599e-02, -1.6939e-02,\n",
       "                       1.1999e-01,  1.4242e-01,  1.3930e-01,  3.5484e-01,  3.9050e-01,\n",
       "                       1.0210e-01,  2.0525e-01,  5.6742e-02, -1.2622e-02,  1.3146e-01,\n",
       "                      -1.1144e-01,  1.1562e-01,  1.0262e-01,  1.7958e-01,  2.0451e-01,\n",
       "                       1.3888e-01,  1.3372e-01,  8.8243e-02,  6.4503e-02,  2.9401e-01,\n",
       "                       2.4639e-01,  2.8830e-01,  1.4810e-01,  1.5498e-01,  6.3617e-02,\n",
       "                       3.0175e-01,  1.0868e-01,  1.0354e-01,  8.6169e-02,  3.1059e-01,\n",
       "                       3.4314e-01,  1.5597e-01, -1.0528e-02, -4.0804e-02,  9.2175e-02,\n",
       "                      -8.0982e-02,  5.4954e-02,  5.7894e-02,  1.2586e-01,  6.0931e-02,\n",
       "                       5.4831e-02,  1.7582e-01, -2.8101e-02,  1.1966e-02, -8.2967e-02,\n",
       "                      -2.2402e-01, -4.9123e-03,  1.7482e-01,  8.8148e-03,  1.7599e-02,\n",
       "                       1.5146e-02, -8.0462e-02, -1.1250e-01,  4.4190e-02, -1.4058e-02,\n",
       "                       4.0726e-02,  6.5512e-02,  1.3147e-02,  1.1966e-02, -2.4136e-02,\n",
       "                       1.2639e-02, -3.8877e-02, -4.6678e-03,  5.1620e-03,  1.7515e-01,\n",
       "                       9.7926e-02,  8.0394e-02, -7.5492e-02, -4.1040e-02,  4.9376e-02,\n",
       "                       5.0480e-02,  8.8533e-02,  1.2691e-01,  1.4550e-01,  2.5543e-02,\n",
       "                       1.8409e-01,  4.1057e-02,  1.3189e-02,  2.8848e-03,  7.7771e-02,\n",
       "                      -1.2215e-01, -5.2464e-02, -1.2032e-02,  1.1471e-01,  2.9530e-02,\n",
       "                      -2.2976e-02,  9.8928e-02,  8.7371e-03,  3.9244e-02,  1.0481e-01,\n",
       "                       1.1331e-01, -1.7508e-02,  7.2140e-02,  8.0640e-02,  3.3998e-02,\n",
       "                       9.5504e-03,  1.5992e-01, -1.1334e-01,  7.8414e-02, -1.4554e-01,\n",
       "                       5.5092e-02,  8.1691e-02,  7.3574e-02, -7.3720e-02, -1.1627e-01,\n",
       "                       4.3049e-02, -6.0614e-02,  1.3741e-01, -2.6769e-02, -3.7116e-06,\n",
       "                       4.1100e-02, -5.6581e-02,  1.4431e-02, -1.1678e-03,  8.3863e-02,\n",
       "                       1.3908e-02,  7.1103e-02, -8.0422e-02, -6.3750e-02, -3.6507e-03,\n",
       "                       1.7879e-01,  9.5489e-02,  7.9847e-02,  6.6817e-02,  7.1048e-02,\n",
       "                       1.7245e-01, -5.7373e-02,  6.1348e-02,  6.1807e-02, -3.4096e-02,\n",
       "                      -9.4557e-02, -6.7906e-02, -1.0886e-01,  1.6957e-01,  1.6720e-01,\n",
       "                       5.9140e-02, -2.7372e-03,  3.7370e-02,  1.0322e-01,  1.0679e-01,\n",
       "                       4.3344e-02, -6.0188e-02,  3.4845e-02,  6.1516e-02,  1.4255e-01,\n",
       "                       1.3928e-01,  8.2594e-02,  4.1223e-02,  1.2054e-01,  1.1534e-01,\n",
       "                      -1.3862e-02,  4.4182e-02,  6.6190e-02,  5.1563e-02, -2.6637e-02,\n",
       "                       5.8629e-02, -4.9842e-02,  2.2845e-01,  3.0944e-02,  1.8736e-02,\n",
       "                       2.0655e-01,  1.0614e-01,  9.9930e-02,  1.2773e-01, -3.5144e-02,\n",
       "                       1.1584e-02, -2.9274e-02,  5.1797e-02, -7.1387e-02, -7.6392e-02,\n",
       "                       8.6926e-02,  2.6063e-02,  8.6432e-02,  9.0351e-02, -2.3893e-02,\n",
       "                       1.3146e-01, -9.0418e-02, -1.3522e-03, -1.1418e-02,  6.0029e-02,\n",
       "                      -1.1581e-01, -6.3676e-02, -2.0494e-02, -9.6460e-02,  5.1317e-02,\n",
       "                      -1.0938e-01, -9.3831e-02,  1.3004e-03,  7.0348e-02,  3.0504e-02,\n",
       "                      -8.7139e-02, -1.7527e-01, -4.8647e-03, -8.7974e-02, -1.5699e-01,\n",
       "                       5.7938e-02,  1.3786e-02, -1.8545e-02,  1.0625e-01, -4.8193e-02,\n",
       "                      -2.2270e-02, -1.6106e-02,  4.8584e-02, -9.4244e-03,  5.4555e-02,\n",
       "                      -9.5012e-02,  1.3855e-01, -2.3717e-02, -1.0139e-01,  1.5299e-01,\n",
       "                      -1.7471e-01,  3.2156e-02,  1.4717e-02, -8.5259e-02, -5.9251e-03,\n",
       "                       1.0403e-01,  3.4808e-02,  1.5312e-01, -6.3387e-02,  7.2478e-02,\n",
       "                      -3.6726e-02,  2.8106e-02,  1.3368e-01,  8.4384e-02,  5.7250e-02,\n",
       "                      -3.4232e-02,  9.5097e-02, -2.0484e-02, -2.2314e-02,  6.6163e-02,\n",
       "                      -9.0602e-02, -7.5957e-02, -3.0177e-02, -5.2263e-02,  1.0793e-01,\n",
       "                       4.7862e-02,  1.5685e-03,  5.4024e-03,  5.2345e-02, -3.2947e-02,\n",
       "                       3.4986e-02,  9.2045e-02, -8.0909e-02, -2.7842e-02, -6.6120e-03,\n",
       "                      -2.8793e-02, -5.3147e-02,  5.1511e-02,  1.6232e-02,  6.7114e-02,\n",
       "                      -3.8896e-02,  7.8971e-02, -5.9414e-02, -2.4101e-02,  1.2549e-01,\n",
       "                      -1.8745e-02,  5.6628e-03, -2.7228e-02, -1.6033e-02, -3.6072e-02,\n",
       "                       1.5273e-02, -4.0315e-02, -6.8274e-02, -8.1394e-02,  4.8548e-02,\n",
       "                       6.5607e-02, -6.3605e-02, -4.0381e-02,  4.5067e-02, -2.9217e-02,\n",
       "                      -8.8608e-02,  7.5970e-02, -2.1321e-01, -1.1615e-01, -8.9135e-02,\n",
       "                      -2.1763e-02,  7.1598e-02, -8.0030e-02,  7.4860e-02,  6.9036e-02,\n",
       "                      -1.7604e-01, -1.4022e-02,  5.8682e-02,  5.7723e-02,  4.1089e-02,\n",
       "                       1.3668e-01, -1.2384e-01,  5.9312e-02, -5.8013e-02,  8.9445e-02,\n",
       "                       2.0200e-01,  6.5413e-02,  1.1588e-02,  1.9668e-01,  3.3546e-02,\n",
       "                       3.5735e-01,  1.0919e-01, -3.9902e-02,  1.6184e-01,  2.9281e-01,\n",
       "                      -1.2708e-01,  1.1872e-01,  7.0066e-02, -7.6314e-03,  1.4143e-01,\n",
       "                      -2.0578e-02,  1.8348e-01,  3.7422e-01,  4.1304e-01,  4.6869e-02,\n",
       "                       2.6403e-01,  2.8089e-01,  2.2803e-01, -1.2187e-02,  4.7724e-03,\n",
       "                       1.5468e-01,  2.2986e-01,  2.2890e-01,  4.9343e-02,  6.8402e-02,\n",
       "                       1.3689e-01,  3.1682e-01, -5.6039e-02,  1.7132e-01,  2.3809e-01,\n",
       "                       1.2045e-01, -3.3288e-03,  9.9658e-02,  2.0234e-01,  1.7719e-01,\n",
       "                       1.6685e-01,  1.4092e-02,  1.2767e-01, -8.5719e-03,  1.1522e-01,\n",
       "                       2.3528e-01,  7.4307e-02,  8.3517e-02,  1.8272e-01,  7.0438e-02,\n",
       "                       4.7315e-02,  7.0042e-02,  1.6055e-01,  1.3602e-01, -3.8669e-02,\n",
       "                       1.1194e-01,  1.7184e-01,  1.3151e-01,  1.2378e-01, -1.0431e-02,\n",
       "                       7.9574e-02,  1.3556e-01,  1.1904e-01,  3.3688e-02,  2.0027e-01,\n",
       "                       1.2238e-01,  2.8329e-01,  1.0695e-01,  2.0595e-01,  1.6444e-01,\n",
       "                       1.6890e-01,  2.5032e-01,  4.3933e-02,  1.6963e-01,  2.3779e-01,\n",
       "                       2.0613e-01,  1.7573e-01,  2.2836e-01, -1.0974e-02,  2.0712e-01,\n",
       "                      -6.4886e-02,  2.0249e-01,  1.4385e-01,  2.7365e-02,  2.1321e-01,\n",
       "                       1.8479e-01,  3.0514e-03, -2.7298e-02,  1.8298e-01, -8.0751e-02,\n",
       "                       1.8425e-01,  1.8322e-01,  1.3866e-01,  6.3697e-02,  2.6294e-02,\n",
       "                       3.8838e-01,  7.0429e-02,  4.0030e-01,  2.2746e-01, -2.4960e-02,\n",
       "                      -2.0232e-02,  2.6787e-02,  9.7068e-02,  1.8802e-01,  1.2569e-01,\n",
       "                       2.7718e-01,  2.2750e-01,  2.9663e-01,  3.3638e-01,  8.9139e-02,\n",
       "                       1.7602e-01, -4.8260e-02,  4.4185e-02,  2.7083e-01,  1.9070e-02,\n",
       "                       4.1770e-01,  2.6985e-01,  1.4979e-02,  2.6821e-01,  2.1408e-01,\n",
       "                       1.3509e-01,  4.1930e-02,  1.3979e-01,  2.1323e-01,  2.7013e-01,\n",
       "                       1.4418e-01,  1.8924e-01])),\n",
       "             ('bilstm_right_context_feature.weight_ih_l0',\n",
       "              tensor([[ 0.5438,  0.0393,  0.1644,  ..., -0.4266,  0.2362, -0.4965],\n",
       "                      [-0.0343, -0.2073,  0.1990,  ...,  0.0686,  0.0671,  0.0356],\n",
       "                      [ 0.1256, -0.4248,  0.2887,  ..., -0.1759, -0.0117,  0.1229],\n",
       "                      ...,\n",
       "                      [ 0.4085, -0.0146, -0.2080,  ..., -0.0210,  0.1897, -0.3348],\n",
       "                      [ 0.1806, -0.1359,  0.1575,  ..., -0.1507,  0.0779, -0.0590],\n",
       "                      [-0.1622, -0.2371,  0.1206,  ..., -0.1053,  0.1649,  0.1811]])),\n",
       "             ('bilstm_right_context_feature.weight_hh_l0',\n",
       "              tensor([[ 0.0951,  0.1212,  0.0969,  ...,  0.1778,  0.0709, -0.1825],\n",
       "                      [ 0.0770, -0.0541,  0.1434,  ..., -0.0150, -0.0036, -0.0496],\n",
       "                      [-0.0835, -0.0910, -0.0297,  ...,  0.0339, -0.0909, -0.0751],\n",
       "                      ...,\n",
       "                      [-0.1144,  0.0049,  0.1613,  ...,  0.0586, -0.0954,  0.1828],\n",
       "                      [-0.0380,  0.0212,  0.1237,  ..., -0.0065,  0.0295,  0.0996],\n",
       "                      [-0.0224, -0.1540, -0.1175,  ...,  0.0508,  0.0876,  0.0193]])),\n",
       "             ('bilstm_right_context_feature.bias_ih_l0',\n",
       "              tensor([-1.9154e-01, -1.2432e-01, -1.1893e-01, -1.4174e-01, -2.4919e-01,\n",
       "                      -4.7148e-02, -4.5203e-02, -5.9237e-02, -2.4528e-01, -1.4472e-01,\n",
       "                       4.8473e-02, -2.3294e-01, -1.2921e-01, -2.3346e-01, -2.1151e-01,\n",
       "                      -1.5496e-01, -1.5911e-01, -4.7978e-02, -1.0674e-01, -8.3497e-02,\n",
       "                      -6.0375e-02, -2.0465e-01, -1.1638e-01, -1.6576e-01, -8.8139e-02,\n",
       "                      -9.0415e-02, -7.5229e-02, -2.0836e-01, -1.0807e-01, -1.2710e-01,\n",
       "                      -1.4472e-01, -1.7133e-01,  5.3753e-02, -2.4574e-01, -8.5996e-02,\n",
       "                      -1.9020e-01, -1.7454e-01, -1.6735e-01, -1.4563e-01, -1.1978e-01,\n",
       "                      -1.6571e-01, -1.0755e-01, -2.3374e-01, -1.6970e-01, -1.8600e-01,\n",
       "                      -2.6125e-01, -7.4007e-02, -5.1084e-02, -1.8612e-01, -1.5585e-01,\n",
       "                      -5.9584e-03, -2.3621e-01, -6.6078e-02, -1.2523e-01, -2.0618e-01,\n",
       "                      -1.1151e-01, -1.2395e-01, -8.1566e-02, -2.7184e-01, -1.1359e-01,\n",
       "                      -2.8210e-01, -1.4574e-01, -1.7667e-01, -1.4181e-01, -9.8725e-02,\n",
       "                      -9.5600e-02, -1.1743e-01, -8.6285e-02, -1.9569e-01, -2.2125e-01,\n",
       "                      -1.0491e-01, -1.9082e-01, -1.2866e-01, -2.5641e-01, -1.5683e-01,\n",
       "                      -1.0884e-01, -2.2366e-01, -2.0924e-01, -1.4334e-01, -4.6967e-02,\n",
       "                      -1.0161e-01, -1.3525e-01, -1.6853e-01, -8.8141e-02, -5.4214e-02,\n",
       "                      -1.5331e-01, -1.4272e-01, -1.4730e-01, -2.4342e-01, -1.5517e-01,\n",
       "                      -1.1266e-01, -1.1794e-01, -1.6840e-01, -3.1120e-01, -7.8241e-02,\n",
       "                      -1.9943e-01, -2.1616e-01, -7.9108e-02, -1.3885e-01, -5.0960e-02,\n",
       "                      -1.9220e-01, -1.0784e-01, -1.9314e-01, -1.0198e-01, -1.4635e-01,\n",
       "                      -1.5693e-01, -5.5002e-02, -3.6423e-02, -1.0199e-01, -1.8222e-01,\n",
       "                      -1.5118e-01, -1.9912e-01, -1.2945e-01, -1.7110e-01, -9.4185e-02,\n",
       "                      -2.1202e-01, -2.3133e-01, -1.7770e-01, -1.0338e-01, -1.4577e-01,\n",
       "                      -1.3867e-01, -1.7300e-01, -8.4512e-02, -3.9444e-02, -1.0485e-01,\n",
       "                      -1.6906e-01, -3.9132e-02, -3.8699e-02, -2.9728e-01, -1.7090e-01,\n",
       "                      -3.4598e-02, -5.7057e-02, -1.2532e-01,  7.0936e-04, -1.2126e-01,\n",
       "                      -3.8860e-02, -1.8575e-01, -8.2274e-02, -2.0798e-01, -1.7117e-01,\n",
       "                      -1.3817e-01, -8.6133e-02, -5.6043e-02, -1.9918e-01, -1.4095e-01,\n",
       "                      -9.4128e-02, -4.9418e-02, -1.3869e-01, -2.0213e-01, -9.0774e-02,\n",
       "                       1.0460e-04, -2.1149e-01, -8.2538e-02, -3.9007e-02, -3.8119e-02,\n",
       "                      -1.3144e-01, -1.0649e-01, -1.7567e-01, -2.1144e-01, -7.3994e-02,\n",
       "                      -1.4265e-01, -6.0359e-02, -7.5568e-02, -5.5702e-02, -4.1776e-02,\n",
       "                      -9.7963e-02, -1.2009e-01, -1.1466e-01, -2.3039e-01, -1.9129e-01,\n",
       "                      -1.1801e-01, -6.5549e-02, -8.4422e-02, -1.0320e-02, -1.7832e-02,\n",
       "                      -1.3145e-01, -1.3752e-01, -1.5395e-02, -1.1964e-01, -1.4393e-01,\n",
       "                      -2.2929e-02, -1.1709e-01, -9.5182e-02, -1.0317e-01, -1.0886e-01,\n",
       "                      -1.5703e-01, -1.9350e-01, -4.9283e-02, -9.0663e-02, -1.5001e-01,\n",
       "                      -1.7640e-01, -2.3876e-02, -1.2601e-02, -1.2285e-01, -1.9366e-01,\n",
       "                      -1.4982e-01, -2.1759e-01, -7.5901e-02, -1.2004e-01, -8.4386e-02,\n",
       "                      -8.7103e-02, -1.0708e-01, -1.2604e-01, -1.5707e-01, -2.6682e-01,\n",
       "                      -1.1458e-01, -1.5007e-01,  1.4461e-03, -8.3808e-02, -1.6885e-01,\n",
       "                      -2.5122e-01, -1.7310e-01, -2.3510e-01, -3.3958e-02, -1.3084e-01,\n",
       "                      -9.4004e-02,  1.4360e-02, -2.2994e-01, -1.5093e-01, -1.4559e-01,\n",
       "                      -1.4026e-01, -2.3512e-02, -7.3397e-02, -1.0438e-01, -5.8269e-02,\n",
       "                      -2.4422e-02, -9.8606e-02, -2.0291e-01, -1.6061e-01, -1.7410e-02,\n",
       "                      -1.4624e-01, -6.0320e-02, -1.3119e-01, -1.9923e-01, -1.4223e-01,\n",
       "                      -1.2876e-01, -1.0203e-01, -7.5094e-02, -4.1026e-02, -1.6742e-01,\n",
       "                      -2.9789e-02, -1.8293e-01,  2.3470e-02, -5.5229e-02, -1.9393e-01,\n",
       "                      -8.8911e-02, -1.1029e-01, -8.4324e-02, -2.3598e-01,  3.1151e-02,\n",
       "                      -1.2922e-01,  1.1061e-03,  7.2308e-02, -8.5314e-02, -1.5491e-01,\n",
       "                      -1.0992e-01,  9.8652e-04,  5.9108e-02, -4.6680e-02,  8.3482e-02,\n",
       "                       4.9047e-02,  6.9165e-02,  1.4901e-02,  1.0916e-01,  4.8158e-02,\n",
       "                       2.8059e-02, -1.1334e-01,  1.2116e-02,  6.4648e-02, -3.0006e-02,\n",
       "                      -9.0813e-02,  2.6799e-02,  7.6935e-02,  3.0960e-03, -3.3441e-02,\n",
       "                      -2.9023e-02, -2.8536e-02, -6.2329e-02,  4.9771e-03, -2.6985e-02,\n",
       "                       2.0569e-02,  9.8138e-02, -1.5559e-02,  5.9858e-02,  2.3401e-02,\n",
       "                       4.9791e-02,  9.5726e-02,  4.2544e-02, -4.8879e-02, -2.0478e-02,\n",
       "                       1.7194e-02,  6.5628e-02,  3.5349e-02, -3.2151e-02, -1.0495e-02,\n",
       "                       7.5569e-02,  9.8417e-02, -7.7986e-04, -1.2085e-02, -5.0929e-02,\n",
       "                      -9.7860e-02,  1.7457e-02,  2.4858e-02, -7.0251e-02,  1.8425e-02,\n",
       "                       5.0797e-03, -1.7232e-02,  5.0827e-02,  8.3236e-02, -6.0537e-02,\n",
       "                      -3.8620e-02,  4.7646e-02, -4.6487e-02, -5.0856e-02, -5.0457e-02,\n",
       "                      -4.9687e-02,  3.0560e-02,  6.3190e-03,  7.5113e-02, -4.0820e-02,\n",
       "                       1.0718e-01, -7.3306e-03,  3.1282e-02, -3.6201e-02, -7.5766e-02,\n",
       "                      -8.0712e-03, -2.4101e-02, -3.7110e-02, -3.2879e-03,  5.1829e-02,\n",
       "                       1.0814e-01, -6.8255e-03,  5.8793e-03, -1.6573e-02, -6.8217e-02,\n",
       "                      -4.6986e-02, -3.8903e-02, -5.5358e-02,  1.1881e-02, -3.3540e-02,\n",
       "                       1.2074e-01, -1.2390e-02, -9.9909e-02, -1.0554e-01, -3.1975e-02,\n",
       "                       2.4863e-02,  4.3251e-02, -8.4204e-02, -5.0426e-02, -1.4011e-02,\n",
       "                      -1.5471e-01,  8.8610e-03,  4.7523e-02,  4.6384e-02, -1.7330e-04,\n",
       "                      -1.7814e-02,  6.1963e-03, -7.3441e-02,  7.5869e-02,  8.3354e-03,\n",
       "                      -3.5627e-03,  4.0412e-02,  4.1779e-02, -5.0764e-03, -3.6976e-02,\n",
       "                      -1.5513e-02, -1.1904e-02,  3.2440e-02,  2.0305e-02,  1.2148e-02,\n",
       "                      -7.7931e-02,  1.5523e-02, -4.3383e-02,  6.6245e-02,  3.4332e-02,\n",
       "                      -7.0078e-03, -1.2065e-02, -3.4813e-02,  6.5018e-02,  7.4570e-02,\n",
       "                       1.8477e-02, -8.3826e-02, -5.1889e-02, -1.3485e-01, -7.7525e-02,\n",
       "                      -3.0654e-01, -2.5766e-01, -2.2237e-01, -9.8957e-02,  8.8410e-03,\n",
       "                      -9.3871e-02, -2.4463e-02, -4.2007e-03, -1.8000e-02, -1.3640e-01,\n",
       "                      -1.2135e-01, -3.3716e-02, -1.2454e-01, -1.6361e-01, -1.3057e-01,\n",
       "                      -8.1467e-02, -5.2515e-02, -3.0251e-01, -1.2182e-01, -2.2958e-01,\n",
       "                      -1.7780e-01, -3.8829e-02, -1.1058e-01, -3.2376e-02, -1.9867e-01,\n",
       "                      -1.4931e-01, -1.6139e-01, -8.5827e-02, -6.8200e-02, -8.3527e-02,\n",
       "                      -9.7112e-02, -7.0528e-02, -1.4220e-01, -8.7802e-02, -1.4435e-01,\n",
       "                      -1.5631e-01,  1.6327e-02, -1.5522e-01, -2.5001e-02, -1.7876e-01,\n",
       "                      -1.0105e-01, -1.0372e-01, -2.1997e-01, -1.7206e-01, -2.5077e-01,\n",
       "                      -1.2463e-01, -9.1644e-02, -1.1556e-01, -2.4073e-01, -1.9755e-01,\n",
       "                      -1.6171e-01, -8.7406e-02, -1.9357e-01, -2.3992e-01, -1.1151e-01,\n",
       "                      -2.3586e-02, -9.8946e-02, -1.3866e-01, -8.0767e-02, -1.0525e-01,\n",
       "                      -1.3155e-01, -5.8712e-02, -1.6528e-01, -1.6692e-01, -9.4805e-02,\n",
       "                      -2.1796e-01, -6.9682e-02, -2.1953e-01, -1.4749e-01, -1.1391e-01,\n",
       "                      -2.7645e-01, -2.5709e-01, -1.1392e-01, -1.2703e-01, -1.6360e-01,\n",
       "                      -1.4436e-01, -2.4780e-01, -8.1376e-02, -1.1403e-01, -9.5875e-02,\n",
       "                      -8.0807e-02, -1.4361e-01,  1.8904e-02, -1.4089e-01,  4.2182e-02,\n",
       "                      -6.8238e-02, -6.7640e-02, -1.5123e-01, -4.3520e-02, -6.8789e-02,\n",
       "                      -1.3282e-01, -2.1165e-01, -8.5608e-02, -2.8148e-01, -1.5975e-01,\n",
       "                      -7.4507e-02, -7.0127e-02, -2.6629e-02, -1.2433e-01,  9.9718e-03,\n",
       "                      -3.8554e-02, -2.3027e-01, -7.8331e-02, -1.1471e-01, -2.2652e-01,\n",
       "                      -8.2343e-02,  3.8774e-02, -1.3596e-01,  9.5866e-03, -1.5220e-01,\n",
       "                      -1.6588e-01, -1.5910e-01, -1.6144e-01, -9.2794e-02, -9.5658e-02,\n",
       "                      -8.0723e-02, -1.9341e-01, -9.7466e-02, -1.5431e-01, -1.8569e-01,\n",
       "                      -1.1995e-01, -1.8543e-01, -1.9578e-01, -1.4273e-01, -1.6371e-01,\n",
       "                      -2.0316e-01, -2.9467e-02])),\n",
       "             ('bilstm_right_context_feature.bias_hh_l0',\n",
       "              tensor([-0.2303, -0.0697, -0.1875, -0.1541, -0.2324, -0.1491, -0.0335, -0.0111,\n",
       "                      -0.1939, -0.0929, -0.2212, -0.1378, -0.1310, -0.0638, -0.0412, -0.2719,\n",
       "                      -0.1927, -0.1661, -0.1278, -0.0964, -0.2286, -0.3107, -0.0181, -0.1453,\n",
       "                      -0.1310, -0.0543, -0.1493, -0.2195, -0.0873, -0.1819, -0.2060,  0.0186,\n",
       "                      -0.0786, -0.2028, -0.1386, -0.2227, -0.1511, -0.0658, -0.1682, -0.1017,\n",
       "                      -0.2155, -0.0904, -0.2559, -0.1549, -0.1100, -0.3055, -0.2322, -0.1343,\n",
       "                      -0.0925, -0.1911, -0.2387, -0.3977,  0.0031, -0.1904, -0.1686, -0.0877,\n",
       "                      -0.2176, -0.0149, -0.1890, -0.0871, -0.0746, -0.0442, -0.1058, -0.1105,\n",
       "                      -0.1470, -0.1997, -0.1383, -0.1235, -0.2260, -0.2107, -0.1493, -0.1105,\n",
       "                      -0.3016, -0.2189, -0.1932, -0.2329, -0.2233, -0.2043, -0.1742, -0.0421,\n",
       "                      -0.0710, -0.1515, -0.1786, -0.1275, -0.1645, -0.0747, -0.2579, -0.2379,\n",
       "                      -0.1020, -0.0940, -0.1775, -0.1269, -0.1420, -0.0533, -0.1755, -0.0125,\n",
       "                      -0.2883, -0.1450, -0.0771, -0.1288, -0.0664, -0.1614, -0.1615, -0.2671,\n",
       "                      -0.0662, -0.1258, -0.1145, -0.0769, -0.0244, -0.1061, -0.1353, -0.0129,\n",
       "                      -0.1163, -0.2320, -0.1026, -0.0667, -0.1013, -0.1666, -0.1929, -0.1245,\n",
       "                      -0.2197, -0.2028, -0.1447, -0.0943, -0.1523, -0.1251, -0.1361, -0.1348,\n",
       "                      -0.2400, -0.0253, -0.1516, -0.1159, -0.1793, -0.1099, -0.1295,  0.0006,\n",
       "                      -0.1388,  0.0041, -0.0853, -0.2165, -0.1871, -0.0830, -0.2340, -0.2428,\n",
       "                      -0.0775, -0.0462, -0.0755, -0.0794, -0.2200, -0.1844, -0.1006, -0.1046,\n",
       "                      -0.1198, -0.0689, -0.0140, -0.0028, -0.2600, -0.1083, -0.2073, -0.1064,\n",
       "                      -0.1269, -0.1703, -0.1766, -0.1770, -0.2168, -0.1791, -0.1078, -0.1680,\n",
       "                      -0.1389, -0.1225, -0.1506, -0.0007, -0.1303, -0.0972, -0.0318, -0.1012,\n",
       "                      -0.1858, -0.0490, -0.0901, -0.1394, -0.1059, -0.2083, -0.0187,  0.0080,\n",
       "                      -0.2204, -0.1206, -0.1003, -0.0423, -0.0885, -0.1221, -0.1178,  0.0562,\n",
       "                      -0.0858, -0.1442, -0.1412, -0.0899, -0.1193, -0.1950, -0.1436, -0.1185,\n",
       "                      -0.2717, -0.0514, -0.0381, -0.1079, -0.1471, -0.1021, -0.0790, -0.1546,\n",
       "                       0.0215, -0.2813, -0.1929, -0.1884, -0.0931, -0.1081, -0.1301, -0.1618,\n",
       "                      -0.2105, -0.0540, -0.1202, -0.1162, -0.0797, -0.0627, -0.1749, -0.0996,\n",
       "                      -0.0692,  0.0142, -0.1824, -0.0321, -0.1160, -0.0700, -0.1388, -0.2106,\n",
       "                      -0.0473, -0.2240, -0.1269, -0.1592, -0.1388, -0.1539, -0.0306, -0.0506,\n",
       "                      -0.0833, -0.1842, -0.0459, -0.0198, -0.0676, -0.1217,  0.0136, -0.0823,\n",
       "                      -0.1042, -0.1316, -0.2393, -0.3118, -0.0760, -0.0839, -0.1199, -0.0234,\n",
       "                      -0.0609, -0.0907,  0.0021,  0.0174, -0.1269,  0.0285,  0.1749,  0.0440,\n",
       "                       0.0845,  0.0156,  0.0137, -0.0302, -0.0302, -0.0981,  0.0824,  0.0475,\n",
       "                       0.0147,  0.0560,  0.1134, -0.0887,  0.0068, -0.0680,  0.0286,  0.0060,\n",
       "                      -0.0791, -0.0157,  0.1553,  0.0312, -0.0179,  0.0110, -0.0220,  0.0749,\n",
       "                      -0.0689,  0.0194,  0.1485, -0.0309,  0.0439, -0.0085, -0.0750, -0.0206,\n",
       "                       0.0214,  0.0051,  0.0136,  0.1257, -0.0008,  0.0064, -0.0043, -0.0768,\n",
       "                      -0.0010, -0.0178,  0.0052,  0.0074, -0.0075,  0.0406, -0.0321, -0.0009,\n",
       "                       0.0208, -0.0195,  0.0940, -0.0719, -0.0591, -0.0102, -0.1832,  0.1096,\n",
       "                       0.0515, -0.0322, -0.1051,  0.0233,  0.0309,  0.0681,  0.0446, -0.0698,\n",
       "                       0.0207,  0.0365, -0.0202,  0.0345,  0.0279, -0.0259,  0.0421,  0.0015,\n",
       "                       0.0189,  0.0038, -0.0169,  0.1022, -0.0458, -0.0035,  0.0038, -0.0281,\n",
       "                      -0.0450,  0.1298,  0.0666, -0.0576,  0.0315,  0.0156,  0.0642,  0.0318,\n",
       "                       0.0988,  0.0806,  0.0496,  0.1555,  0.0361,  0.0510,  0.0095, -0.0767,\n",
       "                       0.0773, -0.0090,  0.0499, -0.0537, -0.0326, -0.0423,  0.0036, -0.0148,\n",
       "                       0.0202, -0.0120,  0.1219, -0.0560,  0.0016,  0.0700, -0.0609,  0.0223,\n",
       "                      -0.0048,  0.0266,  0.0491,  0.0254,  0.0448,  0.0132, -0.0130, -0.0251,\n",
       "                      -0.2450, -0.2348, -0.1776,  0.0156, -0.1374, -0.2378, -0.0336, -0.0984,\n",
       "                      -0.1822, -0.1286, -0.1684, -0.1538, -0.1832, -0.1637, -0.1098, -0.1324,\n",
       "                      -0.0053, -0.0577, -0.1679, -0.1440, -0.1167, -0.0756, -0.1100, -0.0860,\n",
       "                      -0.1895, -0.0926, -0.1019, -0.0684, -0.2063, -0.0606, -0.0829, -0.1880,\n",
       "                      -0.0507, -0.1856, -0.1036, -0.1622, -0.1296, -0.1950, -0.1470, -0.1662,\n",
       "                      -0.2447, -0.1187, -0.1095, -0.1854, -0.1659, -0.0696, -0.0791, -0.1280,\n",
       "                      -0.1415, -0.1028, -0.1265, -0.1990, -0.0112, -0.2399, -0.3024, -0.0657,\n",
       "                      -0.0720, -0.1306, -0.1247,  0.0537, -0.1608, -0.2147, -0.1047, -0.1493,\n",
       "                      -0.1035, -0.0590, -0.1565, -0.1876, -0.1859, -0.2277, -0.1268, -0.1129,\n",
       "                      -0.2152, -0.0972, -0.1921, -0.1338, -0.1872, -0.1402, -0.0963, -0.1022,\n",
       "                      -0.0873, -0.1128, -0.1800, -0.0046, -0.1974, -0.0210, -0.1088, -0.1159,\n",
       "                      -0.0601, -0.1402,  0.0082, -0.0615, -0.3509, -0.0803, -0.0709, -0.0568,\n",
       "                      -0.1989, -0.1624, -0.1000, -0.1194, -0.0636, -0.1654, -0.2292, -0.2188,\n",
       "                      -0.0307, -0.0680, -0.1474, -0.1681, -0.1772,  0.0263, -0.0669, -0.0886,\n",
       "                      -0.0905, -0.1853, -0.0580, -0.0780, -0.1866, -0.0920, -0.1411, -0.2610,\n",
       "                      -0.3151, -0.1686, -0.0665, -0.1000, -0.0988, -0.0860, -0.2657, -0.0334])),\n",
       "             ('bilstm_right_context_feature.weight_ih_l0_reverse',\n",
       "              tensor([[ 0.1408,  0.0621, -0.3366,  ..., -0.1504,  0.1133, -0.4022],\n",
       "                      [-0.2375,  0.0361,  0.3343,  ...,  0.3435, -0.0578, -0.0036],\n",
       "                      [-0.0082,  0.1839,  0.1549,  ...,  0.0056,  0.0938, -0.1180],\n",
       "                      ...,\n",
       "                      [-0.5144, -0.0341,  0.3428,  ...,  0.1042,  0.1911, -0.0043],\n",
       "                      [ 0.0365,  0.1039, -0.1410,  ..., -0.0117,  0.3307, -0.0464],\n",
       "                      [ 0.2812, -0.3854,  0.3164,  ...,  0.2299,  0.0128,  0.0736]])),\n",
       "             ('bilstm_right_context_feature.weight_hh_l0_reverse',\n",
       "              tensor([[ 3.0193e-02, -8.6536e-02,  2.0597e-02,  ...,  1.2624e-02,\n",
       "                        2.0239e-01,  1.8395e-01],\n",
       "                      [ 2.2311e-01, -1.1567e-01,  8.7041e-02,  ...,  4.0960e-01,\n",
       "                        2.7820e-01,  6.7198e-02],\n",
       "                      [ 1.5003e-01,  5.1410e-02, -2.0281e-01,  ..., -2.1292e-01,\n",
       "                       -3.8757e-02, -3.1050e-01],\n",
       "                      ...,\n",
       "                      [ 4.5811e-01,  1.3651e-01,  1.8332e-01,  ..., -8.9180e-02,\n",
       "                        1.4648e-01,  4.1309e-02],\n",
       "                      [ 1.1617e-01, -3.4265e-04, -1.1610e-01,  ...,  1.8560e-01,\n",
       "                       -4.4761e-04, -1.4558e-02],\n",
       "                      [-5.6453e-02, -3.0001e-01,  2.6878e-01,  ...,  7.3715e-02,\n",
       "                       -2.1813e-02,  7.8032e-02]])),\n",
       "             ('bilstm_right_context_feature.bias_ih_l0_reverse',\n",
       "              tensor([-1.3073e-02,  4.7834e-02,  2.3998e-02,  3.0355e-02,  8.8437e-02,\n",
       "                       1.5273e-02,  4.8001e-04,  3.4694e-02,  4.2614e-02, -5.5187e-02,\n",
       "                       5.1928e-02,  1.1177e-01,  1.5289e-01,  1.2780e-01, -2.0983e-02,\n",
       "                      -8.9748e-02, -5.9383e-03, -5.7658e-02,  1.9592e-01, -6.3227e-02,\n",
       "                      -6.5090e-02,  1.7551e-02,  3.2776e-01, -3.6251e-02,  2.0226e-01,\n",
       "                      -6.7358e-02,  3.2320e-02,  1.7073e-01,  6.1274e-02,  1.0051e-01,\n",
       "                       1.1433e-01, -6.5015e-03,  1.5499e-01, -4.4538e-02,  5.5589e-02,\n",
       "                      -1.9099e-02, -6.7009e-02,  6.4047e-02, -1.1571e-01,  4.9031e-03,\n",
       "                       1.0771e-01, -2.8103e-02,  6.8458e-02,  7.0751e-02,  1.2551e-01,\n",
       "                       6.2747e-02,  3.0702e-02,  3.7048e-02,  1.3488e-01, -3.3669e-02,\n",
       "                       1.9076e-01,  5.2841e-02,  2.5020e-01,  1.3773e-01,  1.1665e-01,\n",
       "                       1.4749e-01,  3.2860e-03, -4.5838e-02,  9.4300e-02, -1.1471e-02,\n",
       "                      -1.4207e-01,  1.1740e-01,  2.6184e-02,  1.7409e-01,  2.0763e-02,\n",
       "                       8.3334e-02,  5.7753e-02,  2.0779e-01, -3.5262e-02,  3.8750e-03,\n",
       "                       1.1778e-01,  1.9905e-02,  1.4793e-01,  1.1677e-01,  9.4557e-02,\n",
       "                      -1.3029e-01,  2.7779e-03, -4.5110e-02,  4.7307e-02, -1.2862e-01,\n",
       "                       2.0372e-01,  6.0623e-02, -5.3262e-02, -1.3041e-01,  1.4492e-01,\n",
       "                       6.8351e-02,  9.9778e-02, -8.5929e-03,  2.7837e-01, -9.5884e-03,\n",
       "                       7.1190e-02,  6.3303e-02, -9.1322e-02, -4.8219e-03,  8.4340e-04,\n",
       "                       2.4234e-02,  1.0155e-02, -2.9326e-02, -1.3684e-02,  6.7194e-02,\n",
       "                       1.8703e-02,  9.2626e-02, -8.6272e-02, -1.5082e-01, -2.0861e-02,\n",
       "                       8.1389e-02, -5.9643e-02, -6.0973e-02,  4.1367e-02,  7.6502e-02,\n",
       "                       3.0456e-02,  1.1384e-01,  1.6828e-01,  4.9381e-02, -5.7682e-02,\n",
       "                      -1.3011e-02,  2.3766e-02,  6.2822e-02,  6.5387e-02, -6.0759e-02,\n",
       "                      -7.8062e-02,  1.3715e-01,  5.6195e-02,  6.3824e-02, -1.7186e-01,\n",
       "                       8.6558e-02,  5.7191e-03, -4.4028e-03,  2.6113e-02, -9.8614e-02,\n",
       "                       6.5348e-02,  7.3475e-02, -1.1902e-01, -1.7556e-01, -1.0842e-01,\n",
       "                       4.5792e-02,  8.2043e-02, -6.0825e-02, -7.8639e-02, -7.4132e-02,\n",
       "                      -7.8926e-02, -2.3597e-01,  3.2506e-02, -1.3633e-01, -1.2487e-01,\n",
       "                      -1.8097e-01,  4.0031e-02, -1.9144e-01,  7.7602e-02,  7.8501e-02,\n",
       "                      -8.7676e-02, -1.3932e-01,  5.8047e-02, -2.2001e-02,  3.0919e-02,\n",
       "                       6.8085e-02, -8.0254e-02, -3.1081e-02, -1.2249e-01, -9.3199e-02,\n",
       "                      -5.8971e-02,  2.5250e-02,  5.0359e-02, -1.1368e-01, -1.9875e-02,\n",
       "                       6.0499e-02, -1.3946e-01, -1.2020e-01, -3.2078e-02,  2.8648e-02,\n",
       "                      -3.8201e-02, -7.8514e-02,  2.1706e-02, -2.6766e-02, -4.3982e-02,\n",
       "                       1.0462e-01, -4.9879e-02,  6.7194e-03, -2.4559e-01, -2.4837e-02,\n",
       "                      -6.7803e-03, -2.7998e-02, -6.0147e-02, -1.3574e-01, -1.0042e-01,\n",
       "                       6.8271e-02,  1.3126e-02, -4.6077e-02,  1.2462e-02, -4.6092e-02,\n",
       "                       3.9323e-02, -1.6574e-01, -1.1555e-02, -9.0878e-03, -9.8723e-02,\n",
       "                      -1.4335e-01, -1.8707e-02, -1.3159e-01,  6.5052e-02, -1.7673e-02,\n",
       "                      -2.3708e-02, -1.3863e-01,  3.0994e-03, -1.0614e-01,  4.7688e-02,\n",
       "                      -7.2872e-02, -1.6172e-01, -7.7687e-02,  2.5389e-02,  1.7005e-02,\n",
       "                      -9.8333e-02, -1.2626e-01, -1.2070e-01, -2.1696e-01, -7.9009e-02,\n",
       "                      -5.6263e-02, -4.8247e-02, -4.4319e-02,  1.2183e-01, -8.3915e-02,\n",
       "                      -1.3959e-01, -5.4957e-03,  5.7627e-02, -1.0592e-02,  1.7720e-02,\n",
       "                       6.1890e-03, -1.1882e-01,  3.3564e-02, -1.5844e-01, -7.6030e-02,\n",
       "                      -2.0296e-01,  6.3397e-02, -5.4802e-02, -6.2484e-02, -3.3635e-02,\n",
       "                       5.3844e-02,  2.3384e-02, -1.4778e-01,  8.0019e-02, -2.7772e-03,\n",
       "                       1.6872e-02, -1.3223e-01, -4.2850e-02, -1.0159e-01, -7.8093e-02,\n",
       "                       6.8945e-02,  9.5613e-02, -9.5238e-02, -5.1501e-02, -6.8168e-02,\n",
       "                      -1.8867e-01, -7.1215e-02, -1.1567e-01,  8.4800e-02, -4.8048e-02,\n",
       "                       1.6290e-01, -5.2616e-02,  5.6417e-03,  2.6241e-02,  3.7436e-02,\n",
       "                      -3.4513e-05, -6.4863e-02,  3.1085e-02,  1.1617e-02, -1.2159e-01,\n",
       "                      -3.4113e-02,  1.7002e-01, -6.9185e-02, -2.9133e-02, -2.8490e-02,\n",
       "                      -6.9311e-02, -2.3180e-02, -1.6953e-01,  3.9272e-02, -1.5820e-01,\n",
       "                      -5.3978e-02,  1.0661e-02,  1.8745e-01, -5.2251e-02, -1.1669e-02,\n",
       "                      -6.8538e-02,  6.6528e-02,  6.0290e-04, -6.0786e-02, -2.0703e-02,\n",
       "                      -1.1863e-01, -4.8389e-02, -3.8088e-02, -6.2979e-02,  6.9229e-02,\n",
       "                      -7.4314e-02,  4.3681e-02, -2.4407e-02, -1.2632e-02,  3.1629e-02,\n",
       "                       3.3187e-02,  2.0006e-02, -3.2949e-02, -7.3780e-02, -7.9653e-02,\n",
       "                      -6.1132e-02,  6.6347e-03, -2.3580e-03, -1.9185e-02,  2.7548e-02,\n",
       "                       1.4076e-01,  6.5236e-02,  4.8240e-02,  6.0254e-02, -1.0611e-01,\n",
       "                      -3.0615e-02,  1.0633e-01, -8.8667e-02,  2.6150e-02,  1.2573e-02,\n",
       "                      -5.1492e-02,  2.7585e-02, -1.3699e-01, -1.4731e-01, -8.0355e-02,\n",
       "                      -2.6133e-03, -1.2433e-01,  1.2562e-01,  6.1641e-02, -3.3785e-02,\n",
       "                       4.1430e-02, -1.6596e-02, -7.0468e-02, -1.9364e-02,  1.4959e-01,\n",
       "                       1.6521e-02,  1.4312e-01,  7.0774e-03,  1.4354e-02, -3.3565e-02,\n",
       "                      -4.8617e-02, -4.8710e-03,  3.5970e-02,  6.4778e-02,  5.8615e-02,\n",
       "                      -3.5385e-02, -6.5137e-02, -9.0527e-02, -9.8674e-03,  5.9757e-02,\n",
       "                      -1.0708e-01,  8.1770e-02, -4.6864e-03,  1.9306e-02, -1.9496e-02,\n",
       "                      -9.6561e-03, -3.0343e-02,  2.3162e-02,  2.5118e-02,  7.7648e-02,\n",
       "                      -2.0056e-02, -1.1208e-02, -4.0672e-02, -2.9300e-02,  2.3938e-02,\n",
       "                      -1.4569e-03, -1.2420e-01,  4.7181e-02,  1.6180e-02, -1.2314e-01,\n",
       "                       6.0937e-03, -8.5306e-02, -8.2808e-03,  9.0876e-02, -5.5831e-02,\n",
       "                       8.3961e-02, -6.7905e-02, -1.9634e-02,  2.4686e-03,  9.0648e-03,\n",
       "                      -2.2740e-02,  7.1869e-02,  5.2847e-02,  2.3603e-02, -1.0829e-01,\n",
       "                      -7.2957e-02, -9.0986e-02,  4.3310e-02,  1.1234e-01,  2.6908e-01,\n",
       "                      -1.7445e-01, -1.2319e-01,  7.8662e-02,  3.3059e-02,  1.2319e-01,\n",
       "                       7.4885e-02,  1.7153e-01, -1.2698e-01, -5.5084e-02,  1.0483e-01,\n",
       "                       1.6182e-01,  5.0939e-02,  5.3224e-02,  8.4718e-02,  4.4856e-02,\n",
       "                       1.1974e-01, -5.2465e-02,  1.0850e-01,  4.7743e-02, -1.8468e-02,\n",
       "                      -7.6178e-02,  1.5974e-01, -8.1895e-02,  1.9219e-01, -3.8226e-02,\n",
       "                       4.9236e-02,  2.2196e-01,  2.0414e-01,  1.8248e-02,  2.9181e-01,\n",
       "                       3.5473e-02,  3.0213e-02,  1.0444e-01,  5.0642e-02,  3.0151e-02,\n",
       "                      -1.2127e-01,  1.8151e-02,  7.2555e-02,  8.0793e-02,  4.2459e-02,\n",
       "                       9.3805e-02, -3.2599e-02,  1.0616e-01,  1.5273e-01,  1.0970e-01,\n",
       "                       9.5954e-02, -2.9964e-02,  1.2944e-01,  2.1733e-02,  1.4516e-01,\n",
       "                       4.9922e-02,  7.3992e-02, -2.8544e-02,  2.6615e-01,  9.8884e-02,\n",
       "                       4.3620e-02,  2.0382e-02,  7.1108e-02,  2.6967e-02, -5.8432e-02,\n",
       "                      -1.1828e-01,  9.6620e-02,  2.8273e-01,  9.8052e-03,  3.3131e-03,\n",
       "                       6.4706e-02,  2.5693e-01,  1.2207e-01,  1.0372e-01,  6.3054e-02,\n",
       "                      -2.1199e-02,  2.4244e-01,  1.7975e-01,  1.6541e-02,  1.0705e-02,\n",
       "                       1.2015e-01, -2.0672e-01,  7.8267e-02,  1.7483e-01,  1.0455e-01,\n",
       "                       4.2255e-02, -3.5661e-02, -2.0657e-03,  2.0801e-01,  1.7477e-01,\n",
       "                       1.9079e-01,  5.8985e-02,  3.4933e-01,  8.4125e-02, -8.7704e-02,\n",
       "                      -3.7800e-02,  1.3201e-02,  2.0933e-01,  4.4011e-02,  1.3385e-01,\n",
       "                       1.6322e-01, -2.3211e-03,  1.4615e-01,  5.4962e-02,  9.8198e-02,\n",
       "                       1.5516e-02, -7.1982e-02, -6.7161e-02, -1.8553e-01,  1.1167e-01,\n",
       "                       1.2630e-01,  1.2137e-01,  2.3558e-01,  1.6897e-01, -3.4690e-03,\n",
       "                       1.2024e-01,  1.0806e-01,  1.1022e-01, -5.9904e-02,  1.1327e-01,\n",
       "                       3.4616e-02,  2.0670e-01, -7.1102e-03,  6.6760e-02,  7.2425e-02,\n",
       "                       1.0624e-02, -8.1556e-02,  1.0350e-01, -1.3236e-02,  2.5939e-01,\n",
       "                       1.1865e-01,  5.5325e-02])),\n",
       "             ('bilstm_right_context_feature.bias_hh_l0_reverse',\n",
       "              tensor([ 1.5158e-01,  1.2902e-01, -3.7915e-03,  1.1568e-01,  4.8431e-02,\n",
       "                       3.7735e-02,  3.0412e-02,  6.3241e-02,  3.2659e-03, -5.8649e-02,\n",
       "                       1.5811e-01,  1.7344e-01,  1.5381e-01,  7.9735e-02,  1.0600e-01,\n",
       "                       1.0989e-01,  6.8684e-02, -9.1853e-02,  9.5139e-02,  7.1088e-02,\n",
       "                      -1.4200e-02,  1.3045e-01,  1.7178e-01,  7.3560e-02,  1.4565e-01,\n",
       "                      -2.8690e-02,  6.4229e-02,  2.3252e-02,  1.0901e-01,  1.4017e-02,\n",
       "                       1.2302e-01,  1.0829e-01,  3.6639e-02,  8.1235e-02, -1.6952e-01,\n",
       "                       9.1546e-02, -1.2509e-01,  2.2043e-02,  1.6149e-02, -1.4315e-02,\n",
       "                       9.1582e-02,  3.0528e-02,  3.9123e-02,  9.3467e-02,  1.3732e-01,\n",
       "                       8.7575e-02,  3.2424e-02,  4.0315e-02,  2.6881e-01, -1.2994e-01,\n",
       "                       2.7881e-01,  2.7340e-02,  4.1917e-02,  8.1464e-02,  9.3476e-02,\n",
       "                       1.1724e-01, -6.7949e-02, -3.6447e-02,  6.7035e-02,  8.2401e-03,\n",
       "                      -1.4764e-01,  6.4623e-02,  4.6756e-02,  1.8623e-01,  1.9715e-02,\n",
       "                      -4.8595e-02,  1.4321e-01,  2.6350e-01,  3.0142e-02, -4.2653e-02,\n",
       "                       1.0664e-01,  3.6497e-04,  2.0415e-01,  4.2192e-02,  2.2874e-02,\n",
       "                      -8.8275e-02,  5.6010e-02, -5.6063e-02,  6.5144e-02, -8.8159e-02,\n",
       "                       1.4444e-01,  1.1568e-01, -6.8066e-02, -5.5625e-02,  1.6819e-01,\n",
       "                       3.3233e-02,  1.7610e-01,  4.0359e-02,  1.9206e-01,  9.3733e-03,\n",
       "                      -4.6508e-03, -2.4298e-02, -4.9698e-02, -3.1574e-02,  9.4044e-02,\n",
       "                       1.3104e-01,  5.6870e-02,  1.7916e-02,  3.0952e-02,  3.0521e-02,\n",
       "                      -7.2437e-03, -5.2289e-02, -5.2090e-02,  7.4677e-02, -1.2634e-02,\n",
       "                       2.2253e-02, -5.4474e-02,  1.1583e-01,  1.0352e-01, -1.8183e-02,\n",
       "                       3.5556e-02,  7.4654e-02,  4.6903e-02,  1.6484e-01,  6.7963e-03,\n",
       "                      -1.5477e-01,  9.4521e-02,  1.7856e-01, -1.6207e-02,  3.5719e-02,\n",
       "                       7.9136e-02,  1.6749e-01, -3.0842e-02,  3.6783e-02, -2.4218e-02,\n",
       "                       1.2414e-01,  3.9884e-02, -2.8046e-02,  2.9396e-03, -4.0979e-02,\n",
       "                      -1.5956e-02, -1.8672e-01, -9.8865e-02, -1.8866e-01, -1.8639e-01,\n",
       "                       2.8849e-02, -9.5480e-02,  5.1981e-02, -7.1937e-02, -6.6300e-02,\n",
       "                      -2.6190e-02, -2.7042e-01,  3.4534e-02, -1.2561e-01,  7.0175e-02,\n",
       "                      -2.7273e-02, -1.9163e-01, -1.4122e-01,  1.1368e-01,  8.4034e-02,\n",
       "                       5.0140e-02, -2.4155e-01, -9.5415e-02, -3.7747e-02,  9.2108e-02,\n",
       "                       9.3815e-02, -4.8109e-02, -2.4495e-03, -4.4548e-03,  2.6407e-02,\n",
       "                       5.3074e-02,  4.3101e-02, -1.8195e-01, -1.1046e-01,  8.1110e-02,\n",
       "                       4.4801e-02, -1.1736e-01, -1.8969e-01, -1.3085e-01, -5.5423e-02,\n",
       "                      -7.3026e-02,  1.7703e-02, -6.6093e-02, -2.4053e-01,  4.2163e-02,\n",
       "                       1.1470e-01, -1.4150e-02, -6.3491e-02, -9.8017e-02, -1.0950e-01,\n",
       "                      -8.7574e-02, -1.4309e-01, -1.6678e-01, -7.3775e-04, -5.5725e-02,\n",
       "                      -7.1694e-02,  6.6495e-02, -1.2701e-01, -9.1740e-03, -5.2847e-02,\n",
       "                      -6.4469e-02, -2.3597e-01,  8.2365e-02, -1.2365e-01, -1.0983e-01,\n",
       "                       1.1553e-02, -1.0126e-01,  3.7589e-02,  4.4771e-02,  2.4330e-03,\n",
       "                      -7.6573e-02,  8.8092e-02, -1.1826e-01, -1.0537e-01, -3.0497e-02,\n",
       "                      -2.3466e-02, -1.1631e-01,  4.2215e-02, -6.7347e-02, -2.2355e-02,\n",
       "                      -1.2096e-01, -4.1985e-02, -1.2939e-01, -7.1627e-02, -1.0920e-01,\n",
       "                       2.8835e-02, -4.5380e-02, -3.1296e-02,  9.0501e-02, -1.8945e-02,\n",
       "                      -1.0854e-01, -1.2745e-01, -5.5706e-02, -2.3083e-02, -3.7477e-03,\n",
       "                      -1.4068e-01, -6.9780e-02, -9.5270e-03, -1.1094e-01, -1.3423e-01,\n",
       "                      -1.2468e-01, -4.7853e-02,  5.8449e-02, -1.6130e-01,  4.9128e-02,\n",
       "                       1.3085e-02,  7.8533e-02, -8.3774e-02,  3.3462e-02, -4.7098e-02,\n",
       "                      -2.9166e-02, -7.0437e-02,  1.8998e-02, -2.1173e-01, -1.6796e-01,\n",
       "                      -1.1077e-01,  1.1263e-01,  7.9008e-02, -2.5014e-02, -4.3561e-02,\n",
       "                      -1.9404e-01, -4.0889e-02, -1.4368e-01,  3.1624e-02,  2.7955e-03,\n",
       "                       3.7642e-02,  8.4856e-02, -5.3117e-02,  3.1437e-02, -4.5269e-02,\n",
       "                      -9.1442e-02, -6.7675e-02,  2.7752e-02, -1.1557e-01, -8.7465e-02,\n",
       "                      -1.6410e-01, -7.7001e-02,  3.6836e-02, -6.3326e-02, -2.9670e-02,\n",
       "                      -2.7155e-02,  8.1790e-03, -4.0141e-02,  8.2964e-02, -4.4214e-02,\n",
       "                      -1.4803e-03, -2.7376e-02, -7.3690e-02,  1.9754e-02,  1.8751e-02,\n",
       "                      -9.4922e-03, -5.9503e-02, -1.5613e-01,  4.9132e-02, -1.0241e-02,\n",
       "                      -6.8477e-02,  8.6594e-02,  4.9639e-02, -7.7791e-03,  5.4281e-02,\n",
       "                      -2.0185e-02, -4.6380e-02,  3.4874e-02, -6.9309e-02,  9.3928e-02,\n",
       "                      -1.7384e-02,  6.8443e-02,  9.6191e-02, -9.4247e-02,  3.2607e-03,\n",
       "                      -3.0239e-02,  7.3343e-02, -4.6067e-02, -8.1346e-03,  2.8806e-02,\n",
       "                       1.2897e-01,  6.6811e-02,  2.6850e-02,  3.2737e-02, -1.3248e-02,\n",
       "                       4.7120e-02,  8.3986e-02, -1.2135e-02, -1.6103e-02, -4.0863e-02,\n",
       "                       8.5706e-02, -2.8512e-02, -4.1345e-02, -8.5269e-02, -1.6833e-02,\n",
       "                       3.3493e-02, -1.1507e-01,  5.4781e-02,  5.3852e-03,  7.7304e-02,\n",
       "                      -4.8991e-03, -7.4891e-02, -1.1208e-01, -8.6266e-02, -1.6566e-02,\n",
       "                      -4.4900e-02,  1.0167e-01, -8.0666e-02, -8.1197e-02, -3.1203e-02,\n",
       "                      -2.6374e-02, -1.7928e-02,  1.5064e-01, -1.3382e-02, -8.0416e-02,\n",
       "                      -3.7687e-02, -1.2143e-01, -1.3612e-01,  5.2092e-02, -3.0148e-02,\n",
       "                      -1.4850e-01, -4.0343e-03,  8.3379e-02, -3.7479e-02,  3.7275e-02,\n",
       "                      -1.0742e-02,  5.2535e-02, -7.2600e-02, -3.3834e-02, -1.9135e-02,\n",
       "                      -1.1591e-01,  5.5697e-02,  2.3310e-02,  6.1659e-02,  2.7778e-02,\n",
       "                      -5.7812e-02, -8.5753e-02, -1.8843e-02, -1.5813e-01, -1.2859e-01,\n",
       "                       5.1766e-02, -4.3992e-02,  4.4418e-02, -5.1177e-02, -2.0334e-02,\n",
       "                      -4.7468e-02, -6.1892e-02, -3.0403e-02,  5.3239e-02,  1.4113e-01,\n",
       "                      -1.7360e-02, -3.7004e-02,  3.7318e-02, -2.6487e-02, -5.9864e-02,\n",
       "                      -7.6219e-02, -5.1776e-02,  1.0927e-01,  1.1436e-01,  2.0053e-01,\n",
       "                      -7.4429e-02, -5.2187e-02, -4.1900e-03,  5.7387e-02,  8.7127e-02,\n",
       "                      -5.6039e-02,  2.4073e-01, -2.4782e-03,  1.9783e-02,  1.2269e-01,\n",
       "                       5.1605e-02,  4.8901e-02,  1.6230e-01,  6.2595e-03,  2.8992e-02,\n",
       "                       7.2416e-02, -5.3832e-02,  7.2194e-02,  6.9720e-02,  6.5033e-02,\n",
       "                       1.0599e-01,  2.5551e-01,  8.6017e-03,  2.1694e-01, -1.5531e-01,\n",
       "                       7.6080e-02,  4.1513e-02,  2.8834e-01,  1.3226e-01,  2.3225e-01,\n",
       "                       2.2910e-02,  2.0818e-02,  6.0160e-02,  1.0790e-01,  5.2740e-02,\n",
       "                       5.9031e-03,  5.3000e-02,  4.2626e-02,  2.2882e-02, -1.3172e-03,\n",
       "                       3.1201e-02,  1.4631e-01,  1.3639e-01,  3.9672e-02,  1.0296e-01,\n",
       "                       1.6767e-01,  1.6309e-02,  1.4881e-01,  4.3092e-02,  8.2083e-02,\n",
       "                       1.8783e-03,  2.3086e-01, -4.5424e-02,  1.5962e-01,  5.4783e-02,\n",
       "                       1.7812e-02, -6.5767e-02,  1.1244e-01, -6.1383e-02, -1.2634e-01,\n",
       "                       2.4375e-02,  1.0012e-01,  2.5809e-01,  7.2798e-03,  3.1497e-02,\n",
       "                       1.5336e-02,  1.6511e-01,  2.3486e-02,  8.6011e-02,  1.9473e-01,\n",
       "                      -5.2088e-02,  1.5748e-01,  1.2001e-01,  2.6014e-02,  3.4550e-02,\n",
       "                       9.8366e-03, -7.2820e-02,  3.1049e-03,  8.0672e-02,  1.4413e-01,\n",
       "                       1.8125e-01, -1.9897e-02, -7.2730e-02,  2.3364e-01,  2.4158e-02,\n",
       "                       1.7229e-01,  8.2880e-02,  2.8397e-01, -1.2841e-01,  5.7584e-03,\n",
       "                      -7.8995e-02, -3.6731e-02,  1.3056e-01,  5.7672e-03,  9.6625e-02,\n",
       "                       1.0657e-01,  4.2147e-02,  4.5890e-02, -1.3655e-01,  2.4326e-02,\n",
       "                       1.6014e-01,  9.8888e-03, -3.2569e-02,  1.6828e-02,  1.9243e-01,\n",
       "                       1.9022e-04, -9.0328e-02,  1.2951e-02,  9.3251e-02, -1.0950e-01,\n",
       "                       7.7914e-02,  1.3679e-01,  1.5165e-01,  3.7146e-02, -5.4613e-02,\n",
       "                      -2.8168e-02,  3.4022e-02, -3.0579e-02,  1.2427e-02,  6.0375e-02,\n",
       "                       1.6136e-01,  3.9335e-02, -5.6957e-02,  1.0406e-01,  1.1277e-01,\n",
       "                       1.5986e-01, -1.1111e-02])),\n",
       "             ('fc.0.weight',\n",
       "              tensor([[ 6.8576e-02, -7.9702e-02, -6.7707e-02,  ...,  2.4140e-03,\n",
       "                        8.0645e-03, -1.2636e-01],\n",
       "                      [-1.7193e-04,  3.4199e-03, -9.2535e-02,  ...,  5.4300e-03,\n",
       "                       -1.7750e-01,  1.6643e-02],\n",
       "                      [-1.0560e-02,  1.4081e-01, -1.3934e-01,  ..., -8.5745e-02,\n",
       "                        1.8154e-01, -6.3082e-02],\n",
       "                      ...,\n",
       "                      [-1.7456e-01,  6.2454e-03,  1.9889e-02,  ..., -2.9847e-01,\n",
       "                        8.7382e-02,  4.9003e-01],\n",
       "                      [-1.8247e-01,  1.3590e-01, -1.5794e-01,  ...,  9.2496e-02,\n",
       "                        1.2180e-01, -2.8006e-01],\n",
       "                      [-4.0556e-02,  7.9207e-02, -7.3882e-02,  ..., -3.3567e-01,\n",
       "                        1.1069e-01,  1.9314e-01]])),\n",
       "             ('fc.0.bias',\n",
       "              tensor([ 0.1291,  0.1300, -0.2177,  0.1259, -0.0578, -0.2067, -0.0587,  0.1739,\n",
       "                      -0.1704,  0.0809,  0.0183,  0.0320,  0.0863, -0.0394,  0.0726, -0.1711,\n",
       "                      -0.0658,  0.1076,  0.1790,  0.1466,  0.0496,  0.1288,  0.0439, -0.1891,\n",
       "                      -0.3350,  0.2108,  0.0921, -0.0183, -0.3415, -0.0045, -0.0144, -0.1097,\n",
       "                       0.1889, -0.0746, -0.0113,  0.0434, -0.0105,  0.1908, -0.0648,  0.0507,\n",
       "                       0.0529,  0.2078,  0.0261, -0.2186,  0.1698, -0.0751,  0.3053, -0.0995,\n",
       "                      -0.2578, -0.1931,  0.2790,  0.0331, -0.0347, -0.1093,  0.1614,  0.0420,\n",
       "                       0.1154,  0.0642,  0.0831,  0.2189,  0.5056,  0.1008, -0.3215, -0.1870])),\n",
       "             ('oov_embedding.weight',\n",
       "              tensor([[-0.3999,  0.0045,  0.1593,  ..., -0.0097,  0.0360,  0.1963],\n",
       "                      [ 0.1828, -0.1034, -0.0005,  ...,  0.2340,  0.0901, -0.2588],\n",
       "                      [-0.3017, -0.1953,  0.1618,  ..., -0.0329, -0.1109,  0.0628],\n",
       "                      ...,\n",
       "                      [ 0.1947,  0.0467, -0.0020,  ...,  0.0510, -0.2566,  0.1257],\n",
       "                      [ 0.0555, -0.1220, -0.2357,  ...,  0.0917, -0.1356, -0.0453],\n",
       "                      [-0.2587, -0.4261, -0.0903,  ...,  0.2940, -0.0407, -0.0639]])),\n",
       "             ('oov_embedding.bias',\n",
       "              tensor([ 0.1572, -0.0908,  0.0160,  0.0624, -0.2473,  0.4262, -0.3778, -0.1638,\n",
       "                       0.1183, -0.0583,  0.1240,  0.1297, -0.2779, -0.0902,  0.0221,  0.0779,\n",
       "                       0.3736,  0.0977, -0.0559,  0.0383, -0.0448, -0.1363,  0.1682, -0.0592,\n",
       "                      -0.1097, -0.2284,  0.1157,  0.0242,  0.3400,  0.0942,  0.0492, -0.0527,\n",
       "                      -0.1590,  0.0140, -0.0601, -0.2531,  0.2519,  0.1757,  0.0597, -0.0616,\n",
       "                       0.0824,  0.0942, -0.0234,  0.0547, -0.0914,  0.0489, -0.5425,  0.0107,\n",
       "                      -0.3470, -0.1438,  0.0381,  0.1667,  0.2173,  0.0739, -0.2745,  0.0374,\n",
       "                       0.0478,  0.0998, -0.1455,  0.0414, -0.2303,  0.0967,  0.1077, -0.0040])),\n",
       "             ('prob.0.weight',\n",
       "              tensor([[ 0.0641,  0.0691,  0.2214,  ..., -0.2770, -0.1888, -0.1419],\n",
       "                      [-0.1325, -0.0111, -0.1429,  ...,  0.2121, -0.3016,  0.1196],\n",
       "                      [-0.0540,  0.2116,  0.0400,  ...,  0.3348, -0.1471, -0.2372],\n",
       "                      ...,\n",
       "                      [ 0.2294,  0.0684,  0.5732,  ...,  0.1385, -0.1240,  0.0585],\n",
       "                      [-0.0215, -0.1633,  0.3105,  ..., -0.3066, -0.0849,  0.2742],\n",
       "                      [-0.2495,  0.1749, -0.3454,  ...,  0.2039, -0.0973,  0.0983]])),\n",
       "             ('prob.0.bias',\n",
       "              tensor([-0.6765, -0.0956, -0.0351,  ..., -0.0487, -0.1619, -0.0460]))])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1616de6-2ec1-4a77-980a-addd6d77d6d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
