{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13fc63c4-da08-43a8-9972-2615d377d1fa",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "313363b9-24d1-4b87-87cd-a0b7dd5fc128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "import timeit\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime\n",
    "from itertools import chain\n",
    "from time import time\n",
    "from torch import nn, optim\n",
    "from torchmetrics import F1Score\n",
    "from torch.optim import lr_scheduler\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from polyglot.mapping import Embedding, CaseExpander, DigitExpander\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b49405-006a-4a45-ae79-0e22f6a7172e",
   "metadata": {},
   "source": [
    "# Hyperparameters Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68709d29-24a1-45bf-b549-804952fd1db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HyperparamsDataset:\n",
    "    def __init__(\n",
    "        self,\n",
    "        left_context_seq_len = None,\n",
    "        oov_context_seq_len = None,\n",
    "        right_context_seq_len = None,\n",
    "        n_features_left_context = None,\n",
    "        n_features_oov_context = None,\n",
    "        n_features_right_context = None,\n",
    "        device=device\n",
    "    ):\n",
    "        self.left_context_seq_len = left_context_seq_len\n",
    "        self.oov_context_seq_len = oov_context_seq_len\n",
    "        self.right_context_seq_len = right_context_seq_len\n",
    "        self.n_features_left_context = n_features_left_context,\n",
    "        self.n_features_oov_context = n_features_oov_context,\n",
    "        self.n_features_right_context = n_features_right_context,\n",
    "        self.device = device\n",
    "        \n",
    "        \n",
    "class HyperparamsModel:\n",
    "     def __init__(\n",
    "        self,\n",
    "        num_hidden_layer=None,\n",
    "        hidden_size=None,\n",
    "        device=device\n",
    "    ):\n",
    "        self.num_hidden_layer = num_hidden_layer\n",
    "        self.hidden_size = hidden_size\n",
    "        self.device = device\n",
    "        \n",
    "dataset_hyperparams_config = HyperparamsDataset(\n",
    "    left_context_seq_len = 79,\n",
    "    oov_context_seq_len = 30,\n",
    "    right_context_seq_len = 79,\n",
    "    n_features_left_context = 64,\n",
    "    n_features_oov_context = 20,\n",
    "    n_features_right_context = 64,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "context_size = 79"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f750b1-d4a7-4a2a-9fe1-369a61f28a2b",
   "metadata": {},
   "source": [
    "# Prepare Feature Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f241f20b-fb34-4db2-b887-1687f137b141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left context shape: (16562, 71)\n",
      "OOV context shape: (16562, 28)\n",
      "Right context shape: (16562, 79)\n",
      "Actual lable shape: (16562,)\n"
     ]
    }
   ],
   "source": [
    "def convert_doc_to_idxs(docs, dict_vocabs):\n",
    "    doc_to_idx = []\n",
    "    \n",
    "    for doc in docs:\n",
    "        doc_to_idx.append([dict_vocabs[token] for token in doc])\n",
    "        \n",
    "    return np.array(doc_to_idx)\n",
    "\n",
    "# Left context\n",
    "left_context = open(\"../../datasets/features/79_context/left_context_with_pad.pkl\", \"rb\")\n",
    "left_context = pickle.load(left_context)\n",
    "left_context_to_idx = open(\"../../datasets/features/79_context/token2idx_left_context.pkl\", \"rb\")\n",
    "left_context_to_idx = pickle.load(left_context_to_idx)\n",
    "doc_left_context_to_idx = convert_doc_to_idxs(left_context, left_context_to_idx)\n",
    "\n",
    "# OOV context\n",
    "oov_context = open(\"../../datasets/features/79_context/oov_context_with_pad.pkl\", \"rb\")\n",
    "oov_context = pickle.load(oov_context)\n",
    "oov_context_to_idx = open(\"../../datasets/features/79_context/token2idx_oov_context.pkl\", \"rb\")\n",
    "oov_context_to_idx = pickle.load(oov_context_to_idx)\n",
    "doc_oov_context_to_idx = convert_doc_to_idxs(oov_context, oov_context_to_idx)\n",
    "\n",
    "# Right context\n",
    "right_context = open(\"../../datasets/features/79_context/right_context_with_pad.pkl\", \"rb\")\n",
    "right_context = pickle.load(right_context)\n",
    "right_context_to_idx = open(\"../../datasets/features/79_context/token2idx_right_context.pkl\", \"rb\")\n",
    "right_context_to_idx = pickle.load(right_context_to_idx)\n",
    "doc_right_context_to_idx = convert_doc_to_idxs(right_context, right_context_to_idx)\n",
    "\n",
    "# Actual labels\n",
    "labels_context = open(\"../../datasets/features/79_context/lables.pkl\", \"rb\")\n",
    "labels_context = pickle.load(labels_context)\n",
    "labels_to_idx = open(\"../../datasets/features/79_context/lable_vocabs.pkl\", \"rb\")\n",
    "labels_to_idx = pickle.load(labels_to_idx)\n",
    "doc_labels_to_idx = convert_doc_to_idxs(labels_context, labels_to_idx).flatten()\n",
    "\n",
    "print(f\"Left context shape: {doc_left_context_to_idx.shape}\")\n",
    "print(f\"OOV context shape: {doc_oov_context_to_idx.shape}\")\n",
    "print(f\"Right context shape: {doc_right_context_to_idx.shape}\")\n",
    "print(f\"Actual lable shape: {doc_labels_to_idx.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe386c1f-3e1d-4589-b18e-42e4bc4055ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 2968, 10710,  1320,  1320,  1320,  1320,  1320,  1320,  1320,  1320,\n",
       "          1320,  1320,  1320,  1320,  1320,  1320,  1320,  1320,  1320,  1320,\n",
       "          1320,  1320,  1320,  1320,  1320,  1320,  1320,  1320,  1320,  1320,\n",
       "          1320,  1320,  1320,  1320,  1320,  1320,  1320,  1320,  1320,  1320,\n",
       "          1320,  1320,  1320,  1320,  1320,  1320,  1320,  1320,  1320,  1320,\n",
       "          1320,  1320,  1320,  1320,  1320,  1320,  1320,  1320,  1320,  1320,\n",
       "          1320,  1320,  1320,  1320,  1320,  1320,  1320,  1320,  1320,  1320,\n",
       "          1320]),\n",
       " tensor([19, 31, 19, 32, 29, 19, 32, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "         17, 17, 17, 17, 17, 17, 17, 17, 17, 17]),\n",
       " tensor([1929, 1929, 1929, 1929, 1929, 1929, 1929, 1929, 1929, 1929, 1929, 1929,\n",
       "         1929, 1929, 1929, 1929, 1929, 1929, 1929, 1929, 1929, 1929, 1929, 1929,\n",
       "         1929, 1929, 1929, 1929, 1929, 1929, 1929, 1929, 1929, 1929, 1929, 1929,\n",
       "         1929, 1929, 1929, 1929, 1929, 1929, 1929, 1929, 1929, 1929, 1929, 1929,\n",
       "         1929, 1929, 1929, 1929, 1929, 1929, 1929, 1929, 1929, 1929, 1929, 1929,\n",
       "         1929, 1929, 1929, 1929, 1929, 1929, 1929, 1929, 1929, 1929, 1929, 1929,\n",
       "         1929, 1929, 1929, 1929, 1929, 1929, 1929]),\n",
       " tensor(171))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to Tensor\n",
    "left_contexts = torch.LongTensor(doc_left_context_to_idx)\n",
    "oov_contexts = torch.LongTensor(doc_oov_context_to_idx)\n",
    "right_contexts = torch.LongTensor(doc_right_context_to_idx)\n",
    "actual_labels = torch.LongTensor(doc_labels_to_idx)\n",
    "dataset = TensorDataset(left_contexts, oov_contexts, right_contexts, actual_labels)\n",
    "\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8806cc8-c1d1-450a-833d-f25375c52949",
   "metadata": {},
   "source": [
    "# Char and Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86595b81-a95e-4469-acad-49b9ed2c9662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word Embedding\n",
    "word_embeddings = Embedding.load(\"../../word_embeddings/polyglot/idn_embeddings.tar.bz2\")\n",
    "word_embeddings.apply_expansion(DigitExpander)\n",
    "word_embeddings.apply_expansion(CaseExpander)\n",
    "\n",
    "left_vocabs = open(\"../../datasets/features/79_context/left_context_vocabs.pkl\", \"rb\")\n",
    "left_vocabs = pickle.load(left_vocabs)\n",
    "\n",
    "right_vocabs = open(\"../../datasets/features/79_context/right_context_vocabs.pkl\", \"rb\")\n",
    "right_vocabs = pickle.load(right_vocabs)\n",
    "\n",
    "left_word_embedding_dict = {left_context_to_idx[vocab] : word_embeddings[vocab] for vocab in left_vocabs}\n",
    "right_word_embedding_dict = {right_context_to_idx[vocab] : word_embeddings[vocab] for vocab in right_vocabs}\n",
    "\n",
    "# Char Embedding\n",
    "char_embedding_dict = open(\"../../word_embeddings/chars_embedding/char_embeddings.pkl\", \"rb\")\n",
    "char_embedding_dict = pickle.load(char_embedding_dict)\n",
    "\n",
    "# Context embedding\n",
    "left_context_embedding = nn.Embedding.from_pretrained(torch.FloatTensor(np.array(list(left_word_embedding_dict.values()))), freeze=True)\n",
    "oov_context_embedding = nn.Embedding.from_pretrained(torch.FloatTensor(np.array(list(char_embedding_dict.values()))), freeze=True)\n",
    "right_context_embedding = nn.Embedding.from_pretrained(torch.FloatTensor(np.array(list(right_word_embedding_dict.values()))), freeze=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593ddcfe-1525-41ae-bf02-c9ebf3d957aa",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "998fb38d-da64-4b4c-9371-75e06ebfc8f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[    9,  4780,  4638,  ...,  1320,  1320,  1320],\n",
       "         [ 1320,  1320,  1320,  ...,  1320,  1320,  1320],\n",
       "         [ 9808,  8984,  7151,  ...,  1320,  1320,  1320],\n",
       "         ...,\n",
       "         [ 4511, 10790,  6234,  ...,  1320,  1320,  1320],\n",
       "         [ 4315,   149,  5260,  ...,  1320,  1320,  1320],\n",
       "         [ 5603,  7726,  1320,  ...,  1320,  1320,  1320]]),\n",
       " tensor([[34, 33, 26, 33, 32, 25, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "         [37, 19, 41, 23, 25, 19, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "         [36, 23, 24, 27, 32, 19, 32, 21, 27, 32, 25, 17, 17, 17, 17, 17, 17, 17,\n",
       "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "         [24, 19, 22, 26, 23, 30, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "         [30, 19, 20, 19, 18, 20, 23, 36, 37, 27, 26, 17, 17, 17, 17, 17, 17, 17,\n",
       "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "         [22, 23, 34, 29, 23, 39, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "         [34, 23, 36, 38, 39, 31, 20, 39, 26, 19, 32, 18, 23, 29, 33, 32, 33, 31,\n",
       "          27, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "         [31, 23, 32, 23, 25, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "         [34, 19, 37, 19, 36, 18, 31, 33, 22, 19, 30, 17, 17, 17, 17, 17, 17, 17,\n",
       "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "         [ 3, 32, 43, 19, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "         [28, 19, 38, 27, 18, 22, 27, 36, 27, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "         [ 3, 32, 43, 19, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "         [34, 33, 29, 34, 26, 19, 32, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "         [30, 23, 31, 20, 19, 25, 19, 18, 29, 23, 39, 19, 32, 25, 19, 32, 17, 17,\n",
       "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "         [19, 30,  3, 35, 19, 23, 22, 19, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "         [28, 19, 34, 23, 42, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "         [36, 39, 31, 19, 26, 18, 38, 19, 32, 25, 25, 19, 17, 17, 17, 17, 17, 17,\n",
       "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "         [37, 39, 36, 19, 38, 18, 29, 19, 20, 19, 36, 17, 17, 17, 17, 17, 17, 17,\n",
       "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "         [20, 23, 36, 38, 39, 36, 39, 38,  3, 38, 39, 36, 39, 38, 17, 17, 17, 17,\n",
       "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "         [37, 19, 30, 19, 26, 18, 37, 19, 38, 39, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "         [37, 23, 26, 19, 36, 39, 37, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "         [20, 19, 26, 19, 32, 18, 31, 19, 29, 19, 32, 19, 32, 17, 17, 17, 17, 17,\n",
       "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "         [ 3, 32, 43, 19, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "         [ 3, 32, 43, 19, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "         [38, 26, 23, 33, 22, 23, 32, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "         [ 3, 32, 43, 19, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "         [34, 23, 31, 27, 30, 27, 26, 19, 32, 18, 39, 31, 39, 31, 17, 17, 17, 17,\n",
       "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "         [20, 39, 36, 26, 19, 32, 39, 22, 27, 32, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "         [ 3, 32, 43, 19, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "         [ 3, 32, 43, 19, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "         [ 3, 32, 43, 19, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "         [31, 19, 38, 19, 18, 39, 19, 32, 25, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17]]),\n",
       " tensor([[ 4625,  5771,  1929,  ...,  1929,  1929,  1929],\n",
       "         [ 5766,  9037,  1929,  ...,  1929,  1929,  1929],\n",
       "         [10590,  5970,  8574,  ...,  1929,  1929,  1929],\n",
       "         ...,\n",
       "         [ 9422,  8612, 10439,  ...,  1929,  1929,  1929],\n",
       "         [ 9711,  4381,  1926,  ...,  1929,  1929,  1929],\n",
       "         [ 7453,  6774,     9,  ...,  1929,  1929,  1929]]),\n",
       " tensor([2641, 2937, 2779,  989, 1768,  774, 2568, 2039, 2396,    8, 1448,    8,\n",
       "         2644, 1817,  133, 1436, 2856, 3197,  492, 2885, 2961,  337,    8,    8,\n",
       "         3356,    8, 2454,  587,    8,    8,    8, 1947])]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5be550-2f41-41b4-9df4-ac67744041c5",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed852446-c649-4727-b9ff-64375cf7e966",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Comick(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size_left_context=64,\n",
    "        input_size_oov_context=20,\n",
    "        input_size_right_context=64,\n",
    "        hidden_size = 128,\n",
    "        num_layers = 2,\n",
    "        output_size = len(labels_to_idx),\n",
    "        batch_first = True,\n",
    "        bidirectional = True,\n",
    "        init_wb_with_kaiming_normal=True\n",
    "    ):\n",
    "        super(Comick, self).__init__()\n",
    "        \n",
    "        self.input_size_left_context = input_size_left_context\n",
    "        self.input_size_oov_context = input_size_oov_context\n",
    "        self.input_size_right_context = input_size_right_context\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.output_size = output_size\n",
    "        self.batch_first = batch_first\n",
    "        self.bidirectional = bidirectional\n",
    "        \n",
    "        self.bilstm_left_context_feature = nn.LSTM(\n",
    "            input_size = self.input_size_left_context,\n",
    "            hidden_size = self.hidden_size,\n",
    "            num_layers = self.num_layers,\n",
    "            batch_first = self.batch_first,\n",
    "            bidirectional = self.bidirectional\n",
    "        )\n",
    "        \n",
    "        self.bilstm_oov_context_feature = nn.LSTM(\n",
    "            input_size = self.input_size_oov_context,\n",
    "            hidden_size = self.hidden_size,\n",
    "            num_layers = self.num_layers,\n",
    "            batch_first = self.batch_first,\n",
    "            bidirectional = self.bidirectional\n",
    "        )\n",
    "        \n",
    "        self.bilstm_right_context_feature = nn.LSTM(\n",
    "            input_size = self.input_size_right_context,\n",
    "            hidden_size = self.hidden_size,\n",
    "            num_layers = self.num_layers,\n",
    "            batch_first = self.batch_first,\n",
    "            bidirectional = self.bidirectional\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(2 * self.hidden_size, 64),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "        self.oov_embedding = nn.Linear(in_features=3 * 64, out_features=64)\n",
    "        \n",
    "        self.embedding = np.empty((output_size, 64), dtype=np.float32)\n",
    "        \n",
    "        self.output = nn.Sequential(\n",
    "            nn.Linear(64, self.output_size),\n",
    "            nn.LogSoftmax(dim=1)\n",
    "        )\n",
    "                \n",
    "        if init_wb_with_kaiming_normal:\n",
    "            self.init_wb()\n",
    "            \n",
    "    def init_wb(self):\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, (nn.Linear, nn.LSTM)):\n",
    "                for name, param in module.named_parameters():\n",
    "                    if \"weight\" in name:\n",
    "                        nn.init.kaiming_normal_(param)\n",
    "                    else:\n",
    "                        nn.init.kaiming_normal_(param.reshape(1, -1))\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_left_context,\n",
    "        input_oov_context,\n",
    "        input_right_context,\n",
    "        idxs_target,\n",
    "        hidden_left_context=None,\n",
    "        hidden_oov_context=None,\n",
    "        hidden_right_context=None,\n",
    "    ):\n",
    "        # BiLSTM left, oov, and right context\n",
    "        output_left_context, (hidden_left_context, memory_left_context) = self.bilstm_left_context_feature(input_left_context, hidden_left_context)\n",
    "        output_oov_context, (hidden_oov_context, memory_oov_context) = self.bilstm_oov_context_feature(input_oov_context, hidden_oov_context)\n",
    "        output_right_context, (hidden_right_context, memory_right_context) = self.bilstm_right_context_feature(input_right_context, hidden_right_context)\n",
    "        \n",
    "        # Concate hidden (forward and backward hidden BiLSTM)\n",
    "        hidden_left_bidirectional = torch.cat((hidden_left_context[0], hidden_left_context[-1]), dim=1)\n",
    "        hidden_oov_bidirectional = torch.cat((hidden_oov_context[0], hidden_oov_context[-1]), dim=1)\n",
    "        hidden_right_bidirectional = torch.cat((hidden_right_context[0], hidden_right_context[-1]), dim=1)\n",
    "        \n",
    "        # Fully connected\n",
    "        output_left_fc = self.fc(hidden_left_bidirectional)\n",
    "        output_oov_fc = self.fc(hidden_oov_bidirectional)\n",
    "        output_right_fc = self.fc(hidden_right_bidirectional)\n",
    "        \n",
    "        # Concate output left, oov, and right context feature\n",
    "        output = torch.cat((output_left_fc, output_oov_fc, output_right_fc), dim=1)\n",
    "        \n",
    "        # OOV embedding\n",
    "        output = self.oov_embedding(output)\n",
    "                \n",
    "        # save OOV embedding\n",
    "        self.embedding[idxs_target.tolist()] = output.detach().numpy()\n",
    "        \n",
    "        # Projection OOV embedding\n",
    "        output = self.output(output)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992eb40b-9062-47f1-9703-65e80d6cb07d",
   "metadata": {},
   "source": [
    "# Model, Optimizer, Criterion, Metric, and Learning Rate Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b08d05fc-0bb5-426e-aa7b-eb930ba9f06b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Comick(\n",
       "  (bilstm_left_context_feature): LSTM(64, 128, num_layers=2, batch_first=True, bidirectional=True)\n",
       "  (bilstm_oov_context_feature): LSTM(20, 128, num_layers=2, batch_first=True, bidirectional=True)\n",
       "  (bilstm_right_context_feature): LSTM(64, 128, num_layers=2, batch_first=True, bidirectional=True)\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (1): Tanh()\n",
       "  )\n",
       "  (oov_embedding): Linear(in_features=192, out_features=64, bias=True)\n",
       "  (output): Sequential(\n",
       "    (0): Linear(in_features=64, out_features=3611, bias=True)\n",
       "    (1): LogSoftmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Comick(init_wb_with_kaiming_normal=True).to(device)\n",
    "model.output[0].requires_grad_ = False # disable gradient for projection layer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.005)\n",
    "criterion = nn.NLLLoss().to(device)\n",
    "metric = F1Score().to(device)\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.5)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d463d75-dd43-4b45-9eec-8f4aca21b018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000219"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([param.numel() for param in model.parameters() if param.requires_grad_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "494a567d-acbc-46c2-adc8-b9a512366c17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b39ba3-b103-44da-ae1e-34fd12ad2d2f",
   "metadata": {},
   "source": [
    "# Training and Looping Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c51a3a6-a4af-425f-aa1f-34ffe9ff8248",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_step(dataloader, model, optimizer, criterion, metric, scheduler=None, path_name=None):\n",
    "    batch_losses = []\n",
    "    batch_metric_scores = []\n",
    "    \n",
    "    for batch, (input_left_context, input_oov_context, input_right_context, actual_label) in enumerate(tqdm(dataloader), 1):\n",
    "        # Forward Propagation\n",
    "        probs = model(\n",
    "            left_context_embedding(input_left_context).to(device),\n",
    "            oov_context_embedding(input_oov_context).to(device),\n",
    "            right_context_embedding(input_right_context).to(device),\n",
    "            actual_label.to(device)\n",
    "        )\n",
    "                \n",
    "        loss = criterion(probs, actual_label.to(device))\n",
    "        metric_score = metric(probs.argmax(dim=1), actual_label.to(device))\n",
    "        metric_score = metric.compute()\n",
    "        \n",
    "        if scheduler is not None:\n",
    "            scheduler.step(loss)\n",
    "        \n",
    "        batch_losses.append(loss.item())\n",
    "        batch_metric_scores.append(metric_score)\n",
    "        \n",
    "        if batch % 50 == 0 or batch == len(dataloader):\n",
    "            print(f\"Batch-{batch}: {str(criterion).split('(')[0]}={loss.item()} | {str(metric).split('(')[0]}={metric_score}\")\n",
    "            with open(f\"../../logs/comick/{context_size}_contexts/{path_name}/training_history.txt\", \"a\") as f:\n",
    "                f.write(f\"Batch-{batch}: {str(criterion).split('(')[0]}={loss.item()} | {str(metric).split('(')[0]}={metric_score}\\n\")\n",
    "\n",
    "        # Backward Propagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    return batch_losses, batch_metric_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e139244-b036-4d45-beca-1de5bd7b5e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH-1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5beeef9f77f41da9982cfb2bc23fd71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50: NLLLoss=4.850069046020508 | F1Score=0.31437501311302185\n",
      "Batch-100: NLLLoss=4.076752185821533 | F1Score=0.3578124940395355\n",
      "Batch-150: NLLLoss=3.0721304416656494 | F1Score=0.40166667103767395\n",
      "Batch-200: NLLLoss=2.454435110092163 | F1Score=0.43187499046325684\n",
      "Batch-250: NLLLoss=3.0282704830169678 | F1Score=0.4543750286102295\n",
      "Batch-300: NLLLoss=3.1269445419311523 | F1Score=0.4779166579246521\n",
      "Batch-350: NLLLoss=3.8457987308502197 | F1Score=0.4952678680419922\n",
      "Batch-400: NLLLoss=2.8274483680725098 | F1Score=0.5121874809265137\n",
      "Batch-450: NLLLoss=2.3727686405181885 | F1Score=0.5247916579246521\n",
      "Batch-500: NLLLoss=1.8678960800170898 | F1Score=0.5375000238418579\n",
      "Batch-518: NLLLoss=2.8908822536468506 | F1Score=0.5418427586555481\n",
      "\n",
      "Mean NLLLoss: 3.61639404296875 | Mean F1Score: 0.4396011233329773\n",
      "===========================================================================\n",
      "\n",
      "EPOCH-2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "843ad3e5613e4392b0f6ffb365e6ef01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50: NLLLoss=1.3746342658996582 | F1Score=0.6918749809265137\n",
      "Batch-100: NLLLoss=1.6348791122436523 | F1Score=0.6915624737739563\n",
      "Batch-150: NLLLoss=2.2847845554351807 | F1Score=0.6931250095367432\n",
      "Batch-200: NLLLoss=2.1237876415252686 | F1Score=0.6976562738418579\n",
      "Batch-250: NLLLoss=2.4064762592315674 | F1Score=0.7018749713897705\n",
      "Batch-300: NLLLoss=2.7860002517700195 | F1Score=0.7073958516120911\n",
      "Batch-350: NLLLoss=1.825637936592102 | F1Score=0.7119643092155457\n",
      "Batch-400: NLLLoss=1.4622207880020142 | F1Score=0.7153905630111694\n",
      "Batch-450: NLLLoss=1.3926361799240112 | F1Score=0.7186805009841919\n",
      "Batch-500: NLLLoss=1.684211015701294 | F1Score=0.7216874957084656\n",
      "Batch-518: NLLLoss=2.3933305740356445 | F1Score=0.7225577235221863\n",
      "\n",
      "Yeah 🎉😄! Model improved.\n",
      "Mean NLLLoss: 1.8895258903503418 | Mean F1Score: 0.7045383453369141\n",
      "===========================================================================\n",
      "\n",
      "EPOCH-3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d89c81a5153842a0ac6ab96718dca1c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50: NLLLoss=1.0514910221099854 | F1Score=0.8081250190734863\n",
      "Batch-100: NLLLoss=0.9198795557022095 | F1Score=0.7943750023841858\n",
      "Batch-150: NLLLoss=0.7386568784713745 | F1Score=0.7916666865348816\n",
      "Batch-200: NLLLoss=1.5427154302597046 | F1Score=0.7832812666893005\n",
      "Batch-250: NLLLoss=1.2860729694366455 | F1Score=0.7806249856948853\n",
      "Batch-300: NLLLoss=1.0445141792297363 | F1Score=0.7788541913032532\n",
      "Batch-350: NLLLoss=1.6058205366134644 | F1Score=0.7799999117851257\n",
      "Batch-400: NLLLoss=1.3499650955200195 | F1Score=0.7799218893051147\n",
      "Batch-450: NLLLoss=1.2267979383468628 | F1Score=0.7826389074325562\n",
      "Batch-500: NLLLoss=1.093660831451416 | F1Score=0.7866874933242798\n",
      "Batch-518: NLLLoss=1.2517352104187012 | F1Score=0.787646472454071\n",
      "\n",
      "Yeah 🎉😄! Model improved.\n",
      "Mean NLLLoss: 1.1229726076126099 | Mean F1Score: 0.7873852849006653\n",
      "===========================================================================\n",
      "\n",
      "EPOCH-4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "897691ccf50b49f68fc2952d0b0792aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50: NLLLoss=0.44505399465560913 | F1Score=0.8737499713897705\n"
     ]
    }
   ],
   "source": [
    "def looping_step(dataloader, model, optimizer, criterion, metric, n_epoch=15, patience=3, monitor=\"loss\"):\n",
    "    start_time = time()\n",
    "    \n",
    "    epoch_losses = []\n",
    "    epoch_metric_scores = []\n",
    "    patience_counter = 0\n",
    "    \n",
    "    now = datetime.now()\n",
    "    path_name = now.strftime(\"%m-%d-%Y_%H-%M-%S\")\n",
    "    os.makedirs(f\"../../logs/comick/{context_size}_contexts/{path_name}\")\n",
    "\n",
    "    for epoch in range(1, n_epoch + 1):\n",
    "        print(f\"EPOCH-{epoch}\")\n",
    "        with open(f\"../../logs/comick/{context_size}_contexts/{path_name}/training_history.txt\", \"a\") as f:\n",
    "            f.write(f\"EPOCH-{epoch}\\n\")\n",
    "        \n",
    "        batch_losses, batch_metric_scores = training_step(dataloader, model, optimizer, criterion, metric, path_name=path_name)\n",
    "        epoch_loss = torch.mean(torch.FloatTensor(batch_losses))\n",
    "\n",
    "        epoch_loss = torch.mean(torch.FloatTensor(batch_losses))\n",
    "        epoch_losses.append(epoch_loss.item())\n",
    "\n",
    "        epoch_metric_score = torch.mean(torch.FloatTensor(batch_metric_scores))\n",
    "        epoch_metric_scores.append(epoch_metric_score.item())\n",
    "        \n",
    "        with open(f\"../../logs/comick/{context_size}_contexts/{path_name}/training_history.txt\", \"a\") as f:\n",
    "            if monitor == \"loss\":\n",
    "                if epoch == 1:\n",
    "                    print(f\"\\nMean {str(criterion).split('(')[0]}: {epoch_loss} | Mean {str(metric).split('(')[0]}: {epoch_metric_score}\")\n",
    "                    \n",
    "                    f.write(f\"\\nMean {str(criterion).split('(')[0]}: {epoch_loss} | Mean {str(metric).split('(')[0]}: {epoch_metric_score}\\n\")\n",
    "                elif epoch_losses[-1] < epoch_losses[-2]:\n",
    "                    print(\"\\nYeah 🎉😄! Model improved.\")\n",
    "                    print(f\"Mean {str(criterion).split('(')[0]}: {epoch_loss} | Mean {str(metric).split('(')[0]}: {epoch_metric_score}\")\n",
    "                    \n",
    "                    f.write(\"\\nYeah 🎉😄! Model improved.\\n\")\n",
    "                    f.write(f\"Mean {str(criterion).split('(')[0]}: {epoch_loss} | Mean {str(metric).split('(')[0]}: {epoch_metric_score}\\n\")\n",
    "                else:\n",
    "                    patience_counter += 1\n",
    "                    \n",
    "                    print(\"\\nHuft 😥! Model not improved.\")\n",
    "                    print(f\"Mean {str(criterion).split('(')[0]}: {epoch_loss} | Mean {str(metric).split('(')[0]}: {epoch_metric_score}\")\n",
    "                    print(f\"Patience = {patience_counter}/{patience}❗\")\n",
    "                    \n",
    "                    f.write(\"\\nHuft 😥! Model not improved.\\n\")\n",
    "                    f.write(f\"Mean {str(criterion).split('(')[0]}: {epoch_loss} | Mean {str(metric).split('(')[0]}: {epoch_metric_score}\\n\")                    \n",
    "                    f.write(f\"Patience = {patience_counter}/{patience}❗\")\n",
    "            else:\n",
    "                if epoch == 1:\n",
    "                    print(f\"\\nMean {str(criterion).split('(')[0]}: {epoch_loss} | Mean {str(metric).split('(')[0]}: {epoch_metric_score}\")\n",
    "                    \n",
    "                    f.write(f\"\\nMean {str(criterion).split('(')[0]}: {epoch_loss} | Mean {str(metric).split('(')[0]}: {epoch_metric_score}\\n\")\n",
    "                elif epoch_metric_scores[-1] > epoch_metric_scores[-2]:\n",
    "                    print(\"\\nYeah 🎉😄! Model improved.\")\n",
    "                    print(f\"Mean {str(criterion).split('(')[0]}: {epoch_loss} | Mean Mean {str(metric).split('(')[0]}: {epoch_metric_score}\")\n",
    "                    \n",
    "                    f.write(\"\\nYeah 🎉😄! Model improved.\\n\")\n",
    "                    f.write(f\"Mean {str(criterion).split('(')[0]}: {epoch_loss} | Mean {str(metric).split('(')[0]}: {epoch_metric_score}\\n\")\n",
    "                else:\n",
    "                    patience_counter += 1\n",
    "                    \n",
    "                    print(\"\\nHuft 😥! Model not improved.\")\n",
    "                    print(f\"Mean {str(criterion).split('(')[0]}: {epoch_loss} | Mean {str(metric).split('(')[0]}: {epoch_metric_score}\\n\")\n",
    "                    print(f\"Patience = {patience_counter}/{patience}❗\\n\")\n",
    "                    \n",
    "                    f.write(\"\\nHuft 😥! Model not improved.\\n\")\n",
    "                    f.write(f\"Mean {str(criterion).split('(')[0]}: {epoch_loss} | Mean {str(metric).split('(')[0]}: {epoch_metric_score}\\n\")\n",
    "                    f.write(f\"Patience = {patience_counter}/{patience}❗\")\n",
    "                    \n",
    "            print(\"=\" * 75, end=\"\\n\\n\")\n",
    "            f.write(f\"{'=' * 75}\\n\\n\")\n",
    "            \n",
    "            if patience_counter > patience:\n",
    "                print(f\"Early stopping, patience = {patience_counter}/{patience}❗\")\n",
    "                break\n",
    "        \n",
    "        metric.reset()\n",
    "    \n",
    "    finish_time = time()\n",
    "    \n",
    "    # Training plot \n",
    "    fig, (ax_loss, ax_metric_score) = plt.subplots(nrows=1, ncols=2, figsize=(15, 5))\n",
    "\n",
    "    fig.suptitle(\"Training with context size = 79\")\n",
    "\n",
    "    ax_loss.set_title(\"Loss\")\n",
    "    ax_loss.set_xlabel(\"Epoch\")\n",
    "    ax_loss.set_ylabel(\"Score\")\n",
    "    ax_loss.plot(epoch_losses, \"green\")\n",
    "    ax_loss.grid()\n",
    "\n",
    "    ax_metric_score.set_title(\"F1 Score\")\n",
    "    ax_metric_score.set_xlabel(\"Epoch\")\n",
    "    ax_metric_score.set_ylabel(\"Score\")\n",
    "    ax_metric_score.plot(epoch_metric_scores, \"orange\")\n",
    "    ax_metric_score.grid()\n",
    "\n",
    "    plt.savefig(f\"../../logs/comick/{context_size}_contexts/{path_name}/training_plot.jpg\", dpi=200)                        \n",
    "    \n",
    "    print(f\"Training duration : {((finish_time - start_time) / 60):.3f} minutes.\")\n",
    "    print(f\"Training date     : {now}\")\n",
    "    \n",
    "    with open(f\"../../logs/comick/{context_size}_contexts/{path_name}/training_history.txt\", \"a\") as f:\n",
    "        f.write(f\"\\nTraining duration : {((finish_time - start_time) / 60):.3f} minutes.\\n\")\n",
    "        f.write(f\"Training date     : {now}\\n\")\n",
    "    \n",
    "    # Save epoch losses, epoch metric scores, model, state dict, and oov embedding dict\n",
    "    filename_epoch_losses = open(f\"../../logs/comick/{context_size}_contexts/{path_name}/epoch_losses.pkl\", \"ab\")\n",
    "    filename_epoch_metric_scores = open(f\"../../logs/comick/{context_size}_contexts/{path_name}/epoch_metric_scores.pkl\", \"ab\")\n",
    "    filename_model = f\"../../logs/comick/{context_size}_contexts/{path_name}/model.pth\"\n",
    "    filename_model_params = f\"../../logs/comick/{context_size}_contexts/{path_name}/model_params.pth\"\n",
    "    filename_oov_embedding_dict = open(f\"../../logs/comick/{context_size}_contexts/{path_name}/oov_embedding_dict.pkl\", \"ab\")\n",
    "    \n",
    "    pickle.dump(epoch_losses, filename_epoch_losses)\n",
    "    pickle.dump(epoch_metric_scores, filename_epoch_metric_scores)\n",
    "    torch.save(model, filename_model)\n",
    "    torch.save(model.state_dict(), filename_model_params)\n",
    "    pickle.dump({token : embedding for token, embedding in zip(list(labels_to_idx.keys()), model.embedding)}, filename_oov_embedding_dict)\n",
    "    \n",
    "    return epoch_losses, epoch_metric_scores\n",
    "\n",
    "epoch_losses, epoch_metric_scores = looping_step(dataloader, model, optimizer, criterion, metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92debcb3-d6ea-4299-a3e9-37be5b63d2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0338a288-6f5f-41d5-8626-1cc1a20fbf73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
