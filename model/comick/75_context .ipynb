{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13fc63c4-da08-43a8-9972-2615d377d1fa",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "313363b9-24d1-4b87-87cd-a0b7dd5fc128",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pytz\n",
    "import torch\n",
    "import timeit\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from itertools import chain\n",
    "from time import time\n",
    "from torch import nn, optim\n",
    "from torchmetrics import F1Score\n",
    "from torch.optim import lr_scheduler\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from polyglot.mapping import Embedding, CaseExpander, DigitExpander"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b49405-006a-4a45-ae79-0e22f6a7172e",
   "metadata": {},
   "source": [
    "# Hyperparameters Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68709d29-24a1-45bf-b549-804952fd1db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hyperparams:\n",
    "     def __init__(\n",
    "        self,\n",
    "        context_size=75,\n",
    "        input_size_left_context=64,\n",
    "        input_size_oov_context=20,\n",
    "        input_size_right_context=64,\n",
    "        batch_size=32,\n",
    "        num_hidden_layer=1,\n",
    "        hidden_size=128,\n",
    "        output_size=3611,\n",
    "        shuffle=True,\n",
    "        lr=0.001,\n",
    "        batch_first=True,\n",
    "        bidirectional=True,\n",
    "        init_wb_with_kaiming_normal=True,\n",
    "        n_epoch=20,\n",
    "        patience=20,\n",
    "        device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    ):\n",
    "        self.context_size = context_size\n",
    "        self.input_size_left_context = input_size_left_context\n",
    "        self.input_size_oov_context = input_size_oov_context\n",
    "        self.input_size_right_context = input_size_right_context\n",
    "        self.batch_size = batch_size\n",
    "        self.num_hidden_layer = num_hidden_layer\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.shuffle = shuffle\n",
    "        self.lr = lr\n",
    "        self.batch_first = batch_first\n",
    "        self.bidirectional = bidirectional\n",
    "        self.init_wb_with_kaiming_normal = init_wb_with_kaiming_normal\n",
    "        self.n_epoch = n_epoch\n",
    "        self.patience = patience\n",
    "        self.device = device\n",
    "        \n",
    "hyperparams = Hyperparams()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f750b1-d4a7-4a2a-9fe1-369a61f28a2b",
   "metadata": {},
   "source": [
    "# Prepare Feature Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f241f20b-fb34-4db2-b887-1687f137b141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left context shape: (16562, 70)\n",
      "OOV context shape: (16562, 28)\n",
      "Right context shape: (16562, 73)\n",
      "Actual lable shape: (16562,)\n"
     ]
    }
   ],
   "source": [
    "def convert_doc_to_idxs(docs, dict_vocabs):\n",
    "    doc_to_idx = []\n",
    "    \n",
    "    for doc in docs:\n",
    "        doc_to_idx.append([dict_vocabs[token] for token in doc])\n",
    "        \n",
    "    return np.array(doc_to_idx)\n",
    "\n",
    "# Left context\n",
    "left_context = open(f\"../../datasets/features/{hyperparams.context_size}_context/left_context_with_pad.pkl\", \"rb\")\n",
    "left_context = pickle.load(left_context)\n",
    "left_context_to_idx = open(f\"../../datasets/features/{hyperparams.context_size}_context/token2idx_left_context.pkl\", \"rb\")\n",
    "left_context_to_idx = pickle.load(left_context_to_idx)\n",
    "doc_left_context_to_idx = convert_doc_to_idxs(left_context, left_context_to_idx)\n",
    "\n",
    "# OOV context\n",
    "oov_context = open(f\"../../datasets/features/{hyperparams.context_size}_context/oov_context_with_pad.pkl\", \"rb\")\n",
    "oov_context = pickle.load(oov_context)\n",
    "oov_context_to_idx = open(f\"../../datasets/features/{hyperparams.context_size}_context/token2idx_oov_context.pkl\", \"rb\")\n",
    "oov_context_to_idx = pickle.load(oov_context_to_idx)\n",
    "doc_oov_context_to_idx = convert_doc_to_idxs(oov_context, oov_context_to_idx)\n",
    "\n",
    "# Right context\n",
    "right_context = open(f\"../../datasets/features/{hyperparams.context_size}_context/right_context_with_pad.pkl\", \"rb\")\n",
    "right_context = pickle.load(right_context)\n",
    "right_context_to_idx = open(f\"../../datasets/features/{hyperparams.context_size}_context/token2idx_right_context.pkl\", \"rb\")\n",
    "right_context_to_idx = pickle.load(right_context_to_idx)\n",
    "doc_right_context_to_idx = convert_doc_to_idxs(right_context, right_context_to_idx)\n",
    "\n",
    "# Actual labels\n",
    "labels_context = open(f\"../../datasets/features/{hyperparams.context_size}_context/lables.pkl\", \"rb\")\n",
    "labels_context = pickle.load(labels_context)\n",
    "labels_to_idx = open(f\"../../datasets/features/{hyperparams.context_size}_context/lable_vocabs.pkl\", \"rb\")\n",
    "labels_to_idx = pickle.load(labels_to_idx)\n",
    "doc_labels_to_idx = convert_doc_to_idxs(labels_context, labels_to_idx).flatten()\n",
    "\n",
    "print(f\"Left context shape: {doc_left_context_to_idx.shape}\")\n",
    "print(f\"OOV context shape: {doc_oov_context_to_idx.shape}\")\n",
    "print(f\"Right context shape: {doc_right_context_to_idx.shape}\")\n",
    "print(f\"Actual lable shape: {doc_labels_to_idx.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe386c1f-3e1d-4589-b18e-42e4bc4055ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to Tensor\n",
    "left_contexts = torch.LongTensor(doc_left_context_to_idx)\n",
    "oov_contexts = torch.LongTensor(doc_oov_context_to_idx)\n",
    "right_contexts = torch.LongTensor(doc_right_context_to_idx)\n",
    "actual_labels = torch.LongTensor(doc_labels_to_idx)\n",
    "dataset = TensorDataset(left_contexts, oov_contexts, right_contexts, actual_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8806cc8-c1d1-450a-833d-f25375c52949",
   "metadata": {},
   "source": [
    "# Char and Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86595b81-a95e-4469-acad-49b9ed2c9662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word Embedding\n",
    "word_embeddings = Embedding.load(\"../../word_embeddings/polyglot/idn_embeddings.tar.bz2\")\n",
    "word_embeddings.apply_expansion(DigitExpander)\n",
    "word_embeddings.apply_expansion(CaseExpander)\n",
    "\n",
    "left_vocabs = open(f\"../../datasets/features/{hyperparams.context_size}_context/left_context_vocabs.pkl\", \"rb\")\n",
    "left_vocabs = pickle.load(left_vocabs)\n",
    "\n",
    "right_vocabs = open(f\"../../datasets/features/{hyperparams.context_size}_context/right_context_vocabs.pkl\", \"rb\")\n",
    "right_vocabs = pickle.load(right_vocabs)\n",
    "\n",
    "left_word_embedding_dict = {left_context_to_idx[vocab] : word_embeddings[vocab] for vocab in left_vocabs}\n",
    "right_word_embedding_dict = {right_context_to_idx[vocab] : word_embeddings[vocab] for vocab in right_vocabs}\n",
    "\n",
    "# Char Embedding\n",
    "char_embedding_dict = open(\"../../word_embeddings/chars_embedding/char_embeddings.pkl\", \"rb\")\n",
    "char_embedding_dict = pickle.load(char_embedding_dict)\n",
    "\n",
    "# Context embedding\n",
    "left_context_embedding = nn.Embedding.from_pretrained(torch.FloatTensor(np.array(list(left_word_embedding_dict.values()))), padding_idx=left_vocabs.index(\"<PAD>\"), freeze=True)\n",
    "oov_context_embedding = nn.Embedding.from_pretrained(torch.FloatTensor(np.array(list(char_embedding_dict.values()))), padding_idx=list(char_embedding_dict.keys()).index(\"PAD\"), freeze=True)\n",
    "right_context_embedding = nn.Embedding.from_pretrained(torch.FloatTensor(np.array(list(right_word_embedding_dict.values()))), padding_idx=right_vocabs.index(\"<PAD>\"), freeze=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593ddcfe-1525-41ae-bf02-c9ebf3d957aa",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "998fb38d-da64-4b4c-9371-75e06ebfc8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=hyperparams.batch_size, shuffle=hyperparams.shuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5be550-2f41-41b4-9df4-ac67744041c5",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed852446-c649-4727-b9ff-64375cf7e966",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Comick(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size_left_context=hyperparams.input_size_left_context,\n",
    "        input_size_oov_context=hyperparams.input_size_oov_context,\n",
    "        input_size_right_context=hyperparams.input_size_right_context,\n",
    "        hidden_size=hyperparams.hidden_size,\n",
    "        num_layers=hyperparams.num_hidden_layer,\n",
    "        output_size=hyperparams.output_size,\n",
    "        batch_first=hyperparams.batch_first,\n",
    "        bidirectional=hyperparams.bidirectional,\n",
    "        init_wb_with_kaiming_normal=hyperparams.init_wb_with_kaiming_normal\n",
    "    ):\n",
    "        super(Comick, self).__init__()\n",
    "        \n",
    "        self.input_size_left_context = input_size_left_context\n",
    "        self.input_size_oov_context = input_size_oov_context\n",
    "        self.input_size_right_context = input_size_right_context\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.output_size = output_size\n",
    "        self.batch_first = batch_first\n",
    "        self.bidirectional = bidirectional\n",
    "        \n",
    "        self.bilstm_left_context_feature = nn.LSTM(\n",
    "            input_size = self.input_size_left_context,\n",
    "            hidden_size = self.hidden_size,\n",
    "            num_layers = self.num_layers,\n",
    "            batch_first = self.batch_first,\n",
    "            bidirectional = self.bidirectional\n",
    "        )\n",
    "        \n",
    "        self.bilstm_oov_context_feature = nn.LSTM(\n",
    "            input_size = self.input_size_oov_context,\n",
    "            hidden_size = self.hidden_size,\n",
    "            num_layers = self.num_layers,\n",
    "            batch_first = self.batch_first,\n",
    "            bidirectional = self.bidirectional\n",
    "        )\n",
    "        \n",
    "        self.bilstm_right_context_feature = nn.LSTM(\n",
    "            input_size = self.input_size_right_context,\n",
    "            hidden_size = self.hidden_size,\n",
    "            num_layers = self.num_layers,\n",
    "            batch_first = self.batch_first,\n",
    "            bidirectional = self.bidirectional\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(2 * self.hidden_size, 64),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "        self.oov_embedding = nn.Linear(in_features=3 * 64, out_features=64)\n",
    "        \n",
    "        self.embedding = np.empty((output_size, 64), dtype=np.float32)\n",
    "        \n",
    "        self.prob = nn.Sequential(\n",
    "            nn.Linear(64, self.output_size),\n",
    "            nn.LogSoftmax(dim=1)\n",
    "        )\n",
    "                \n",
    "        if init_wb_with_kaiming_normal:\n",
    "            self.init_wb()\n",
    "            \n",
    "    def init_wb(self):\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, (nn.Linear, nn.LSTM)):\n",
    "                for name, param in module.named_parameters():\n",
    "                    if \"weight\" in name:\n",
    "                        nn.init.kaiming_normal_(param)\n",
    "                    else:\n",
    "                        nn.init.kaiming_normal_(param.reshape(1, -1))\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_left_context,\n",
    "        input_oov_context,\n",
    "        input_right_context,\n",
    "        idxs_target,\n",
    "        hidden_left_context=None,\n",
    "        hidden_oov_context=None,\n",
    "        hidden_right_context=None,\n",
    "    ):\n",
    "        # BiLSTM left, oov, and right context\n",
    "        output_left_context, (hidden_left_context, memory_left_context) = self.bilstm_left_context_feature(input_left_context, hidden_left_context)\n",
    "        output_oov_context, (hidden_oov_context, memory_oov_context) = self.bilstm_oov_context_feature(input_oov_context, hidden_oov_context)\n",
    "        output_right_context, (hidden_right_context, memory_right_context) = self.bilstm_right_context_feature(input_right_context, hidden_right_context)\n",
    "                \n",
    "        # Concate hidden (forward and backward hidden BiLSTM)\n",
    "        hidden_left_bidirectional = torch.cat((hidden_left_context[0], hidden_left_context[-1]), dim=1)\n",
    "        hidden_oov_bidirectional = torch.cat((hidden_oov_context[0], hidden_oov_context[-1]), dim=1)\n",
    "        hidden_right_bidirectional = torch.cat((hidden_right_context[0], hidden_right_context[-1]), dim=1)\n",
    "        \n",
    "        # Fully connected\n",
    "        output_left_fc = self.fc(hidden_left_bidirectional)\n",
    "        output_oov_fc = self.fc(hidden_oov_bidirectional)\n",
    "        output_right_fc = self.fc(hidden_right_bidirectional)\n",
    "        \n",
    "        # Concate output left, oov, and right context feature\n",
    "        output = torch.cat((output_left_fc, output_oov_fc, output_right_fc), dim=1)\n",
    "        \n",
    "        # OOV embedding\n",
    "        output = self.oov_embedding(output)\n",
    "                \n",
    "        # save OOV embedding\n",
    "        self.embedding[idxs_target.tolist()] = output.cpu().detach().numpy()\n",
    "        \n",
    "        # Projection OOV embedding\n",
    "        prob = self.prob(output)\n",
    "        \n",
    "        return prob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992eb40b-9062-47f1-9703-65e80d6cb07d",
   "metadata": {},
   "source": [
    "# Model, Optimizer, Criterion, Metric, and Learning Rate Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b08d05fc-0bb5-426e-aa7b-eb930ba9f06b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Comick(\n",
       "  (bilstm_left_context_feature): LSTM(64, 128, batch_first=True, bidirectional=True)\n",
       "  (bilstm_oov_context_feature): LSTM(20, 128, batch_first=True, bidirectional=True)\n",
       "  (bilstm_right_context_feature): LSTM(64, 128, batch_first=True, bidirectional=True)\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (1): Tanh()\n",
       "  )\n",
       "  (oov_embedding): Linear(in_features=192, out_features=64, bias=True)\n",
       "  (prob): Sequential(\n",
       "    (0): Linear(in_features=64, out_features=3611, bias=True)\n",
       "    (1): LogSoftmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Comick().to(hyperparams.device)\n",
    "model.prob[0].requires_grad_ = False # disable gradient for projection layer\n",
    "optimizer = optim.Adam(model.parameters(), lr=hyperparams.lr)\n",
    "criterion = nn.NLLLoss(ignore_index=list(char_embedding_dict.keys()).index(\"PAD\")).to(hyperparams.device)\n",
    "metric = F1Score(ignore_index=list(char_embedding_dict.keys()).index(\"PAD\")).to(hyperparams.device)\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.5)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d463d75-dd43-4b45-9eec-8f4aca21b018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "814,427\n"
     ]
    }
   ],
   "source": [
    "print(f\"{sum([param.numel() for param in model.parameters() if param.requires_grad_]):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "494a567d-acbc-46c2-adc8-b9a512366c17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-5.7093925e-18,  4.5875709e-41, -5.7093925e-18, ...,\n",
       "         0.0000000e+00,  1.7934352e-27,  4.5875709e-41],\n",
       "       [ 2.1663284e-28,  4.5875709e-41,  1.0404081e-40, ...,\n",
       "         4.5875709e-41,  1.0405482e-40,  0.0000000e+00],\n",
       "       [ 1.7935030e-27,  4.5875709e-41,  2.1665133e-28, ...,\n",
       "         4.5875709e-41,  2.1666673e-28,  4.5875709e-41],\n",
       "       ...,\n",
       "       [ 1.6045404e-28,  4.5875709e-41,  2.1464220e-28, ...,\n",
       "         4.5875709e-41,  2.1465760e-28,  4.5875709e-41],\n",
       "       [ 1.1345613e-40,  0.0000000e+00,  1.6045828e-28, ...,\n",
       "         0.0000000e+00,  1.6046213e-28,  4.5875709e-41],\n",
       "       [ 2.1467455e-28,  4.5875709e-41,  1.1347154e-40, ...,\n",
       "         4.5875709e-41,  1.1348556e-40,  0.0000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b39ba3-b103-44da-ae1e-34fd12ad2d2f",
   "metadata": {},
   "source": [
    "# Training Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c51a3a6-a4af-425f-aa1f-34ffe9ff8248",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_step(dataloader, model, optimizer, criterion, metric, scheduler=None, path_name=None):\n",
    "    model.train()\n",
    "    \n",
    "    batch_losses = []\n",
    "    batch_metric_scores = []\n",
    "    \n",
    "    for batch, (input_left_context, input_oov_context, input_right_context, actual_label) in enumerate(tqdm(dataloader), 1):\n",
    "        # Forward Propagation\n",
    "        prob = model(\n",
    "            left_context_embedding(input_left_context).to(hyperparams.device),\n",
    "            oov_context_embedding(input_oov_context).to(hyperparams.device),\n",
    "            right_context_embedding(input_right_context).to(hyperparams.device),\n",
    "            actual_label.to(hyperparams.device)\n",
    "        )\n",
    "                \n",
    "        loss = criterion(prob, actual_label.to(hyperparams.device))\n",
    "        metric_score = metric(prob.argmax(dim=1), actual_label.to(hyperparams.device))\n",
    "        metric_score = metric.compute()\n",
    "        \n",
    "        if scheduler is not None:\n",
    "            scheduler.step(loss)\n",
    "        \n",
    "        batch_losses.append(loss.item())\n",
    "        batch_metric_scores.append(metric_score)\n",
    "        \n",
    "        if batch % 50 == 0 or batch == len(dataloader):\n",
    "            batch_name = \"Batch-\" + str(batch)\n",
    "            print(f\"{batch_name.ljust(9)}: {str(criterion).split('(')[0]}={(loss.item()):.4f} | {str(metric).split('(')[0]}={(metric_score):.4f}\")\n",
    "            with open(f\"../../logs/comick/{hyperparams.context_size}_contexts/{path_name}/training_history.txt\", \"a\") as f:\n",
    "                f.write(f\"{batch_name.ljust(9)}: {str(criterion).split('(')[0]}={(loss.item()):.4f} | {str(metric).split('(')[0]}={(metric_score):.4f}\\n\")\n",
    "\n",
    "        # Backward Propagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    return batch_losses, batch_metric_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3043a1-39cb-4b38-8024-54f909a565a9",
   "metadata": {},
   "source": [
    "# Looping Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e139244-b036-4d45-beca-1de5bd7b5e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH-1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ee24af476c549268c9542a3f7daa389",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=6.1964 | F1Score=0.2569\n",
      "Batch-100: NLLLoss=4.7256 | F1Score=0.2972\n",
      "Batch-150: NLLLoss=5.7057 | F1Score=0.3106\n",
      "Batch-200: NLLLoss=3.9199 | F1Score=0.3322\n",
      "Batch-250: NLLLoss=3.1171 | F1Score=0.3548\n",
      "Batch-300: NLLLoss=3.5555 | F1Score=0.3745\n",
      "Batch-350: NLLLoss=3.7680 | F1Score=0.3912\n",
      "Batch-400: NLLLoss=3.4508 | F1Score=0.4046\n",
      "Batch-450: NLLLoss=4.9516 | F1Score=0.4172\n",
      "Batch-500: NLLLoss=2.6373 | F1Score=0.4302\n",
      "Batch-518: NLLLoss=1.4986 | F1Score=0.4357\n",
      "\n",
      "Mean NLLLoss: 4.5231 | Mean F1Score: 0.3466\n",
      "==================================================\n",
      "\n",
      "EPOCH-2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2bf4b0af69c4b9397461bc9eb06a7d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=4.3062 | F1Score=0.5969\n",
      "Batch-100: NLLLoss=3.4311 | F1Score=0.5963\n",
      "Batch-150: NLLLoss=2.3704 | F1Score=0.6032\n",
      "Batch-200: NLLLoss=2.1314 | F1Score=0.6130\n",
      "Batch-250: NLLLoss=1.9218 | F1Score=0.6219\n",
      "Batch-300: NLLLoss=2.7350 | F1Score=0.6264\n",
      "Batch-350: NLLLoss=4.0043 | F1Score=0.6298\n",
      "Batch-400: NLLLoss=2.4300 | F1Score=0.6349\n",
      "Batch-450: NLLLoss=2.6664 | F1Score=0.6380\n",
      "Batch-500: NLLLoss=3.3792 | F1Score=0.6423\n",
      "Batch-518: NLLLoss=1.8223 | F1Score=0.6440\n",
      "\n",
      "Yeah 🎉😄! Model improved.\n",
      "Mean NLLLoss: 2.6799 | Mean F1Score: 0.6194\n",
      "==================================================\n",
      "\n",
      "EPOCH-3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75f5b2a8fefe40afbad10a9c5bb6b5a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=2.2479 | F1Score=0.7331\n",
      "Batch-100: NLLLoss=1.8120 | F1Score=0.7341\n",
      "Batch-150: NLLLoss=2.3277 | F1Score=0.7299\n",
      "Batch-200: NLLLoss=2.1023 | F1Score=0.7333\n",
      "Batch-250: NLLLoss=1.1819 | F1Score=0.7338\n",
      "Batch-300: NLLLoss=1.1156 | F1Score=0.7390\n",
      "Batch-350: NLLLoss=1.6171 | F1Score=0.7426\n",
      "Batch-400: NLLLoss=1.7566 | F1Score=0.7445\n",
      "Batch-450: NLLLoss=2.0020 | F1Score=0.7478\n",
      "Batch-500: NLLLoss=1.6255 | F1Score=0.7491\n",
      "Batch-518: NLLLoss=1.8228 | F1Score=0.7501\n",
      "\n",
      "Yeah 🎉😄! Model improved.\n",
      "Mean NLLLoss: 1.7674 | Mean F1Score: 0.7388\n",
      "==================================================\n",
      "\n",
      "EPOCH-4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76ed08072b714b70af595826575a2b3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=0.8565 | F1Score=0.8306\n",
      "Batch-100: NLLLoss=0.6488 | F1Score=0.8138\n",
      "Batch-150: NLLLoss=1.3516 | F1Score=0.8163\n",
      "Batch-200: NLLLoss=0.4816 | F1Score=0.8152\n",
      "Batch-250: NLLLoss=0.9638 | F1Score=0.8167\n",
      "Batch-300: NLLLoss=0.8787 | F1Score=0.8177\n",
      "Batch-350: NLLLoss=1.0396 | F1Score=0.8207\n",
      "Batch-400: NLLLoss=1.1555 | F1Score=0.8211\n",
      "Batch-450: NLLLoss=0.8277 | F1Score=0.8197\n",
      "Batch-500: NLLLoss=1.3204 | F1Score=0.8206\n",
      "Batch-518: NLLLoss=1.0045 | F1Score=0.8206\n",
      "\n",
      "Yeah 🎉😄! Model improved.\n",
      "Mean NLLLoss: 1.1491 | Mean F1Score: 0.8188\n",
      "==================================================\n",
      "\n",
      "EPOCH-5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2844be413b60444fb8570a454e8f7ab4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=0.4795 | F1Score=0.9019\n",
      "Batch-100: NLLLoss=0.4740 | F1Score=0.8930\n",
      "Batch-150: NLLLoss=0.8050 | F1Score=0.8836\n",
      "Batch-200: NLLLoss=0.8604 | F1Score=0.8810\n",
      "Batch-250: NLLLoss=0.5603 | F1Score=0.8804\n",
      "Batch-300: NLLLoss=1.0023 | F1Score=0.8780\n",
      "Batch-350: NLLLoss=0.7605 | F1Score=0.8759\n",
      "Batch-400: NLLLoss=0.6782 | F1Score=0.8764\n",
      "Batch-450: NLLLoss=0.5919 | F1Score=0.8775\n",
      "Batch-500: NLLLoss=0.9391 | F1Score=0.8747\n",
      "Batch-518: NLLLoss=0.7334 | F1Score=0.8751\n",
      "\n",
      "Yeah 🎉😄! Model improved.\n",
      "Mean NLLLoss: 0.6854 | Mean F1Score: 0.8832\n",
      "==================================================\n",
      "\n",
      "EPOCH-6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce71f792a7bf4744aa01927b5c7e77ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=0.3874 | F1Score=0.9559\n",
      "Batch-100: NLLLoss=0.1527 | F1Score=0.9551\n",
      "Batch-150: NLLLoss=0.3510 | F1Score=0.9530\n",
      "Batch-200: NLLLoss=0.2589 | F1Score=0.9504\n",
      "Batch-250: NLLLoss=0.5146 | F1Score=0.9464\n",
      "Batch-300: NLLLoss=0.4397 | F1Score=0.9463\n",
      "Batch-350: NLLLoss=0.4288 | F1Score=0.9460\n",
      "Batch-400: NLLLoss=0.8414 | F1Score=0.9441\n",
      "Batch-450: NLLLoss=0.5383 | F1Score=0.9414\n",
      "Batch-500: NLLLoss=0.2849 | F1Score=0.9396\n",
      "Batch-518: NLLLoss=0.4429 | F1Score=0.9394\n",
      "\n",
      "Yeah 🎉😄! Model improved.\n",
      "Mean NLLLoss: 0.3320 | Mean F1Score: 0.9488\n",
      "==================================================\n",
      "\n",
      "EPOCH-7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "201215c3a9c547f1a087790dbb93f062",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=0.1837 | F1Score=0.9906\n",
      "Batch-100: NLLLoss=0.0673 | F1Score=0.9925\n",
      "Batch-150: NLLLoss=0.1574 | F1Score=0.9933\n",
      "Batch-200: NLLLoss=0.1165 | F1Score=0.9931\n",
      "Batch-250: NLLLoss=0.0806 | F1Score=0.9912\n",
      "Batch-300: NLLLoss=0.2765 | F1Score=0.9887\n",
      "Batch-350: NLLLoss=0.0485 | F1Score=0.9883\n",
      "Batch-400: NLLLoss=0.0999 | F1Score=0.9882\n",
      "Batch-450: NLLLoss=0.1927 | F1Score=0.9878\n",
      "Batch-500: NLLLoss=0.0809 | F1Score=0.9873\n",
      "Batch-518: NLLLoss=0.0965 | F1Score=0.9873\n",
      "\n",
      "Yeah 🎉😄! Model improved.\n",
      "Mean NLLLoss: 0.1108 | Mean F1Score: 0.9905\n",
      "==================================================\n",
      "\n",
      "EPOCH-8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb34ad7b0c914004a245473b5b70e6be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=0.0470 | F1Score=0.9981\n",
      "Batch-100: NLLLoss=0.0477 | F1Score=0.9987\n",
      "Batch-150: NLLLoss=0.0118 | F1Score=0.9987\n",
      "Batch-200: NLLLoss=0.0266 | F1Score=0.9986\n",
      "Batch-250: NLLLoss=0.0312 | F1Score=0.9989\n",
      "Batch-300: NLLLoss=0.0530 | F1Score=0.9986\n",
      "Batch-350: NLLLoss=0.0115 | F1Score=0.9988\n",
      "Batch-400: NLLLoss=0.0173 | F1Score=0.9988\n",
      "Batch-450: NLLLoss=0.0118 | F1Score=0.9985\n",
      "Batch-500: NLLLoss=0.0142 | F1Score=0.9984\n",
      "Batch-518: NLLLoss=0.0213 | F1Score=0.9983\n",
      "\n",
      "Yeah 🎉😄! Model improved.\n",
      "Mean NLLLoss: 0.0307 | Mean F1Score: 0.9987\n",
      "==================================================\n",
      "\n",
      "EPOCH-9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43efb49c975e4178842747eab219f870",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=0.0156 | F1Score=0.9987\n",
      "Batch-100: NLLLoss=0.0036 | F1Score=0.9984\n",
      "Batch-150: NLLLoss=0.0059 | F1Score=0.9987\n",
      "Batch-200: NLLLoss=0.0115 | F1Score=0.9989\n",
      "Batch-250: NLLLoss=0.0205 | F1Score=0.9990\n",
      "Batch-300: NLLLoss=0.0060 | F1Score=0.9990\n",
      "Batch-350: NLLLoss=0.0101 | F1Score=0.9990\n",
      "Batch-400: NLLLoss=0.0044 | F1Score=0.9991\n",
      "Batch-450: NLLLoss=0.0080 | F1Score=0.9992\n",
      "Batch-500: NLLLoss=0.0051 | F1Score=0.9991\n",
      "Batch-518: NLLLoss=0.0131 | F1Score=0.9992\n",
      "\n",
      "Yeah 🎉😄! Model improved.\n",
      "Mean NLLLoss: 0.0125 | Mean F1Score: 0.9989\n",
      "==================================================\n",
      "\n",
      "EPOCH-10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e21817431f84141bd42f3843eb5b214",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=0.0047 | F1Score=0.9997\n",
      "Batch-100: NLLLoss=0.0058 | F1Score=0.9995\n",
      "Batch-150: NLLLoss=0.0050 | F1Score=0.9996\n",
      "Batch-200: NLLLoss=0.0070 | F1Score=0.9992\n",
      "Batch-250: NLLLoss=0.0068 | F1Score=0.9992\n",
      "Batch-300: NLLLoss=0.0057 | F1Score=0.9994\n",
      "Batch-350: NLLLoss=0.0091 | F1Score=0.9994\n",
      "Batch-400: NLLLoss=0.0038 | F1Score=0.9993\n",
      "Batch-450: NLLLoss=0.0068 | F1Score=0.9992\n",
      "Batch-500: NLLLoss=0.0071 | F1Score=0.9992\n",
      "Batch-518: NLLLoss=0.0027 | F1Score=0.9992\n",
      "\n",
      "Yeah 🎉😄! Model improved.\n",
      "Mean NLLLoss: 0.0092 | Mean F1Score: 0.9994\n",
      "==================================================\n",
      "\n",
      "EPOCH-11\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8b1be7e632d4aec91220b5c0201725d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=0.0039 | F1Score=1.0000\n",
      "Batch-100: NLLLoss=0.0041 | F1Score=0.9997\n",
      "Batch-150: NLLLoss=0.0042 | F1Score=0.9994\n",
      "Batch-200: NLLLoss=0.0037 | F1Score=0.9995\n",
      "Batch-250: NLLLoss=0.0037 | F1Score=0.9995\n",
      "Batch-300: NLLLoss=0.0034 | F1Score=0.9995\n",
      "Batch-350: NLLLoss=0.0029 | F1Score=0.9995\n",
      "Batch-400: NLLLoss=0.0090 | F1Score=0.9995\n",
      "Batch-450: NLLLoss=0.0036 | F1Score=0.9995\n",
      "Batch-500: NLLLoss=0.0044 | F1Score=0.9995\n",
      "Batch-518: NLLLoss=0.0042 | F1Score=0.9995\n",
      "\n",
      "Yeah 🎉😄! Model improved.\n",
      "Mean NLLLoss: 0.0053 | Mean F1Score: 0.9996\n",
      "==================================================\n",
      "\n",
      "EPOCH-12\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5cfe72d985d4cfd88b5e16037352a4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=0.0043 | F1Score=1.0000\n",
      "Batch-100: NLLLoss=0.0028 | F1Score=0.9997\n",
      "Batch-150: NLLLoss=0.0047 | F1Score=0.9998\n",
      "Batch-200: NLLLoss=0.0027 | F1Score=0.9998\n",
      "Batch-250: NLLLoss=0.0031 | F1Score=0.9997\n",
      "Batch-300: NLLLoss=0.0034 | F1Score=0.9997\n",
      "Batch-350: NLLLoss=0.0062 | F1Score=0.9997\n",
      "Batch-400: NLLLoss=0.0036 | F1Score=0.9998\n",
      "Batch-450: NLLLoss=0.0022 | F1Score=0.9997\n",
      "Batch-500: NLLLoss=0.0021 | F1Score=0.9997\n",
      "Batch-518: NLLLoss=0.0022 | F1Score=0.9997\n",
      "\n",
      "Yeah 🎉😄! Model improved.\n",
      "Mean NLLLoss: 0.0038 | Mean F1Score: 0.9998\n",
      "==================================================\n",
      "\n",
      "EPOCH-13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db3e669d5bb44a76afc0df4c986918a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=0.0035 | F1Score=1.0000\n",
      "Batch-100: NLLLoss=0.0022 | F1Score=1.0000\n",
      "Batch-150: NLLLoss=0.0034 | F1Score=0.9998\n",
      "Batch-200: NLLLoss=0.0010 | F1Score=0.9998\n",
      "Batch-250: NLLLoss=0.0082 | F1Score=0.9997\n",
      "Batch-300: NLLLoss=0.0019 | F1Score=0.9997\n",
      "Batch-350: NLLLoss=0.0022 | F1Score=0.9997\n",
      "Batch-400: NLLLoss=0.0014 | F1Score=0.9998\n",
      "Batch-450: NLLLoss=0.0016 | F1Score=0.9997\n",
      "Batch-500: NLLLoss=0.0025 | F1Score=0.9997\n",
      "Batch-518: NLLLoss=0.0056 | F1Score=0.9997\n",
      "\n",
      "Huft 😥! Model not improved.\n",
      "Mean NLLLoss: 0.0044 | Mean F1Score: 0.9998\n",
      "Patience = 1/20❗\n",
      "==================================================\n",
      "\n",
      "EPOCH-14\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c649310e50d4457f9f5e3b83a60ac297",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=0.0046 | F1Score=0.9994\n",
      "Batch-100: NLLLoss=0.0023 | F1Score=0.9997\n",
      "Batch-150: NLLLoss=0.0023 | F1Score=0.9996\n",
      "Batch-200: NLLLoss=0.0016 | F1Score=0.9997\n",
      "Batch-250: NLLLoss=0.0015 | F1Score=0.9996\n",
      "Batch-300: NLLLoss=0.0014 | F1Score=0.9996\n",
      "Batch-350: NLLLoss=0.0013 | F1Score=0.9997\n",
      "Batch-400: NLLLoss=0.0014 | F1Score=0.9997\n",
      "Batch-450: NLLLoss=0.0028 | F1Score=0.9996\n",
      "Batch-500: NLLLoss=0.0032 | F1Score=0.9996\n",
      "Batch-518: NLLLoss=0.0179 | F1Score=0.9995\n",
      "\n",
      "Huft 😥! Model not improved.\n",
      "Mean NLLLoss: 0.0044 | Mean F1Score: 0.9995\n",
      "Patience = 2/20❗\n",
      "==================================================\n",
      "\n",
      "EPOCH-15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da8ddd03234d4068b369ed2a97421c82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=0.7368 | F1Score=0.9812\n",
      "Batch-100: NLLLoss=0.2141 | F1Score=0.9248\n",
      "Batch-150: NLLLoss=0.2077 | F1Score=0.8988\n",
      "Batch-200: NLLLoss=0.1011 | F1Score=0.8959\n",
      "Batch-250: NLLLoss=0.2707 | F1Score=0.8997\n",
      "Batch-300: NLLLoss=0.3018 | F1Score=0.9021\n",
      "Batch-350: NLLLoss=0.1961 | F1Score=0.9046\n",
      "Batch-400: NLLLoss=0.2056 | F1Score=0.9090\n",
      "Batch-450: NLLLoss=0.1702 | F1Score=0.9135\n",
      "Batch-500: NLLLoss=0.0454 | F1Score=0.9181\n",
      "Batch-518: NLLLoss=0.1730 | F1Score=0.9188\n",
      "\n",
      "Huft 😥! Model not improved.\n",
      "Mean NLLLoss: 0.3261 | Mean F1Score: 0.9181\n",
      "Patience = 3/20❗\n",
      "==================================================\n",
      "\n",
      "EPOCH-16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a4d652f1e754b738c19c731d1e86b43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=0.0130 | F1Score=0.9937\n",
      "Batch-100: NLLLoss=0.0173 | F1Score=0.9942\n",
      "Batch-150: NLLLoss=0.1021 | F1Score=0.9950\n",
      "Batch-200: NLLLoss=0.0326 | F1Score=0.9947\n",
      "Batch-250: NLLLoss=0.0276 | F1Score=0.9949\n",
      "Batch-300: NLLLoss=0.0079 | F1Score=0.9953\n",
      "Batch-350: NLLLoss=0.0203 | F1Score=0.9952\n",
      "Batch-400: NLLLoss=0.0319 | F1Score=0.9955\n",
      "Batch-450: NLLLoss=0.0051 | F1Score=0.9956\n",
      "Batch-500: NLLLoss=0.0934 | F1Score=0.9958\n",
      "Batch-518: NLLLoss=0.0033 | F1Score=0.9958\n",
      "\n",
      "Yeah 🎉😄! Model improved.\n",
      "Mean NLLLoss: 0.0253 | Mean F1Score: 0.9948\n",
      "==================================================\n",
      "\n",
      "EPOCH-17\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "961cb36bd2a84381a16bdb68cd154c25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=0.0017 | F1Score=0.9994\n",
      "Batch-100: NLLLoss=0.0018 | F1Score=0.9997\n",
      "Batch-150: NLLLoss=0.0020 | F1Score=0.9998\n",
      "Batch-200: NLLLoss=0.0022 | F1Score=0.9998\n",
      "Batch-250: NLLLoss=0.0025 | F1Score=0.9999\n",
      "Batch-300: NLLLoss=0.0011 | F1Score=0.9999\n",
      "Batch-350: NLLLoss=0.0017 | F1Score=0.9998\n",
      "Batch-400: NLLLoss=0.0016 | F1Score=0.9998\n",
      "Batch-450: NLLLoss=0.0019 | F1Score=0.9998\n",
      "Batch-500: NLLLoss=0.0029 | F1Score=0.9998\n",
      "Batch-518: NLLLoss=0.0004 | F1Score=0.9998\n",
      "\n",
      "Yeah 🎉😄! Model improved.\n",
      "Mean NLLLoss: 0.0030 | Mean F1Score: 0.9998\n",
      "==================================================\n",
      "\n",
      "EPOCH-18\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53ce24af308b4a00913e9cf7996357c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=0.0010 | F1Score=1.0000\n",
      "Batch-100: NLLLoss=0.0005 | F1Score=1.0000\n",
      "Batch-150: NLLLoss=0.0013 | F1Score=0.9999\n",
      "Batch-200: NLLLoss=0.0011 | F1Score=0.9998\n",
      "Batch-250: NLLLoss=0.0009 | F1Score=0.9998\n",
      "Batch-300: NLLLoss=0.0009 | F1Score=0.9998\n",
      "Batch-350: NLLLoss=0.0016 | F1Score=0.9999\n",
      "Batch-400: NLLLoss=0.0025 | F1Score=0.9999\n",
      "Batch-450: NLLLoss=0.0014 | F1Score=0.9998\n",
      "Batch-500: NLLLoss=0.0022 | F1Score=0.9997\n",
      "Batch-518: NLLLoss=0.0007 | F1Score=0.9998\n",
      "\n",
      "Yeah 🎉😄! Model improved.\n",
      "Mean NLLLoss: 0.0025 | Mean F1Score: 0.9999\n",
      "==================================================\n",
      "\n",
      "EPOCH-19\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "709249dd73cb47769019f85cd7af58bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=0.0013 | F1Score=0.9994\n",
      "Batch-100: NLLLoss=0.0008 | F1Score=0.9994\n",
      "Batch-150: NLLLoss=0.0009 | F1Score=0.9996\n",
      "Batch-200: NLLLoss=0.0016 | F1Score=0.9997\n",
      "Batch-250: NLLLoss=0.0018 | F1Score=0.9998\n",
      "Batch-300: NLLLoss=0.0007 | F1Score=0.9997\n",
      "Batch-350: NLLLoss=0.0008 | F1Score=0.9998\n",
      "Batch-400: NLLLoss=0.0009 | F1Score=0.9997\n",
      "Batch-450: NLLLoss=0.0013 | F1Score=0.9998\n",
      "Batch-500: NLLLoss=0.0010 | F1Score=0.9997\n",
      "Batch-518: NLLLoss=0.0008 | F1Score=0.9998\n",
      "\n",
      "Yeah 🎉😄! Model improved.\n",
      "Mean NLLLoss: 0.0016 | Mean F1Score: 0.9997\n",
      "==================================================\n",
      "\n",
      "EPOCH-20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1524f9dc28a4e0db91913e3db3da39f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=0.0003 | F1Score=1.0000\n",
      "Batch-100: NLLLoss=0.0009 | F1Score=1.0000\n",
      "Batch-150: NLLLoss=0.0009 | F1Score=1.0000\n",
      "Batch-200: NLLLoss=0.0009 | F1Score=1.0000\n",
      "Batch-250: NLLLoss=0.0004 | F1Score=1.0000\n",
      "Batch-300: NLLLoss=0.0011 | F1Score=1.0000\n",
      "Batch-350: NLLLoss=0.0008 | F1Score=1.0000\n",
      "Batch-400: NLLLoss=0.0009 | F1Score=1.0000\n",
      "Batch-450: NLLLoss=0.0005 | F1Score=1.0000\n",
      "Batch-500: NLLLoss=0.0008 | F1Score=0.9999\n",
      "Batch-518: NLLLoss=0.0006 | F1Score=0.9999\n",
      "\n",
      "Yeah 🎉😄! Model improved.\n",
      "Mean NLLLoss: 0.0008 | Mean F1Score: 1.0000\n",
      "==================================================\n",
      "\n",
      "TRAINING SUMMARY\n",
      "Best NLLLoss      : 0.0008\n",
      "Best F1Score      : 1.0000\n",
      "Training duration : 34.174 minutes.\n",
      "Training date     : 2022-10-11 18:36:07.451122+08:00\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA24AAAFhCAYAAAAImPmbAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAABQ9ElEQVR4nO3deXxU5dn/8c+VjX1fwiIKKCKLCWrclaZSK1qVWv1ZN6hai3Vrq23V1rUuffTpplWronXD/VFrrXVXIu6CCgREBJFddgOENcv1+2NOcAxJCCQzZ87M9+1rXnO2Oeebw8jNlXOf+5i7IyIiIiIiIqkrK+wAIiIiIiIi0jAVbiIiIiIiIilOhZuIiIiIiEiKU+EmIiIiIiKS4lS4iYiIiIiIpDgVbiIiIiIiIilOhZuISISY2Ytm9pPm3jYRzOx0M3ulgfXFZrYomZlS1fbOlYiIiOk5biIiiWVm5XGzrYHNQFUwf667P5L8VMlnZg4McPc5wXwx8LC77xJipjOBc9z9sFTaV5jM7EXg8LhFecAsd987WD8PyOeb7/C77v79pIYUEclAOWEHEBFJd+7etmY6+EfvOe7+Wu3tzCzH3SuTmU2kNnc/On7ezEqAN2ptdlxd32EREUkcdZUUEQlJTVdBM7vMzJYC95tZJzN73sxWmNnXwfQucZ8pMbNzgukzzextM/tzsO2XZnb0Tm7bz8wmmtk6M3vNzO4ws4fryf2mmZ0YTB9qZm5mPwjmR5jZlPhjBtMTg49PNbNyM/tx3P5+bWbLzewrMzurgfPV2czuN7Mlwc/wbNy6n5nZHDNbbWbPmVmvuHVuZj83s9lmVhb8bGZmg4C7gIODTGXB9i2C87TAzJaZ2V1m1ipY94KZ/SVu34+b2X317auOn+FMM5sbnOcvzez0Os7VpcE+al4VZvZAsK6Dmf0zOFeLzewGM8uu75w1lZn1JXb17aFEHUNERBpHhZuISLh6AJ2B3YCxxP5evj+Y3xXYCNzewOcPBGYBXYH/Bf5pZrYT2z4KfAh0Aa4FRjdwzDeB4mD6O8BcYHjc/Ju1P+DuNesL3b2tuz8RzPcAOgC9gZ8Cd5hZp3qOO55YV9MhQHfgbwBmdgTwP8DJQE9gPvB4rc8eC+wPFATbHeXuM4GfA+8FmToG294E7AkMA/YIsl0drDsbGG1mRwRF1wHALxvY11Zm1gb4O3C0u7cDDgGm1HGu/jfYR1tgELACqDlfDwCVQa59gO8D59R1sszstKBQre+1a12fq2UM8Ja7z6u1/JHglwuvmFlhI/YjIiJNpMJNRCRc1cA17r7Z3Te6+yp3f9rdN7j7OuBGYsVQfea7+z3uXgU8SKxwyd+RbYN/wO8PXO3uW9z9beC5Bo75Zlym4cSKppr5Ogu3BlQA17l7hbu/AJQDA2tvZGY9gaOBn7v718H2Ncc5HbjP3T92983A74hd+eobt4ub3L3M3RcAE4gVZdsICtmxwMXuvjr4M/gjcAqAuy8FziN2/m4FxgTbNFY1MNTMWrn7V+4+o74Ng6t8zwK3uvuLZpYPHAP8yt3Xu/tyYsXrKXV93t0fdfeODbwWNCLvGGLFYrzTgb7EfrkwAXjZzDo2Yl8iItIEKtxERMK1wt031cyYWWszu9vM5pvZWmAi0LGB7nBLaybcfUMw2XYHt+0FrI5bBrCwgczvAXsGhcQwYt3o+phZV2JXoCY28NnaVtW6r29DPfn7BBm/rmNdL2JX2QBw93JgFbErZTWWxk3XdwyAbsSu6n1Uc2UKeClYXuM/QDaxATvermc/23D39cCPiV2Z+8rM/mtmezXwkX8Gx7g5mN8NyA0+W5PtbmJXH5udmR1G7IroU/HL3f2d4JcMG9z9f4Ayvj2YiYiIJIAKNxGRcNUe2vfXxK44Heju7fmmC2J93R+bw1dAZzNrHbesT30bBwXeR8AvgenuvgV4F7gE+MLdVyYg48IgY8c61i0hVtQAW7skdgEWN2K/tc//SmLdU4fEXZnqED/ADLGroDOBnmZ2agP72vZg7i+7+5HErnZ+BtxT13Zmdjmx7po/jVu8kNiIpF3jsrV39yH17OP0WvfK1X5tr6vkT4BngkK4wR+LxH4/RUQEFW4iIqmmHbHCoczMOgPXJPqA7j4fmAxca2Z5ZnYwcNx2PvYmcCHfdIssqTVfl2VA/53M+BXwIvAPiw3gkmtmNUXtY8BZZjbMzFoQ69r4QR33ZdWXaRczywuOU02smPqbmXUHMLPeZnZUMD0cOItYF8KfALeZWe+69lWbmeWb2aigsNxMrFtodR3bHQ38AjjB3TfWOgevAH8xs/ZmlmVmu5tZnV1p3f2Rmnvl6nnV21Uy6KZ5MrW6SZrZrhYbkCbPzFqa2W+J3TP5Tn37EhGR5qHCTUQktdwCtCJ25ed9Yt30kuF04GBiXQxvIDYYxuYGtn+TWJE5sZ75ulwLPBh08zt5JzKOJnZP3GfAcuBXAMGw9FcBTxO7erg79dz3VYc3gBnAUjOruVJ4GTAHeD/orvoaMNDM2hPrFnqhuy9297eIdWe8P7g3rq59xcsidlVyCbCa2P2A59Wx3Y+Jdc2cGXd17K5g3Rhiz1X7FPiaWDfGno38WXfED4l1gZxQa3k74M7g2IuBkcQGW1mVgAwiIhJHD+AWEZFtmNkTwGfunvArfiIiIrJ9uuImIiKY2f5Bt7ssMxsJjCI2oqGIiIikgJywA4iISEroATxDbFCPRcB57v5JuJFERESkhrpKioiIiIiIpDh1lRQREREREUlxKtxERERERERSnAo3ERERERGRFKfCTUREREREJMWpcBMREREREUlxKtxERERERERSnAo3ERERERGRFKfCTaSZmdk8M/te2DlEREQSKWjvNppZedyrV7BunJnNMrNqMztzO/vZxcyeNrOVZrbGzKZv7zMimUiFm4iIiIjsrOPcvW3ca0mwfCpwPvBxI/YxHlgI7AZ0AUYDy5ozpJnlNOf+RMKgwk0kCcyshZndYmZLgtctZtYiWNfVzJ43szIzW21mb5lZVrDuMjNbbGbrgt9cjgj3JxEREdk+d7/D3V8HNjVi8/2BB9x9vbtXuvsn7v5izUozO8zM3g3ayYU1V+PMrIOZPWRmK8xsvpldGdd+nmlm75jZ38xsFXBt0Bb/2cwWmNkyM7vLzFol4McXSQgVbiLJcQVwEDAMKAQOAK4M1v0aWAR0A/KB3wNuZgOBC4H93b0dcBQwL6mpRUREEu994A4zO8XMdo1fYWa7AS8CtxFrJ4cBU4LVtwEdgP7Ad4AxwFlxHz8QmEusbb0RuAnYM9jHHkBv4OoE/DwiCaHCTSQ5Tgeuc/fl7r4C+AOxriAAFUBPYDd3r3D3t9zdgSqgBTDYzHLdfZ67fxFKehERkbo9G1wJKzOzZ3dyH/8PeAu4CvjSzKaY2f7ButOA19z9saCNXOXuU8wsGzgF+J27r3P3ecBf+KZtBVji7re5eyWxK39jgYvdfbW7rwP+GOxDJBJUuIkkRy9gftz8/GAZwJ+AOcArZjbXzC4HcPc5wK+Aa4HlZvZ4zU3fIiIiKeKH7t4xeP1wZ3bg7l+7++XuPoTY1bEpxApCA/oAdf3SsiuQy7Zta++4+YVx092A1sBHNYUm8FKwXCQSVLiJJMcSYjdd19g1WEbwm8Jfu3t/4Hjgkpp72dz9UXc/LPisAzcnN7aIiEjyuPtK4M/EfrnZmVjxtXsdm64k1mOldtu6OH53tbbfCAyJKzQ7uHvb5swvkkgq3EQSI9fMWta8gMeAK82sm5l1Jdan/mEAMzvWzPYIfrO4hlgXyWozG2hmRwSDmGwi1uBUh/PjiIiINJ6Z5QXtn/FNm1jnvzvN7GYzG2pmOWbWDjgPmOPuq4BHgO+Z2cnB+i5mNszdq4AngRvNrF1wL9wlBG1rbe5eDdwD/M3MugfH7W1mRzX3zy6SKCrcRBLjBWKFVs2rJTAZmAaUEhse+YZg2wHAa0A58B7wD3efQOz+tpuI/ZZwKdAd+F3yfgQREZGd9gqx9u8QYFwwPbyebVsD/wLKiA0mshuxHii4+wLgGGIDea0m1o2yMPjcRcD64DNvA48C9zWQ6TJitya8b2ZribW9A3fiZxMJhcXGQBAREREREZFUpStuIiIiIiIiKU6Fm4iIiIiISIpT4SYiIiIiIpLiVLiJiIiIiIikOBVuIiIiIiIiKS4n7ADxunbt6n379m3SPtavX0+bNm2aJ1CSRDEzRDN3FDNDNHNHMTNEM3cUM3/00Ucr3b1b2DmiIlPbR4hm7ihmhmjmjmJmiGbuKGaGaOaur41MqcKtb9++TJ48uUn7KCkpobi4uHkCJUkUM0M0c0cxM0QzdxQzQzRzRzGzmc0PO0OUZGr7CNHMHcXMEM3cUcwM0cwdxcwQzdz1tZHqKikiIiIiIpLiVLiJiIiIiIikOBVuIiIiIiIiKU6Fm4iIiIiISIpT4SYiIiIiIpLiVLiJiIiIiIikOBVuIiIiIiIiKU6Fm4iISDMxs/vMbLmZTa9nvZnZ381sjplNM7N9k51RRESiSYWbiIhI83kAGNnA+qOBAcFrLHBnEjKJiEgayAk7QHNxd56c8SRflX1FMcVhxxERkQzk7hPNrG8Dm4wCHnJ3B943s45m1tPdv0pOQpFm4g5e1fhXda15qmP7wGt2+O35rdM1y6lzvsPmqbDMaq2rNb31vbrh7er+Qev/+RtiWYDV+95pUyksrQSywKzubTsMgbwODR8nKrwaNq2AjYth41dQXcHW8w/b/hnXXvat9fHvAPbN+9ZzGbxjdN04AxZ+vc3yb6Zr9lHznaz+5rsS/7513Xbe+/8UsrKbesbqlDaFm5lx+euX0y+3H7/iV2HHERERqUtvYGHc/KJg2TaFm5mNJXZVjvz8fEpKSpp04PLy8ibvIwxRzB1m5izfQuvKBbSp+JLWlfNoU/ElbSrnk+3rMTz4927sH8f2rX/8Ooe5U/XYt5fhtberxqiutSw8+wC8HnaKHVcI8EbD22zM7smkbvdRndUyGZG2q77vdXb1BlpUrSSveiUtqlZ+azqvahUtqmPvWVQlPzQwFOCt5B1v4sK+VFteQvadNoUbQEF+AVMXTg07hoiISJO5+zhgHEBRUZEXFxc3aX8lJSU0dR9hiGLupGSu2gLrPoc1M6Bseux9zXQo/yK4SgBk5UK7gdDhcGjRJfhgXVcdYssXLlpEnz67brN8289kf/PKyv72fKNfWbX2WztbHVmh1hUVmDJ1KsMK96nnSkr8FZisOpbVd/WltnqWWz3La1/h2/r+zZWZjz+ezL777EO9V27Wz6PVh2MZ3vU9KPhDPbmSqGoLs166goEds2HDYti4JHb1bMNiqCzfdvvc9tCqN7TqBa2L4qZ7Q6uekF1TjNb+s65ZFv/n3dCy+q7QfjM9afKH7F9UVP9V1pppy6p11bPmamg97/VcTR3eqlf9340mSqvCrTC/kOdnPc+myk20zEmN306IiIjEWQz0iZvfJVgmUrfqqlgxtmb6twu0tZ+DV8a2sSxoNwA6FsBup0LHobFudu0GxIq3RvpiXQl99i1OyI+RKGWf5UCP4rBj7LC1LTZD98Ma3mjZG/DpzdD/J9C2f3KC1af0Ggau+TOsy40VYK16QYe9ocdRQTHWG1r3+qZAy20bbt4463NXQ6dhYcdoFmlVuBXkF1BNNZ+u+JR9e2qgLhERSTnPARea2ePAgcAa3d8mdVo7Cz74KayaDNWbv1netn+sKOs9KvbecSi0Hxh3BUPSxj5/gkXPwceXwPBnw8tRVgoz/8zSVt+nxw9fDK4sSRjSrnADmLp0qgo3ERFJOjN7DCgGuprZIuAaIBfA3e8CXgCOAeYAG4CzwkkqKW35RJj4Q7Ac2PPC4AraUOgwCHLahJ1OkqX1LjD0Kpj6O1jyMvQ6KvkZvBo+GAt5Hfii/fn0UNEWqrQq3HbvtDstslowbdm0sKOIiEgGcvdTt7PegQuSFEeiaN6j8P5Z0LYfFL8Qfhc5CddeF8Pc++CjX0B+KWQnZtCLes25G1a9Dwc9SMWCNBnhMsLSqmzOzsqmX5t+TFuuwk1EREQixB1m/BHePR26HgxHvquiTSC7Bex7S2wgmlm3JPfYG5bAlMshfwT0G53cY0ud0qpwA9i9ze5MXToV397zNURERERSQXUFfPgzmHoF9D0dvvsytOgcdipJFb2Pgd7HwfTrY8VUsnz0S6jaDPvfmbBREmXHpF3h1r9tf1ZtXMVX5brXW0RERFLcljVQ8gP44p+x+5kOHh+7yiISb9+/xQr8KZcm53iLn4eFT8HQK6H9gOQcU7Yr/Qq3NrFuBbrPTURERFLa+oXw2uGwbAIceB8UXKcrG1K3drvDoN/AvEdgeYKfJl1RDpMugA6DYVCSCkVplLQr3HZvszugwk1ERERS2OpP4JUDYf18+O6LsLsGGJXtGPI7aN0HJl8Ue75fopReAxsWwP53J38wFGlQ2hVu7XLb0ad9H6Yumxp2FBEREZFtLX4hdqXNcuDId6DH98JOJFGQ0wb2/QuUTY2N9pgIqz+ODYKyx9jtPyBcki7tCjeIPc9NV9xEREQk5cy+EyYeB+0GwlEfxJ7RJtJYfU6C/O/CtCth08rm3Xd1FXw4Flp0g2E3Ne++pVmkZeFWmF/IZys/Y3Pl5rCjiIiIiMQeZPzJb2HS+dDzaPjem9CqZ9ipJGrMYL/boGItTLuieff9+e2w+qPY4wfyOjXvvqVZpGXhVpBfQGV1JZ+t/CzsKCIiIpLpKjfC2z+GmX+GAefD8Gcht23YqSSqOg6BPS+COffECq3msH5h7Cpez5Gw24+bZ5/S7NK2cAN0n5uIiIiEa9MKeP0IWPg07PMXKLodsnLCTiVRt/e10LJbbKASr276/j66CLwK9v+HRjZNYWlZuA3oMoAW2S10n5uIiIiEZ+3n8MpBUDYFDn8KBl2ifxRL88jrAMNuhpXvwZfjm7avhf+CRf+OFYNt+zVLPEmMtCzccrJyGNp9qAo3ERERCcfyt+CVg6FiHYyYAH1+FHYiSTf9xkCXg2DKZbEHue+MirWxq3YdC2Cvi5s3nzS7tCzcQCNLioiISDi6b3gd3vgetOgK338Puh4UdiRJR5YFRbfBpuUw/bqd28fUK2DjEjjgHsjKbd580uzSunBbtn4Zy8qXhR1FREREMsX8JxlcdgN0OTBWtLXbPexEks66FMHuP4VZf4c1n+7YZ1d+CJ/fAXteAF0PSEw+aVZpXbgBuuomIiIiyVE+Fz44hzW5Q+CIV6FF57ATSSYo/CPktIXJvwD3xn2muiL2zLZWPaHwxsTmk2ajwk1ERESkqaq2wNungGXzaacrIbtF2IkkU7TsBgXXw7LXYeEzjfvMZ7dA2dRYV8vc9gmNJ80nbQu3rq270qtdLz0SQERERBJv2hWwehIc9E825/QIO41kmgE/h457w8eXQOWGhrct/xJKr4Hex8MuJyQnnzSLtC3cQAOUiIiISBIseTF4uPZ5Gj1SwpGVE3tG4IYF8OlN9W/nDpPODwY2uV2Pp4iYtC7cCvML+XTFp1RUVYQdRURERNLRxq/gvZ/Ernbs85ew00gm6z4cdjsVPv3f2P2WdVnwJHz1EhTcAG36JDefNFnCCzczyzazT8zs+UQfq7aC/AIqqiuYtWpWsg8tIiIi6a66Ct49AyrXw6FPQE6rsBNJptvnT7Grbx9fsu26LV/DR7+EzvvBnhclP5s0WTKuuP0SmJmE42yjZoCSqUt1n5uIiIg0s5k3w7I3YgM8dBgUdhoRaN0bhl4Fi/4NS1769ropl8PmFXDAOMjKDiefNElCCzcz2wX4AXBvIo9Tn4FdBpKXnaf73ERERKR5rXgHpl0d65rW/6yw04h8Y+CvoN2A2NW1qi2xZSvegTnjYus67xtmOmmCRF9xuwW4FKhO8HHqlJudy+Bug5m2XIWbiIiINJPNq+Gd06DNbnDAXRrgQVJLdgvY71ZY9znMuiVWvH04FlrvCnv/Iex00gQ5idqxmR0LLHf3j8ysuIHtxgJjAfLz8ykpKWnSccvLy7+1j+7enckLJjd5v4lUO3NURDF3FDNDNHNHMTNEM3cUM4tEljt8cA5sXALff1fPwJLU1Ovo2HD/06+DDQthzafwnf9Abtuwk0kTJKxwAw4FjjezY4CWQHsze9jdz4jfyN3HAeMAioqKvLi4uEkHLSkpIX4fH+V9xCuvvsLQA4bStXXXJu07UWpnjooo5o5iZohm7ihmhmjmjmJmkciafScs+hfs82fosn/YaUTqt9/f4PnB8Pnt0Ock6H1s2ImkiRLWVdLdf+fuu7h7X+AU4I3aRVsy1AxQovvcREREpEm+nhobra/n0bDXxWGnEWlY2/5Q8Ado1SvWdVIiL62f4wZQ2KMQUOEmIiIiTVC5Ht45BVp0hoMfiD3AWCTVDb4MRi2A1r3CTiLNIJFdJbdy9xKgJBnHqq17m+7kt8ln6jI9EkBERER20uRfwNpZcMRr0LJ72GlEGk9D/6eNjPh1UUF+ga64iYhIUpjZSDObZWZzzOzyOtbvZmavm9k0MysJHp0jqWzeozD3Phjye+hxRNhpRCRDZUzhNmP5DCqrK8OOIiIiaczMsoE7gKOBwcCpZja41mZ/Bh5y9wLgOuB/kptSdsi6OfDhz6HbobD3tWGnEZEMlhGFW2F+IZurNjN71eywo4iISHo7AJjj7nPdfQvwODCq1jaDgTeC6Ql1rJdUUbUldl+bZcMhj0JWUu4wERGpU0YUbjUjS+o+NxERSbDewMK4+UXBsnhTgR8F0ycA7cysSxKyyY6a+jtY/REcdB+02TXsNCKS4TLiV0d7dd2LnKwcpi2bxilDTwk7joiIZLbfALeb2ZnARGAxUFV7IzMbC4wFyM/Pb/JD1qP6oPawcnfe9D4Fq//K4tY/ZPYXneCLxmfQuU6eKGaGaOaOYmaIbu66ZETh1iKnBYO6DtIAJSIikmiLgT5x87sEy7Zy9yUEV9zMrC1woruX1d6Ru48DxgEUFRV5Ux+yHtUHtYeSe8MSePH/QccCeh/1GL2zW+7Qx3WukyeKmSGauaOYGaKbuy4Z0VUSNLKkiIgkxSRggJn1M7M84BTgufgNzKyr2daHgP0OuC/JGaUh1VXw3hlQuQEOfRx2sGgTEUmUjCrcFq5dyOqNq8OOIiIiacrdK4ELgZeBmcCT7j7DzK4zs+ODzYqBWWb2OZAP3BhKWKnbp/8DyyZA0e3QYVDYaUREtsqIrpLwzQAlpctK+U7f74ScRkRE0pW7vwC8UGvZ1XHTTwFPJTuXNMLyt6D0GtjtNOh/ZthpRES+JWOuuBXmFwKou6SIiIhsa/NqePc0aNMPDrgTzMJOJCLyLRlzxa1H2x50bd1VjwQQERGRb3OH98+CTcvgyHcht33YiUREtpExhZuZaYASERER2dasW2Dxc7Dv36BLUdhpRETqlDFdJQEKuhcwffl0qqq3eVyOiIiIZKKVH8KUy2CXUTDwl2GnERGpV0YVboU9CtlYuZEvvv4i7CgiIiISti1fwzs/hla94MD7dF+biKS0jCrcakaWnLpU97mJiIhkNHd4/2zYsAgOfQJadA47kYhIgzKqcBvcbTDZlq373ERERDLd57fBomdh2E3Q9cCw04iIbFdGFW4tc1oysOtApi1X4SYiIpKxVk2GT34DvY6FvS4JO42ISKNkVOEGaGRJERGRTLalDN4+GVr2gIMf0H1tIhIZmVe4dS9gXtk81mxaE3YUERERSSZ3+OAc2LAADn0cWnQJO5GISKNlXuEWDFBSurw05CQiIiKSVLP/AQufhsI/QrdDwk4jIrJDMq5wK+xRCKDukiIiIplk9cfw8SXQ6xgY9Juw04iI7LCMK9x6t+tNp5adVLiJiIhkioq1sfvaWnSDgx4Ey7h//ohIGsgJO0CymRkF+QVMXaZnuYmIiKQ9d/jgZ7B+HowogZZdQw4kIrJzMvJXTgX5BZQuK6Xaq8OOIiIiIok0525Y8CQUXA/dDws7jYjITsvIwq0wv5D1Fev58usvw44iIiIiifL1FPjoV9DzKBh8WdhpRESaJCMLt5qRJdVdUkREJE1VrAvua+sCB4/XfW0iEnkZ+bfYkO5DyLIsDVAiIiKSjtzhw3Oh/As49DFo2S3sRCIiTZZxg5MAtM5tzYDOA1S4iYiIpKMv7oX5j0HBDdB9eNhpRESaRUZecYNYd0kVbiIiImnm62nw0S+gx5Ew5HdhpxERaTYZXbh98fUXrNu8LuwoIiIi0hwqyuGdkyG3o+5rE5G0k7F/o9UMUDJ9+fSQk4iIiEiTucOk82DdbDj0UWiVH3YiEZFmlbGFW2F+IYC6S4qIiKSDuffDvIdh6DWQ/92w04iINLuMLdx27bAr7Vu0V+EmIiISdWXTYfKFkH8EDLki7DQiIgmRsYWbmVGQX6BnuYmIiERZ5frY89py28Mhj0BWdtiJREQSImMLN4CC7rGRJd097CgiIiKyMz66GNZ+FivaWvUIO42ISMJkdOFW2KOQdVvWMX/N/LCjiIiIyI5a8S58cQ8M+jX0GBF2GhGRhMrowq1mZMmpS9VdUkREJFKqK2HyBdB6l9iAJCIiaS6jC7eh3YcCGllSREQkcmbfBV9PgX3/Brltw04jIpJwGV24tc1ry+6ddmfachVuIiLSPMxspJnNMrM5ZnZ5Het3NbMJZvaJmU0zs2PCyBlpG5fBtCuhx5HQ58Sw04iIJEVGF24Qu89NV9xERKQ5mFk2cAdwNDAYONXMBtfa7ErgSXffBzgF+EdyU6aBKZdB1QYoug3Mwk4jIpIUGV+4FXQvYPaq2azfsj7sKCIiEn0HAHPcfa67bwEeB0bV2saB9sF0B2BJEvNF3/K34csHYa/fQPuBYacREUkaFW75BTjOjBUzwo4iIiLR1xtYGDe/KFgW71rgDDNbBLwAXJScaGlg64AkfWCoHrQtIpklJ+wAYSvsUQjEBig5oPcBIacREZEMcCrwgLv/xcwOBsab2VB3r47fyMzGAmMB8vPzKSkpadJBy8vLm7yPMMTn7l3+NAPWTmN6pz+w8u1J4QZrQDqc66iIYmaIZu4oZobo5q5LxhdufTv2pW1eW93nJiIizWEx0CdufpdgWbyfAiMB3P09M2sJdAWWx2/k7uOAcQBFRUVeXFzcpGAlJSU0dR9h2Jp741J4/iHoeRRDi69K6XvbIn+uIySKmSGauaOYGaKbuy4Z31Uyy7LYu/veTF2mZ7mJiEiTTQIGmFk/M8sjNvjIc7W2WQCMADCzQUBLYEVSU0bRJ5dC1SbYTwOSiEhmyvjCDWL3uU1bNg13DzuKiIhEmLtXAhcCLwMziY0eOcPMrjOz44PNfg38zMymAo8BZ7oaoIYtnwjzxsOg30L7AWGnEREJRcK6SgZdPyYCLYLjPOXu1yTqeE1RmF/I3R/dzaK1i+jToc/2PyAiIlIPd3+B2KAj8cuujpv+FDg02bmiyrwSJl0MrXeFIb8PO46ISGgSecVtM3CEuxcCw4CRZnZQAo+30wryCwDUXVJERCTF9F7/LKyZDvvdCjmtw44jIhKahBVuHlMezOYGr5TsCjK0+1AADVAiIiKSSjZ+Rd9190PPo2GX2o/DExHJLAm9x83Mss1sCrGRsl519w8Sebyd1aFlB/p27KvCTUREJJV88luyvAKK/q4BSUQk4yX0cQDuXgUMM7OOwL+C59RMj98mVZ5T0zu7N+9/+X4oz3mI6vMlopg7ipkhmrmjmBmimTuKmUW2a9mbMO8RFrQdTd92e4SdRkQkdEl5jpu7l5nZBGLPrZlea11KPKfmCD+CG9+6kQMPPZBWua2alGFHRfX5ElHMHcXMEM3cUcwM0cwdxcwiDaqugMkXQJu+LGh7Gn3DziMikgIS1lXSzLoFV9ows1bAkcBniTpeUxXkF1Dt1Xy64tOwo4iIiGS2WbfBmhmw361UZ7UMO42ISEpI5D1uPYEJZjaN2ANJX3X35xN4vCYpzC8ENECJiIhIqDYsgdJroNcPoPdxYacREUkZCesq6e7TgH0Stf/m1r9Tf1rntlbhJiIiEqZPfhPrKrnfrRqQREQkTkJHlYyS7KxshnYfqme5iYiIhGXZBJj/GAy+HNrtHnYaEZGUosItTkH3AqYtm4Z7Sj5uTkREJH1VV8CkC6BNPxh8WdhpRERSjgq3OIU9Clm1cRVflX8VdhQREZHMMutWWDsz1kUyJ7mjO4uIRIEKtzgF+QWABigRERFJqg2LoPRa6HUs7KIBSURE6qLCLc7e3fcGYOpS3ecmIiKSNB//BqoroejWsJOIiKQsFW5xOrXqRJ/2fZi2XFfcREREkmLp67DgCRjyO2jbP+w0IiIpS4VbLYU9CtVVUkREJBmqtsDkC2MF26BLw04jIpLSVLjVUtC9gM9Wfsbmys1hRxEREUlvs26BtZ/Bfn/XgCQiItuhwq2WgvwCKqsrmblyZthRRERE0tf6hTD9Ouh9PPT+QdhpRERSngq3WjSypIiISBJ88hvwKtjvlrCTiIhEggq3WgZ0GUDLnJYq3ERERBJl3RxY8CTs9Wto2y/sNCIikaDCrZacrByGdBvClKVTwo4iIiKSnubcA5YNA84LO4mISGSocKvDYbsextsL3qZsU1nYUURERNJL1WaYez/0Pg5a9w47jYhIZKhwq8Ppe5/O5qrNPPXpU2FHERERSS8L/wWbV8Ae54adREQkUlS41aGoVxF7dd2Lh6Y+FHYUERGR9DLnbmjTF3p+P+wkIiKRosKtDmbG6ILRvLXgLb78+suw44iIiKSHtbNgeQnsMRZM/wQREdkR+luzHmcUnAHAw9MeDjmJiIhImpgzDiwH+p8VdhIRkchR4VaPXTvsSnHfYsZPG4+7hx1HREQk2qo2wdwHYJcfQqseYacREYkcFW4NGFMwhtmrZ/PB4g/CjiIiIhJtC56CLathgAYlERHZGSrcGnDi4BNpmdOS8VPHhx1FREQk2ubcDW33gPwjwk4iIhJJKtwa0L5Fe07Y6wQen/E4W6q2hB1HREQkmspmwIq3NSiJiEgT6G/P7RhdMJrVG1fzwuwXwo4iIiIRYGYjzWyWmc0xs8vrWP83M5sSvD43s7IQYibXnHGQlQf9zww7iYhIZKlw244jdz+S/Db5eqabiIhsl5llA3cARwODgVPNbHD8Nu5+sbsPc/dhwG3AM0kPmkyVG+DLB6HPj6Blt7DTiIhEVqMLNzNrZWYDExkmFeVk5XDa3qfx/OfPs3rj6rDjiIhIEu1E23cAMMfd57r7FuBxYFQD258KPNaUjClvwZNQsQb2+HnYSUREIq1RhZuZHQdMAV4K5oeZ2XMJzJVSxhSOoaK6giemPxF2FBERSZKdbPt6Awvj5hcFy+ra/25AP+CNJodNZbPvhvZ7QffhYScREYm0nEZudy2x3yKWALj7FDPrl6BMKacwv5Ch3Ycyftp4ztv/vLDjiIhIclxLYtu+U4Cn3L2qrpVmNhYYC5Cfn09JSUmTDlZeXt7kfeyoNhVz2H/V+8xpfz6L3nxzp/YRRu6mimJmiGbuKGaGaOaOYmaIbu66NLZwq3D3NWYWvyxjnkptZowpGMOlr13K7FWzGdBlQNiRREQk8Xam7VsM9Imb3yVYVpdTgAvq25G7jwPGARQVFXlxcfH28jaopKSEpu5jh016Ela1YI8jr2ePFp13aheh5G6iKGaGaOaOYmaIZu4oZobo5q5LY+9xm2FmpwHZZjbAzG4D3k1grpRz2t6nYRgPT3s47CgiIpIcO9P2TQIGmFk/M8sjVpxt073SzPYCOgHvNXfolFFRDl8+DLueDDtZtImIyDcaW7hdBAwBNgOPAmuAXyUoU0rq3b43I/qPYPy08bhnzMVGEZFMtsNtn7tXAhcCLwMzgSfdfYaZXWdmx8dtegrwuKdzgzL/cahcBwPODTuJiEha2G5XyWBo4/+6+3eBKxIfKXWNKRjDmGfH8M7Cdzhs18PCjiMiIgnSlLbP3V8AXqi17Opa89c2NWPKm3M3dBgCXQ8JO4mISFrY7hW34KbpajPrkIQ8Ke2EQSfQOrc146eODzuKiIgkkNq+Jlr9EayeDHucC9++R1BERHZSYwcnKQdKzexVYH3NQnf/RUJSpai2eW05cdCJPDHjCW49+lZa5rQMO5KIiCSO2r6dNftuyG4F/UaHnUREJG00tnB7JnhlvNEFoxk/bTzPf/48Jw0+Kew4IiKSOGr7dkbFWpj/KOx2CuR1DDuNiEjaaFTh5u4PBqNj7RksmuXuFYmLlbqO6HcEvdr14qGpD6lwExFJY2r7dtK8R6FyfaybpIiINJtGjSppZsXAbOAO4B/A52Y2PHGxUld2Vjan7306L855kRXrV4QdR0REEkRt305wh9l3QcdC6HJA2GlERNJKYx8H8Bfg++7+HXcfDhwF/C1xsVLbmMIxVFZX8vj0x8OOIiIiiaO2b0et+hDKpsKAn2tQEhGRZtbYwi3X3WfVzLj750BuYiKlvqHdhzKsxzDGT9PokiIiaUxt346aczfktIG+p4WdREQk7TS2cJtsZveaWXHwugeYnMhgqW5MwRgmLZnEZys/CzuKiIgkhtq+HbGlLPbQ7d1Og9z2YacREUk7jS3czgM+BX4RvD4NlmWsU/c+lSzL0jPdRETSl9q+HfHleKjaCAM0KImISCI0tnDLAW519x+5+4+AvwPZiYuV+nq07cFRux/Fw6UPU+3VYccREZHmp7avsdxj3SQ7F0Hn/cJOIyKSlhpbuL0OtIqbbwW81vxxomV0wWgWrFnAxPkTw44iIiLNT21fY618F9bM0CMAREQSqLGFW0t3L6+ZCaZbJyZSdIzaaxTt8trx0NSHwo4iIiLNT21fY82+G3LaxR66LSIiCdHYwm29me1bM2NmRcDGxESKjta5rTlp8Ek89elTbKjYEHYcERFpXmr7GmPzKljwJPQ7A3Lbhp1GRCRtNbZw+xXwf2b2lpm9BTwOXJiwVBEyumA067as49+f/TvsKCIi0rx+hdq+7fvyIajerG6SIiIJ1mDhZmb7m1kPd58E7AU8AVQALwFfJiFfyvtO3+/Qp30fPdNNRCRNqO3bATWDknQ5CDoVhp1GRCStbe+K293AlmD6YOD3wB3A18C4hj5oZn3MbIKZfWpmM8zsl01Om4KyLIszCs7g5S9eZmn50rDjiIhI0+1025dxlk+EtbP0CAARkSTYXuGW7e6rg+kfA+Pc/Wl3vwrYYzufrQR+7e6DgYOAC8xscNPipqbRBaOp9moeK30s7CgiItJ0TWn7MsucuyC3A+x6cthJRETS3nYLNzPLCaZHAG/ErcupY/ut3P0rd/84mF4HzAR672zQVDao2yCKehXx0DSNLikikgZ2uu3LKJtWwMKnod9PIEeDbYqIJNr2CrfHgDfN7N/ERtJ6C8DM9gDWNPYgZtYX2Af4YOdipr4xBWOYsnQK05dPDzuKiIg0TbO0fWlv7gNQXaFukiIiSbK9q2Y3mtnrQE/gFXf3YFUWcFFjDmBmbYGngV+5+9o61o8FxgLk5+dTUlLS+PR1KC8vb/I+dkafLX3ItmxufP5Gzu2/Y41YWJmbKoq5o5gZopk7ipkhmrmjmDmVNUfbl/a8GuaMg26HQYe0vAtCRCTlbLfLh7u/X8eyzxuzczPLJVa0PeLuz9Sz/3EEN3sXFRV5cXFxY3Zdr5KSEpq6j511zKpjmPjVRB4e/jDZWdmN/lyYmZsiirmjmBmimTuKmSGauaOYOdU1pe3LCMsmQPkc2PuasJOIiGSMxj7HbYeZmQH/BGa6+18TdZxUMrpgNEvWLWHCvAlhRxEREUmc2XdBXmfY9aSwk4iIZIyEFW7AocBo4AgzmxK8jkng8UJ33MDj6NCiAw9N1SAlIiKSpjYuhUXPQv8zIbtl2GlERDJGwgo3d3/b3c3dC9x9WPB6IVHHSwUtc1py8pCTeWbmM5RvKQ87joiISPObez94JewxNuwkIiIZJZFX3DLS6ILRrK9Yz79m/ivsKCIiIs2rZlCS7sXQfmDYaUREMooKt2Z26K6H0q9jP8ZPGx92FBERkeZVVgrr58W6SYqISFKpcGtmWZbFGQVn8Nrc11i8dnHYcURERJpPWWnsvXNRuDlERDKQCrcEGF0wGsd5tPTRsKOIiIg0n7JpkJUH7fcMO4mISMZR4ZYAA7oM4KBdDuKhaQ/xzXNbRUREIq6sFNoPgqzcsJOIiGQcFW4JMqZgDNOXT2fqsqlhRxERkSQys5FmNsvM5pjZ5fVsc7KZfWpmM8wsOt0zykqh495hpxARyUgq3BLk5CEnk5uVq2e6iYhkEDPLBu4AjgYGA6ea2eBa2wwAfgcc6u5DgF8lO+dO2fI1bFyswk1EJCQq3BKkS+suHLvnsTxa+iibKzeHHUdERJLjAGCOu8919y3A48CoWtv8DLjD3b8GcPflSc64c2oGJlHhJiISChVuCXTB/hewbP0y7px8Z9hRREQkOXoDC+PmFwXL4u0J7Glm75jZ+2Y2MmnpmuLrabF3FW4iIqHICTtAOhvRfwRH9j+SGybewFnDzqJDyw5hRxIRkfDlAAOAYmAXYKKZ7e3uZfEbmdlYYCxAfn4+JSUlTTpoeXl5k/axZ9nLdLN2vPPBbLA5TcqyI5qaOwxRzAzRzB3FzBDN3FHMDNHNXRcVbgl20/duYr9x+/Gnd//EDUfcEHYcERFJrMVAn7j5XYJl8RYBH7h7BfClmX1OrJCbFL+Ru48DxgEUFRV5cXFxk4KVlJTQpH288ntouw/F3/1uk3LsqCbnDkEUM0M0c0cxM0QzdxQzQ3Rz10VdJRNs3577curQU/nre3/lq3VfhR1HREQSaxIwwMz6mVkecArwXK1tniV2tQ0z60qs6+TcJGbcce5QNh06qJukiEhYVLglwQ1H3EBldSV/ePMPYUcREZEEcvdK4ELgZWAm8KS7zzCz68zs+GCzl4FVZvYpMAH4rbuvCidxI62fD5XrdH+biEiIVLglQf9O/fl50c+59+N7mbVyVthxREQkgdz9BXff0913d/cbg2VXu/tzwbS7+yXuPtjd93b3x8NN3AgaUVJEJHQq3JLkyuFX0iq3FVe8cUXYUURERHZMWc2IkkPDzSEiksFUuCVJ9zbd+e0hv+XpmU/z/qL3w44jIiLSeGWl0KYv5LYPO4mISMZS4ZZElxx8Cd3bdOfy1y7H3cOOIyIi0jhrStVNUkQkZCrckqhtXluu+c41vDn/TV6a81LYcURERLavajOsnaXCTUQkZCrckuxn+/6MPTrvwWWvXUZVdVXYcURERBq29jPwKj0KQEQkZCrckiw3O5cbj7iR0uWlPFr6aNhxREREGrZ1YBIVbiIiYVLhFoKTBp9EUa8irpxwJZsqN4UdR0REpH5lpZCVB+33DDuJiEhGU+EWgizL4qYRN7FgzQLunHRn2HFERETqV1YK7QdBVm7YSUREMpoKt5CM6D+C7+/+fW546wbKK8vDjiMiIlK3Mo0oKSKSClS4heimETexeuNqHl/4eNhRREREtrXla9i4WIWbiEgKUOEWon167sNpe5/GU4ueYsm6JWHHERER+bay0ti7CjcRkdCpcAvZ9d+9niqv4g8lfwg7ioiIyLd9rRElRURShQq3kPXv1J/jex3PPz/5J5+t/CzsOCIiIt9YUwp5naBV77CTiIhkPBVuKWD0rqNpnduaK964IuwoIiIi36gZmMQs7CQiIhlPhVsK6JjXkd8e8luemfkM7y96P+w4IiIi4A5l06GDukmKiKQCFW4p4uKDLya/TT6Xvnop7h52HBERyXTr50PlOt3fJiKSIlS4pYi2eW255jvX8NaCt3hh9gthxxERkUynESVFRFKKCrcUcs6+57BH5z24/PXLqaquCjuOiIhksrKaESWHhptDREQAFW4pJTc7lz8e8UemL5/Ow9MeDjuOiIhksrJSaNMXctuHnURERFDhlnJOGnwS+/fan6smXMWmyk1hxxERkUy1plTdJEVEUogKtxRjZtz8vZtZuHYhd3x4R9hxREQkE1VthrWzVLiJiKQQFW4p6Lv9vsvIPUZy41s3UrapLOw4IiKSadZ+Bl6lRwGIiKQQFW4p6qYRN1G2qYyb37457CgiIpJptg5MosJNRCRVqHBLUYU9Cjm94HRu+eAWFq9dHHYcERHJJGWlkJUH7fcMO4mIiARUuKWw6797PdVezbUl14YdRUREMklZKbQfBFm5YScREZGACrcU1rdjX84vOp/7ptzHzBUzw44jIiKZokwjSoqIpBoVbinuiuFX0Ca3Db9/4/dhRxERkUyw5WvYuFiFm4hIilHhluK6tu7KpYdeyrOfPcurX7wadhwREUl3ZaWxdxVuIiIpRYVbBFxy8CUM6jqInzz7E1ZuWBl2HBERSWdfa0RJEZFUpMItAlrntuaxEx9j1cZV/PS5n+LuYUcSEZF6mNlIM5tlZnPM7PI61p9pZivMbErwOieMnPVaUwp5naBV77CTiIhIHBVuEVHYo5Cbv3czz816jrsm3xV2HBERqYOZZQN3AEcDg4FTzWxwHZs+4e7Dgte9SQ25PTUDk5iFnUREROKocIuQXxz4C0buMZJLXrmEGctnhB1HRES2dQAwx93nuvsW4HFgVMiZGs8dyqZDB3WTFBFJNTmJ2rGZ3QccCyx396GJOk4mybIsHhj1AAV3FXDq06fy4c8+pGVOy7BjiYjIN3oDC+PmFwEH1rHdiWY2HPgcuNjdF9bewMzGAmMB8vPzKSkpaVKw8vLy7e6jZeVSDqpcx6zleXzVxOM1l8bkTjVRzAzRzB3FzBDN3FHMDNHNXZeEFW7AA8DtwEMJPEbGyW+bz/2j7ucHj/6Ay169jFuPvjXsSCIismP+Azzm7pvN7FzgQeCI2hu5+zhgHEBRUZEXFxc36aAlJSVsdx+LnoPlMPCAkxjY7ZAmHa+5NCp3ioliZohm7ihmhmjmjmJmiG7uuiSsq6S7TwRWJ2r/meyYAcfwywN/yd8//Dv//fy/YccREZFvLAb6xM3vEizbyt1XufvmYPZeYL8kZdu+rY8CUEcZEZFUo3vcIuqm791EQX4BZ/37LJaWLw07joiIxEwCBphZPzPLA04BnovfwMx6xs0eD8xMYr6GlZVCm76Q2z7sJCIiUksiu0o2Shh9+FPNzma+uM/FnPvxuRx333HcvPfNZFly6/BMOtdhi2LuKGaGaOaOYuZ05e6VZnYh8DKQDdzn7jPM7Dpgsrs/B/zCzI4HKon1TDkztMC1rSnV89tERFJU6IVbKH34U0xTMm/K38R5/z2PqS2ncvHBFzdvsO3ItHMdpijmjmJmiGbuKGZOZ+7+AvBCrWVXx03/DvhdsnNtV9VmWDsLdvlh2ElERKQO6ioZcefudy6jBo7i8tcvZ8rSKWHHERGRqFr7GXiVHgUgIpKiEla4mdljwHvAQDNbZGY/TdSxMpmZce/x99K1dVdOffpUNlRsCDuSiIhEUdm02Lu6SoqIpKREjip5qrv3dPdcd9/F3f+ZqGNluq6tu/LQDx9i1spZXPLyJWHHERGRKCorhaw8aL9n2ElERKQO6iqZJkb0H8Glh17K3R/dzb9m/ivsOCIiEjVlpdB+EGTlhp1ERETqoMItjVz33eso6lXEOf85h0VrF4UdR0REoqRMI0qKiKQyFW5pJC87j0d/9CibKzcz5l9jqKquCjuSiIhEwebVsHGxCjcRkRSmwi3NDOgygNuOvo0J8ybwp3f/FHYcERGJgrLS2LsKNxGRlKXCLQ2dOexMTh5yMldNuIoPF38YdhwREUl1KtxERFKeCrc0ZGbc9YO76NWuF6c9fRrrNq8LO5KIiKSyNaWQ1wla9Q47iYiI1EOFW5rq1KoTD5/wMF+WfclFL14UdhwREUllNQOTmIWdRERE6qHCLY0dvtvhXHn4lTw49UEen/542HFERCQVuUPZdOigbpIiIqlMhVuau+o7V3HwLgfz8+d/zryyeWHHERGRVLN+PlSu0/1tIiIpToVbmsvJyuGRHz2C45zxzBlUVleGHUlERFJJ2bTYuwo3EZGUpsItA/Tr1I+7fnAX7yx8hxsn3hh2HBERSSVbR5QcGm4OERFpkAq3DHHq3qcypnAM1028jglfTgg7joiIpIqyUmjTF3Lbh51EREQaoMItg9x+9O0M7DKQUY+PYvKSyWHHERGRVLCmVN0kRUQiQIVbBmnXoh2vjn6VLq27MPLhkcxYPiPsSCIiEqaqzbB2lgo3EZEIUOGWYXq3781ro18jLzuPI8cfydyv54YdSUREwrJ2JniVHgUgIhIBKtwy0O6dd+fV0a+ypWoLIx4aweK1i8OOJCIiYdg6MIkKNxGRVKfCLUMN6T6El854iVUbVnHk+CNZsX5F2JFERCTZykohKw/a7xl2EhER2Q4VbhmsqFcRz5/2PF+WfclRDx/Fmk1rwo4kIiLJVFYK7QdBVm7YSUREZDtUuGW44bsN55mTn2H68ukc+9ixbKjYEHYkERFJljKNKCkiEhUq3ISjBxzNIz96hHcXvssJT5zA5srNYUcSEZFE27waNi5W4SYiEhEq3ASA/zfk/3HPcffwyhevcNozp1FZXRl2JBERSSQNTCIiEikq3GSrs/c5m1uOuoVnZj7DOc+dQ7VXhx1JREQSRYWbiEik5IQdQFLLLw/6JWs2r+Gakmto36I9t468FTMLO5aIiDS3NaWQ1wla9Q47iYiINIIKN9nGVcOvYu3mtfzlvb/QvkV7bjjihrAjiYhIc6sZmES/nBMRiQQVbrINM+NPR/6JtZvXcuNbN9KhRQd+e+hvw44lIiLNxauhbDr0GxN2EhERaSTd4yZ1MjPu/MGd/HjIj7n0tUu5e/LdYUcSEYkEMxtpZrPMbI6ZXd7AdieamZtZUTLzAbB+PlSu0/1tIiIRoituUq/srGzGnzCe9RXrOe+/59GuRTtO2/u0sGOJiKQsM8sG7gCOBBYBk8zsOXf/tNZ27YBfAh8kPyUamEREJIJ0xU0alJudy5MnPUlx32LG/GsMz816LuxIIiKp7ABgjrvPdfctwOPAqDq2ux64GdiUzHBbbS3choZyeBER2XEq3GS7WuW24t+n/Jv9eu3Hyf93Mq/PfT3sSCIiqao3sDBuflGwbCsz2xfo4+7/TWawbykrhTZ9Ibd9aBFERGTHqKukNEq7Fu148fQX+c4D32HU46N4dfSrYUcSEYkcM8sC/gqc2YhtxwJjAfLz8ykpKWnSscvLy7fuY//l77MxuzfTm7jPZIjPHRVRzAzRzB3FzBDN3FHMDNHNXRcVbtJonVt15tXRr3L4/YdzzKPHcNPgmyimOOxYIlRUVZCbnRt2DBGAxUCfuPldgmU12gFDgZLgGZk9gOfM7Hh3nxy/I3cfB4wDKCoq8uLi4iYFKykpobi4GKo2w5OLaDPwdIoLm7bPZNiaO0KimBmimTuKmSGauaOYGaKbuy7qKik7pEfbHrw2+jXa5bXjok8u4saJN1JRVRF2LMlgE+dPpNufunHms2fquyipYBIwwMz6mVkecAqw9eZgd1/j7l3dva+79wXeB7Yp2hJq7UzwKuiggUlERKJEhZvssN067sZHYz/i0K6HcuWEKznonwdRuqw07FiSgV6b+xojHx5Jy5yWPDj1QY5//HjKt5SHHUsymLtXAhcCLwMzgSfdfYaZXWdmx4ebLqARJUVEIkmFm+yUbm26cc3ga3jq/z3ForWL2G/cflz/5vW64iFJ8/znz3Pso8cyoMsApp03jXuOu4dXvniFIx48ghXrV4QdTzKYu7/g7nu6++7ufmOw7Gp332ZYXncvTurVNogVbll50H7PpB5WRESaRoWbNMmJg09kxvkzOGnwSVxdcjUH3nsgU5dODTuWpLlnZj7Dj574EUO7D2XCTybQvU13ztn3HJ45+RlKl5dy6H2HMq9sXtgxRVJTWSm0HwRZui9URCRKVLhJk3Vt3ZVHT3yUZ05+hiXrllB0TxF/KPkDW6q2hB1N0tCjpY9y8v+dTFGvIl4f8zqdW3Xeum7UXqN4bfRrrNywkoP/ebB+iSBSl7JSdZMUEYkgFW7SbE4YdAIzzp/BKUNP4do3r+WAew5gytIpYceSNHL/J/dzxjNncPhuh/PK6Ffo0LLDNtscuuuhvHXWW+Rk5TD8geGUzCtJflCRVLV5NWxcrMJNRCSCVLhJs+rSugvjTxjPv0/5N8vWL2P/e/bnmgnX6OqbNNmdk+7k7OfO5sjdj+S/p/2Xtnlt6912SPchvHv2u/Ru15ujHj6Kpz59KolJRVKYBiYREYksFW6SEMcPPJ4Z58/gtL1P47qJ11E0roiPv/o47FgSUX9772+c/8L5HLfncTx3ynO0zm293c/06dCHt89+m6JeRZz8fyfzj0n/SEJSkRSnwk1EJLJUuEnCdG7VmQd/+CD/OfU/rNq4igPuOYAr37iSzZWbw44mEfLHt/7IJa9cwkmDT+Kpk5+iRU6LRn+25qHxx+55LBe8cAFXvXEV7p7AtCIpbk0p5HWCVr3DTiIiIjtIhZsk3LF7Hsv086YzunA0N751I/uN24/JS5I7+rVEj7tz9YSrueKNKzij4AweO/Ex8rLzdng/rXNb88yPn+Gn+/yUG966gbH/GUtldWUCEotEQM3AJGZhJxERkR2kwk2SolOrTtw/6n5eOO0FyjaVcdC9B/H713+vq29SJ3fn0lcv5fqJ13POPufwwKgHyMnK2en95WTlcM9x93Dl4Vdy7yf3cuKTJ7KxYmMzJhaJAK+GsunQQd0kRUSiSIWbJNXRA45mxvkzOHPYmfzP2//DvuP25eU5L7OpclPY0SRFVHs1v3jxF/z5vT9zwf4XcPdxd5Odld3k/ZoZ1x9xPbcffTv/mfUfjhx/JKs3rm6GxCLR0LJqGVSu0/1tIiIRpcJNkq5Dyw7ce/y9vHT6S6zdvJaRj4ykw00dOPz+w7ni9St4aU5suWSequoqzv3Pudw+6XZ+c/BvuO3o28iy5v1r6oIDLuDJ//ckk5ZM4vD7D2fhmoXNun+RVNWmcm5sQoWbiEgk7XzfI5EmOmqPo/jsgs9448s3eGvBW0ycP5H/ffd/+ePbfyTLshjWYxjDdx3O8N2Gc9iuh9GtTbewI0sCVVZXcuazZ/JI6SNcNfwq/lD8ByxB9+GcNPgkurTqwg+f+CGH3HcIL5/xMoO7DU7IsURSRZuKL2MTHYeGG0RERHaKCjcJVZu8Nhw38DiOG3gcAOu3rOf9Re8zcf5EJi6YyF0f3cUtH9wCwKCugzh818MZvttwDt/tcHbtsGuIyaU5banawunPnM5Tnz7FjUfcyO8P/33Cj/ndft9l4pkTGfnISA677zCeP+15DulzSMKPKxKWthVzoU1fyG0fdhQREdkJCS3czGwkcCuQDdzr7jcl8ngSfW3y2jCi/whG9B8BxP5BP3nJZN6a/xYTF0zkiRlPMO7jcQDs1mG3WBEXFHN7dtkzYVdoJHE2VW7i5P87mf98/h/++v2/cvHBFyft2IU9Cnn37Hc56uGjGPHQCJ486Una0S5pxxdJpjaVc6FLQdgxRERkJyWscDOzbOAO4EhgETDJzJ5z908TdUxJP3nZeRzS5xAO6XMIl3EZVdVVlC4v3VrIvfzFy4yfNh6Adnnt6NyqM+1btK/3tXzRcuZ+Mrfe9W3z2jb7PVVSvw0VGzjhiRN45YtX+Mcx/+C8/c9LeoZ+nfrxztnv8INHf8AJT5zAEd2P4L9b/kunVp3o1LLTt947t+pMp5ad6NiyY7MMmCKSNFWbaV25EDqeHnYSERHZSYm84nYAMMfd5wKY2ePAKECFm+y07KxshvUYxrAew7jowItwd2avns3E+ROZtmwaazev3fpauWElc7+eu3V+fcX62E6+aPgYbfPakpOVQ5ZlkW3Zsfes7G/N17WsofnsrOyt7zlZOdss+9Z7HcsWL17M81uexzDMrM73LMuqd138O/Cth1A7Xu+y+OXxyxpj3rx5lJSUNLjNa3Nf492F7/LP4//J2fucvUP7b07d2nTjjZ+8wc/+8zNe+/w13p70NhsrG35cQPsW7b9V2NUUdTXzbfLaYMTOd/yV4IaWxS+vvSz+c7WnP1v6GfOmzKt3m5r9bW8/jZ0e1G0Qe3bZc7vnVVLI2pkY1XoUgIhIhCWycOsNxA/Xtgg4sPZGZjYWGAuQn5+/3X/obU95eXmT95FsUcwMqZV7D/Zgj1Z7QKv6t6nyKlasWYG1NDZUbWB95fo63zdUbaDaq2Mvar3HTbs7VVTh7lRXV1NdFSzHqfIqKrxi63TNZ6uITW9dFrffKq9qcJ4lseLJ8W8VUzXzNf+llPkNr26Z1ZLf7/V7+q/pnxLfpXO7nMvpe59O27Zt2VK9hfLKctZVrGNt5drYdOU61lWs2zq9tnIt5VvKWbFhBXMr51JeWc7airVUeEXyw89K3qHO7ns2o3cbnbwDStOVlcbeNaKkiEhkhT44ibuPA8YBFBUVeXFxcZP2V1JSQlP3kWxRzAzRzB3FzLDjubcWcnW813dFp75l8ct35B7CTDnXddlYsZENFRuA7V+9bMzVz28V6nVMv/f+exx44IF1blOzv8bsp7HTPdv2pGe7njt9fiQEfX7Ex7PXsW97XSkVEYmqRBZui4E+cfO7BMtEJMG2dmvTWC2haJXbila5DVz+bWZftvySfp36Je14EkE5bVibNxiycsNOIiIiOymRozBMAgaYWT8zywNOAZ5L4PFERERERETSUsKuuLl7pZldCLxM7HEA97n7jEQdT0REREREJF0l9B43d38BeCGRxxAREREREUl3emCViIiIiIhIilPhJiIiIiIikuJUuImIiIiIiKQ4FW4iIiIiIiIpToWbiIiIiIhIilPhJiIiIiIikuJUuImIiIiIiKQ4c/ewM2xlZiuA+U3cTVdgZTPESaYoZoZo5o5iZohm7ihmhmjmjmLm3dy9W9ghoiKD20eIZu4oZoZo5o5iZohm7ihmhmjmrrONTKnCrTmY2WR3Lwo7x46IYmaIZu4oZoZo5o5iZohm7ihmluSL6vckirmjmBmimTuKmSGauaOYGaKbuy7qKikiIiIiIpLiVLiJiIiIiIikuHQs3MaFHWAnRDEzRDN3FDNDNHNHMTNEM3cUM0vyRfV7EsXcUcwM0cwdxcwQzdxRzAzRzb2NtLvHTUREREREJN2k4xU3ERERERGRtBLZws3MRprZLDObY2aX17G+hZk9Eaz/wMz6hhAzPk8fM5tgZp+a2Qwz+2Ud2xSb2RozmxK8rg4ja21mNs/MSoNMk+tYb2b29+BcTzOzfcPIGZdnYNw5nGJma83sV7W2SYlzbWb3mdlyM5set6yzmb1qZrOD9071fPYnwTazzewnIWf+k5l9Fvz5/8vMOtbz2Qa/S4lUT+5rzWxx3PfgmHo+2+DfN0nO/ERc3nlmNqWez4Z2riVcUWsfg0yRbCOj1j4GmdRGJj9zSreRUWwfg2NnXhvp7pF7AdnAF0B/IA+YCgyutc35wF3B9CnAEyFn7gnsG0y3Az6vI3Mx8HzY57eO7POArg2sPwZ4ETDgIOCDsDPX+q4sJfY8jJQ718BwYF9getyy/wUuD6YvB26u43OdgbnBe6dgulOImb8P5ATTN9eVuTHfpRByXwv8phHfoQb/vklm5lrr/wJcnWrnWq/wXlFsH4MckWwjo9w+xn1f1EYmPnNKt5FRbB/ry11rfdq1kVG94nYAMMfd57r7FuBxYFStbUYBDwbTTwEjzMySmPFb3P0rd/84mF4HzAR6h5WnmY0CHvKY94GOZtYz7FCBEcAX7t7UB9cmhLtPBFbXWhz/3X0Q+GEdHz0KeNXdV7v718CrwMhE5YxXV2Z3f8XdK4PZ94FdkpFlR9RzrhujMX/fJERDmYO/z04GHktGFomMyLWPkNZtZCq3j6A2stlFsY2MYvsImdlGRrVw6w0sjJtfxLZ/wW/dJvifZQ3QJSnptiPolrIP8EEdqw82s6lm9qKZDUlusno58IqZfWRmY+tY35g/j7CcQv3/06biuQbId/evgumlQH4d26TyOT+b2G+Y67K971IYLgy6r9xXT5ebVD3XhwPL3H12PetT8VxL4kW6fYTItZFRbh9BbWQYotRGRrV9hDRtI6NauEWWmbUFngZ+5e5ra63+mFh3hULgNuDZJMerz2Huvi9wNHCBmQ0PO1BjmFkecDzwf3WsTtVz/S0eu54fmaFfzewKoBJ4pJ5NUu27dCewOzAM+IpYt4qoOJWGf5OYaudaZLsi2EZG9v8ztZHJF7E2MsrtI6RpGxnVwm0x0CdufpdgWZ3bmFkO0AFYlZR09TCzXGIN0iPu/kzt9e6+1t3Lg+kXgFwz65rkmNtw98XB+3LgX8QujcdrzJ9HGI4GPnb3ZbVXpOq5Diyr6UoTvC+vY5uUO+dmdiZwLHB60JhuoxHfpaRy92XuXuXu1cA99eRJxXOdA/wIeKK+bVLtXEvSRLJ9DLJEro2McPsIaiOTKmptZFTbR0jvNjKqhdskYICZ9Qt+Y3QK8FytbZ4DakYROgl4o77/UZIh6Gv7T2Cmu/+1nm161NxnYGYHEPvzCbvYbGNm7Wqmid1gO73WZs8BYyzmIGBNXDeGMNX725ZUPNdx4r+7PwH+Xcc2LwPfN7NOQfeF7wfLQmFmI4FLgePdfUM92zTmu5RUte41OYG68zTm75tk+x7wmbsvqmtlKp5rSZrItY8QzTYy4u0jqI1Mmii2kRFuHyGd28jGjmKSai9iIzV9Tmw0myuCZdcR+58CoCWxy/9zgA+B/iHnPYzY5fxpwJTgdQzwc+DnwTYXAjOIjcrzPnBICpzn/kGeqUG2mnMdn9uAO4I/i1KgKAVytyHWyHSIW5Zy55pYo/kVUEGsb/hPid1r8jowG3gN6BxsWwTcG/fZs4Pv9xzgrJAzzyHWz73mu10zYl0v4IWGvksh5x4ffGenEWtsetbOHcxv8/dNWJmD5Q/UfJfjtk2Zc61XuK+6vq+kcPsYZIpcG1nf/2ekePsY5FIbmdzMKd1G1pM5pdvH+nIHyx8gTdtIC34AERERERERSVFR7SopIiIiIiKSMVS4iYiIiIiIpDgVbiIiIiIiIilOhZuIiIiIiEiKU+EmIiIiIiKS4lS4iTQTM6sysylxr8ubcd99zSwazxgRERGJo/ZRpHnkhB1AJI1sdPdhYYcQERFJMWofRZqBrriJJJiZzTOz/zWzUjP70Mz2CJb3NbM3zGyamb1uZrsGy/PN7F9mNjV4HRLsKtvM7jGzGWb2ipm1Cu2HEhERaSK1jyI7RoWbSPNpVasryI/j1q1x972B24FbgmW3AQ+6ewHwCPD3YPnfgTfdvRDYF5gRLB8A3OHuQ4Ay4MSE/jQiIiLNQ+2jSDMwdw87g0haMLNyd29bx/J5wBHuPtfMcoGl7t7FzFYCPd29Ilj+lbt3NbMVwC7uvjluH32BV919QDB/GZDr7jck4UcTERHZaWofRZqHrriJJIfXM70jNsdNV6F7VEVEJPrUPoo0kgo3keT4cdz7e8H0u8ApwfTpwFvB9OvAeQBmlm1mHZIVUkREJMnUPoo0kn4jIdJ8WpnZlLj5l9y9ZsjjTmY2jdhvBU8Nll0E3G9mvwVWAGcFy38JjDOznxL7zeF5wFeJDi8iIpIgah9FmoHucRNJsKAPf5G7rww7i4iISKpQ+yiyY9RVUkREREREJMXpipuIiIiIiEiK0xU3ERERERGRFKfCTUREREREJMWpcBMREREREUlxKtxERERERERSnAo3ERERERGRFKfCTUREREREJMX9f+3JwUTcVcNSAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def looping_step(dataloader, model, optimizer, criterion, metric, n_epoch=hyperparams.n_epoch, patience=hyperparams.patience, monitor=\"loss\"):    \n",
    "    start_time = time()\n",
    "    \n",
    "    epoch_losses = []\n",
    "    epoch_metric_scores = []\n",
    "    patience_counter = 0\n",
    "    \n",
    "    now = datetime.now(pytz.timezone(\"Asia/Ujung_Pandang\"))\n",
    "    path_name = now.strftime(\"%m-%d-%Y_%H-%M-%S\")\n",
    "    os.makedirs(f\"../../logs/comick/{hyperparams.context_size}_contexts/{path_name}\")\n",
    "    \n",
    "    # Hyperparameters\n",
    "    with open(f\"../../logs/comick/{hyperparams.context_size}_contexts/{path_name}/training_history.txt\", \"a\") as f:\n",
    "        f.write(f\"HYPERPARAMETERS\\n\")\n",
    "        f.write(f\"{'-' * 50}\\n\")\n",
    "        for name, value in vars(hyperparams).items():\n",
    "            f.write(f\"{name}: {value}\\n\")\n",
    "        \n",
    "        f.write(\"\\n\\nTRAINING PROGRESS\\n\")\n",
    "        f.write(f\"{'-' * 50}\\n\")\n",
    "    \n",
    "    # Training Progress\n",
    "    for epoch in range(1, n_epoch + 1):\n",
    "        print(f\"EPOCH-{epoch}\")\n",
    "        with open(f\"../../logs/comick/{hyperparams.context_size}_contexts/{path_name}/training_history.txt\", \"a\") as f:\n",
    "            f.write(f\"EPOCH-{epoch}\\n\")\n",
    "        \n",
    "        batch_losses, batch_metric_scores = training_step(dataloader, model, optimizer, criterion, metric, path_name=path_name)\n",
    "        epoch_loss = torch.mean(torch.FloatTensor(batch_losses))\n",
    "\n",
    "        epoch_loss = torch.mean(torch.FloatTensor(batch_losses))\n",
    "        epoch_losses.append(epoch_loss.item())\n",
    "\n",
    "        epoch_metric_score = torch.mean(torch.FloatTensor(batch_metric_scores))\n",
    "        epoch_metric_scores.append(epoch_metric_score.item())\n",
    "        \n",
    "        with open(f\"../../logs/comick/{hyperparams.context_size}_contexts/{path_name}/training_history.txt\", \"a\") as f:\n",
    "            if monitor == \"loss\":\n",
    "                if epoch == 1:\n",
    "                    best_state_dict = model.state_dict()\n",
    "                    best_loss = (epoch_loss)\n",
    "                    best_metric = (epoch_metric_score)\n",
    "                    \n",
    "                    print(f\"\\nMean {str(criterion).split('(')[0]}: {(epoch_loss):.4f} | Mean {str(metric).split('(')[0]}: {(epoch_metric_score):.4f}\")\n",
    "                    \n",
    "                    f.write(f\"\\nMean {str(criterion).split('(')[0]}: {(epoch_loss):.4f} | Mean {str(metric).split('(')[0]}: {(epoch_metric_score):.4f}\\n\")\n",
    "                elif epoch_losses[-1] < epoch_losses[-2]:\n",
    "                    best_state_dict = model.state_dict()\n",
    "                    best_loss = (epoch_loss)\n",
    "                    best_metric = (epoch_metric_score)\n",
    "                    \n",
    "                    print(\"\\nYeah 🎉😄! Model improved.\")\n",
    "                    print(f\"Mean {str(criterion).split('(')[0]}: {(epoch_loss):.4f} | Mean {str(metric).split('(')[0]}: {(epoch_metric_score):.4f}\")\n",
    "                    \n",
    "                    f.write(\"\\nYeah 🎉😄! Model improved.\\n\")\n",
    "                    f.write(f\"Mean {str(criterion).split('(')[0]}: {(epoch_loss):.4f} | Mean {str(metric).split('(')[0]}: {(epoch_metric_score):.4f}\\n\")\n",
    "                else:\n",
    "                    patience_counter += 1\n",
    "                    \n",
    "                    print(\"\\nHuft 😥! Model not improved.\")\n",
    "                    print(f\"Mean {str(criterion).split('(')[0]}: {(epoch_loss):.4f} | Mean {str(metric).split('(')[0]}: {(epoch_metric_score):.4f}\")\n",
    "                    print(f\"Patience = {patience_counter}/{patience}❗\")\n",
    "                    \n",
    "                    f.write(\"\\nHuft 😥! Model not improved.\\n\")\n",
    "                    f.write(f\"Mean {str(criterion).split('(')[0]}: {(epoch_loss):.4f} | Mean {str(metric).split('(')[0]}: {(epoch_metric_score):.4f}\\n\")                    \n",
    "                    f.write(f\"Patience = {patience_counter}/{patience}❗\\n\")\n",
    "            else:\n",
    "                if epoch == 1:\n",
    "                    best_state_dict = model.state_dict()\n",
    "                    best_loss = (epoch_loss)\n",
    "                    best_metric = (epoch_metric_score)\n",
    "                    \n",
    "                    print(f\"\\nMean {str(criterion).split('(')[0]}: {(epoch_loss):.4f} | Mean {str(metric).split('(')[0]}: {(epoch_metric_score):.4f}\")\n",
    "                    \n",
    "                    f.write(f\"\\nMean {str(criterion).split('(')[0]}: {(epoch_loss):.4f} | Mean {str(metric).split('(')[0]}: {(epoch_metric_score):.4f}\\n\")\n",
    "                elif epoch_metric_scores[-1] > epoch_metric_scores[-2]:\n",
    "                    best_state_dict = model.state_dict()\n",
    "                    best_loss = (epoch_loss)\n",
    "                    best_metric = (epoch_metric_score)\n",
    "                    \n",
    "                    print(\"\\nYeah 🎉😄! Model improved.\")\n",
    "                    print(f\"Mean {str(criterion).split('(')[0]}: {(epoch_loss):.4f} | Mean Mean {str(metric).split('(')[0]}: {(epoch_metric_score):.4f}\")\n",
    "                    \n",
    "                    f.write(\"\\nYeah 🎉😄! Model improved.\\n\")\n",
    "                    f.write(f\"Mean {str(criterion).split('(')[0]}: {(epoch_loss):.4f} | Mean {str(metric).split('(')[0]}: {(epoch_metric_score):.4f}\\n\")\n",
    "                else:\n",
    "                    patience_counter += 1\n",
    "                    \n",
    "                    print(\"\\nHuft 😥! Model not improved.\")\n",
    "                    print(f\"Mean {str(criterion).split('(')[0]}: {(epoch_loss):.4f} | Mean {str(metric).split('(')[0]}: {(epoch_metric_score):.4f}\\n\")\n",
    "                    print(f\"Patience = {patience_counter}/{patience}❗\\n\")\n",
    "                    \n",
    "                    f.write(\"\\nHuft 😥! Model not improved.\\n\")\n",
    "                    f.write(f\"Mean {str(criterion).split('(')[0]}: {(epoch_loss):.4f} | Mean {str(metric).split('(')[0]}: {(epoch_metric_score):.4f}\\n\")\n",
    "                    f.write(f\"Patience = {patience_counter}/{patience}❗\\n\")\n",
    "                    \n",
    "            print(\"=\" * 50, end=\"\\n\\n\")\n",
    "            f.write(f\"{'=' * 50}\\n\\n\")\n",
    "            \n",
    "            if patience_counter == patience:\n",
    "                print(f\"Early stopping, patience = {patience_counter}/{patience}❗\\n\")\n",
    "                f.write(f\"Early stopping, patience = {patience_counter}/{patience}❗\\n\")\n",
    "                break\n",
    "        \n",
    "        metric.reset()\n",
    "    \n",
    "    finish_time = time()\n",
    "    \n",
    "    # Training plot \n",
    "    fig, (ax_loss, ax_metric_score) = plt.subplots(nrows=1, ncols=2, figsize=(15, 5))\n",
    "\n",
    "    fig.suptitle(f\"Training with context size = {hyperparams.context_size}\")\n",
    "\n",
    "    ax_loss.set_title(\"Loss\")\n",
    "    ax_loss.set_xlabel(\"Epoch\")\n",
    "    ax_loss.set_ylabel(\"Score\")\n",
    "    ax_loss.plot(epoch_losses, \"green\")\n",
    "    ax_loss.grid()\n",
    "\n",
    "    ax_metric_score.set_title(\"F1 Score\")\n",
    "    ax_metric_score.set_xlabel(\"Epoch\")\n",
    "    ax_metric_score.set_ylabel(\"Score\")\n",
    "    ax_metric_score.plot(epoch_metric_scores, \"orange\")\n",
    "    ax_metric_score.grid()\n",
    "\n",
    "    plt.savefig(f\"../../logs/comick/{hyperparams.context_size}_contexts/{path_name}/training_plot.jpg\", dpi=200)                        \n",
    "    \n",
    "    print(\"TRAINING SUMMARY\")\n",
    "    criterion_name = \"Best \" + str(criterion).split('(')[0]\n",
    "    metric_name = \"Best \" + str(metric).split('(')[0]\n",
    "    \n",
    "    print(f\"{criterion_name.ljust(18)}: {best_loss:.4f}\")\n",
    "    print(f\"{metric_name.ljust(18)}: {best_metric:.4f}\")\n",
    "    print(f\"{'Training duration'.ljust(18)}: {((finish_time - start_time) / 60):.3f} minutes.\")\n",
    "    print(f\"{'Training date'.ljust(18)}: {now}\")\n",
    "    \n",
    "    with open(f\"../../logs/comick/{hyperparams.context_size}_contexts/{path_name}/training_history.txt\", \"a\") as f:\n",
    "        f.write(\"\\nTRAINING SUMMARY\\n\")\n",
    "        f.write(f\"{'-' * 50}\\n\")\n",
    "        f.write(f\"{criterion_name.ljust(18)}: {best_loss:.4f}\\n\")\n",
    "        f.write(f\"{metric_name.ljust(18)}: {best_metric:.4f}\\n\")\n",
    "        f.write(f\"{'Training duration'.ljust(18)}: {((finish_time - start_time) / 60):.3f} minutes.\\n\")\n",
    "        f.write(f\"{'Training date'.ljust(18)}: {now}\\n\")\n",
    "    \n",
    "    # Save epoch losses, epoch metric scores, model, state dict, and oov embedding dict\n",
    "    filename_model_params = f\"../../logs/comick/{hyperparams.context_size}_contexts/{path_name}/model_params.pth\"\n",
    "    filename_oov_embedding_dict = open(f\"../../logs/comick/{hyperparams.context_size}_contexts/{path_name}/oov_embedding_dict.pkl\", \"ab\")\n",
    "    \n",
    "    pd.DataFrame(\n",
    "        data={\n",
    "            \"epoch\": list(range(1, len(epoch_losses) + 1)),\n",
    "            \"loss\": epoch_losses\n",
    "        }\n",
    "    ).to_csv(f\"../../logs/comick/{hyperparams.context_size}_contexts/{path_name}/epoch_losses.csv\", index=False)\n",
    "    \n",
    "    pd.DataFrame(\n",
    "        data={\n",
    "            \"epoch\": list(range(1, len(epoch_metric_scores) + 1)),\n",
    "            \"f1_score\": epoch_metric_scores\n",
    "        }\n",
    "    ).to_csv(f\"../../logs/comick/{hyperparams.context_size}_contexts/{path_name}/epoch_metric_scores.csv\", index=False)\n",
    "    \n",
    "    torch.save(best_state_dict, filename_model_params)\n",
    "    pickle.dump({token : embedding for token, embedding in zip(list(labels_to_idx.keys()), model.embedding)}, filename_oov_embedding_dict)\n",
    "    \n",
    "    return epoch_losses, epoch_metric_scores\n",
    "\n",
    "epoch_losses, epoch_metric_scores = looping_step(dataloader, model, optimizer, criterion, metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfef50c-e71c-4288-a9f3-6fd8831033b0",
   "metadata": {},
   "source": [
    "# END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92debcb3-d6ea-4299-a3e9-37be5b63d2b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.123893  , -4.758261  ,  2.4090116 , ..., -5.3842897 ,\n",
       "        -1.1657342 , -0.5031694 ],\n",
       "       [ 2.6494255 , -2.9381366 ,  5.783752  , ..., -2.6590643 ,\n",
       "         2.869532  , -0.581211  ],\n",
       "       [ 2.5816772 , -4.116673  ,  3.3116522 , ..., -1.1632373 ,\n",
       "         5.8818603 , -0.10008387],\n",
       "       ...,\n",
       "       [-4.815262  ,  0.8319473 ,  0.73953366, ..., -4.19462   ,\n",
       "        -0.09331445,  3.5281932 ],\n",
       "       [-6.008277  , -1.5984788 , -7.2975583 , ...,  4.407662  ,\n",
       "        -2.0702205 ,  1.2784096 ],\n",
       "       [ 4.537079  , -2.6377301 ,  2.0319297 , ..., -2.1295185 ,\n",
       "         3.9135327 , -0.90989745]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27ce78c3-ac2c-4a84-a8e8-4d8e85d26563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('bilstm_left_context_feature.weight_ih_l0',\n",
       "              tensor([[ 0.2279,  0.1173,  0.2839,  ..., -0.3686,  0.3743, -0.2088],\n",
       "                      [-0.0447,  0.1772,  0.3711,  ...,  0.2441, -0.1194,  0.0585],\n",
       "                      [ 0.2194, -0.1225,  0.1520,  ..., -0.4866, -0.0883, -0.4994],\n",
       "                      ...,\n",
       "                      [-0.2099, -0.0119,  0.0727,  ..., -0.1183,  0.0479,  0.0429],\n",
       "                      [ 0.4173, -0.3220, -0.2509,  ..., -0.0648,  0.1155, -0.2906],\n",
       "                      [ 0.4071, -0.2240,  0.2803,  ..., -0.2233, -0.0966, -0.0993]])),\n",
       "             ('bilstm_left_context_feature.weight_hh_l0',\n",
       "              tensor([[ 0.0337, -0.0804,  0.1614,  ...,  0.1311,  0.0366, -0.0398],\n",
       "                      [-0.0462, -0.0560,  0.0547,  ...,  0.0682, -0.1361, -0.0874],\n",
       "                      [ 0.1633, -0.1799, -0.2947,  ..., -0.0098,  0.0121,  0.1039],\n",
       "                      ...,\n",
       "                      [-0.1146, -0.1018, -0.0478,  ...,  0.2246,  0.1673, -0.0256],\n",
       "                      [-0.1153, -0.0476,  0.2051,  ..., -0.0572, -0.0182, -0.1715],\n",
       "                      [-0.1562,  0.0910, -0.0397,  ...,  0.1938,  0.0363,  0.1891]])),\n",
       "             ('bilstm_left_context_feature.bias_ih_l0',\n",
       "              tensor([-2.2624e-01, -5.8214e-02, -6.7908e-02, -1.6422e-02, -1.4275e-01,\n",
       "                      -1.5252e-01, -7.6592e-02, -1.0658e-02, -1.9002e-01, -2.2749e-01,\n",
       "                      -2.8888e-01, -1.8987e-01, -1.4434e-01, -8.2406e-02, -2.2512e-01,\n",
       "                      -1.5381e-01, -2.0065e-01, -1.0396e-01, -1.4528e-01, -8.8903e-02,\n",
       "                      -1.3771e-02, -2.6393e-01, -2.0348e-01, -1.9608e-01, -1.2651e-01,\n",
       "                      -3.0804e-01, -6.1810e-02, -5.3983e-02, -7.2933e-02, -1.7602e-01,\n",
       "                      -1.1216e-01, -1.0816e-01,  4.3056e-02, -1.5338e-01, -1.7021e-01,\n",
       "                      -1.3386e-01,  2.5138e-03, -1.9808e-01, -1.2479e-01, -5.9183e-02,\n",
       "                      -4.5963e-02, -1.9864e-01, -1.8883e-01, -1.8110e-01, -2.5203e-01,\n",
       "                      -2.2588e-01, -2.4813e-01, -1.5437e-01, -2.0763e-01, -1.8898e-01,\n",
       "                      -1.1707e-01, -1.9774e-01, -1.9410e-01, -4.5210e-02, -1.0061e-01,\n",
       "                      -2.6911e-01, -1.9772e-01, -1.5715e-01, -2.7746e-02, -2.0654e-01,\n",
       "                      -1.4039e-01, -4.5943e-02, -1.6931e-01, -3.2763e-01, -2.0697e-01,\n",
       "                      -1.5149e-01, -2.3416e-01, -1.6542e-01, -1.4806e-01, -1.6991e-01,\n",
       "                      -1.5280e-01, -1.9126e-01, -1.8482e-01, -7.7908e-02, -1.4453e-01,\n",
       "                      -7.9169e-02, -1.8076e-01, -1.3274e-01, -1.3302e-01, -7.8029e-02,\n",
       "                      -2.1603e-01, -1.7053e-01, -1.1403e-02, -1.7497e-01, -1.1253e-01,\n",
       "                      -1.8000e-01, -1.0903e-01, -1.2014e-01, -9.0928e-02, -1.8715e-01,\n",
       "                      -1.0177e-01, -7.6945e-02, -9.1992e-02, -1.3113e-02, -2.4731e-01,\n",
       "                      -7.0953e-02, -1.3333e-01, -8.2180e-02,  9.5215e-03, -1.0059e-01,\n",
       "                      -1.5518e-01, -1.1726e-01, -1.1954e-01, -2.8151e-01, -2.2896e-01,\n",
       "                      -1.0683e-01, -2.7322e-01, -1.7565e-01, -1.1745e-01, -1.4162e-01,\n",
       "                      -1.5427e-01, -9.9206e-02, -6.9785e-02, -1.2038e-01, -1.0960e-01,\n",
       "                       4.4375e-02, -1.2889e-01, -1.1593e-01, -2.3294e-01, -2.0368e-01,\n",
       "                      -2.5850e-01, -3.0831e-01, -1.2020e-01, -2.1385e-01, -2.0407e-01,\n",
       "                      -7.1134e-02, -1.6209e-01, -5.0657e-02, -5.2088e-02, -1.3045e-01,\n",
       "                      -1.3824e-01, -5.6977e-02, -1.7148e-01, -8.0979e-02, -8.3695e-02,\n",
       "                      -7.7599e-02, -1.3460e-01, -2.7181e-01, -1.6730e-01, -1.4854e-01,\n",
       "                      -1.2246e-01, -1.3667e-01, -4.6614e-02, -5.5313e-02, -1.9543e-01,\n",
       "                      -2.2762e-02, -8.8135e-02, -7.3074e-02, -1.3428e-01, -2.0722e-01,\n",
       "                      -1.4401e-01, -2.2245e-01, -1.3079e-01, -2.5123e-01, -1.6520e-01,\n",
       "                      -1.4884e-01, -4.9027e-02, -5.0291e-02, -2.1587e-01, -1.1261e-01,\n",
       "                      -6.3738e-02, -8.1070e-02,  2.3175e-02, -1.8759e-01, -1.9116e-02,\n",
       "                      -1.6049e-01, -7.0020e-02, -1.8207e-02, -6.9490e-02, -1.7263e-01,\n",
       "                      -3.3724e-02, -5.3853e-02, -8.2535e-02, -1.8890e-01, -3.8123e-02,\n",
       "                      -1.0968e-01, -1.5077e-01, -1.4333e-01, -1.8172e-01, -5.9426e-02,\n",
       "                      -2.0785e-02, -2.4652e-02, -1.4362e-01, -1.9715e-01, -1.0314e-01,\n",
       "                      -1.8695e-01, -3.9448e-02, -8.6970e-02, -1.6649e-01, -1.7304e-01,\n",
       "                      -1.4069e-01, -1.5817e-01, -2.8019e-02, -1.7245e-01, -5.3989e-02,\n",
       "                      -6.2186e-02, -2.2864e-01, -3.2475e-02, -1.1864e-01, -1.7667e-01,\n",
       "                      -4.6969e-02, -9.0056e-02, -1.1795e-01, -6.3482e-02, -1.4345e-01,\n",
       "                      -5.9278e-02, -1.1892e-01, -5.2453e-02, -2.9734e-01, -2.2531e-01,\n",
       "                      -7.8591e-02, -8.8131e-02, -1.4551e-01, -2.1292e-01, -1.7689e-01,\n",
       "                      -1.1896e-01, -1.8611e-01, -1.8810e-01, -1.5860e-01, -2.1596e-01,\n",
       "                      -1.3441e-01, -6.6094e-02, -6.6254e-02, -1.2253e-01, -1.5991e-01,\n",
       "                      -1.1852e-01, -5.7305e-02, -1.1282e-01, -9.7441e-02, -2.2668e-01,\n",
       "                      -1.0068e-02, -1.6538e-01, -6.6075e-03, -1.1289e-01, -2.2383e-01,\n",
       "                      -1.0871e-01, -9.9619e-02, -9.6183e-03, -5.8728e-02, -2.7542e-02,\n",
       "                      -8.1701e-02, -7.7023e-02, -1.8094e-02,  1.5970e-02, -2.5439e-01,\n",
       "                      -6.6934e-02, -1.6469e-01, -1.6472e-01, -1.6015e-01, -1.2852e-01,\n",
       "                      -2.0055e-01, -3.1820e-02, -2.1173e-01, -1.3934e-01, -2.1378e-01,\n",
       "                      -5.8361e-02,  9.9871e-03, -5.7033e-02, -5.1093e-02,  7.9233e-02,\n",
       "                       7.3215e-02,  5.2839e-03,  5.2566e-02, -2.2470e-02, -4.6377e-02,\n",
       "                       3.0611e-02,  7.1769e-03,  4.8958e-02, -4.3048e-02, -7.2346e-02,\n",
       "                      -6.8693e-02,  3.5159e-02, -5.7408e-02,  1.1424e-01, -3.5588e-02,\n",
       "                       1.3030e-01, -8.0035e-03,  5.5308e-02,  3.2332e-02, -5.3139e-03,\n",
       "                       3.2638e-02,  7.7520e-03, -2.1155e-02,  9.3722e-02,  1.4470e-01,\n",
       "                      -3.7475e-02, -3.1790e-02,  7.1384e-02,  9.5673e-02, -1.3936e-01,\n",
       "                       7.0641e-02,  1.6291e-02,  4.9123e-03, -8.1212e-02,  7.3155e-02,\n",
       "                      -4.2180e-02,  4.2482e-02,  7.2005e-02,  3.8213e-03,  5.6538e-04,\n",
       "                      -4.4539e-02, -1.1225e-01,  3.2692e-02,  7.0493e-02,  8.8106e-02,\n",
       "                      -4.5364e-02,  1.1410e-02, -1.7565e-02,  8.0497e-02, -1.1411e-02,\n",
       "                      -3.9173e-02, -1.3170e-03, -9.7849e-02, -5.6957e-02, -1.0628e-02,\n",
       "                       3.4794e-02, -7.3461e-02, -1.0747e-01,  5.2041e-02, -4.8864e-02,\n",
       "                       6.0072e-03, -3.4254e-02,  2.6814e-02, -1.7277e-02,  3.5916e-02,\n",
       "                       2.2357e-02, -2.1352e-02, -4.7512e-03, -6.2362e-02, -1.3338e-02,\n",
       "                       6.7321e-02,  7.5698e-02, -2.4458e-04, -4.0007e-02, -1.2430e-01,\n",
       "                       4.3643e-02,  7.8594e-02,  5.8929e-02,  1.5693e-02, -4.0742e-02,\n",
       "                      -3.3622e-02, -3.1181e-02,  5.8263e-02,  4.7015e-02,  2.6706e-02,\n",
       "                       7.3587e-02, -1.2275e-02, -4.0239e-03, -4.1742e-02,  7.2158e-02,\n",
       "                      -9.3226e-02, -1.1234e-01, -2.3410e-03, -3.6656e-02, -8.0629e-03,\n",
       "                      -4.6691e-02, -3.0079e-02, -2.5569e-02,  1.3010e-02, -4.8678e-02,\n",
       "                       7.3002e-03,  1.0537e-01, -1.7906e-02,  3.7034e-02,  5.5143e-02,\n",
       "                      -1.4148e-01, -2.4686e-02, -3.2235e-03, -6.3530e-02,  2.5734e-02,\n",
       "                       2.0722e-02,  2.3992e-02,  5.2015e-02,  1.5387e-01, -1.0837e-02,\n",
       "                       9.0516e-02, -7.1496e-02,  1.9668e-02,  8.1700e-02, -5.1209e-02,\n",
       "                       3.3588e-02, -2.8227e-03,  4.1960e-02, -2.5386e-02, -2.7615e-01,\n",
       "                      -2.4989e-01, -2.3377e-01, -1.9435e-01, -3.6092e-02, -7.7924e-02,\n",
       "                      -3.1551e-02, -3.1857e-02, -1.6420e-01,  1.4577e-02, -3.0811e-01,\n",
       "                      -1.5822e-01, -1.3534e-02, -1.7365e-01, -1.5866e-01, -1.6914e-01,\n",
       "                      -2.2298e-01, -1.2255e-02, -2.1629e-02, -1.7347e-01, -1.4838e-01,\n",
       "                      -3.1018e-02, -2.2374e-01, -9.0437e-02, -6.3900e-02, -1.8206e-01,\n",
       "                      -4.6218e-02, -1.5643e-02, -1.0271e-01, -9.3163e-02, -1.9320e-01,\n",
       "                      -6.0053e-02, -4.6986e-02, -9.6745e-02, -4.3828e-02, -2.3514e-01,\n",
       "                      -8.9659e-02, -1.5000e-02, -1.2288e-03, -1.6982e-01, -1.3991e-01,\n",
       "                      -1.7845e-01, -1.3939e-01, -2.1383e-01, -1.6774e-01, -1.1835e-01,\n",
       "                      -1.1558e-01, -1.8487e-01, -2.6607e-01, -7.1622e-03, -1.0035e-01,\n",
       "                      -1.4359e-01, -2.0694e-02, -1.5357e-01, -1.6743e-01, -1.7084e-01,\n",
       "                      -1.8191e-01, -2.1636e-01, -1.0944e-01, -1.0602e-01, -1.8906e-01,\n",
       "                      -8.9535e-02, -2.2035e-01, -1.8386e-01, -2.1996e-01, -1.4446e-01,\n",
       "                      -1.6521e-01, -2.2075e-01, -1.6710e-01, -1.2842e-01, -1.4727e-01,\n",
       "                      -1.7567e-01, -2.6309e-01, -1.9286e-01, -1.5720e-01, -1.1873e-01,\n",
       "                      -1.8998e-01, -2.0805e-01, -7.4640e-02, -2.5647e-01, -2.2085e-01,\n",
       "                      -1.0748e-01, -1.0452e-01, -9.9880e-02, -1.1501e-01, -2.4701e-01,\n",
       "                      -3.1257e-02, -1.7680e-01, -3.8876e-02, -2.4973e-02, -3.5016e-01,\n",
       "                      -1.4103e-01, -6.6693e-02, -1.0078e-01, -5.7479e-02, -2.2665e-01,\n",
       "                      -1.4395e-01, -1.3829e-01, -1.5616e-01, -1.6303e-01, -1.5860e-01,\n",
       "                      -2.1938e-01, -7.5776e-02, -1.7298e-01, -2.0674e-01, -1.6000e-01,\n",
       "                      -1.4975e-01,  2.6101e-03, -1.7412e-01, -1.7369e-01, -8.9334e-02,\n",
       "                      -6.9625e-02, -1.6870e-01, -2.4801e-01, -1.4402e-01, -1.4323e-01,\n",
       "                      -1.2935e-01, -2.5104e-01, -1.7098e-01, -1.1559e-01, -1.6877e-01,\n",
       "                      -1.5574e-01, -2.1363e-01, -1.7757e-01, -8.6705e-02, -1.6321e-01,\n",
       "                      -1.9176e-01, -3.3229e-02])),\n",
       "             ('bilstm_left_context_feature.bias_hh_l0',\n",
       "              tensor([-2.3345e-01, -2.1350e-01, -1.8544e-01, -7.4213e-02, -2.1355e-01,\n",
       "                      -1.1456e-01, -4.2485e-02, -2.3712e-01, -1.6294e-01, -5.8121e-02,\n",
       "                      -9.3227e-02, -2.4413e-01, -8.8720e-02, -1.6668e-01, -1.3878e-01,\n",
       "                      -1.4848e-01, -9.9813e-02, -1.6435e-01, -1.4027e-01, -1.8719e-01,\n",
       "                      -2.6806e-01, -1.7717e-01, -1.1407e-01, -1.4890e-01,  3.8793e-03,\n",
       "                      -1.5779e-02, -5.9493e-02, -7.0599e-02, -8.4836e-02, -2.5089e-02,\n",
       "                      -2.2157e-01, -1.2331e-01, -8.1358e-02,  5.0172e-02, -2.0199e-01,\n",
       "                      -1.0622e-01, -1.8513e-01,  1.3200e-02, -4.3262e-02, -9.2464e-02,\n",
       "                      -2.2150e-01, -2.9773e-01, -1.7921e-01, -1.1658e-01, -1.9678e-01,\n",
       "                      -1.6418e-01, -2.0836e-01, -7.3737e-02, -3.2558e-01, -2.1879e-02,\n",
       "                      -1.1923e-01, -7.0768e-02, -5.5574e-02, -1.2142e-01, -8.0594e-02,\n",
       "                      -2.1253e-01, -2.0833e-01, -1.3590e-01, -1.3237e-01,  2.8399e-02,\n",
       "                      -1.6044e-01, -6.4004e-02, -1.3120e-01, -1.6783e-01, -2.7480e-01,\n",
       "                      -1.0728e-01, -1.9505e-01, -1.3794e-01, -1.7235e-01, -2.0526e-01,\n",
       "                      -1.4283e-01, -1.2538e-01, -1.4648e-01, -6.4832e-02, -7.2613e-02,\n",
       "                      -2.2818e-01, -1.6835e-01, -1.1060e-01, -1.1140e-01, -1.1634e-01,\n",
       "                      -2.0961e-01, -1.1668e-01, -5.2071e-02, -9.4123e-02, -6.7246e-02,\n",
       "                      -3.3848e-01, -6.1661e-02, -5.2479e-02,  5.5835e-04, -2.1164e-01,\n",
       "                      -1.1213e-01,  9.6764e-02, -1.0883e-01, -5.0417e-02, -2.2016e-01,\n",
       "                      -2.5791e-01, -7.6474e-02, -1.8866e-01, -1.1509e-01, -6.7483e-02,\n",
       "                      -1.4887e-01, -2.2841e-01, -3.0623e-02, -3.5697e-01, -4.8931e-02,\n",
       "                      -1.7258e-01, -2.6526e-02, -1.4711e-01, -8.8481e-02, -1.5982e-01,\n",
       "                      -1.0306e-01, -1.6247e-01, -9.2097e-02, -2.0370e-01, -3.9253e-02,\n",
       "                      -2.1744e-01, -1.0812e-01, -1.5932e-01, -2.7127e-01, -4.6737e-02,\n",
       "                      -2.6141e-01, -1.8447e-01, -1.8008e-01, -1.8706e-01, -2.0173e-01,\n",
       "                      -2.5688e-02, -1.8222e-01, -1.8907e-01, -2.3590e-01, -7.0282e-02,\n",
       "                      -5.4552e-02,  5.4883e-02, -7.6408e-02, -1.0873e-01, -6.1865e-02,\n",
       "                      -1.4192e-01, -1.3316e-01, -1.1579e-01, -7.7728e-02, -1.9762e-01,\n",
       "                      -9.3243e-03, -3.2834e-03, -1.4609e-01, -6.0819e-02, -1.1955e-01,\n",
       "                      -6.2000e-02, -1.6992e-01, -1.0637e-01, -2.0801e-01, -6.8169e-02,\n",
       "                      -1.0880e-01, -1.3161e-01, -6.0762e-03, -1.6115e-01, -1.0972e-02,\n",
       "                      -8.5910e-02, -1.2677e-01, -5.9471e-02, -1.3482e-01, -7.7231e-02,\n",
       "                       1.7596e-02, -1.5907e-02, -1.8515e-01, -6.8167e-02, -1.8366e-01,\n",
       "                      -6.9928e-02, -1.4058e-01,  1.3117e-01, -1.4855e-01, -1.0874e-01,\n",
       "                      -8.1491e-02, -2.2923e-01, -2.5970e-01, -9.7644e-02, -1.0841e-01,\n",
       "                      -1.8079e-01, -1.4872e-01, -1.6780e-02, -1.6139e-01, -1.2888e-01,\n",
       "                      -1.0246e-01, -6.0120e-02, -2.6780e-02, -2.5745e-01, -2.2054e-01,\n",
       "                      -1.1159e-01, -7.6064e-02, -6.8870e-02, -5.6316e-02, -9.6719e-02,\n",
       "                      -1.9736e-01, -2.2113e-01, -6.4158e-02, -1.3592e-01, -1.9096e-01,\n",
       "                      -2.2816e-01, -1.1151e-01, -1.1056e-01, -9.8735e-02, -2.2241e-01,\n",
       "                      -1.4290e-01, -8.9611e-02, -1.1436e-01, -1.3986e-01, -9.9979e-02,\n",
       "                      -1.5190e-01, -1.1855e-01, -1.2516e-01, -1.5263e-01, -1.3453e-01,\n",
       "                      -1.3107e-01, -3.3898e-02, -1.0713e-01, -2.4541e-01, -2.0885e-01,\n",
       "                      -5.3872e-02, -1.8626e-01, -8.2612e-02, -2.2896e-01, -2.0991e-01,\n",
       "                      -1.0583e-01, -1.5731e-02, -1.1607e-01, -2.0912e-01, -1.9058e-01,\n",
       "                      -1.1749e-01, -1.4147e-01, -7.7593e-02, -1.2612e-01, -6.8500e-02,\n",
       "                      -1.7192e-01, -2.7206e-01, -1.7192e-01, -6.2220e-02, -6.0874e-02,\n",
       "                      -1.1415e-01, -1.0596e-01, -8.0591e-02, -8.2797e-02, -7.0927e-02,\n",
       "                      -6.7945e-02, -1.0944e-01, -3.8135e-02, -1.7218e-02, -8.3415e-02,\n",
       "                      -1.5947e-01, -1.6910e-01, -1.0566e-01, -1.7809e-01, -1.4932e-01,\n",
       "                      -1.4170e-01, -4.4624e-02, -7.4316e-02,  2.6223e-02, -1.0660e-01,\n",
       "                      -5.4880e-02, -4.8997e-02, -1.2955e-01,  3.5690e-03,  1.2629e-01,\n",
       "                      -1.1472e-01,  2.0330e-02,  2.1642e-02,  7.7206e-05, -2.0279e-02,\n",
       "                      -4.8840e-02, -7.9382e-03,  1.7558e-02,  7.4192e-02,  6.7418e-02,\n",
       "                      -4.2672e-03, -1.8151e-01,  6.2712e-02, -3.9220e-03,  5.8501e-02,\n",
       "                      -8.9574e-02, -1.8213e-02,  1.5781e-03,  4.6616e-02, -3.0572e-02,\n",
       "                      -3.7450e-03,  2.8641e-02,  1.5943e-01,  4.7469e-02, -4.9758e-02,\n",
       "                      -4.9740e-02,  1.1733e-02, -9.3579e-02,  9.2866e-02,  8.4488e-03,\n",
       "                       7.3028e-02, -1.1105e-01, -7.5740e-02,  3.1863e-02,  7.5760e-02,\n",
       "                       4.7889e-02, -5.4958e-02,  7.5203e-02,  1.4128e-01, -9.0644e-02,\n",
       "                       8.4415e-03, -5.9180e-03, -6.5881e-02, -4.0762e-02, -7.6410e-03,\n",
       "                       4.7411e-02, -8.5681e-03,  8.6741e-02,  2.7612e-02, -4.8956e-02,\n",
       "                       3.7865e-02, -5.0395e-03, -5.0011e-02,  5.8449e-02, -7.9039e-02,\n",
       "                      -5.9188e-02,  1.6375e-01,  2.3274e-02,  1.3454e-02, -1.4890e-02,\n",
       "                      -1.0598e-01,  7.2874e-02,  2.5411e-02,  3.2751e-02,  5.4210e-02,\n",
       "                      -2.9134e-02, -3.0485e-02,  6.6435e-02, -6.5709e-02,  6.4004e-02,\n",
       "                      -2.1696e-02,  1.7326e-01,  1.1647e-01, -6.3407e-04, -7.7187e-02,\n",
       "                       9.7963e-03,  3.8859e-02,  6.0093e-02,  4.2508e-02,  1.3371e-02,\n",
       "                       3.4474e-02, -1.5215e-02,  1.0620e-02,  1.3592e-02, -7.5190e-02,\n",
       "                       5.0267e-02, -4.3718e-02, -6.6192e-02, -9.4038e-03,  8.9082e-02,\n",
       "                      -3.2940e-03,  8.4358e-02, -2.8403e-02, -9.7809e-02, -1.1382e-02,\n",
       "                       8.4963e-02, -5.3119e-03,  7.3296e-02, -1.1939e-01,  2.9082e-02,\n",
       "                      -2.0851e-02,  2.4476e-02, -1.8465e-02,  1.5695e-01, -2.1607e-02,\n",
       "                       8.2600e-03,  5.7365e-03,  1.3670e-02, -7.1248e-02, -9.1980e-03,\n",
       "                       6.9452e-02, -1.8946e-02, -6.1118e-02, -9.9201e-03, -1.3804e-02,\n",
       "                       6.8366e-02, -5.1002e-02, -3.1149e-02, -4.3082e-02, -1.0855e-02,\n",
       "                       7.4596e-02,  1.2799e-02,  5.2361e-03,  6.1898e-03, -1.9502e-01,\n",
       "                      -9.7751e-02, -1.9394e-01, -6.0526e-02, -1.4212e-01, -8.9448e-02,\n",
       "                      -2.1027e-01, -4.1518e-02, -2.5141e-01, -3.2772e-01, -2.7396e-01,\n",
       "                      -2.1497e-01, -1.5121e-01, -1.4944e-01, -1.9331e-01, -2.1524e-01,\n",
       "                      -8.0780e-02, -5.2621e-03, -1.8509e-01, -1.4136e-01, -1.0664e-01,\n",
       "                      -1.3084e-01, -2.8608e-01, -2.8060e-01, -6.9346e-02, -2.2648e-01,\n",
       "                      -3.9359e-02, -2.4711e-01, -1.5238e-01, -1.2373e-01, -9.9815e-02,\n",
       "                       5.8201e-04, -5.3594e-03,  1.2157e-02, -1.9193e-01, -1.1562e-01,\n",
       "                      -1.6446e-01, -6.3745e-02, -1.1890e-01, -5.3973e-02, -1.6355e-01,\n",
       "                      -2.6020e-01, -1.0856e-01, -1.6530e-01, -9.0347e-02, -2.1997e-01,\n",
       "                      -1.3072e-01, -2.5860e-01, -2.8915e-01, -1.3832e-01, -1.3303e-01,\n",
       "                      -3.6449e-02, -1.3149e-01, -7.4023e-02, -7.9683e-02, -1.9065e-01,\n",
       "                      -7.2745e-02, -7.0563e-02, -1.1039e-01, -1.7413e-01, -1.8731e-01,\n",
       "                       2.1570e-02, -1.2897e-03, -2.7072e-01, -1.3587e-01, -1.7238e-01,\n",
       "                      -1.4339e-01, -2.5275e-01, -2.5121e-01, -1.3348e-01, -1.4853e-01,\n",
       "                      -1.3497e-01, -1.7935e-01, -1.6645e-01, -1.6457e-01, -3.4904e-02,\n",
       "                      -9.1661e-02, -3.1661e-02, -9.6598e-02, -1.7929e-01, -2.9350e-01,\n",
       "                      -1.9812e-01, -3.9481e-02, -1.7856e-01, -1.5457e-01, -2.5915e-01,\n",
       "                      -2.4638e-01, -1.3614e-01, -1.1872e-01, -2.0282e-01, -1.8544e-01,\n",
       "                      -1.4802e-01, -3.1346e-02, -1.0694e-01, -2.3475e-01, -2.0406e-01,\n",
       "                      -1.5940e-01, -1.3920e-01, -1.5488e-01, -1.4039e-01, -1.0639e-01,\n",
       "                      -2.9920e-01, -2.7347e-01, -2.1301e-01, -1.5075e-01, -9.2332e-02,\n",
       "                      -2.0812e-02, -1.8705e-01, -2.2477e-01, -8.8784e-02, -1.5465e-01,\n",
       "                      -1.3424e-01,  2.3706e-02, -1.4487e-01, -6.4865e-02, -3.8458e-02,\n",
       "                      -1.1335e-01, -1.6877e-01, -1.5938e-01, -1.6066e-01, -1.7713e-01,\n",
       "                      -1.7105e-01, -1.1134e-01, -1.2614e-01, -1.8103e-01, -2.7969e-02,\n",
       "                      -1.4808e-01, -1.5693e-01])),\n",
       "             ('bilstm_left_context_feature.weight_ih_l0_reverse',\n",
       "              tensor([[ 0.0068, -0.3004,  0.0457,  ..., -0.0782, -0.4440, -0.2036],\n",
       "                      [ 0.1321, -0.5298,  0.0075,  ..., -0.2324,  0.5555,  0.0987],\n",
       "                      [ 0.0364,  0.3693,  0.1115,  ...,  0.0006,  0.2580,  0.1132],\n",
       "                      ...,\n",
       "                      [-0.0263,  0.1156,  0.4437,  ...,  0.0864, -0.1893, -0.0052],\n",
       "                      [ 0.4399, -0.2887,  0.0407,  ..., -0.2569, -0.1680,  0.0875],\n",
       "                      [-0.1738, -0.1389, -0.0913,  ...,  0.2654, -0.1476, -0.2183]])),\n",
       "             ('bilstm_left_context_feature.weight_hh_l0_reverse',\n",
       "              tensor([[ 0.1185, -0.0774,  0.0031,  ...,  0.0587, -0.2217, -0.0695],\n",
       "                      [-0.2132, -0.1935,  0.2178,  ...,  0.0175, -0.4766, -0.2593],\n",
       "                      [-0.2184,  0.1024, -0.1359,  ..., -0.1747,  0.1985,  0.2397],\n",
       "                      ...,\n",
       "                      [-0.1265,  0.1900, -0.2485,  ...,  0.3998, -0.0487,  0.1408],\n",
       "                      [ 0.0920, -0.2226,  0.1170,  ...,  0.3269, -0.1602,  0.1780],\n",
       "                      [-0.0465, -0.1453, -0.1791,  ..., -0.3329,  0.1684, -0.1150]])),\n",
       "             ('bilstm_left_context_feature.bias_ih_l0_reverse',\n",
       "              tensor([ 1.0098e-01,  9.8611e-02,  3.4805e-02,  1.4321e-02,  3.6998e-02,\n",
       "                       8.0026e-02,  3.2979e-02, -2.4065e-03,  2.4536e-01, -2.1452e-02,\n",
       "                      -5.4036e-02,  1.0599e-01,  2.2809e-02,  1.6786e-01, -3.0096e-02,\n",
       "                       3.0938e-02,  6.6141e-02,  7.2090e-02,  5.8430e-03,  5.4149e-02,\n",
       "                       7.7742e-02, -2.0688e-01,  2.4533e-02,  1.2717e-01, -6.6297e-03,\n",
       "                      -1.3557e-01,  1.0450e-01, -7.7218e-02, -1.2669e-01,  8.5201e-02,\n",
       "                       2.1821e-01,  1.3352e-01,  2.6791e-02,  1.2386e-01,  1.1521e-01,\n",
       "                       3.2707e-02, -8.4145e-02,  1.6261e-02, -2.0917e-02,  1.8990e-01,\n",
       "                      -4.0315e-02,  3.4015e-02,  8.4070e-02,  3.6717e-02,  1.3913e-01,\n",
       "                      -2.2716e-02, -6.7287e-02,  1.0572e-02, -1.4624e-01, -1.1396e-01,\n",
       "                      -2.1837e-04,  1.6840e-01,  1.3090e-01, -4.2242e-03,  5.0540e-02,\n",
       "                       5.0841e-02, -3.1674e-02, -1.1448e-01,  5.3830e-02,  1.1936e-01,\n",
       "                      -4.0984e-02, -2.5203e-02, -1.7412e-03, -2.4284e-02,  2.5106e-02,\n",
       "                      -3.2254e-02,  7.4337e-02,  1.0484e-02, -7.1085e-02, -2.0298e-02,\n",
       "                       1.1380e-01,  7.0532e-02,  3.1257e-02,  1.2442e-02,  4.9382e-02,\n",
       "                       1.0551e-01,  8.8591e-02, -5.1143e-03,  3.1820e-02, -1.2007e-01,\n",
       "                      -5.6751e-02,  2.0087e-01, -4.4540e-02,  4.3214e-03,  3.4460e-02,\n",
       "                       5.2764e-02,  1.6330e-01,  2.4858e-02,  1.5006e-01,  5.6478e-02,\n",
       "                       2.4489e-03, -5.0627e-02,  1.4667e-01, -4.6255e-02,  9.6064e-02,\n",
       "                      -6.1872e-03,  1.2251e-02,  2.7435e-02, -1.1548e-01, -3.1551e-02,\n",
       "                      -1.2267e-01,  3.6235e-03,  1.8981e-01,  1.0635e-01, -9.2380e-02,\n",
       "                      -1.0651e-01, -8.6835e-03, -8.8457e-02, -1.3023e-01,  1.7505e-01,\n",
       "                       4.6804e-02, -7.6543e-02,  6.2592e-02, -1.4354e-01,  1.5492e-01,\n",
       "                       1.5903e-01,  2.2137e-01,  4.2566e-02,  3.2213e-02,  1.0669e-02,\n",
       "                      -2.1334e-02,  3.4466e-02,  3.6655e-02, -8.8724e-03, -3.5733e-02,\n",
       "                       3.6291e-02, -3.8736e-02, -2.4015e-02, -8.7940e-04, -9.1628e-02,\n",
       "                      -5.1418e-02, -5.2669e-02, -1.0857e-02, -5.9525e-02, -7.1098e-02,\n",
       "                      -7.8510e-02,  1.2867e-01, -6.9043e-02, -5.5755e-02,  2.9625e-02,\n",
       "                       1.3678e-02, -8.6626e-02, -4.2954e-02,  1.8911e-01,  2.8535e-02,\n",
       "                      -1.8847e-04, -1.0432e-01, -5.9392e-02,  5.7718e-02, -3.2557e-02,\n",
       "                      -1.4273e-02, -1.6805e-01,  1.2764e-02, -1.1202e-01,  6.1327e-02,\n",
       "                      -8.1968e-02, -2.1162e-01, -1.3714e-01, -7.4540e-02, -1.9518e-01,\n",
       "                       1.2722e-03, -1.1148e-01, -6.7003e-02, -9.7510e-02,  2.5312e-02,\n",
       "                      -3.5558e-02,  8.2027e-02, -1.3108e-01,  3.3124e-02,  4.6600e-02,\n",
       "                      -9.6952e-02, -1.1487e-02,  8.7752e-02, -1.3969e-01,  1.0930e-01,\n",
       "                      -4.5656e-02,  5.8163e-03,  8.0435e-03, -1.6467e-03, -1.8966e-01,\n",
       "                      -4.2217e-02, -1.1558e-01, -6.4992e-02,  9.3900e-03,  1.0039e-02,\n",
       "                      -8.2063e-02, -2.1046e-02, -5.0823e-02, -2.1200e-02, -4.9154e-02,\n",
       "                      -1.9953e-01, -3.1120e-02,  4.6072e-02,  7.8151e-04, -7.4083e-02,\n",
       "                      -3.1228e-02,  4.2225e-02, -1.2985e-01,  5.0132e-03,  3.3434e-03,\n",
       "                       5.2753e-02, -1.0817e-01, -1.5808e-01, -1.1354e-01, -9.4837e-02,\n",
       "                       9.4104e-02, -3.4220e-02,  1.2973e-01, -1.8922e-02, -6.4255e-02,\n",
       "                      -1.4368e-02,  6.4757e-02, -1.1024e-01,  4.4093e-02, -8.3966e-02,\n",
       "                      -1.0250e-01, -8.6805e-02, -9.6554e-02,  2.2377e-02,  2.3611e-02,\n",
       "                      -9.7733e-02, -6.1404e-02, -6.4830e-02, -5.9627e-02,  8.9273e-02,\n",
       "                      -5.7707e-02,  2.2896e-02, -1.5160e-01,  1.4090e-02,  4.9749e-02,\n",
       "                      -7.7229e-02, -8.5629e-02,  6.0331e-02, -1.4987e-01, -7.3282e-02,\n",
       "                       2.5315e-02,  3.1226e-02, -1.4541e-01, -1.2394e-01,  1.5957e-01,\n",
       "                      -1.1577e-01,  7.9388e-02, -9.5881e-02,  1.0073e-01, -1.6301e-01,\n",
       "                      -2.9151e-02, -7.4231e-02, -3.5023e-02,  9.4570e-03, -7.3075e-02,\n",
       "                       4.4316e-02, -1.2692e-01, -1.3149e-01, -9.2189e-03,  6.7746e-02,\n",
       "                      -9.9090e-02,  4.7514e-02,  3.1146e-03, -2.2671e-02,  4.3073e-02,\n",
       "                       1.0224e-02, -2.3971e-02,  5.1604e-02,  2.9625e-02, -5.2553e-02,\n",
       "                      -5.0462e-02, -3.3164e-02,  1.0870e-01,  1.1883e-01,  9.4068e-02,\n",
       "                       5.2254e-02,  3.2805e-02, -4.8176e-02,  3.1302e-03,  8.0896e-02,\n",
       "                      -3.5190e-02,  1.0736e-01,  1.5570e-02, -2.4481e-04, -6.0020e-02,\n",
       "                      -8.2485e-02, -3.0490e-02,  6.8288e-02,  2.0321e-02, -1.3842e-01,\n",
       "                       3.6262e-02, -1.2285e-02, -1.8219e-01,  7.5218e-02, -1.4159e-01,\n",
       "                       7.1127e-03,  2.3091e-02, -1.0985e-01,  2.3163e-02,  1.1767e-01,\n",
       "                      -4.9222e-02,  1.2434e-01,  2.8215e-02, -1.1588e-02,  2.7669e-02,\n",
       "                      -1.0260e-01,  1.6731e-02,  3.5065e-03, -5.2766e-03, -1.3300e-01,\n",
       "                      -5.2011e-02,  4.4707e-02, -7.0510e-03,  8.3854e-02, -3.6725e-02,\n",
       "                      -2.3530e-02,  8.3158e-02, -6.0805e-02,  3.2848e-02, -1.0832e-02,\n",
       "                      -6.2083e-02, -3.3760e-02, -1.4887e-02,  5.6850e-02, -5.0411e-02,\n",
       "                      -1.1134e-01,  2.1618e-01,  9.8253e-02,  1.0953e-02,  7.0558e-03,\n",
       "                       1.4871e-02,  4.3430e-02,  2.3536e-03, -2.9799e-02, -5.5283e-02,\n",
       "                       5.5500e-02, -1.2134e-01,  2.7676e-02,  1.0580e-02,  5.8321e-02,\n",
       "                       5.4084e-02, -7.5573e-02, -8.9658e-02, -4.9989e-02, -8.8053e-02,\n",
       "                      -5.5742e-02,  5.6140e-02,  5.6661e-02,  7.4459e-02, -9.5252e-02,\n",
       "                       1.2346e-01,  6.5760e-04, -3.5369e-02,  3.7146e-02,  9.2195e-02,\n",
       "                       2.4770e-02,  1.5034e-02, -1.2622e-01,  9.7998e-02, -1.7405e-02,\n",
       "                      -4.7159e-03, -4.9115e-02, -2.3173e-02,  1.7505e-01,  7.9854e-02,\n",
       "                      -2.5819e-02, -1.1308e-01,  8.6729e-03, -4.0062e-02, -2.1936e-02,\n",
       "                       1.2311e-01,  7.4476e-03, -2.1025e-02, -2.0159e-01, -1.3055e-01,\n",
       "                      -1.3103e-01,  4.7208e-02, -2.4572e-02,  2.5890e-02,  3.1207e-02,\n",
       "                      -7.0162e-02,  2.6259e-02,  2.3798e-02, -1.1217e-01,  1.1847e-01,\n",
       "                      -1.6714e-02,  2.6748e-02,  8.9917e-03, -6.3798e-03,  1.5685e-02,\n",
       "                       4.8968e-02,  9.1452e-02,  1.0691e-01,  2.4182e-02,  9.9694e-02,\n",
       "                      -2.7266e-03, -7.3463e-03,  3.4088e-01,  7.0320e-02, -4.9675e-02,\n",
       "                       1.1740e-01,  1.6391e-01,  1.5854e-01,  1.3390e-01,  1.3365e-01,\n",
       "                       7.9508e-02,  1.4067e-01,  7.3519e-02, -1.6720e-01,  8.0326e-02,\n",
       "                      -5.4195e-02,  1.1741e-02,  6.5550e-02,  3.1111e-02, -3.1856e-03,\n",
       "                       8.0226e-02,  1.2225e-01, -8.4643e-02,  9.4678e-02,  1.6443e-01,\n",
       "                       2.1767e-01,  9.5013e-02,  1.7085e-01,  1.1604e-01,  3.6357e-03,\n",
       "                       6.4975e-02,  1.4129e-01, -3.1437e-02,  6.0800e-02,  2.4679e-02,\n",
       "                       2.1851e-02,  1.0029e-01,  1.5311e-01,  1.5735e-01,  6.5623e-02,\n",
       "                      -1.9278e-02, -8.2242e-03, -7.3034e-02, -1.1215e-01,  7.1329e-02,\n",
       "                       2.5308e-01,  1.1501e-01,  4.4486e-02,  2.0819e-02, -3.4746e-02,\n",
       "                      -7.7479e-02, -5.1299e-02, -5.8239e-04,  4.5069e-02,  8.4874e-02,\n",
       "                       6.2245e-02, -3.4983e-02, -1.0947e-02,  1.6280e-02, -6.0388e-02,\n",
       "                       9.6166e-02, -4.0651e-02,  2.8642e-02,  4.5305e-02,  1.0464e-01,\n",
       "                       1.2082e-01, -7.5741e-02,  5.0251e-02,  2.1092e-01,  2.2034e-01,\n",
       "                       1.0671e-01, -3.5807e-02, -4.6460e-02, -2.6847e-02, -6.7765e-02,\n",
       "                       9.5275e-02, -3.5172e-02, -6.7300e-02,  9.9293e-02,  4.2789e-02,\n",
       "                       9.5941e-02,  8.6524e-03,  9.2978e-03,  8.9313e-03, -7.9099e-02,\n",
       "                      -1.6995e-03,  1.1393e-01,  5.8940e-03,  1.1868e-01, -4.2906e-02,\n",
       "                       6.6054e-02, -7.8418e-02,  9.7411e-02, -5.5049e-02, -9.4825e-02,\n",
       "                       1.0651e-01,  2.1544e-01,  1.4809e-01, -8.3676e-03, -8.9418e-02,\n",
       "                       1.3816e-01,  4.8955e-02,  2.4415e-02,  1.6580e-01,  1.1351e-01,\n",
       "                      -7.5243e-02, -8.5174e-02,  8.0529e-02,  1.9400e-01,  2.0130e-01,\n",
       "                       1.1327e-01,  2.4270e-03,  4.6909e-02,  1.0921e-01,  1.2519e-02,\n",
       "                      -3.0047e-03,  9.6718e-02, -1.0333e-03,  8.2924e-02,  8.9879e-02,\n",
       "                       1.1726e-02,  7.4338e-03])),\n",
       "             ('bilstm_left_context_feature.bias_hh_l0_reverse',\n",
       "              tensor([-9.9103e-03,  5.4543e-02,  2.1316e-02,  5.8917e-02, -2.9726e-03,\n",
       "                       2.0046e-01,  2.1913e-02, -9.1437e-02,  1.1523e-01,  4.7369e-02,\n",
       "                      -1.1284e-02,  1.2683e-01,  6.3032e-02,  1.1700e-01, -8.2860e-03,\n",
       "                      -1.6744e-02,  2.7292e-02,  9.5698e-02, -3.2307e-02,  6.5805e-02,\n",
       "                       9.7022e-02, -1.5049e-01, -1.6631e-02,  9.1168e-03, -4.4036e-02,\n",
       "                      -6.6715e-02,  2.0454e-02, -4.6267e-02, -5.1754e-02,  6.6334e-02,\n",
       "                       7.0241e-02,  1.7344e-01, -3.2385e-02, -5.3201e-03,  1.0513e-01,\n",
       "                       1.6769e-01,  5.4321e-02,  1.4529e-01,  3.3804e-02,  1.7147e-01,\n",
       "                      -1.1004e-01,  3.5428e-02,  8.6574e-02,  2.8639e-02,  1.3370e-01,\n",
       "                       1.7000e-01,  3.0147e-02,  4.3649e-02, -6.0240e-02,  3.6555e-02,\n",
       "                       9.1244e-02,  6.0571e-02,  1.2633e-01, -5.0564e-02,  6.3089e-02,\n",
       "                       8.1529e-02, -8.9495e-02, -9.2850e-02,  6.3906e-02,  1.1967e-01,\n",
       "                       3.3917e-02, -4.0460e-02, -1.1115e-01, -3.2303e-02,  4.8330e-02,\n",
       "                      -3.3539e-02, -4.0436e-02,  6.1667e-02, -1.2258e-01, -1.9248e-01,\n",
       "                       1.3928e-01,  4.6602e-02,  4.7347e-02, -8.1612e-02,  1.3382e-01,\n",
       "                       2.0104e-01,  4.0388e-02, -1.5276e-02, -8.0681e-02,  4.8212e-02,\n",
       "                      -1.0425e-01,  1.8734e-01, -8.4528e-02,  5.6070e-02,  2.8539e-02,\n",
       "                       8.2324e-03,  1.1727e-01,  2.7737e-02,  1.0344e-01, -3.6682e-02,\n",
       "                      -3.6107e-02,  9.5759e-03,  6.5535e-02,  6.1707e-02,  7.2351e-02,\n",
       "                      -2.7117e-02,  7.7966e-02,  2.8317e-02,  4.2419e-02, -8.6516e-02,\n",
       "                      -2.7665e-02, -1.9337e-02,  1.7618e-01,  1.0443e-02, -1.1170e-01,\n",
       "                      -2.2547e-01, -9.5412e-02,  2.5424e-02,  6.7782e-02,  1.2425e-01,\n",
       "                       1.0169e-03, -1.4010e-02, -6.8466e-02, -5.0257e-02,  3.4400e-03,\n",
       "                       2.5328e-01,  9.4718e-02,  1.1676e-01, -2.4607e-02,  7.9200e-02,\n",
       "                      -5.4074e-02, -4.0023e-02,  3.9915e-02,  6.4433e-03, -6.7675e-02,\n",
       "                       2.9964e-02,  1.7270e-01, -1.7025e-01, -6.3263e-02, -1.0630e-01,\n",
       "                      -9.4534e-03, -9.4114e-02,  6.3212e-02, -1.1729e-01, -1.1060e-01,\n",
       "                      -7.5294e-02,  2.0046e-01,  5.4334e-02,  3.2739e-03, -2.8470e-02,\n",
       "                       9.5722e-03, -1.0063e-01,  4.4934e-02,  6.6075e-02, -1.2587e-01,\n",
       "                       1.2260e-01, -9.5391e-02,  4.9616e-02,  4.3443e-02, -8.8961e-02,\n",
       "                      -7.6048e-02, -2.2948e-01, -1.9611e-02,  1.4979e-02,  1.8115e-01,\n",
       "                       2.0884e-02, -5.0394e-02, -7.0346e-02,  1.7032e-02, -1.9704e-02,\n",
       "                       1.8612e-01, -1.4155e-01,  1.7516e-02,  9.1327e-02, -2.1095e-01,\n",
       "                       1.1076e-02,  5.0063e-02, -4.8289e-02, -5.7281e-02, -1.7328e-02,\n",
       "                      -7.9672e-02,  4.3801e-02, -1.0324e-01, -1.2237e-01,  1.4838e-02,\n",
       "                      -4.4718e-02,  1.2357e-01, -2.2783e-01,  5.5845e-03, -3.3360e-02,\n",
       "                      -1.3758e-01, -4.3656e-02, -6.4142e-02, -6.2707e-02, -4.7310e-02,\n",
       "                       2.8447e-02, -7.2350e-02, -1.0527e-01, -1.1405e-01,  2.1359e-02,\n",
       "                      -1.1655e-01, -8.3951e-02, -1.4227e-01, -1.4281e-01, -1.2042e-01,\n",
       "                      -8.6889e-02, -3.5242e-02, -7.6060e-02,  2.3729e-05,  2.4621e-02,\n",
       "                       1.7059e-02,  1.0184e-02, -1.4157e-01, -1.5481e-01, -1.1185e-01,\n",
       "                       2.0927e-02, -3.9740e-02,  1.5342e-01,  1.8322e-02, -1.1510e-01,\n",
       "                      -6.8455e-02,  1.4262e-01,  3.8609e-02,  1.1059e-03, -3.0494e-02,\n",
       "                       1.1184e-01,  1.2752e-02,  6.4653e-02,  6.4862e-02,  2.4973e-02,\n",
       "                      -1.8080e-01, -9.9839e-02, -2.0204e-01, -1.5441e-01, -1.3790e-01,\n",
       "                      -1.3815e-01,  3.4358e-02, -1.8638e-01,  1.0116e-02, -4.9258e-02,\n",
       "                      -3.0107e-02, -8.7716e-02, -1.1275e-01, -8.7394e-02,  5.8241e-02,\n",
       "                      -4.1951e-02,  5.1024e-02, -2.0573e-01, -1.6844e-01, -3.2822e-02,\n",
       "                      -2.6206e-03, -3.6142e-02, -3.8602e-02,  3.4518e-02, -2.6860e-01,\n",
       "                      -1.5611e-02,  3.7068e-02, -6.6117e-02, -4.4047e-02,  3.0584e-02,\n",
       "                       1.4413e-01, -5.8021e-02, -1.6661e-01, -4.4502e-02, -4.3721e-02,\n",
       "                      -1.3702e-01, -6.5393e-02,  4.8834e-02, -3.9643e-02, -5.3021e-02,\n",
       "                      -7.8272e-02, -4.9093e-02,  1.2876e-01,  3.1997e-02,  8.3472e-03,\n",
       "                       9.7507e-02, -3.5976e-03,  2.5244e-02,  1.6838e-01, -3.2693e-02,\n",
       "                      -1.1974e-02,  4.8519e-02, -5.7005e-04,  7.1010e-02, -3.7826e-02,\n",
       "                      -2.5820e-02,  1.3494e-02,  5.5365e-02, -2.2380e-02, -2.9036e-02,\n",
       "                       4.4369e-02,  3.1246e-02,  2.5654e-02,  9.1390e-02, -5.9444e-02,\n",
       "                       6.2881e-02, -1.6319e-02,  2.7796e-02, -2.7195e-02,  1.3792e-02,\n",
       "                       4.2955e-02,  1.6012e-01, -2.9622e-02,  4.4643e-02,  1.1120e-01,\n",
       "                      -1.7005e-03,  5.5231e-02,  3.9388e-03, -5.3881e-03, -1.0096e-01,\n",
       "                      -5.2936e-02,  5.8420e-03,  7.0533e-02, -5.3076e-02,  9.6050e-03,\n",
       "                      -3.3018e-02,  3.0392e-02, -2.2268e-02,  1.3931e-02, -4.8272e-02,\n",
       "                       2.0359e-02,  6.0642e-02, -7.3046e-02, -2.4984e-02, -4.2291e-02,\n",
       "                      -1.2905e-01, -2.6710e-03,  6.4492e-02,  7.4365e-02,  1.0783e-01,\n",
       "                      -6.9245e-02, -4.7107e-02, -1.8006e-01, -6.8912e-02,  6.0467e-02,\n",
       "                       2.0106e-02,  6.9941e-02, -2.2771e-02, -2.8451e-02,  1.4826e-01,\n",
       "                      -4.3205e-02, -2.3553e-02, -8.6330e-02,  9.4582e-02, -3.6219e-02,\n",
       "                      -1.0706e-01, -9.3907e-02, -5.3738e-02,  5.4044e-02,  1.8731e-02,\n",
       "                       1.4748e-01, -5.4559e-02,  1.1210e-01, -1.7109e-02,  5.5844e-02,\n",
       "                      -7.0089e-02, -3.2503e-02,  3.6242e-02,  4.1756e-03, -3.4082e-02,\n",
       "                       1.5388e-02, -1.0404e-01, -2.1108e-03, -3.0417e-03, -4.3994e-02,\n",
       "                       3.5959e-02,  5.7830e-02, -8.3484e-02, -4.9178e-02,  6.5836e-02,\n",
       "                       1.9306e-02,  1.3489e-02, -1.0750e-01,  3.3659e-02, -3.3382e-02,\n",
       "                      -1.2224e-02, -6.7511e-02,  6.0531e-02, -2.7532e-02, -9.9904e-02,\n",
       "                      -8.0385e-02, -9.2841e-02,  3.6885e-02, -5.2594e-03,  8.6414e-02,\n",
       "                      -6.2890e-02, -1.4522e-02, -8.6747e-02, -4.9052e-02, -3.6220e-02,\n",
       "                       4.5157e-02,  1.0405e-01,  1.7309e-01, -3.9013e-04, -2.4406e-02,\n",
       "                       3.6541e-02,  6.7323e-02,  7.2552e-02,  9.2367e-04,  2.1827e-01,\n",
       "                       4.3464e-02,  7.8283e-02,  6.8467e-02,  1.3283e-01, -1.3204e-02,\n",
       "                       9.0561e-02,  8.6373e-02,  1.6921e-01,  8.3371e-02,  6.8004e-02,\n",
       "                       4.6289e-02,  8.8467e-02,  1.0266e-01, -9.5606e-03, -8.2000e-03,\n",
       "                      -1.6186e-01, -2.3025e-02,  4.9620e-02, -1.7437e-02,  4.5537e-02,\n",
       "                       1.0840e-01, -1.1936e-01, -3.3630e-02,  2.0922e-01,  1.2183e-01,\n",
       "                       1.3947e-01,  2.2325e-01, -1.9655e-04,  8.6264e-02, -7.6741e-02,\n",
       "                       1.6242e-01,  1.7037e-01,  6.2977e-02,  6.1364e-02,  1.2669e-01,\n",
       "                      -4.1370e-02,  1.4755e-01,  8.8434e-02,  1.9050e-01,  1.5321e-01,\n",
       "                       1.6094e-01,  1.6337e-01, -1.4687e-01, -5.5759e-02, -2.1024e-02,\n",
       "                       2.3933e-01,  2.5829e-01,  8.3488e-03, -3.6203e-02,  1.1477e-01,\n",
       "                       9.9265e-05,  2.9324e-02,  9.7204e-02, -4.2106e-02,  1.7980e-01,\n",
       "                      -6.7921e-02, -8.3163e-02,  9.4658e-03,  1.1217e-02, -2.7394e-02,\n",
       "                       1.5729e-01,  5.1950e-02,  2.0091e-02, -5.6866e-02,  1.4206e-01,\n",
       "                       4.2845e-02,  1.1933e-02, -2.5318e-02,  2.0569e-01,  1.0092e-01,\n",
       "                      -1.3658e-03, -9.6704e-02, -7.9201e-02, -5.2313e-02,  4.8331e-03,\n",
       "                      -1.0843e-02,  1.4511e-02,  4.6127e-02, -4.5406e-02,  1.8399e-01,\n",
       "                       2.8188e-02,  8.5718e-02,  1.7956e-01, -5.0352e-02, -2.4223e-02,\n",
       "                       1.2266e-01,  1.6657e-01,  3.7672e-02,  7.6002e-02,  1.0598e-02,\n",
       "                       3.1590e-02, -3.7630e-02,  5.7643e-02,  3.5769e-02,  6.0396e-02,\n",
       "                       9.6678e-03,  2.8873e-01,  1.3869e-02, -1.0806e-01, -1.1341e-01,\n",
       "                       4.3895e-02,  1.4667e-02,  1.1723e-01,  1.9190e-01,  7.0904e-02,\n",
       "                      -9.5920e-03, -1.4146e-01,  3.3763e-02,  6.2903e-02,  1.9105e-01,\n",
       "                       1.4756e-01, -2.9834e-02, -5.9353e-03,  2.0499e-02,  7.3425e-02,\n",
       "                      -4.6825e-02,  1.8388e-01, -4.8418e-02, -7.8651e-02,  4.6000e-02,\n",
       "                       1.6001e-01, -3.7551e-03])),\n",
       "             ('bilstm_oov_context_feature.weight_ih_l0',\n",
       "              tensor([[ 0.2475,  0.8182,  0.6497,  ..., -0.8703,  0.2533,  0.1956],\n",
       "                      [ 0.3608,  0.2028,  0.9765,  ...,  0.3676,  0.1967, -0.0790],\n",
       "                      [-0.1329, -0.0055,  0.1841,  ...,  0.0290, -0.2318,  0.1376],\n",
       "                      ...,\n",
       "                      [-0.6747, -0.2064,  0.3543,  ...,  0.0516,  0.1163,  0.3407],\n",
       "                      [-0.2852, -0.1425,  0.1420,  ...,  0.0248,  0.1269, -0.1513],\n",
       "                      [-0.0416,  0.0139, -0.2254,  ..., -0.3540, -0.1210, -0.1231]])),\n",
       "             ('bilstm_oov_context_feature.weight_hh_l0',\n",
       "              tensor([[ 0.1045, -0.0526, -0.2757,  ...,  0.0891, -0.1426, -0.0318],\n",
       "                      [-0.0378,  0.1035,  0.2182,  ..., -0.0659, -0.1519,  0.2948],\n",
       "                      [-0.0385, -0.1234, -0.0348,  ..., -0.1738,  0.1331,  0.0455],\n",
       "                      ...,\n",
       "                      [-0.1250, -0.0542, -0.1011,  ...,  0.2475,  0.2359,  0.2594],\n",
       "                      [ 0.1850,  0.2389, -0.0624,  ...,  0.1442, -0.0650,  0.1200],\n",
       "                      [ 0.1857, -0.1316, -0.0526,  ..., -0.2309, -0.2298,  0.2362]])),\n",
       "             ('bilstm_oov_context_feature.bias_ih_l0',\n",
       "              tensor([-0.0276, -0.0866, -0.0296,  0.0530, -0.2406, -0.0732, -0.1893, -0.0442,\n",
       "                      -0.0933, -0.1869, -0.0501, -0.1724,  0.0644,  0.0737, -0.0994, -0.0632,\n",
       "                      -0.0871, -0.0841, -0.1168,  0.0540,  0.0014, -0.0612, -0.0109,  0.0094,\n",
       "                      -0.1082, -0.2029,  0.0389, -0.0258,  0.0854, -0.0509, -0.0213, -0.1546,\n",
       "                      -0.1392, -0.0279, -0.0920, -0.1510, -0.2548, -0.0307, -0.1546,  0.0575,\n",
       "                       0.1162, -0.0875, -0.0162, -0.1661, -0.1700, -0.1848, -0.2214, -0.1499,\n",
       "                       0.0754, -0.1052,  0.0426, -0.2095, -0.1019, -0.1581, -0.0992, -0.0259,\n",
       "                      -0.0511, -0.1440, -0.2000, -0.0455, -0.0814, -0.0898, -0.1170, -0.1704,\n",
       "                       0.1219, -0.0421, -0.0998, -0.0573,  0.0061, -0.1836, -0.2221, -0.0748,\n",
       "                      -0.1839, -0.0558,  0.1968, -0.0111, -0.1828, -0.1919, -0.1572, -0.0933,\n",
       "                      -0.0698, -0.0741, -0.0121, -0.2010, -0.2160,  0.0032, -0.0793, -0.0411,\n",
       "                      -0.1403,  0.0428, -0.0563, -0.0202, -0.1561,  0.0123, -0.1348, -0.0714,\n",
       "                      -0.1561, -0.0865, -0.0685, -0.2391, -0.1778,  0.0337, -0.1559, -0.1634,\n",
       "                      -0.1498, -0.2172, -0.0472, -0.0517, -0.0379, -0.0076, -0.2492, -0.1535,\n",
       "                      -0.1142, -0.0475, -0.1363, -0.0762, -0.1415, -0.0639, -0.0633, -0.1340,\n",
       "                      -0.1263, -0.2440, -0.0834, -0.2282, -0.2421, -0.1131,  0.0859, -0.0630,\n",
       "                      -0.1190, -0.0717, -0.0648,  0.1298,  0.0254,  0.1075,  0.0296, -0.1040,\n",
       "                       0.0237, -0.0323, -0.1670,  0.0528,  0.1548,  0.1038, -0.0585, -0.0955,\n",
       "                      -0.0242,  0.0811,  0.0639, -0.0462,  0.0089, -0.0182, -0.0797, -0.0321,\n",
       "                       0.0877, -0.0438,  0.0703,  0.1054, -0.0432,  0.0423, -0.0556,  0.0963,\n",
       "                      -0.1944,  0.0293, -0.0812, -0.1743,  0.0287, -0.1483, -0.1309,  0.0027,\n",
       "                       0.0017,  0.0022, -0.0275,  0.0160, -0.0291, -0.0264, -0.0328, -0.1617,\n",
       "                      -0.0279, -0.1488, -0.0179, -0.1276, -0.0603,  0.0025, -0.1462, -0.1575,\n",
       "                      -0.0562,  0.1897, -0.1456, -0.0590,  0.0231, -0.0889,  0.0315,  0.0196,\n",
       "                       0.0754,  0.0447,  0.0809, -0.0020,  0.1238, -0.1172,  0.0164, -0.0893,\n",
       "                      -0.1227,  0.0479,  0.0389,  0.0043,  0.0109, -0.1247, -0.1765,  0.1149,\n",
       "                      -0.2289,  0.0260,  0.0796, -0.0081, -0.0855,  0.0096, -0.1953, -0.1415,\n",
       "                       0.0854,  0.1570,  0.0851,  0.2195, -0.0499, -0.1821, -0.1506, -0.0063,\n",
       "                      -0.0035,  0.0789,  0.0320, -0.1700, -0.0686, -0.0994, -0.1483,  0.0814,\n",
       "                       0.0847, -0.0040,  0.0430,  0.0850,  0.0029,  0.0093, -0.1485, -0.0180,\n",
       "                      -0.1543, -0.0012, -0.0793, -0.0141,  0.1127,  0.0341,  0.1147, -0.0982,\n",
       "                      -0.0034, -0.1144, -0.1521, -0.0820,  0.0285, -0.1554, -0.2248,  0.0213,\n",
       "                       0.0477, -0.1074, -0.0036,  0.0835, -0.0411,  0.0488, -0.0862, -0.0439,\n",
       "                       0.0602,  0.0118, -0.0517, -0.0101,  0.0752,  0.0686,  0.0322,  0.0211,\n",
       "                      -0.0330, -0.0676,  0.0546,  0.0563,  0.1047,  0.0914, -0.0624, -0.0069,\n",
       "                      -0.0559,  0.0048, -0.2001, -0.0148,  0.0819, -0.0299, -0.0688,  0.0672,\n",
       "                      -0.0353,  0.0299, -0.0674,  0.0554,  0.1451, -0.0665, -0.0606, -0.0101,\n",
       "                       0.0441, -0.0485, -0.0083,  0.0704,  0.1784, -0.0085, -0.0075,  0.0392,\n",
       "                       0.0403, -0.0558,  0.0759, -0.0818,  0.0554,  0.0361, -0.0182, -0.0471,\n",
       "                       0.0373,  0.0007,  0.0041, -0.0014,  0.0261,  0.0376, -0.1628,  0.0969,\n",
       "                       0.0288,  0.0077, -0.0420, -0.1103, -0.0726, -0.0119, -0.0328,  0.0941,\n",
       "                      -0.0234,  0.0057,  0.0820,  0.0400, -0.1207, -0.0411,  0.0617, -0.0601,\n",
       "                      -0.0652, -0.0445,  0.1024,  0.0227, -0.0941, -0.0310,  0.0313, -0.0300,\n",
       "                      -0.0048,  0.0588,  0.0177, -0.0030,  0.1158,  0.0351,  0.0152,  0.0230,\n",
       "                       0.0089,  0.0403, -0.1132,  0.1005, -0.1041, -0.0747, -0.0581,  0.0256,\n",
       "                      -0.0115,  0.0142,  0.0281, -0.0609,  0.0211,  0.1344, -0.0085,  0.0721,\n",
       "                      -0.0306, -0.0554,  0.0167,  0.0230,  0.0040,  0.1236, -0.1270, -0.0102,\n",
       "                      -0.1072, -0.0035, -0.0197, -0.0614,  0.0139, -0.0948,  0.0929,  0.0234,\n",
       "                      -0.1615, -0.0783, -0.1846, -0.0150, -0.0732,  0.0505, -0.0400, -0.1007,\n",
       "                      -0.0577, -0.0931, -0.0627, -0.0260, -0.0820, -0.0548, -0.1663, -0.0550,\n",
       "                      -0.0561, -0.0204, -0.0229,  0.0172, -0.0010, -0.1056, -0.0616, -0.0561,\n",
       "                       0.0387, -0.0890, -0.1119, -0.1206, -0.0256, -0.0590,  0.0032,  0.0070,\n",
       "                      -0.1901, -0.1327, -0.0526, -0.1760, -0.1320, -0.0501, -0.1696,  0.1055,\n",
       "                       0.0144,  0.0137, -0.1005, -0.1253,  0.1003, -0.1727, -0.1159, -0.2078,\n",
       "                       0.0098, -0.0908,  0.0851, -0.0732, -0.0797, -0.1310, -0.0644, -0.2365,\n",
       "                      -0.0790, -0.1599, -0.1900, -0.1320, -0.1510, -0.1486, -0.0677, -0.1195,\n",
       "                      -0.0218, -0.0854,  0.0115, -0.0557,  0.1203, -0.2612,  0.0171, -0.0460,\n",
       "                      -0.0556, -0.0264, -0.0155, -0.1642, -0.1815, -0.1072, -0.1324, -0.1048,\n",
       "                      -0.0087,  0.1588, -0.1079, -0.0159, -0.0430,  0.0257, -0.1777, -0.0662,\n",
       "                       0.0186, -0.0056,  0.0358,  0.0373, -0.1876, -0.1795, -0.1110, -0.2068,\n",
       "                      -0.1848,  0.0370, -0.0319, -0.0527, -0.0766,  0.0092, -0.0632, -0.0384,\n",
       "                      -0.0563, -0.0904, -0.1376,  0.1166, -0.1263, -0.1431, -0.2051, -0.0971,\n",
       "                      -0.1020, -0.0135, -0.0745,  0.0362,  0.0708, -0.1275, -0.0610, -0.3609,\n",
       "                      -0.0865, -0.0462, -0.1409, -0.2000,  0.0487, -0.1153, -0.0763, -0.2992])),\n",
       "             ('bilstm_oov_context_feature.bias_hh_l0',\n",
       "              tensor([-0.1389, -0.2439, -0.0607,  0.0935, -0.1769,  0.0730, -0.2253, -0.0472,\n",
       "                       0.0205, -0.1228, -0.0816, -0.0514,  0.0642, -0.1436, -0.1272, -0.0863,\n",
       "                       0.0444, -0.0389, -0.1732, -0.0127, -0.0406, -0.0980, -0.1562, -0.0546,\n",
       "                      -0.1813, -0.1293, -0.0125, -0.0579, -0.0542, -0.1103,  0.0068, -0.0718,\n",
       "                      -0.2148, -0.1106, -0.2480, -0.2828, -0.1273, -0.0903, -0.0639, -0.2169,\n",
       "                      -0.0119, -0.0435, -0.1011, -0.1743, -0.0934, -0.1170, -0.1764, -0.1345,\n",
       "                      -0.0234, -0.1714, -0.0202, -0.1541, -0.1255, -0.0493, -0.0343, -0.0963,\n",
       "                      -0.1858, -0.1238, -0.0499, -0.1463, -0.2335, -0.0361, -0.1535, -0.0769,\n",
       "                       0.0154, -0.1265, -0.0755, -0.1604, -0.0233, -0.1497, -0.1763,  0.0089,\n",
       "                      -0.1223, -0.0008, -0.0090,  0.0334, -0.0808, -0.1384, -0.0737,  0.0551,\n",
       "                       0.0179, -0.0607,  0.0901, -0.1702, -0.1000, -0.1340, -0.1546, -0.1159,\n",
       "                      -0.1172,  0.0431, -0.1685,  0.0315, -0.1572, -0.0691, -0.0854, -0.0480,\n",
       "                      -0.1578, -0.1044, -0.0707, -0.1622, -0.0891,  0.0162, -0.0767, -0.0813,\n",
       "                      -0.1908, -0.1537, -0.0414, -0.0258, -0.0631, -0.0425, -0.1975, -0.1023,\n",
       "                      -0.0501, -0.1602, -0.1415, -0.1615, -0.0264, -0.0727, -0.0082, -0.1750,\n",
       "                      -0.1256, -0.1089, -0.0614, -0.1653, -0.0516, -0.1889,  0.0212, -0.0682,\n",
       "                       0.1163, -0.0794, -0.0641, -0.0241, -0.0748,  0.1029, -0.1126, -0.0608,\n",
       "                       0.0197, -0.0631, -0.2930, -0.0656,  0.3041,  0.1063, -0.2033, -0.0101,\n",
       "                       0.0096,  0.0233,  0.0462,  0.0198,  0.0027, -0.1842,  0.0340,  0.0300,\n",
       "                       0.1180, -0.0472,  0.1033, -0.0030,  0.0489, -0.0068,  0.0703,  0.0524,\n",
       "                      -0.1079, -0.1562, -0.0396, -0.1147, -0.0649, -0.1750, -0.1041, -0.0133,\n",
       "                       0.0137,  0.0235, -0.0553, -0.0466, -0.0787, -0.0536,  0.0292, -0.1236,\n",
       "                       0.0713, -0.0839,  0.0990, -0.0692, -0.0132, -0.1207, -0.0674,  0.0449,\n",
       "                      -0.0473,  0.0348, -0.0337, -0.0406,  0.0458, -0.0739,  0.0300,  0.0397,\n",
       "                      -0.0018, -0.0191, -0.0845, -0.0063,  0.1716,  0.0048,  0.0522,  0.1380,\n",
       "                      -0.0142,  0.0332,  0.2710,  0.1576, -0.0900, -0.0716,  0.0040,  0.0698,\n",
       "                      -0.0604, -0.0922,  0.0286, -0.1118, -0.0493, -0.1628, -0.1211, -0.0783,\n",
       "                       0.0573,  0.1060, -0.0476,  0.1768, -0.0293, -0.1584, -0.0659,  0.0561,\n",
       "                      -0.0143, -0.0428,  0.0850, -0.1102, -0.0342,  0.0577,  0.0280,  0.1802,\n",
       "                       0.0249,  0.0122,  0.0294, -0.0802, -0.1379, -0.0682, -0.1274, -0.1506,\n",
       "                      -0.0077,  0.0095, -0.1624, -0.0017,  0.1180,  0.0263, -0.0432, -0.0568,\n",
       "                       0.0217, -0.0954, -0.1300, -0.0690, -0.1384, -0.1030, -0.1179,  0.0337,\n",
       "                       0.0096, -0.0201, -0.1064,  0.0335, -0.0661,  0.0037,  0.0132, -0.0193,\n",
       "                      -0.0155, -0.0923,  0.0323,  0.0311,  0.0851, -0.0547,  0.1336, -0.1439,\n",
       "                       0.0372, -0.0019,  0.0270, -0.1043, -0.0420, -0.0074,  0.0971,  0.0101,\n",
       "                      -0.0528,  0.0795, -0.0294,  0.0741,  0.1916,  0.2950,  0.0396, -0.0809,\n",
       "                      -0.0030, -0.0294,  0.0474, -0.1088, -0.1082, -0.0248,  0.0201,  0.0006,\n",
       "                      -0.1712, -0.1824,  0.0792, -0.0770,  0.1133,  0.0102,  0.0696, -0.1933,\n",
       "                       0.0287,  0.0640,  0.0241,  0.0551,  0.0009,  0.0958, -0.0568, -0.0518,\n",
       "                       0.1274, -0.1226,  0.0394, -0.0285, -0.0673,  0.0079,  0.1219,  0.0490,\n",
       "                       0.0088, -0.0992,  0.0731,  0.0140, -0.0918,  0.0021, -0.0775,  0.1086,\n",
       "                      -0.0767, -0.0436,  0.0123,  0.0320, -0.0491, -0.0908, -0.0321, -0.0421,\n",
       "                      -0.1102,  0.0060, -0.0072, -0.0556,  0.0889, -0.0475,  0.0215, -0.0134,\n",
       "                       0.0383,  0.0522, -0.0530,  0.0219, -0.0542,  0.0445, -0.0851,  0.0834,\n",
       "                       0.0672,  0.1295, -0.1021,  0.0655,  0.0730, -0.0638,  0.1434, -0.0275,\n",
       "                      -0.0012, -0.0022, -0.0518, -0.0761, -0.0133,  0.0718,  0.1162,  0.0129,\n",
       "                       0.0041,  0.0386, -0.0446, -0.0159, -0.1002, -0.0590, -0.0863, -0.0068,\n",
       "                      -0.1180,  0.0739,  0.0101,  0.0235, -0.0274,  0.0791,  0.1227, -0.0338,\n",
       "                      -0.1105, -0.1312, -0.1326, -0.1072, -0.0733, -0.0512, -0.1035, -0.1376,\n",
       "                      -0.0321, -0.2654,  0.0072, -0.0167,  0.0351, -0.0581, -0.0612, -0.0922,\n",
       "                      -0.0451,  0.0034, -0.1002,  0.0004, -0.0376, -0.0641, -0.1932,  0.0387,\n",
       "                      -0.0180, -0.0125, -0.1124,  0.0336, -0.1154, -0.0569,  0.0141, -0.1341,\n",
       "                      -0.2162, -0.0980, -0.0033, -0.1150, -0.1297, -0.0977, -0.1205, -0.0119,\n",
       "                      -0.0483,  0.0205, -0.1188, -0.0721, -0.0119, -0.0209, -0.1536, -0.0235,\n",
       "                       0.0552, -0.0308, -0.0612, -0.1713, -0.0252, -0.2514, -0.2030, -0.1459,\n",
       "                      -0.1134, -0.1218, -0.2277, -0.1832, -0.0103, -0.1385, -0.1037, -0.0926,\n",
       "                       0.0187, -0.0866,  0.0028, -0.0742,  0.0352, -0.1084, -0.1817, -0.0411,\n",
       "                      -0.1953, -0.0152, -0.0139, -0.0192, -0.0276, -0.1522, -0.0935, -0.0111,\n",
       "                      -0.0687, -0.0566, -0.0216, -0.0284, -0.1802,  0.0406, -0.1805, -0.0645,\n",
       "                       0.0248,  0.1325,  0.0963,  0.0538, -0.1594, -0.1518, -0.1389, -0.1242,\n",
       "                      -0.0758, -0.1115,  0.0125, -0.1272, -0.1283,  0.0573, -0.1092, -0.0462,\n",
       "                      -0.0907,  0.0074, -0.1019,  0.1114, -0.0387, -0.1829, -0.1039,  0.0264,\n",
       "                      -0.1124, -0.0457, -0.1628, -0.0441, -0.0980, -0.1262, -0.1385, -0.2117,\n",
       "                      -0.0524, -0.0719, -0.1914, -0.2444, -0.1322, -0.3261, -0.0258, -0.2091])),\n",
       "             ('bilstm_oov_context_feature.weight_ih_l0_reverse',\n",
       "              tensor([[-5.7768e-01,  1.6597e-01, -5.4670e-02,  ...,  2.9285e-04,\n",
       "                        1.3683e+00,  6.0509e-01],\n",
       "                      [-3.2188e-01, -3.2163e-01, -3.5946e-01,  ..., -1.6036e-01,\n",
       "                        3.1244e-01,  4.5501e-01],\n",
       "                      [-3.0890e-01,  7.9787e-02, -2.7091e-01,  ..., -7.7785e-02,\n",
       "                       -3.6312e-02, -3.3374e-01],\n",
       "                      ...,\n",
       "                      [-1.1470e-01, -2.8774e-01,  9.0736e-02,  ...,  9.4657e-01,\n",
       "                        1.3142e-01, -2.0792e-01],\n",
       "                      [-4.4528e-01,  8.7686e-01,  5.5995e-01,  ..., -1.3697e-01,\n",
       "                        2.4148e-01,  4.5651e-01],\n",
       "                      [-1.5791e-01, -3.5080e-01, -2.4961e-01,  ...,  2.4027e-01,\n",
       "                        4.5256e-01,  9.2569e-02]])),\n",
       "             ('bilstm_oov_context_feature.weight_hh_l0_reverse',\n",
       "              tensor([[-0.3535,  0.2285, -0.1572,  ..., -0.1299, -0.2063,  0.0451],\n",
       "                      [ 0.1217, -0.2799, -0.0343,  ..., -0.1196,  0.0057, -0.3036],\n",
       "                      [-0.2746,  0.0443, -0.0037,  ..., -0.2658,  0.0054, -0.3984],\n",
       "                      ...,\n",
       "                      [-0.2837,  0.0511, -0.2015,  ...,  0.0473,  0.0494, -0.1611],\n",
       "                      [-0.0856, -0.0305,  0.0687,  ..., -0.0216, -0.2879, -0.4075],\n",
       "                      [ 0.1907, -0.4961,  0.0989,  ...,  0.0268, -0.1208,  0.2111]])),\n",
       "             ('bilstm_oov_context_feature.bias_ih_l0_reverse',\n",
       "              tensor([ 1.0945e-02,  2.3178e-01,  1.4127e-01,  1.9759e-01,  1.9690e-01,\n",
       "                       1.4934e-01,  1.6322e-01,  2.7985e-01,  1.7180e-01,  2.1234e-01,\n",
       "                       1.7260e-01,  2.6156e-01,  2.5653e-01, -6.6138e-02,  2.5787e-01,\n",
       "                      -1.2590e-03,  4.0864e-01, -6.7270e-02,  1.3493e-01,  5.0184e-02,\n",
       "                       1.8780e-01,  1.5761e-01,  1.5347e-01,  2.9368e-01,  2.4216e-01,\n",
       "                       7.9943e-02,  1.9248e-01,  1.7261e-01,  5.2350e-02,  1.7200e-01,\n",
       "                       4.9095e-02,  1.4358e-01,  2.0490e-01,  1.5482e-01,  8.0061e-02,\n",
       "                       1.3011e-01,  1.0134e-01,  1.1980e-01,  4.3356e-02,  1.7344e-01,\n",
       "                       1.0100e-01,  1.8407e-01,  2.3017e-01,  2.3056e-01,  1.9673e-01,\n",
       "                       1.5454e-01,  1.7631e-01,  1.3799e-01,  1.3148e-01, -9.3189e-02,\n",
       "                       2.2296e-01,  1.1631e-01,  2.0565e-01,  1.4036e-01,  1.2687e-01,\n",
       "                       6.7783e-03,  1.5581e-01,  1.6610e-01,  3.7241e-02,  9.0960e-02,\n",
       "                       1.6264e-01,  2.6489e-01,  1.6206e-01,  2.8951e-01,  1.2118e-01,\n",
       "                       5.2048e-03,  2.1547e-01,  1.7476e-01,  1.3532e-01,  1.2152e-01,\n",
       "                      -4.0209e-02,  1.2613e-01,  1.2592e-01,  1.9858e-01,  1.3592e-01,\n",
       "                       1.9549e-01,  5.6980e-03,  2.2379e-01,  1.0768e-01,  1.6886e-02,\n",
       "                       1.7735e-01,  9.4387e-02,  4.4993e-01,  2.8273e-01,  1.0471e-01,\n",
       "                      -5.0362e-02,  2.4782e-01,  1.5787e-01,  3.0924e-01, -9.7348e-02,\n",
       "                       2.0779e-03,  1.0651e-01,  2.3820e-01,  1.0447e-01,  2.1440e-01,\n",
       "                       2.5278e-01,  1.2804e-01,  8.8231e-02,  1.1931e-01,  9.8957e-02,\n",
       "                       2.2361e-01,  3.2647e-01,  3.4393e-02,  2.0633e-01,  1.2946e-01,\n",
       "                       2.2317e-01,  1.1016e-01,  1.1992e-01,  6.0414e-02,  1.3433e-01,\n",
       "                       1.6935e-01,  2.0191e-01, -7.0581e-02,  7.1272e-02,  1.9671e-01,\n",
       "                       1.7136e-01,  2.2102e-01,  1.1631e-01,  2.0045e-01, -8.8550e-02,\n",
       "                       9.3917e-02,  1.8313e-01,  2.9442e-01,  1.9438e-01,  2.6872e-01,\n",
       "                       2.0734e-01, -6.6655e-04,  9.6301e-02,  1.2286e-01, -4.2857e-02,\n",
       "                       7.2104e-02,  6.0578e-02, -7.3665e-02, -3.7567e-02, -2.7621e-02,\n",
       "                       9.2560e-02,  6.6472e-02,  1.3178e-01,  6.7115e-02, -5.7449e-03,\n",
       "                       8.9565e-02, -4.4827e-02,  5.5045e-02,  1.5805e-01,  1.8812e-02,\n",
       "                      -7.2439e-02, -1.0803e-01, -5.3868e-02,  3.6128e-02, -6.5465e-02,\n",
       "                       9.4015e-02,  1.2995e-01,  9.6919e-02,  4.8675e-02, -1.8169e-03,\n",
       "                      -3.7726e-02,  6.4975e-03,  5.6819e-02,  7.7241e-02,  5.8677e-02,\n",
       "                       1.0857e-01,  3.2227e-02, -7.9008e-02,  1.4787e-01,  6.5292e-02,\n",
       "                       1.5906e-01, -2.7992e-02,  2.4469e-03, -3.7445e-02,  2.5943e-02,\n",
       "                       9.9712e-03, -8.9287e-02,  3.9232e-02,  1.4578e-01, -4.8209e-03,\n",
       "                       2.1178e-02, -5.7817e-02,  1.3479e-02,  1.1613e-01,  8.8193e-02,\n",
       "                       2.5300e-02, -1.3299e-02,  8.9801e-02,  8.5071e-02,  2.5454e-02,\n",
       "                      -8.7491e-02,  5.7767e-02, -9.0375e-02, -9.4011e-02, -4.1070e-02,\n",
       "                       2.5563e-02, -1.5287e-01,  3.8347e-02,  1.6761e-01, -4.3508e-02,\n",
       "                       1.1434e-01,  4.4523e-02,  5.9836e-02,  9.7054e-02,  7.4081e-02,\n",
       "                       1.1320e-02,  7.4848e-02,  8.5756e-02,  1.6076e-01, -2.7856e-02,\n",
       "                      -6.1722e-03,  3.4938e-02, -7.2651e-03,  1.5891e-02,  7.3594e-02,\n",
       "                      -1.8167e-01,  1.2223e-02,  1.4854e-02, -1.8913e-02,  3.9360e-02,\n",
       "                       1.8110e-01,  1.2912e-02,  3.2868e-02,  8.8721e-02,  1.1443e-01,\n",
       "                      -3.9957e-02,  1.9728e-01, -1.6050e-01, -4.3170e-02,  5.1165e-02,\n",
       "                       3.9896e-02,  2.9959e-02,  1.6471e-01, -6.2841e-02, -1.5739e-02,\n",
       "                      -1.1342e-04,  9.6333e-02,  7.3657e-02,  9.4328e-02, -1.2419e-02,\n",
       "                       2.1945e-01,  1.0648e-01,  9.9425e-02, -3.6186e-02, -2.0924e-02,\n",
       "                       1.2594e-02,  5.8773e-02,  8.2374e-03, -3.3328e-02, -7.0846e-02,\n",
       "                       6.3500e-02, -6.7803e-02,  6.5525e-02, -3.9460e-02,  7.1220e-02,\n",
       "                       1.2405e-01, -1.8998e-01, -7.4605e-02,  5.8523e-02,  1.4947e-02,\n",
       "                       8.3794e-02,  5.7024e-03, -4.1538e-02,  4.7789e-02,  1.3837e-02,\n",
       "                       5.4560e-02,  1.1360e-01, -2.1321e-02,  2.7604e-02,  9.0460e-02,\n",
       "                      -2.6459e-02,  3.6553e-02, -4.2909e-02, -2.6480e-02,  3.7735e-02,\n",
       "                      -3.7749e-02,  3.1108e-02, -1.0916e-01,  9.8993e-02,  5.8053e-02,\n",
       "                      -2.1063e-02, -1.5892e-01,  2.3884e-02, -7.8108e-02, -9.9756e-02,\n",
       "                      -3.7160e-02,  3.6026e-02,  2.0482e-02,  4.7218e-02, -9.6684e-02,\n",
       "                      -6.1908e-02,  1.2434e-01, -5.0026e-02,  4.1562e-02, -1.9696e-03,\n",
       "                       5.4734e-04,  4.2687e-02,  5.1683e-02,  4.5840e-02,  1.0219e-01,\n",
       "                      -2.8388e-02,  5.5998e-02, -8.3386e-02,  1.0856e-02,  5.4249e-02,\n",
       "                      -7.8043e-02,  4.9592e-02, -5.6888e-02, -7.3370e-02,  1.3638e-01,\n",
       "                       4.5727e-02, -1.4711e-01, -1.2296e-02,  5.0037e-02,  1.1472e-01,\n",
       "                       7.4372e-02,  7.2439e-02,  1.1895e-01,  3.5946e-02,  4.1086e-02,\n",
       "                       1.2168e-01,  8.4647e-02, -1.5132e-02,  6.3004e-02,  5.6665e-02,\n",
       "                       3.8035e-02, -4.8451e-02, -2.9510e-02,  2.4953e-02, -4.9085e-02,\n",
       "                       4.3727e-02, -7.5754e-02, -2.4889e-02, -8.2905e-02,  3.6617e-02,\n",
       "                       4.1784e-02,  1.7887e-01, -4.9772e-02,  5.5944e-02, -9.8840e-02,\n",
       "                      -6.5216e-02, -3.9281e-02,  2.1409e-02,  4.5657e-03,  4.2277e-02,\n",
       "                      -1.3126e-01,  8.0515e-02,  7.7840e-02,  4.1266e-02,  1.1192e-02,\n",
       "                       5.3587e-02, -1.0063e-01, -5.7879e-02,  8.9812e-04,  1.7840e-02,\n",
       "                      -8.5901e-02,  2.2140e-02,  3.4265e-02, -1.1301e-02, -3.7091e-02,\n",
       "                      -1.1677e-02,  8.4672e-02, -9.3719e-02,  1.0442e-01, -5.5617e-02,\n",
       "                       8.0746e-02,  1.4080e-01, -3.5141e-02,  3.5581e-02,  3.1655e-03,\n",
       "                       1.1203e-02, -5.6059e-02,  2.8364e-02, -1.7854e-02,  3.6860e-02,\n",
       "                      -1.1023e-01,  1.0702e-01, -3.4854e-02, -8.4590e-02,  1.0850e-01,\n",
       "                      -6.5895e-02, -5.9437e-03,  1.0416e-01,  5.1047e-02,  2.0619e-02,\n",
       "                      -5.8986e-02, -1.1741e-01,  1.0603e-01,  2.2469e-02,  1.9624e-01,\n",
       "                       1.2424e-01,  9.7717e-02,  9.8192e-02,  2.2763e-01,  1.7561e-01,\n",
       "                       3.0862e-01,  1.4135e-01, -5.8850e-03,  2.3131e-01,  9.5208e-02,\n",
       "                       1.4364e-01,  2.2744e-01,  6.2313e-03,  2.2301e-01,  2.8332e-01,\n",
       "                       6.2309e-02,  7.8185e-02,  1.6666e-01,  9.2608e-02,  2.6863e-02,\n",
       "                       2.2929e-01,  1.3317e-01,  2.9881e-01,  4.8394e-03, -1.1547e-02,\n",
       "                       1.9187e-01,  1.4903e-01, -2.6399e-03,  4.0724e-02,  2.9427e-01,\n",
       "                       2.4080e-01,  1.1910e-01,  1.8971e-01,  5.4147e-03,  2.2105e-01,\n",
       "                       2.5215e-01,  4.3279e-02,  2.4610e-01,  1.1172e-02,  1.4811e-01,\n",
       "                       1.3158e-01,  6.9281e-02,  4.4559e-02,  3.7629e-01,  6.3064e-02,\n",
       "                       9.9011e-02,  2.9184e-01,  8.3703e-02,  4.8607e-02,  1.4974e-01,\n",
       "                       1.9001e-01,  2.3221e-01,  1.5402e-01, -1.0130e-01,  6.3141e-02,\n",
       "                       1.2220e-01,  3.4593e-01, -2.8436e-02,  1.7832e-01,  1.7928e-01,\n",
       "                       2.3364e-01,  4.0372e-02,  2.1934e-01,  2.9597e-01,  1.9082e-01,\n",
       "                       2.1525e-01,  1.5839e-01, -2.0970e-02,  7.5907e-02, -4.2219e-02,\n",
       "                       6.4410e-02,  1.9181e-01,  2.2925e-01,  2.4302e-01,  2.4318e-01,\n",
       "                       1.9438e-02,  2.9203e-01,  4.7634e-02,  3.1056e-02,  7.8019e-02,\n",
       "                       2.8652e-01,  2.1327e-01,  2.2966e-01, -6.4489e-02,  1.8064e-01,\n",
       "                       5.5529e-02,  2.3460e-01,  2.2245e-01,  2.0397e-01,  9.6716e-02,\n",
       "                       9.2123e-02,  2.1716e-01,  1.1926e-01,  4.0158e-01,  7.9115e-02,\n",
       "                       1.7533e-01, -8.9144e-02,  1.6115e-02,  4.8539e-02,  1.2915e-01,\n",
       "                       2.0894e-01,  1.6594e-01,  1.0733e-01,  1.7876e-01,  1.9335e-01,\n",
       "                       7.9984e-02,  4.7696e-02,  2.1141e-01,  1.7799e-01,  2.0617e-01,\n",
       "                       2.3055e-01,  5.9673e-02,  1.2563e-01,  1.2502e-01,  1.7746e-01,\n",
       "                       2.7987e-01,  1.4902e-01,  8.3696e-02,  6.9610e-02,  1.2055e-01,\n",
       "                       1.4176e-01,  7.5311e-02,  2.2391e-01,  1.9179e-01,  1.5217e-01,\n",
       "                       2.7002e-01,  2.3207e-01])),\n",
       "             ('bilstm_oov_context_feature.bias_hh_l0_reverse',\n",
       "              tensor([ 2.2764e-01,  1.9668e-01,  8.5556e-02,  1.9608e-01,  1.9981e-01,\n",
       "                       7.6883e-02,  2.9603e-02,  2.3397e-01,  2.2880e-01,  1.3103e-01,\n",
       "                       1.3336e-01,  2.3909e-01,  7.0039e-02,  3.8516e-02,  2.6346e-01,\n",
       "                       2.4899e-01,  3.4626e-01, -2.4372e-02,  2.2063e-01,  7.2375e-02,\n",
       "                       1.5416e-01,  1.4531e-01,  1.6525e-01,  2.6443e-01,  2.1551e-01,\n",
       "                      -8.7947e-02,  9.1788e-02,  1.0865e-01,  1.3899e-01,  2.7522e-01,\n",
       "                       9.8305e-02,  3.7853e-02,  2.1380e-02,  1.3598e-01,  9.4946e-02,\n",
       "                       1.9243e-02,  1.4123e-01,  7.0088e-02,  1.9956e-01,  1.3200e-01,\n",
       "                       2.2609e-01,  1.5638e-01,  1.4824e-01,  2.8679e-01,  2.5964e-01,\n",
       "                       2.4509e-01,  1.2105e-01,  1.3533e-01,  1.2355e-01, -2.8655e-02,\n",
       "                       8.7157e-02,  3.2314e-02,  1.9068e-01,  1.2944e-01,  6.2459e-02,\n",
       "                      -2.4907e-02,  1.0486e-01,  1.7853e-01, -6.1709e-02,  2.5011e-01,\n",
       "                       4.5048e-02,  1.2801e-01,  1.4314e-01,  2.7983e-01,  2.2514e-01,\n",
       "                       4.8362e-02,  3.8865e-02,  1.4032e-01,  1.8896e-01,  1.0978e-01,\n",
       "                       6.0426e-02,  1.4518e-01,  1.2110e-01,  2.0707e-01,  1.5083e-01,\n",
       "                       6.3502e-02,  8.8410e-02,  2.2120e-01,  1.2584e-01,  7.2717e-02,\n",
       "                       1.2029e-01,  2.3223e-01,  3.6357e-01,  2.5285e-01,  1.7717e-01,\n",
       "                       8.5914e-03,  5.0298e-03,  2.6762e-01,  1.0933e-01, -2.4168e-02,\n",
       "                       1.0845e-01,  3.1458e-02,  1.3079e-01,  4.4030e-02,  2.3353e-01,\n",
       "                       3.0417e-01,  1.9920e-01,  8.7999e-02,  8.3275e-02,  8.8459e-02,\n",
       "                      -7.0129e-03,  2.5798e-01,  2.4793e-01,  2.1269e-01,  1.5701e-01,\n",
       "                       1.6737e-01,  8.5118e-02,  1.2140e-01,  2.2755e-01,  1.3993e-01,\n",
       "                       1.7197e-01,  2.6929e-01,  3.5703e-02,  1.1190e-01,  2.8358e-01,\n",
       "                       3.2556e-02,  2.5208e-01,  1.7329e-01,  1.3951e-01, -3.5850e-02,\n",
       "                       3.0920e-02,  1.7596e-01,  3.6856e-02,  1.8076e-01,  1.6111e-01,\n",
       "                       2.8170e-01,  2.5001e-02,  5.3088e-02,  1.0711e-01, -8.1474e-02,\n",
       "                       2.6694e-02,  7.7754e-02, -1.3827e-01,  1.4544e-02, -8.9469e-02,\n",
       "                       1.2441e-01,  9.5731e-02,  5.7937e-03,  7.3256e-02,  3.4629e-02,\n",
       "                       9.5355e-02, -2.0293e-02,  6.8490e-02,  1.0634e-01, -6.8984e-02,\n",
       "                      -4.6567e-02,  9.5208e-02,  5.9484e-02, -9.0740e-03,  1.6476e-01,\n",
       "                       1.0780e-01, -1.2766e-02,  2.8113e-01, -6.7844e-02,  1.2960e-02,\n",
       "                      -3.0230e-02, -4.0530e-02,  7.0184e-02,  6.1986e-02, -9.5210e-03,\n",
       "                       1.2531e-01,  9.8235e-02,  2.5599e-02,  1.0089e-01,  1.0043e-01,\n",
       "                       8.4657e-02,  2.1250e-03,  1.9495e-02, -6.1282e-02,  8.4963e-02,\n",
       "                       3.9624e-02,  4.7126e-03, -3.0452e-02,  4.7186e-02,  8.1583e-02,\n",
       "                      -1.4754e-02, -1.0298e-02, -5.5169e-02,  2.4379e-02,  2.2327e-02,\n",
       "                       6.6809e-02, -2.4604e-02,  1.1697e-01,  6.7486e-02,  6.8457e-02,\n",
       "                      -8.4628e-02,  1.7399e-02, -1.9917e-02, -7.5386e-02,  1.8429e-03,\n",
       "                       7.5290e-03, -7.6204e-02, -3.0070e-02, -5.8816e-02,  9.2040e-02,\n",
       "                      -3.5740e-02,  2.0432e-02,  1.1627e-01,  7.6908e-02,  1.0301e-01,\n",
       "                       7.9807e-02, -4.0720e-02,  1.0212e-02,  4.4316e-02, -2.6820e-02,\n",
       "                      -1.3273e-02, -6.6310e-02,  9.9123e-02,  5.6309e-02,  1.1340e-01,\n",
       "                      -1.5852e-01,  9.4215e-02,  1.2395e-01, -1.6347e-01,  1.0021e-02,\n",
       "                       2.4668e-02,  1.5466e-02,  8.3507e-02, -1.5538e-01,  1.0052e-01,\n",
       "                      -3.0908e-02,  5.5246e-02, -9.7875e-02, -4.1547e-02,  6.4374e-03,\n",
       "                       4.3904e-02,  1.7567e-01,  6.9313e-02,  9.2085e-03,  4.7119e-02,\n",
       "                      -5.1475e-02, -8.8761e-02,  1.0788e-01,  7.4899e-02,  8.3326e-02,\n",
       "                       1.0292e-01, -2.0595e-02,  2.7006e-02,  3.5582e-03, -1.2730e-03,\n",
       "                       3.0778e-02,  4.4340e-02,  6.4397e-02, -1.8370e-02, -4.7705e-02,\n",
       "                       5.2103e-02, -1.2620e-01,  1.0270e-01,  6.0318e-02, -3.6995e-02,\n",
       "                       4.0296e-02,  2.7809e-02, -5.4834e-02,  1.2368e-02, -2.1367e-02,\n",
       "                       1.0735e-01, -8.4046e-02,  2.9536e-02, -4.2447e-02, -9.1434e-02,\n",
       "                      -4.6248e-02,  1.7211e-01, -3.1867e-02, -7.4011e-02,  1.2128e-01,\n",
       "                      -9.2996e-02,  9.2184e-02, -1.0067e-01, -4.7883e-02, -6.3022e-02,\n",
       "                      -2.7914e-02, -3.0507e-02, -4.2254e-02,  1.2564e-01,  1.3108e-01,\n",
       "                       4.6840e-02,  2.3458e-02, -1.1268e-01, -7.9526e-02, -1.1428e-02,\n",
       "                       2.1376e-02, -2.2564e-02, -5.3928e-03,  8.1678e-02,  3.2425e-02,\n",
       "                      -8.5442e-02,  1.7407e-02, -3.2845e-03, -2.4513e-02,  9.6711e-02,\n",
       "                      -1.0691e-01,  4.5672e-03, -1.4705e-01,  8.2303e-02, -1.3979e-01,\n",
       "                      -1.4720e-01,  7.2918e-02,  1.7671e-02, -6.7304e-02,  4.7223e-02,\n",
       "                      -7.5371e-02, -2.9582e-02, -2.6229e-02, -3.4389e-02, -3.6121e-02,\n",
       "                      -6.9884e-02,  3.1066e-02, -3.2863e-02, -9.8855e-02,  2.5670e-02,\n",
       "                       8.4021e-02,  3.4845e-02, -1.6091e-02, -7.8059e-02, -1.2511e-02,\n",
       "                      -2.4545e-02, -6.9105e-02,  7.6658e-02,  1.5838e-01, -7.0885e-02,\n",
       "                      -9.6549e-02, -4.1042e-02,  8.4442e-02, -1.9102e-02,  1.1150e-01,\n",
       "                      -1.0977e-01, -9.2586e-02,  8.1386e-02,  3.3101e-02,  6.2043e-02,\n",
       "                      -5.9424e-02,  9.0920e-02,  1.2057e-01, -1.4755e-01, -3.1079e-02,\n",
       "                       1.2672e-01, -2.7031e-02,  8.1002e-02, -4.9017e-02, -9.4666e-02,\n",
       "                      -5.2368e-02,  1.0164e-02,  4.8342e-02, -3.5113e-02, -2.6803e-03,\n",
       "                       5.3433e-02,  3.0266e-02,  6.1853e-03, -1.9672e-02, -9.8272e-02,\n",
       "                      -4.1937e-02, -8.4926e-02,  6.2372e-02,  1.8390e-01, -1.6117e-01,\n",
       "                       4.2804e-02,  7.4819e-02,  6.4844e-02, -6.9428e-03, -8.8876e-02,\n",
       "                       4.5238e-02, -3.5110e-02,  4.3699e-02,  9.1954e-03,  3.2234e-02,\n",
       "                       2.6480e-02,  1.3097e-01,  9.9561e-02, -4.0451e-02,  5.1810e-02,\n",
       "                       1.5216e-01,  5.5205e-02, -3.6293e-02, -1.6301e-02,  1.2195e-01,\n",
       "                      -1.0057e-01,  5.9560e-03,  2.2231e-02, -5.3867e-05,  1.1562e-02,\n",
       "                       5.0722e-02, -9.9214e-02,  3.0831e-02,  3.6212e-02,  6.7032e-02,\n",
       "                       2.4578e-01,  1.0319e-01,  3.3350e-02,  1.6815e-01,  1.7484e-01,\n",
       "                       1.3338e-01,  8.3887e-02,  6.2732e-02,  2.2152e-01,  8.2365e-02,\n",
       "                       1.5801e-01,  1.8550e-01,  8.6984e-02,  1.1424e-01,  1.5525e-01,\n",
       "                       3.1288e-01,  6.0089e-02,  2.8287e-01,  7.1201e-02,  1.8631e-02,\n",
       "                       3.7273e-01,  1.0278e-01,  3.0955e-01, -1.0131e-02, -2.3905e-02,\n",
       "                       3.2164e-01,  8.9404e-02,  2.2894e-02,  4.5373e-02,  3.8778e-04,\n",
       "                       2.0850e-01,  3.2263e-01,  1.8809e-01,  1.1383e-02,  9.5961e-02,\n",
       "                       3.1856e-01,  6.6220e-02,  2.7796e-01, -1.4416e-01,  8.5504e-02,\n",
       "                       7.1050e-02,  1.2352e-01,  5.0385e-02,  2.1972e-01,  1.1258e-01,\n",
       "                       2.8860e-01,  2.2362e-01,  1.5335e-01,  9.1158e-02,  3.0664e-01,\n",
       "                       4.0787e-01,  5.8005e-02,  1.0644e-01, -1.9438e-02,  4.2605e-03,\n",
       "                       1.3637e-01,  3.0057e-01,  1.3259e-02,  1.3228e-02,  9.1612e-02,\n",
       "                       1.9402e-01, -1.2325e-02,  2.7667e-01,  2.6072e-01,  7.4226e-02,\n",
       "                       2.6642e-01,  5.0366e-02,  1.4121e-02,  1.2308e-02, -7.4066e-02,\n",
       "                       1.9064e-01,  1.5363e-01,  1.8283e-01,  1.5488e-01,  1.7452e-01,\n",
       "                      -1.6021e-02,  2.3449e-01, -1.6500e-02,  5.1331e-02,  6.3781e-02,\n",
       "                       2.3670e-01,  2.4659e-01,  1.2618e-01, -2.1499e-02,  4.8131e-02,\n",
       "                       7.6176e-02,  3.1032e-02,  1.9896e-01,  1.0581e-01,  5.7117e-02,\n",
       "                       1.6101e-01,  2.7394e-01,  1.5647e-01,  1.7895e-01,  3.4524e-03,\n",
       "                       2.1907e-01,  1.5808e-02, -1.1728e-02,  1.7360e-02,  2.4727e-01,\n",
       "                       3.0537e-01,  2.1305e-01,  2.7102e-01,  1.5979e-01,  2.9469e-01,\n",
       "                       1.1937e-01,  6.2313e-02,  2.1535e-01,  1.9600e-01,  2.4814e-01,\n",
       "                       2.6956e-01, -1.5784e-03,  6.2023e-02,  2.6695e-01,  1.7214e-01,\n",
       "                       2.1183e-01,  1.6445e-01,  2.6873e-01, -3.7784e-02,  1.5932e-01,\n",
       "                       6.4423e-03,  6.6469e-02,  2.1336e-01,  1.5877e-01,  1.2807e-01,\n",
       "                       2.5377e-01,  1.9269e-01])),\n",
       "             ('bilstm_right_context_feature.weight_ih_l0',\n",
       "              tensor([[ 0.4674,  0.1945,  0.0791,  ..., -0.3535,  0.0679,  0.1157],\n",
       "                      [ 0.2926, -0.0745, -0.1691,  ..., -0.3757,  0.5014, -0.0881],\n",
       "                      [-0.0072, -0.3234, -0.3241,  ..., -0.1646,  0.0576,  0.0082],\n",
       "                      ...,\n",
       "                      [-0.0733, -0.2493, -0.0412,  ..., -0.3362,  0.3156, -0.1251],\n",
       "                      [ 0.1686,  0.0100, -0.0914,  ..., -0.0057,  0.1879, -0.2688],\n",
       "                      [ 0.2366, -0.3654,  0.1418,  ..., -0.1008, -0.0663, -0.1343]])),\n",
       "             ('bilstm_right_context_feature.weight_hh_l0',\n",
       "              tensor([[ 0.2001, -0.0078,  0.2146,  ...,  0.1601,  0.1815, -0.0520],\n",
       "                      [-0.0744, -0.2338, -0.1491,  ..., -0.0217, -0.1673,  0.1586],\n",
       "                      [ 0.1551, -0.0459,  0.1781,  ..., -0.0856,  0.2187,  0.1114],\n",
       "                      ...,\n",
       "                      [ 0.1493, -0.1631,  0.2649,  ...,  0.0154,  0.1884,  0.0278],\n",
       "                      [-0.0667, -0.1274,  0.2027,  ..., -0.0552,  0.2245,  0.0670],\n",
       "                      [ 0.2369,  0.0077, -0.1001,  ..., -0.0285,  0.0931,  0.1381]])),\n",
       "             ('bilstm_right_context_feature.bias_ih_l0',\n",
       "              tensor([-1.6290e-01, -1.4997e-01, -2.0858e-01, -1.1331e-01, -1.7257e-01,\n",
       "                      -6.9857e-02, -2.0872e-01, -5.1670e-02, -2.2467e-01, -1.6985e-01,\n",
       "                      -1.6766e-01, -4.5197e-02, -1.2333e-01, -8.8579e-02, -2.0693e-01,\n",
       "                      -1.5345e-01, -2.0374e-01, -1.3667e-01, -3.0878e-01, -8.9983e-02,\n",
       "                      -1.3723e-01, -1.8831e-02, -4.7228e-02, -2.3763e-01, -3.0328e-02,\n",
       "                      -3.5527e-02, -1.1865e-01, -1.6460e-01, -2.0144e-01, -1.2031e-01,\n",
       "                      -1.6459e-01, -2.1318e-01, -1.4478e-01, -1.2757e-01, -1.3226e-01,\n",
       "                      -2.9134e-01, -8.5892e-02, -1.5604e-01, -2.6891e-01, -9.8015e-02,\n",
       "                      -2.6670e-01, -1.7359e-01, -1.2899e-01, -2.7590e-01, -1.8585e-01,\n",
       "                      -2.0821e-01, -8.0428e-02, -1.8893e-01, -9.2349e-02, -9.0982e-02,\n",
       "                      -1.3234e-01, -1.4454e-01, -2.0913e-01, -1.6340e-01, -2.0560e-01,\n",
       "                      -1.8793e-01, -1.7289e-01, -1.7667e-01, -8.9409e-02, -3.3734e-02,\n",
       "                      -1.4866e-01, -1.5615e-01, -1.4928e-01, -2.6597e-01, -1.7890e-01,\n",
       "                      -1.7052e-01, -2.0276e-01, -1.5163e-01, -1.7376e-01, -1.4074e-01,\n",
       "                      -6.3589e-02, -2.1638e-01, -8.2884e-02, -2.0083e-01, -5.1199e-02,\n",
       "                      -1.9466e-01, -6.2846e-02, -1.9435e-01, -3.2720e-02, -1.3100e-01,\n",
       "                      -1.5616e-01, -1.0649e-01, -1.8360e-01, -9.2989e-02, -1.6567e-01,\n",
       "                      -9.3009e-02, -1.3030e-01, -1.9599e-01, -9.6097e-02, -1.4946e-01,\n",
       "                      -2.6762e-01, -8.0931e-02,  7.1369e-03,  2.2506e-02, -1.0620e-01,\n",
       "                      -2.6935e-01, -2.6545e-01, -8.6447e-02, -2.3157e-01, -1.8406e-01,\n",
       "                      -1.3517e-01, -1.5874e-01, -2.7856e-01, -2.2452e-01, -2.2504e-01,\n",
       "                      -2.0823e-01, -2.7522e-01, -7.7248e-02, -1.0048e-01, -9.0102e-02,\n",
       "                      -2.7894e-01, -2.0458e-01, -4.5218e-02, -1.7821e-01, -1.0471e-01,\n",
       "                      -2.3939e-01, -8.6906e-03, -2.8128e-02, -1.7314e-01, -2.0075e-01,\n",
       "                      -2.0195e-01, -1.8350e-01, -1.6877e-01, -1.0357e-01, -3.8422e-02,\n",
       "                      -1.6553e-01, -1.8494e-01, -6.5649e-02, -2.2314e-01, -1.1428e-01,\n",
       "                      -1.1782e-01, -1.0871e-01, -2.0025e-01, -6.7988e-02, -1.1497e-01,\n",
       "                      -1.4621e-01, -2.3014e-01, -1.6454e-01,  7.7542e-03, -1.4680e-01,\n",
       "                      -1.1157e-01, -7.5279e-02, -2.4278e-01, -1.1794e-01, -9.5495e-02,\n",
       "                      -1.4570e-01, -5.9046e-02, -1.0707e-01, -1.8808e-01, -1.7783e-01,\n",
       "                      -1.4356e-01, -1.3618e-01, -2.7088e-01, -1.2906e-01, -6.8853e-02,\n",
       "                      -1.1876e-01, -7.7398e-02, -1.8697e-01, -5.0821e-02,  2.2029e-03,\n",
       "                      -1.1171e-01, -1.5104e-01, -1.5971e-01, -1.5325e-01, -1.4243e-01,\n",
       "                      -1.2910e-01, -9.2871e-02, -1.3496e-01, -1.8185e-01, -2.3188e-01,\n",
       "                      -1.4135e-01, -2.4230e-01, -4.4876e-02, -1.5102e-01, -9.5136e-02,\n",
       "                      -3.0864e-02, -1.5604e-01, -1.4035e-01, -1.0899e-01, -2.6312e-01,\n",
       "                      -1.3068e-01, -1.8553e-01, -6.1536e-02, -1.3081e-01, -2.5825e-01,\n",
       "                      -1.3803e-01, -1.6692e-01, -1.3818e-01, -8.4319e-02, -1.5577e-01,\n",
       "                      -1.5222e-01, -1.6450e-01, -1.2216e-01, -8.7321e-02, -3.4636e-02,\n",
       "                      -2.6465e-02, -1.4269e-01, -1.8305e-01, -1.3902e-01,  2.8413e-02,\n",
       "                      -1.2140e-01, -2.5766e-01, -1.8451e-01, -1.7248e-01, -3.1309e-02,\n",
       "                       1.6065e-02, -1.1372e-01, -2.6623e-02, -1.2753e-01, -1.3672e-01,\n",
       "                      -1.5625e-01, -9.7694e-02, -1.2036e-01, -1.8369e-01, -6.9651e-02,\n",
       "                      -1.8663e-01, -2.0369e-01, -1.2272e-01, -2.2281e-01, -2.7220e-01,\n",
       "                      -7.0617e-02, -8.5484e-02, -1.5677e-01, -1.4810e-01, -1.5075e-01,\n",
       "                      -1.1520e-01, -1.1711e-01, -2.9274e-01, -8.9793e-02, -1.6091e-01,\n",
       "                      -1.1834e-01, -7.6026e-02, -5.3424e-03, -1.6899e-01, -2.0736e-01,\n",
       "                      -2.2060e-02, -1.2113e-01, -2.4442e-01, -2.4779e-01, -1.9495e-01,\n",
       "                      -9.1267e-02, -1.9067e-01, -1.0654e-01, -8.5454e-02, -4.0309e-02,\n",
       "                      -1.1926e-01, -1.1349e-01, -7.0715e-02, -2.5824e-01, -3.4092e-02,\n",
       "                      -4.3655e-02, -3.4458e-02, -1.5091e-01, -8.2966e-02, -1.6638e-01,\n",
       "                      -1.0284e-01,  6.9633e-02,  8.3653e-03,  5.5725e-03,  5.9772e-02,\n",
       "                      -1.7480e-02,  1.0967e-03, -3.0210e-02, -1.1620e-02,  9.7529e-03,\n",
       "                      -5.1134e-02, -6.5248e-02,  5.2236e-02,  5.9896e-03,  7.8589e-04,\n",
       "                       7.0503e-02,  4.7302e-02,  5.4339e-02, -3.6336e-02,  5.5580e-02,\n",
       "                       1.8800e-02,  2.8164e-03, -9.1026e-02, -6.6444e-02,  8.0013e-02,\n",
       "                       6.5907e-02, -1.1725e-01,  4.4912e-02, -1.6210e-01,  6.7911e-02,\n",
       "                      -2.4684e-02,  5.0094e-02,  7.5102e-03, -1.6906e-02, -2.3213e-02,\n",
       "                       3.8336e-02,  2.6070e-02, -7.5342e-02, -1.8845e-02, -9.4105e-02,\n",
       "                      -7.7611e-02,  5.6091e-02,  2.8049e-02,  4.7259e-02, -1.1424e-01,\n",
       "                       1.2685e-02, -3.8357e-02, -2.2086e-02, -5.4912e-02, -5.1791e-02,\n",
       "                       7.9441e-02,  2.1362e-02, -1.1675e-02,  1.9106e-02,  6.9158e-04,\n",
       "                       4.7424e-02,  1.2153e-01,  6.4553e-03,  4.7573e-02, -3.5090e-02,\n",
       "                       2.5080e-02,  7.7226e-02,  7.5230e-02, -8.7762e-03, -2.1929e-02,\n",
       "                       1.2422e-02, -7.6188e-02, -1.3142e-01, -1.8054e-02,  1.2266e-01,\n",
       "                      -1.8429e-02,  6.7480e-02, -1.4132e-01,  3.0716e-02,  4.4874e-02,\n",
       "                      -3.7588e-02,  4.5452e-03, -6.2682e-03, -4.3044e-02, -6.6901e-02,\n",
       "                       7.2245e-02,  2.2150e-01, -2.6187e-02, -8.0816e-02, -1.2333e-03,\n",
       "                      -8.0985e-03, -3.5756e-02,  1.7488e-02,  1.0273e-01,  4.8279e-02,\n",
       "                      -7.9236e-02,  2.0502e-02, -4.7316e-02,  3.5228e-02,  3.1595e-03,\n",
       "                       7.4071e-02, -8.9651e-03, -2.3517e-02,  3.3020e-02,  4.8422e-02,\n",
       "                      -2.4118e-02,  1.0484e-01, -5.3753e-02, -1.4002e-02, -8.9151e-02,\n",
       "                       2.2551e-02,  1.2993e-01, -4.9699e-02, -9.0144e-02, -1.5939e-02,\n",
       "                       1.4377e-02, -4.8652e-02,  2.4407e-02, -3.0223e-02, -9.5425e-02,\n",
       "                       3.2413e-02, -2.7803e-02,  1.0623e-01,  7.2793e-02, -6.6770e-03,\n",
       "                       1.7570e-04, -1.4051e-01, -7.2803e-04,  2.9600e-02,  4.5690e-02,\n",
       "                       6.7680e-03,  2.4799e-02,  1.4562e-02,  8.7303e-03, -8.5609e-02,\n",
       "                      -9.7726e-02, -1.6847e-01, -1.0937e-01, -1.4852e-01, -2.3948e-01,\n",
       "                      -9.9344e-02, -7.3263e-02, -1.6278e-01, -1.2465e-01, -1.2386e-01,\n",
       "                      -5.8708e-03, -2.2867e-01, -6.7990e-03, -2.4852e-01, -1.3924e-01,\n",
       "                       1.5369e-02, -2.0890e-01, -1.0095e-01, -5.2432e-02, -2.4904e-01,\n",
       "                      -8.8675e-02, -2.8166e-01, -1.1459e-01, -2.3709e-02, -1.3754e-01,\n",
       "                       8.5450e-02, -1.6698e-01, -8.4508e-02, -2.0948e-01, -8.5388e-02,\n",
       "                      -1.3366e-01, -2.2093e-01, -1.3528e-01, -1.4051e-01, -1.8974e-01,\n",
       "                      -1.0961e-01, -1.8339e-01, -2.6434e-01, -6.3138e-02, -1.2871e-01,\n",
       "                      -2.1061e-01, -1.2172e-01, -5.6671e-02, -1.3057e-01, -1.6111e-01,\n",
       "                      -1.2625e-01, -1.2387e-01, -1.6856e-01, -1.3202e-01, -8.4240e-02,\n",
       "                      -2.5148e-01, -1.1041e-01, -1.6059e-01, -1.3292e-01, -1.5388e-01,\n",
       "                      -2.5557e-01, -6.4991e-02, -1.7726e-01, -2.4994e-01, -1.4438e-01,\n",
       "                      -2.1311e-01, -1.0632e-01, -2.3385e-01, -2.1315e-01, -5.0059e-02,\n",
       "                      -2.3702e-01, -9.5212e-02, -1.2423e-01, -1.5340e-01, -1.3606e-01,\n",
       "                      -1.8853e-01, -8.1942e-02, -2.3950e-01, -8.5808e-02, -2.3962e-01,\n",
       "                      -1.2452e-01, -1.2710e-01, -1.4390e-01, -1.1504e-01, -3.1243e-01,\n",
       "                      -1.5633e-01, -1.1584e-01, -1.2066e-01, -1.1003e-01, -1.6507e-02,\n",
       "                      -1.0306e-01, -1.2529e-01, -1.3308e-01, -2.3600e-01, -2.4649e-01,\n",
       "                      -1.7719e-01, -1.7766e-01, -3.8016e-02, -3.3899e-03, -1.5122e-01,\n",
       "                      -1.0327e-01, -2.4784e-01, -8.3435e-02, -1.9210e-01, -1.1486e-01,\n",
       "                      -1.6903e-01, -1.9245e-01, -2.2767e-01, -1.6275e-01, -1.7452e-01,\n",
       "                      -1.4808e-01, -1.0368e-01, -3.5316e-01, -1.4773e-01, -2.1720e-01,\n",
       "                      -2.0120e-01, -1.9579e-01, -1.3643e-01, -1.8658e-01, -1.4745e-01,\n",
       "                      -1.4295e-01, -3.1785e-02, -7.7463e-02, -1.6201e-01, -1.9623e-02,\n",
       "                      -1.3346e-01, -1.3004e-01, -1.1481e-01, -8.4671e-02, -1.9601e-01,\n",
       "                      -1.1681e-01, -7.4364e-02])),\n",
       "             ('bilstm_right_context_feature.bias_hh_l0',\n",
       "              tensor([-1.1404e-01, -1.0374e-01, -1.4755e-01,  9.2242e-02, -2.1523e-01,\n",
       "                      -2.4105e-01, -8.6847e-02, -8.9707e-02, -1.6209e-01, -1.6713e-01,\n",
       "                      -3.9068e-02, -1.0962e-01, -1.6434e-01, -1.9853e-01, -2.4255e-01,\n",
       "                      -1.7095e-01, -7.5174e-02, -1.7767e-01, -5.6984e-02, -6.0491e-02,\n",
       "                      -1.7554e-01, -8.1045e-02, -5.6192e-02, -9.8282e-02, -1.9145e-01,\n",
       "                      -8.7299e-02,  3.9757e-02, -2.8308e-01, -1.4635e-01, -1.7113e-01,\n",
       "                      -2.5541e-01, -1.4935e-01, -1.7839e-01, -9.2142e-02, -1.8746e-01,\n",
       "                      -2.1296e-01, -1.6316e-01, -1.6408e-01, -1.6068e-01, -8.3258e-02,\n",
       "                      -1.3914e-01, -1.3265e-01, -1.0545e-01, -1.8859e-01, -7.5960e-02,\n",
       "                      -2.1309e-01, -2.4912e-02, -4.2087e-02, -1.5720e-01, -7.0911e-02,\n",
       "                      -1.5464e-01, -2.1271e-01, -6.5356e-02, -7.3634e-02, -1.7592e-01,\n",
       "                      -2.7500e-01, -1.9679e-01, -1.1356e-01, -1.5062e-01, -1.8532e-01,\n",
       "                      -6.8721e-03, -1.5234e-01, -3.0739e-01, -7.6635e-02, -2.4566e-01,\n",
       "                      -1.8136e-01, -1.0416e-01, -2.0396e-01, -1.4858e-01, -9.0631e-02,\n",
       "                      -2.0213e-01, -2.4350e-01, -4.1983e-02, -1.8432e-01, -1.0216e-01,\n",
       "                      -2.0784e-01, -1.1324e-01, -5.1043e-02, -1.1215e-01, -2.1891e-01,\n",
       "                      -1.3075e-01, -8.4406e-02, -1.2055e-01, -2.1628e-01, -2.5395e-01,\n",
       "                      -7.0676e-02, -2.4359e-01, -2.4253e-01, -1.5524e-01, -2.3479e-01,\n",
       "                      -2.4006e-01, -2.5567e-01, -2.3227e-02, -1.0846e-01, -6.5199e-02,\n",
       "                      -1.7284e-01, -2.0340e-01, -1.9665e-01, -1.1421e-01, -2.1482e-01,\n",
       "                      -2.5132e-01, -1.4676e-01, -1.9820e-01, -2.0435e-01, -1.5155e-01,\n",
       "                      -3.1266e-01, -2.3432e-02, -5.3769e-02, -2.2224e-01, -1.0852e-01,\n",
       "                      -2.0647e-01, -1.0812e-01, -1.8530e-01, -8.7934e-02, -2.1056e-01,\n",
       "                      -2.2506e-01, -2.2935e-01, -1.7026e-02, -1.6886e-01, -1.7698e-01,\n",
       "                      -1.7415e-01, -1.4409e-01, -2.8616e-01, -1.3348e-01, -5.8251e-02,\n",
       "                      -2.3148e-01, -1.6051e-01, -7.4545e-02, -5.4648e-02, -1.3582e-01,\n",
       "                      -1.1436e-01,  1.1265e-01, -1.2448e-01, -8.2924e-02, -1.8085e-01,\n",
       "                      -1.0591e-01, -2.1144e-02, -1.4244e-01, -1.2731e-03, -7.3475e-02,\n",
       "                      -8.6438e-02, -5.1229e-02, -8.1674e-02, -1.2317e-01, -1.8824e-01,\n",
       "                      -5.9456e-02, -7.9865e-02, -7.9728e-02, -8.1739e-02, -1.5050e-01,\n",
       "                      -2.5327e-01, -5.9863e-02, -1.9360e-01, -4.8860e-02, -1.0038e-02,\n",
       "                      -1.6636e-01, -2.2772e-01, -4.5769e-02, -5.1029e-02, -1.5719e-01,\n",
       "                      -2.0781e-01, -2.2684e-01, -1.5492e-01, -4.4598e-03, -1.5805e-01,\n",
       "                      -1.3441e-01, -1.0873e-01, -8.6184e-02, -1.0931e-01, -8.3338e-02,\n",
       "                      -1.5437e-01, -1.7123e-01, -2.1356e-01, -1.8271e-01, -1.2859e-01,\n",
       "                      -1.2864e-01, -1.4435e-01, -9.1235e-02, -7.7079e-02, -1.5165e-01,\n",
       "                      -9.6646e-02, -1.6694e-01, -1.4136e-01, -1.1927e-01, -1.2259e-01,\n",
       "                      -1.1774e-01, -1.3060e-01, -2.0752e-01, -1.8845e-01, -2.3741e-01,\n",
       "                      -5.8170e-02, -2.0114e-01, -1.3132e-01, -1.1543e-01, -1.1586e-01,\n",
       "                      -4.5277e-02, -8.8421e-02, -4.2155e-02, -1.2567e-01, -9.2259e-02,\n",
       "                      -1.1870e-01, -2.1220e-01, -1.6308e-01, -1.0575e-01, -8.4896e-02,\n",
       "                      -4.8064e-02, -1.4094e-01, -1.0039e-01, -1.2390e-01, -9.0625e-02,\n",
       "                      -1.4639e-01, -1.8696e-01, -7.3778e-02, -8.3778e-02, -2.2233e-01,\n",
       "                      -9.3728e-02, -1.0393e-01,  2.2771e-02, -1.1849e-01, -4.5768e-02,\n",
       "                      -1.6172e-01, -1.5014e-01, -7.8616e-02, -1.6037e-01, -1.1395e-01,\n",
       "                      -1.7440e-01, -4.4951e-02, -1.1064e-01, -1.5349e-01, -1.4981e-01,\n",
       "                      -1.4910e-01, -8.2258e-02, -8.5110e-02, -1.9444e-01, -1.6762e-01,\n",
       "                      -1.2389e-01, -1.9153e-01, -1.2434e-02, -1.3697e-01, -1.3673e-01,\n",
       "                      -1.4314e-01, -1.2085e-01, -6.7550e-02, -1.6303e-01, -4.7797e-02,\n",
       "                      -1.1451e-02, -6.8796e-02, -1.6397e-01, -8.0429e-02, -9.8919e-02,\n",
       "                      -7.7644e-02, -1.6120e-01, -7.0446e-02, -1.3801e-01, -1.3656e-01,\n",
       "                      -6.1011e-02, -9.8057e-04,  4.6210e-02, -5.0304e-02,  3.0809e-02,\n",
       "                      -1.7335e-01, -1.9544e-02, -5.0135e-02, -1.1406e-01, -2.1072e-03,\n",
       "                       1.1676e-01, -9.0875e-02,  1.1289e-02,  1.6494e-02, -8.6255e-02,\n",
       "                       2.6119e-02, -3.6398e-02,  8.4146e-02,  2.5448e-02, -1.7316e-02,\n",
       "                      -6.2767e-02, -7.2470e-02, -3.0701e-04, -1.4400e-01, -2.5391e-02,\n",
       "                      -2.0345e-02, -6.1981e-02, -1.1082e-01,  1.5338e-02,  4.4492e-02,\n",
       "                       2.7866e-02, -1.0673e-01,  1.6822e-02,  7.8408e-02, -4.1485e-02,\n",
       "                       2.1120e-02,  1.0397e-02,  5.2896e-02,  7.7347e-03,  1.0945e-02,\n",
       "                       4.8464e-02,  1.3857e-01, -5.5611e-02,  3.7586e-02,  1.6743e-01,\n",
       "                       3.2691e-02, -3.8400e-02, -1.3588e-02, -4.9446e-02,  2.9519e-02,\n",
       "                       7.0289e-02, -4.3219e-02,  1.5098e-02, -2.2735e-02, -7.0465e-02,\n",
       "                       1.4478e-02, -3.7615e-02,  9.3696e-02,  1.4804e-02,  1.0817e-02,\n",
       "                       6.9988e-02,  7.0266e-02, -7.7728e-02, -1.2189e-01,  1.2478e-03,\n",
       "                      -6.1314e-02,  2.9474e-02,  5.5950e-02, -4.6373e-02, -3.0621e-02,\n",
       "                      -1.0530e-01,  3.7414e-02,  8.8041e-03,  1.5698e-02, -5.7643e-02,\n",
       "                       8.6540e-02, -8.1138e-02,  3.9133e-02,  2.1144e-02,  3.4281e-02,\n",
       "                       1.6478e-02,  5.8435e-02,  6.5848e-02,  6.4191e-03, -6.5952e-02,\n",
       "                      -9.5414e-02,  4.3784e-02,  1.1262e-01,  3.2083e-02, -2.1074e-02,\n",
       "                      -2.0604e-02,  1.2198e-02, -3.8134e-02, -8.7947e-02,  9.3146e-02,\n",
       "                       9.7736e-02,  2.4670e-02,  5.1551e-02, -4.5440e-02,  2.8390e-02,\n",
       "                       7.4813e-02,  6.8588e-03, -9.9021e-02, -4.5520e-02,  8.9110e-02,\n",
       "                       2.3157e-02,  1.8760e-02,  3.4488e-02,  3.8745e-02,  1.2912e-02,\n",
       "                      -5.6076e-02, -4.2414e-02, -3.8409e-02,  6.2496e-02,  6.1703e-02,\n",
       "                       4.4104e-02, -9.8272e-02,  4.9833e-02,  2.8383e-03,  1.7666e-02,\n",
       "                      -3.2913e-02, -2.1617e-02,  1.4099e-01,  1.2786e-01,  8.5192e-02,\n",
       "                      -8.7955e-02,  1.6067e-02, -5.1737e-02,  1.1831e-01, -1.0196e-01,\n",
       "                      -1.9905e-01, -1.6720e-01, -9.4787e-02, -2.4376e-01, -2.0045e-01,\n",
       "                      -1.3082e-01, -2.0128e-01, -3.2872e-01, -1.6896e-01, -9.9526e-02,\n",
       "                      -9.4212e-03, -5.9557e-02, -1.2948e-01, -1.3380e-01, -2.9909e-02,\n",
       "                      -2.0664e-01, -1.4464e-01, -3.1775e-01, -1.7320e-01, -1.7061e-01,\n",
       "                      -1.5865e-01, -1.7555e-01, -1.3254e-01, -5.9481e-02, -1.0256e-01,\n",
       "                      -1.3072e-01, -1.9756e-01, -1.2741e-01, -1.6725e-01, -1.2464e-01,\n",
       "                      -1.5030e-01, -2.0519e-01, -1.1427e-01, -1.3081e-01, -4.9846e-02,\n",
       "                      -1.2303e-01, -1.5235e-01, -1.1574e-01, -1.6991e-01, -2.2053e-01,\n",
       "                      -1.6812e-01, -1.2158e-01, -1.8455e-01, -2.1231e-01, -1.7548e-01,\n",
       "                      -5.8490e-02, -1.8110e-01,  1.4669e-01, -2.0819e-01, -2.0884e-01,\n",
       "                      -1.7865e-01, -1.1494e-01, -2.5212e-01, -6.7661e-02, -2.8241e-01,\n",
       "                      -2.0774e-01, -7.5014e-02, -1.0083e-01, -1.3327e-01, -4.9845e-02,\n",
       "                      -1.2971e-01, -2.0442e-01, -1.7964e-01, -1.6376e-01, -1.0514e-01,\n",
       "                      -2.4340e-01, -1.0560e-01, -2.4159e-01,  5.8466e-02, -1.5317e-01,\n",
       "                      -2.4443e-01, -5.8863e-02, -1.6494e-01, -2.0247e-01, -1.3996e-01,\n",
       "                      -1.0393e-01, -2.2189e-01, -6.4333e-02, -1.6677e-01, -1.8447e-01,\n",
       "                      -1.3843e-01, -1.5382e-01, -2.1775e-01, -1.8107e-01, -2.9469e-02,\n",
       "                      -1.1584e-01, -2.0942e-01,  5.0404e-02, -1.1961e-01, -2.5569e-01,\n",
       "                      -7.7449e-02, -1.5980e-01, -7.4010e-02, -1.8409e-01, -1.6691e-01,\n",
       "                      -1.7441e-01, -6.1199e-02, -1.8073e-01, -2.4351e-01, -1.8365e-01,\n",
       "                      -2.2920e-01, -1.0422e-01, -2.5685e-01, -1.8378e-01, -1.6264e-01,\n",
       "                      -1.5542e-01, -1.1774e-01, -1.1394e-01, -9.0002e-02, -3.5093e-01,\n",
       "                      -1.1604e-01, -1.8415e-01, -2.1202e-01, -1.8195e-01, -2.8260e-01,\n",
       "                       2.3821e-02, -7.2676e-02, -1.8045e-01, -1.4404e-01, -1.9385e-01,\n",
       "                      -3.5136e-02, -1.5711e-01, -1.7840e-01, -8.9490e-02, -9.5272e-02,\n",
       "                      -4.9101e-02, -9.1374e-02])),\n",
       "             ('bilstm_right_context_feature.weight_ih_l0_reverse',\n",
       "              tensor([[ 0.3582, -0.0116,  0.4594,  ..., -0.3217,  0.1243, -0.3331],\n",
       "                      [-0.2309, -0.1556, -0.1544,  ..., -0.3238,  0.0618, -0.4387],\n",
       "                      [-0.0700, -0.0149,  0.1912,  ...,  0.0462, -0.0360,  0.0411],\n",
       "                      ...,\n",
       "                      [-0.3184,  0.0418,  0.1229,  ...,  0.0210,  0.0873,  0.1864],\n",
       "                      [-0.0168, -0.1388, -0.1066,  ...,  0.2159,  0.1529,  0.1832],\n",
       "                      [-0.1010, -0.3584, -0.1584,  ..., -0.5194, -0.2826, -0.2099]])),\n",
       "             ('bilstm_right_context_feature.weight_hh_l0_reverse',\n",
       "              tensor([[ 0.1938,  0.1012, -0.2205,  ...,  0.2510, -0.0339,  0.0301],\n",
       "                      [-0.4604,  0.1249, -0.1018,  ..., -0.2004,  0.1736, -0.0295],\n",
       "                      [ 0.1953,  0.2692,  0.1169,  ...,  0.1347, -0.0370, -0.0894],\n",
       "                      ...,\n",
       "                      [ 0.2519, -0.0159,  0.0013,  ...,  0.0725,  0.1198, -0.0237],\n",
       "                      [-0.1160,  0.0127,  0.0604,  ..., -0.0938, -0.0372,  0.2043],\n",
       "                      [-0.2043, -0.6085,  0.1555,  ..., -0.3563,  0.0099, -0.1075]])),\n",
       "             ('bilstm_right_context_feature.bias_ih_l0_reverse',\n",
       "              tensor([ 1.3261e-01,  8.1253e-02, -9.7123e-03, -5.8174e-02,  8.0011e-02,\n",
       "                      -1.5165e-01, -1.1746e-01,  8.8350e-02, -1.8751e-02,  1.5400e-01,\n",
       "                      -3.4413e-02,  3.9948e-02,  1.5139e-01,  4.4992e-02,  1.3275e-01,\n",
       "                      -1.4928e-01,  3.9656e-02, -9.9144e-03,  1.3503e-01,  6.4730e-02,\n",
       "                       4.8198e-02,  1.6009e-01, -9.7554e-03, -3.6872e-02,  8.8443e-02,\n",
       "                      -3.8810e-02,  8.5241e-02,  9.1994e-02, -4.9856e-02,  7.9985e-02,\n",
       "                       2.0627e-01,  8.5299e-02,  2.2294e-01, -2.2627e-02, -4.9654e-02,\n",
       "                       1.7483e-01,  6.5364e-02, -7.0092e-02,  1.5376e-01, -7.3747e-02,\n",
       "                      -1.0694e-01,  4.8741e-02,  9.0406e-02, -3.0814e-02,  8.6731e-02,\n",
       "                       1.0763e-02,  7.5283e-02, -7.5944e-02, -2.3357e-01, -5.2025e-03,\n",
       "                      -5.7110e-02, -2.0261e-02,  3.5876e-02,  5.7113e-02,  1.6551e-01,\n",
       "                       1.4789e-01, -9.1592e-02, -1.6361e-02,  1.4858e-02, -1.5553e-02,\n",
       "                      -3.0985e-03,  3.6040e-03,  1.2186e-01,  2.1769e-02,  1.4948e-01,\n",
       "                       5.7020e-02,  3.7219e-03, -2.5211e-02,  3.5067e-02, -1.1809e-02,\n",
       "                       4.5025e-02,  1.3501e-01, -2.8862e-02,  2.6670e-02,  1.2924e-01,\n",
       "                       4.1252e-03,  8.7022e-02,  3.4371e-02, -1.4371e-02,  1.0936e-02,\n",
       "                      -8.4154e-02,  3.4736e-01,  1.1159e-01, -3.4253e-02, -4.2624e-02,\n",
       "                       9.2420e-02,  8.8509e-02, -6.4184e-03,  1.8044e-01,  1.2520e-03,\n",
       "                      -4.5162e-02, -2.1234e-02,  7.2919e-02,  1.2214e-01,  4.5474e-02,\n",
       "                       1.2377e-01,  1.4511e-01,  1.3182e-01,  1.3741e-01,  1.4974e-01,\n",
       "                       1.3209e-01,  2.1758e-01,  6.1485e-02,  1.3087e-01,  1.0874e-01,\n",
       "                       3.3752e-03, -2.5652e-03,  1.4078e-01,  1.4615e-01, -4.5551e-02,\n",
       "                       5.3409e-02,  1.2654e-01,  9.3560e-02,  1.6100e-01,  1.7887e-01,\n",
       "                       7.3497e-03,  1.3483e-01, -2.8078e-02,  8.2523e-02, -2.6800e-02,\n",
       "                      -7.3699e-02,  6.9381e-03,  6.0824e-02,  1.4014e-01,  1.2148e-01,\n",
       "                       3.4994e-02, -3.9457e-02,  1.6447e-01, -1.0587e-01,  3.3239e-03,\n",
       "                       8.2891e-02, -9.5120e-02, -7.0539e-02, -7.5422e-02,  8.5996e-02,\n",
       "                      -1.8344e-01, -4.5617e-02, -4.8392e-02, -2.1954e-02, -3.8914e-02,\n",
       "                      -1.2983e-01, -3.7842e-02, -1.3005e-01, -9.5708e-02, -8.2102e-02,\n",
       "                      -1.2001e-01, -2.0587e-02, -1.4404e-01, -4.9295e-02, -2.2643e-01,\n",
       "                      -1.8858e-01, -1.4026e-02, -4.1277e-02, -6.2403e-02, -7.6548e-02,\n",
       "                      -5.9063e-02, -5.9687e-02, -1.9982e-01,  1.9185e-02, -1.5859e-01,\n",
       "                      -6.5263e-03,  4.0488e-02, -1.5496e-01, -5.5200e-02, -5.1485e-02,\n",
       "                      -1.7019e-01,  1.4652e-02, -1.7085e-01, -5.8124e-02, -4.4282e-02,\n",
       "                      -1.7967e-02, -9.2468e-02,  6.8244e-02, -1.2284e-02, -6.6006e-02,\n",
       "                      -1.7139e-02, -8.3431e-02,  3.5219e-03, -4.6200e-02, -9.0850e-02,\n",
       "                      -1.9755e-01,  7.5358e-02, -3.7480e-02, -1.8457e-02, -9.3767e-02,\n",
       "                      -2.2942e-02,  9.9210e-02, -1.4493e-02,  3.3432e-02, -3.4563e-02,\n",
       "                      -1.2575e-01, -9.4601e-02, -1.2647e-01, -6.8200e-02, -5.0394e-02,\n",
       "                      -8.5113e-02,  4.4125e-02,  9.2878e-03,  7.5062e-02,  2.3558e-02,\n",
       "                       4.8475e-02, -5.6600e-02, -2.8119e-02, -5.5173e-02, -5.2160e-02,\n",
       "                      -1.2275e-02,  8.6811e-02,  5.5804e-02, -1.5697e-01,  1.1474e-02,\n",
       "                      -1.8563e-02,  4.1931e-02, -6.0596e-02,  1.0393e-02, -2.9129e-02,\n",
       "                      -6.4102e-02, -6.6729e-02,  6.9553e-02,  3.7389e-02, -7.4834e-02,\n",
       "                      -6.1898e-02, -8.0019e-02, -1.5893e-02, -8.1370e-02, -2.5602e-02,\n",
       "                      -1.6545e-01, -2.5316e-02,  2.9315e-02, -1.1514e-01, -1.5412e-01,\n",
       "                      -1.4142e-03, -3.1702e-02, -1.0642e-01, -3.9124e-02,  9.0831e-02,\n",
       "                       1.3264e-02, -2.1115e-01,  4.5730e-02, -4.2698e-02, -6.3672e-02,\n",
       "                      -5.9690e-02,  6.2336e-02, -4.8928e-02, -1.1500e-01,  8.4209e-02,\n",
       "                      -5.3806e-02, -1.4186e-01, -2.4692e-01,  1.3864e-02, -2.6902e-01,\n",
       "                      -2.1911e-02, -6.9348e-02, -2.9081e-02, -5.5428e-02, -4.5201e-02,\n",
       "                       4.3201e-02, -1.4856e-01, -8.7301e-02,  1.0526e-01, -1.6176e-01,\n",
       "                      -1.1373e-01,  3.5098e-02, -6.0301e-02,  9.3161e-02,  6.3037e-03,\n",
       "                      -3.3444e-02, -4.1070e-02,  3.6581e-02,  6.7613e-02, -9.6522e-02,\n",
       "                      -2.0882e-02,  1.7431e-02, -9.9852e-02, -4.9587e-02,  1.0632e-01,\n",
       "                       5.2637e-02, -1.0221e-01, -4.3129e-02, -4.0672e-02, -1.2388e-01,\n",
       "                      -3.1334e-02, -7.6632e-03, -6.7331e-03,  7.7118e-02,  1.6308e-01,\n",
       "                      -7.3873e-02, -1.4813e-02,  1.6842e-01, -9.5490e-02, -9.3589e-02,\n",
       "                      -4.4574e-02, -5.5095e-03, -3.3949e-02,  7.1078e-02,  2.3471e-02,\n",
       "                      -5.5831e-02,  3.9104e-02,  9.3694e-03, -7.1103e-02, -5.1050e-02,\n",
       "                       9.0128e-03, -8.6063e-02,  2.2487e-03,  6.0783e-02,  2.6467e-02,\n",
       "                      -7.7125e-02,  6.1275e-02, -4.8939e-02, -9.4749e-02,  4.3648e-02,\n",
       "                       1.2275e-01,  2.5957e-02,  7.5705e-02,  6.1566e-02, -2.6372e-02,\n",
       "                      -8.9111e-02,  3.3020e-02, -3.3515e-02, -4.9779e-02, -4.1066e-02,\n",
       "                       9.0826e-02,  5.8613e-02,  2.8916e-02, -1.1175e-01, -5.4135e-03,\n",
       "                       1.6997e-01, -7.0251e-02,  9.8201e-02, -5.5235e-02,  7.6402e-02,\n",
       "                      -9.0691e-02, -2.1515e-02,  6.2210e-02,  8.8300e-02,  1.1120e-01,\n",
       "                       8.1480e-02, -7.9690e-02, -8.0576e-02, -3.0088e-04,  1.4722e-01,\n",
       "                       2.3731e-02,  5.0683e-02,  4.8818e-02, -4.6404e-03, -1.1565e-02,\n",
       "                       2.5660e-03,  1.4594e-02, -9.4332e-02,  4.3097e-03,  1.8471e-01,\n",
       "                       1.4002e-02,  9.9056e-03, -8.8980e-02, -5.4467e-02,  2.2287e-02,\n",
       "                       1.4177e-01,  3.8464e-02, -2.0210e-02,  2.7207e-02, -3.2653e-02,\n",
       "                      -4.1806e-02, -6.3437e-03,  1.1311e-01, -5.5406e-02, -5.6676e-02,\n",
       "                      -1.0607e-01,  8.8529e-02, -5.6837e-02, -3.2778e-02, -6.8892e-03,\n",
       "                      -7.3627e-02, -5.8193e-02, -1.2835e-01, -7.6697e-02,  9.6519e-03,\n",
       "                      -1.8064e-02,  1.3494e-03,  5.2487e-02, -3.3292e-02, -6.9508e-04,\n",
       "                      -1.1379e-01,  7.6722e-02,  3.8132e-02, -4.2973e-02,  6.4042e-02,\n",
       "                       2.6894e-01,  6.8982e-02,  9.8273e-02,  2.2328e-01, -1.8814e-01,\n",
       "                      -2.5484e-02,  1.9607e-02, -1.9726e-03,  2.5849e-01, -5.6484e-02,\n",
       "                      -3.1370e-02,  2.1852e-01,  6.8630e-02,  2.9104e-02,  7.0785e-02,\n",
       "                       1.5167e-01,  1.8030e-01, -8.7525e-02,  4.6509e-02,  2.1409e-01,\n",
       "                       1.2870e-01,  5.9377e-03,  2.7447e-02,  1.0693e-02, -6.9209e-02,\n",
       "                       4.2222e-02,  2.5560e-01,  1.6701e-02,  5.1729e-02,  1.8215e-01,\n",
       "                       1.4002e-01, -8.8360e-03,  2.8719e-02, -1.6371e-01, -2.1103e-02,\n",
       "                       5.2482e-02, -2.1873e-03,  1.2116e-01, -9.2827e-03, -2.1116e-01,\n",
       "                      -6.9868e-02,  1.7139e-03,  1.1623e-01,  2.0459e-02,  7.9550e-03,\n",
       "                       2.4540e-02,  2.9168e-02,  8.7707e-02, -1.0565e-01,  1.5864e-02,\n",
       "                       6.6290e-02,  1.8360e-01, -4.6304e-04,  1.4761e-01, -1.4151e-02,\n",
       "                       5.2145e-02,  1.6812e-02, -1.5478e-01,  9.1468e-02,  1.6080e-01,\n",
       "                       8.3207e-02,  1.7651e-03,  5.6373e-02,  2.6798e-01,  1.0397e-01,\n",
       "                       2.9905e-02, -1.1062e-01,  1.8305e-01,  3.1528e-02, -2.7121e-02,\n",
       "                      -2.6057e-02, -6.3456e-02, -1.5963e-03, -7.9221e-02, -1.8037e-02,\n",
       "                       4.2767e-02,  7.3818e-03,  1.3005e-01,  1.5710e-01,  7.1643e-02,\n",
       "                       1.8341e-01,  8.2580e-02,  1.5579e-02, -7.2399e-02,  6.4382e-02,\n",
       "                       1.9519e-02,  1.4594e-01,  1.5832e-01, -1.1400e-02, -6.4806e-02,\n",
       "                       1.2064e-01,  1.9875e-01, -6.4815e-03,  5.6657e-02,  3.2347e-02,\n",
       "                       1.0217e-01,  4.7448e-02,  4.7495e-02,  8.7782e-02,  3.1624e-02,\n",
       "                       1.7371e-01,  1.0592e-02,  6.9373e-02, -1.7232e-02, -7.9320e-02,\n",
       "                       8.1739e-03,  5.1406e-03,  2.5093e-01,  8.4533e-02,  1.3001e-01,\n",
       "                       2.7676e-01,  1.6403e-01,  2.8477e-02,  8.6499e-02,  9.7762e-02,\n",
       "                       1.0141e-01,  1.5988e-01,  5.2397e-02,  1.6187e-02,  3.8835e-02,\n",
       "                       1.5164e-01,  2.1132e-01,  2.9904e-02,  8.5233e-02,  9.3209e-02,\n",
       "                       1.2063e-01,  1.8977e-01])),\n",
       "             ('bilstm_right_context_feature.bias_hh_l0_reverse',\n",
       "              tensor([ 0.0735,  0.2193,  0.0570,  0.0101,  0.1496, -0.1977,  0.0395,  0.0066,\n",
       "                      -0.1247,  0.1958,  0.0210,  0.0376,  0.1796,  0.0948,  0.0906, -0.0742,\n",
       "                       0.0982,  0.0534, -0.0497,  0.0897,  0.1725,  0.1166,  0.0068, -0.0944,\n",
       "                       0.1087, -0.1027,  0.1117,  0.2529,  0.1250,  0.0559,  0.2190,  0.0710,\n",
       "                       0.1132,  0.0651, -0.0831,  0.0865,  0.0958,  0.0247, -0.0820, -0.0581,\n",
       "                      -0.0222,  0.1528, -0.0353, -0.0257,  0.0238,  0.0261,  0.1689, -0.0378,\n",
       "                      -0.0607,  0.0848, -0.0986,  0.0728, -0.0171,  0.0134,  0.2152,  0.1697,\n",
       "                       0.0075,  0.0257,  0.0660,  0.0129,  0.1665,  0.0005,  0.1531, -0.0107,\n",
       "                       0.1005,  0.0589,  0.0892, -0.0441,  0.0842, -0.1577,  0.0856,  0.1679,\n",
       "                      -0.1686,  0.0491,  0.1413, -0.0082,  0.0411, -0.0679,  0.0085, -0.0383,\n",
       "                       0.0232,  0.1946,  0.0422, -0.1044,  0.0437,  0.0864,  0.0385,  0.0054,\n",
       "                       0.0644,  0.0083, -0.0322,  0.1035,  0.1516,  0.1078, -0.0964,  0.1108,\n",
       "                       0.1403,  0.0429,  0.0783,  0.0770,  0.1974,  0.1997,  0.0641,  0.1670,\n",
       "                       0.0542, -0.0740,  0.0691, -0.0345,  0.1043,  0.0175,  0.0078,  0.1823,\n",
       "                       0.2256,  0.1146,  0.1273, -0.0932,  0.1379, -0.0319,  0.2339,  0.0620,\n",
       "                      -0.0094,  0.1493,  0.1580,  0.1356,  0.0641, -0.0769, -0.0573,  0.0551,\n",
       "                      -0.1271, -0.0207, -0.0118, -0.0814,  0.0412, -0.0863, -0.0217, -0.0311,\n",
       "                       0.0480,  0.0843, -0.1135, -0.1888, -0.0272,  0.1216,  0.0668, -0.1151,\n",
       "                      -0.0322, -0.1862, -0.0515,  0.0047,  0.0307, -0.1346, -0.2447,  0.0194,\n",
       "                       0.0009, -0.1399, -0.1753, -0.0428,  0.0466, -0.0697, -0.0610, -0.1317,\n",
       "                      -0.1924, -0.0349, -0.0350, -0.0492, -0.0662, -0.1755,  0.0040, -0.0655,\n",
       "                      -0.1226,  0.0577,  0.0146, -0.0861, -0.0206,  0.0604, -0.0230, -0.0741,\n",
       "                      -0.0295,  0.0782, -0.0352, -0.0057, -0.0472, -0.0806,  0.0175,  0.0770,\n",
       "                      -0.1328, -0.0286,  0.0886,  0.0373,  0.0829, -0.1271, -0.1709, -0.2154,\n",
       "                      -0.1292, -0.1414, -0.1446, -0.0547,  0.0105,  0.0005,  0.0391,  0.0025,\n",
       "                      -0.0124, -0.0074, -0.0809, -0.0943, -0.0372, -0.1722, -0.0525, -0.1036,\n",
       "                      -0.0273,  0.0511, -0.0834,  0.0004, -0.0460,  0.0292,  0.0922, -0.1156,\n",
       "                      -0.1242, -0.0432,  0.0327,  0.0018,  0.0029, -0.1813, -0.0386, -0.0172,\n",
       "                      -0.0089, -0.1361, -0.0770,  0.0535, -0.2501, -0.1360, -0.0387,  0.1180,\n",
       "                      -0.0937, -0.0202, -0.0202,  0.0108, -0.0311,  0.0268, -0.0399, -0.0553,\n",
       "                       0.0345,  0.0150, -0.0772, -0.0130, -0.1470, -0.1242, -0.2153, -0.1296,\n",
       "                      -0.0154, -0.2408, -0.0660, -0.0694, -0.0750, -0.0894,  0.0227, -0.1201,\n",
       "                      -0.0288, -0.0263,  0.0301, -0.0507, -0.0454, -0.0342, -0.0083, -0.1099,\n",
       "                       0.0757,  0.0755, -0.1090,  0.0208, -0.0502,  0.0647,  0.0570, -0.0720,\n",
       "                       0.0387, -0.1169, -0.0781, -0.0649, -0.0941,  0.0927, -0.1364, -0.0113,\n",
       "                      -0.2684,  0.0614,  0.0946,  0.0739, -0.0727, -0.0446, -0.0338,  0.0780,\n",
       "                      -0.0230, -0.0547, -0.0259, -0.0260,  0.0198,  0.0070,  0.1217, -0.0655,\n",
       "                       0.0067,  0.1613,  0.0317, -0.0190, -0.0695,  0.1521, -0.0768, -0.0073,\n",
       "                      -0.0194, -0.0573,  0.0190, -0.0076,  0.0474,  0.0217,  0.1166,  0.0156,\n",
       "                       0.0321,  0.0947, -0.0128,  0.0674,  0.1017, -0.0608, -0.0422, -0.0367,\n",
       "                      -0.0057,  0.0200, -0.1757,  0.0682, -0.0314,  0.0315, -0.1111, -0.0727,\n",
       "                       0.0233, -0.1035, -0.1687, -0.1081,  0.0413, -0.0059,  0.0144,  0.0077,\n",
       "                      -0.0065,  0.0310,  0.0568,  0.0380, -0.0404,  0.0181,  0.0073,  0.0933,\n",
       "                      -0.0964, -0.0264,  0.0765,  0.0775, -0.1354,  0.0531, -0.0044, -0.0835,\n",
       "                      -0.0078, -0.1231,  0.0080,  0.0084,  0.0400, -0.0373, -0.0515, -0.0294,\n",
       "                      -0.0055, -0.0399, -0.0552, -0.0255, -0.0308, -0.1052, -0.0069, -0.0243,\n",
       "                      -0.0463,  0.0244, -0.0401, -0.1203,  0.0394,  0.0635, -0.0571, -0.0048,\n",
       "                       0.0328,  0.0240, -0.0428,  0.0261,  0.0848,  0.0351, -0.0273, -0.0060,\n",
       "                       0.1027,  0.1167,  0.1010,  0.0947,  0.2104, -0.1468,  0.0997,  0.1560,\n",
       "                      -0.0142,  0.1760, -0.0799, -0.0429,  0.2372,  0.0285,  0.1551, -0.0389,\n",
       "                       0.1067,  0.0906,  0.0422,  0.0057,  0.0530,  0.0862,  0.0718,  0.1389,\n",
       "                       0.1757, -0.0697,  0.1043,  0.0108,  0.0487, -0.0014,  0.2841,  0.1456,\n",
       "                       0.2679,  0.0975, -0.0485,  0.2440,  0.0633,  0.0050,  0.0863, -0.0808,\n",
       "                      -0.0306,  0.0987,  0.0583,  0.0617, -0.0407,  0.1546,  0.0761,  0.0916,\n",
       "                      -0.0450, -0.1215, -0.0265, -0.0676,  0.0440,  0.0866,  0.2227,  0.1798,\n",
       "                      -0.0141, -0.0573, -0.0921, -0.0513,  0.0713,  0.0230,  0.0359,  0.1027,\n",
       "                       0.2530,  0.0921,  0.0440,  0.0009,  0.0550, -0.0837,  0.1820,  0.0331,\n",
       "                      -0.0725,  0.1255, -0.0349, -0.0055, -0.0075,  0.0152,  0.0762,  0.0526,\n",
       "                      -0.0787,  0.1627,  0.0442,  0.1814,  0.0029,  0.0980,  0.1262,  0.1550,\n",
       "                       0.1486,  0.1463, -0.0232,  0.1766,  0.1735,  0.0954, -0.0857,  0.0183,\n",
       "                       0.1054, -0.0103,  0.0895,  0.0708,  0.2201,  0.2422, -0.0330,  0.1262,\n",
       "                       0.1504,  0.0452,  0.0152,  0.0777,  0.2262,  0.1320,  0.1279,  0.2803,\n",
       "                       0.0459,  0.0739,  0.1393,  0.1889,  0.1867,  0.0172,  0.1884,  0.0541,\n",
       "                      -0.0284,  0.1126,  0.0269,  0.2065,  0.0332, -0.0082,  0.1158,  0.1309])),\n",
       "             ('fc.0.weight',\n",
       "              tensor([[-0.0148,  0.0252,  0.0017,  ..., -0.3836, -0.4651, -0.2937],\n",
       "                      [ 0.0671, -0.0621, -0.0101,  ..., -0.1084,  0.1617, -0.2011],\n",
       "                      [ 0.1539,  0.1292,  0.1251,  ..., -0.0016,  0.1531,  0.2930],\n",
       "                      ...,\n",
       "                      [-0.1375, -0.0195,  0.0088,  ..., -0.1831,  0.3050,  0.2325],\n",
       "                      [-0.0934, -0.0709,  0.1143,  ..., -0.1103, -0.1625,  0.4597],\n",
       "                      [-0.0037,  0.2042,  0.0271,  ...,  0.0496,  0.2287, -0.0864]])),\n",
       "             ('fc.0.bias',\n",
       "              tensor([-0.1717, -0.0671,  0.1200, -0.1040, -0.1056, -0.1203, -0.0413, -0.0469,\n",
       "                      -0.0758, -0.1107, -0.1342, -0.2049,  0.0982, -0.0615,  0.1758, -0.1144,\n",
       "                      -0.3441,  0.0578, -0.1209, -0.1914, -0.0042,  0.1727,  0.0435, -0.2975,\n",
       "                       0.1488, -0.0954, -0.1257, -0.0376, -0.1150,  0.3635, -0.2222,  0.1940,\n",
       "                       0.2026, -0.0511, -0.1459,  0.1191, -0.2761,  0.0304,  0.1129,  0.1624,\n",
       "                      -0.1523, -0.2851,  0.0694,  0.2816,  0.0668,  0.1218,  0.0320,  0.0886,\n",
       "                       0.4322, -0.1173,  0.2086,  0.1584, -0.1189, -0.0674, -0.1661, -0.2613,\n",
       "                       0.0878, -0.0405,  0.0638, -0.1027,  0.0428, -0.0113,  0.1281,  0.0240])),\n",
       "             ('oov_embedding.weight',\n",
       "              tensor([[ 0.2309, -0.1914,  0.1835,  ...,  0.1011, -0.3153,  0.1360],\n",
       "                      [ 0.1218, -0.1347,  0.0739,  ..., -0.3194,  0.1270,  0.1796],\n",
       "                      [-0.2580, -0.1619,  0.0894,  ..., -0.3146,  0.0502,  0.2000],\n",
       "                      ...,\n",
       "                      [ 0.1697, -0.2369,  0.0346,  ...,  0.2043, -0.0747, -0.2717],\n",
       "                      [ 0.1637, -0.3189, -0.2519,  ...,  0.1476, -0.1026,  0.1176],\n",
       "                      [-0.1880,  0.0538, -0.3379,  ..., -0.0547,  0.1690,  0.0301]])),\n",
       "             ('oov_embedding.bias',\n",
       "              tensor([-0.1704,  0.0887,  0.0145, -0.0188, -0.3296, -0.0165,  0.1034, -0.0197,\n",
       "                       0.1306,  0.0851, -0.0820,  0.0917,  0.1284,  0.0448, -0.1759,  0.0541,\n",
       "                       0.0585, -0.2391, -0.0567, -0.2332, -0.1733,  0.2092,  0.2783,  0.0279,\n",
       "                      -0.2693,  0.0441, -0.1623, -0.2896, -0.1656, -0.0183, -0.0018, -0.1115,\n",
       "                       0.1344, -0.1509, -0.0790,  0.2544,  0.0188,  0.2612, -0.1497, -0.2896,\n",
       "                       0.0235, -0.1869,  0.2294, -0.0037, -0.1684,  0.0348,  0.3360,  0.2034,\n",
       "                      -0.3968,  0.2556,  0.1619,  0.1498, -0.0234,  0.1321,  0.0401,  0.0235,\n",
       "                       0.2368, -0.0413, -0.0203, -0.1673, -0.2078, -0.2513,  0.0954, -0.0458])),\n",
       "             ('prob.0.weight',\n",
       "              tensor([[-0.1736,  0.2615,  0.0667,  ...,  0.1866, -0.0171,  0.0676],\n",
       "                      [ 0.0079, -0.0428, -0.0072,  ..., -0.1291, -0.0317, -0.0869],\n",
       "                      [ 0.3453, -0.2655,  0.2960,  ..., -0.0268,  0.3883,  0.4341],\n",
       "                      ...,\n",
       "                      [-0.2062, -0.0346, -0.0152,  ..., -0.2326, -0.0668,  0.2319],\n",
       "                      [-0.2917, -0.2983, -0.0911,  ..., -0.1154, -0.0859, -0.0479],\n",
       "                      [ 0.2638, -0.2360, -0.0921,  ..., -0.1091, -0.0303,  0.0559]])),\n",
       "             ('prob.0.bias',\n",
       "              tensor([-0.6944, -0.1179, -0.1011,  ..., -0.0496, -0.4399, -0.1229]))])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1616de6-2ec1-4a77-980a-addd6d77d6d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
