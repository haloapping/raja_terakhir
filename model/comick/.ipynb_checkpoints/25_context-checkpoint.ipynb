{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13fc63c4-da08-43a8-9972-2615d377d1fa",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "313363b9-24d1-4b87-87cd-a0b7dd5fc128",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pytz\n",
    "import torch\n",
    "import timeit\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from itertools import chain\n",
    "from time import time\n",
    "from torch import nn, optim\n",
    "from torchmetrics import F1Score\n",
    "from torch.optim import lr_scheduler\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from polyglot.mapping import Embedding, CaseExpander, DigitExpander"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b49405-006a-4a45-ae79-0e22f6a7172e",
   "metadata": {},
   "source": [
    "# Hyperparameters Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68709d29-24a1-45bf-b549-804952fd1db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hyperparams:\n",
    "     def __init__(\n",
    "        self,\n",
    "        context_size=25,\n",
    "        input_size_left_context=64,\n",
    "        input_size_oov_context=20,\n",
    "        input_size_right_context=64,\n",
    "        batch_size=32,\n",
    "        num_hidden_layer=1,\n",
    "        hidden_size=128,\n",
    "        output_size=3611,\n",
    "        shuffle=True,\n",
    "        lr=0.001,\n",
    "        batch_first=True,\n",
    "        bidirectional=True,\n",
    "        init_wb_with_kaiming_normal=True,\n",
    "        n_epoch=20,\n",
    "        patience=20,\n",
    "        device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    ):\n",
    "        self.context_size = context_size\n",
    "        self.input_size_left_context = input_size_left_context\n",
    "        self.input_size_oov_context = input_size_oov_context\n",
    "        self.input_size_right_context = input_size_right_context\n",
    "        self.batch_size = batch_size\n",
    "        self.num_hidden_layer = num_hidden_layer\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.shuffle = shuffle\n",
    "        self.lr = lr\n",
    "        self.batch_first = batch_first\n",
    "        self.bidirectional = bidirectional\n",
    "        self.init_wb_with_kaiming_normal = init_wb_with_kaiming_normal\n",
    "        self.n_epoch = n_epoch\n",
    "        self.patience = patience\n",
    "        self.device = device\n",
    "        \n",
    "hyperparams = Hyperparams()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f750b1-d4a7-4a2a-9fe1-369a61f28a2b",
   "metadata": {},
   "source": [
    "# Prepare Feature Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f241f20b-fb34-4db2-b887-1687f137b141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left context shape: (16562, 25)\n",
      "OOV context shape: (16562, 28)\n",
      "Right context shape: (16562, 25)\n",
      "Actual lable shape: (16562,)\n"
     ]
    }
   ],
   "source": [
    "def convert_doc_to_idxs(docs, dict_vocabs):\n",
    "    doc_to_idx = []\n",
    "    \n",
    "    for doc in docs:\n",
    "        doc_to_idx.append([dict_vocabs[token] for token in doc])\n",
    "        \n",
    "    return np.array(doc_to_idx)\n",
    "\n",
    "# Left context\n",
    "left_context = open(f\"../../datasets/features/{hyperparams.context_size}_context/left_context_with_pad.pkl\", \"rb\")\n",
    "left_context = pickle.load(left_context)\n",
    "left_context_to_idx = open(f\"../../datasets/features/{hyperparams.context_size}_context/token2idx_left_context.pkl\", \"rb\")\n",
    "left_context_to_idx = pickle.load(left_context_to_idx)\n",
    "doc_left_context_to_idx = convert_doc_to_idxs(left_context, left_context_to_idx)\n",
    "\n",
    "# OOV context\n",
    "oov_context = open(f\"../../datasets/features/{hyperparams.context_size}_context/oov_context_with_pad.pkl\", \"rb\")\n",
    "oov_context = pickle.load(oov_context)\n",
    "oov_context_to_idx = open(f\"../../datasets/features/{hyperparams.context_size}_context/token2idx_oov_context.pkl\", \"rb\")\n",
    "oov_context_to_idx = pickle.load(oov_context_to_idx)\n",
    "doc_oov_context_to_idx = convert_doc_to_idxs(oov_context, oov_context_to_idx)\n",
    "\n",
    "# Right context\n",
    "right_context = open(f\"../../datasets/features/{hyperparams.context_size}_context/right_context_with_pad.pkl\", \"rb\")\n",
    "right_context = pickle.load(right_context)\n",
    "right_context_to_idx = open(f\"../../datasets/features/{hyperparams.context_size}_context/token2idx_right_context.pkl\", \"rb\")\n",
    "right_context_to_idx = pickle.load(right_context_to_idx)\n",
    "doc_right_context_to_idx = convert_doc_to_idxs(right_context, right_context_to_idx)\n",
    "\n",
    "# Actual labels\n",
    "labels_context = open(f\"../../datasets/features/{hyperparams.context_size}_context/lables.pkl\", \"rb\")\n",
    "labels_context = pickle.load(labels_context)\n",
    "labels_to_idx = open(f\"../../datasets/features/{hyperparams.context_size}_context/lable_vocabs.pkl\", \"rb\")\n",
    "labels_to_idx = pickle.load(labels_to_idx)\n",
    "doc_labels_to_idx = convert_doc_to_idxs(labels_context, labels_to_idx).flatten()\n",
    "\n",
    "print(f\"Left context shape: {doc_left_context_to_idx.shape}\")\n",
    "print(f\"OOV context shape: {doc_oov_context_to_idx.shape}\")\n",
    "print(f\"Right context shape: {doc_right_context_to_idx.shape}\")\n",
    "print(f\"Actual lable shape: {doc_labels_to_idx.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe386c1f-3e1d-4589-b18e-42e4bc4055ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to Tensor\n",
    "left_contexts = torch.LongTensor(doc_left_context_to_idx)\n",
    "oov_contexts = torch.LongTensor(doc_oov_context_to_idx)\n",
    "right_contexts = torch.LongTensor(doc_right_context_to_idx)\n",
    "actual_labels = torch.LongTensor(doc_labels_to_idx)\n",
    "dataset = TensorDataset(left_contexts, oov_contexts, right_contexts, actual_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8806cc8-c1d1-450a-833d-f25375c52949",
   "metadata": {},
   "source": [
    "# Char and Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86595b81-a95e-4469-acad-49b9ed2c9662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word Embedding\n",
    "word_embeddings = Embedding.load(\"../../word_embeddings/polyglot/idn_embeddings.tar.bz2\")\n",
    "word_embeddings.apply_expansion(DigitExpander)\n",
    "word_embeddings.apply_expansion(CaseExpander)\n",
    "\n",
    "left_vocabs = open(f\"../../datasets/features/{hyperparams.context_size}_context/left_context_vocabs.pkl\", \"rb\")\n",
    "left_vocabs = pickle.load(left_vocabs)\n",
    "\n",
    "right_vocabs = open(f\"../../datasets/features/{hyperparams.context_size}_context/right_context_vocabs.pkl\", \"rb\")\n",
    "right_vocabs = pickle.load(right_vocabs)\n",
    "\n",
    "left_word_embedding_dict = {left_context_to_idx[vocab] : word_embeddings[vocab] for vocab in left_vocabs}\n",
    "right_word_embedding_dict = {right_context_to_idx[vocab] : word_embeddings[vocab] for vocab in right_vocabs}\n",
    "\n",
    "# Char Embedding\n",
    "char_embedding_dict = open(\"../../word_embeddings/chars_embedding/char_embeddings.pkl\", \"rb\")\n",
    "char_embedding_dict = pickle.load(char_embedding_dict)\n",
    "\n",
    "# Context embedding\n",
    "left_context_embedding = nn.Embedding.from_pretrained(torch.FloatTensor(np.array(list(left_word_embedding_dict.values()))), padding_idx=left_vocabs.index(\"<PAD>\"), freeze=True)\n",
    "oov_context_embedding = nn.Embedding.from_pretrained(torch.FloatTensor(np.array(list(char_embedding_dict.values()))), padding_idx=list(char_embedding_dict.keys()).index(\"PAD\"), freeze=True)\n",
    "right_context_embedding = nn.Embedding.from_pretrained(torch.FloatTensor(np.array(list(right_word_embedding_dict.values()))), padding_idx=right_vocabs.index(\"<PAD>\"), freeze=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593ddcfe-1525-41ae-bf02-c9ebf3d957aa",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "998fb38d-da64-4b4c-9371-75e06ebfc8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=hyperparams.batch_size, shuffle=hyperparams.shuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5be550-2f41-41b4-9df4-ac67744041c5",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed852446-c649-4727-b9ff-64375cf7e966",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Comick(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size_left_context=hyperparams.input_size_left_context,\n",
    "        input_size_oov_context=hyperparams.input_size_oov_context,\n",
    "        input_size_right_context=hyperparams.input_size_right_context,\n",
    "        hidden_size=hyperparams.hidden_size,\n",
    "        num_layers=hyperparams.num_hidden_layer,\n",
    "        output_size=hyperparams.output_size,\n",
    "        batch_first=hyperparams.batch_first,\n",
    "        bidirectional=hyperparams.bidirectional,\n",
    "        init_wb_with_kaiming_normal=hyperparams.init_wb_with_kaiming_normal\n",
    "    ):\n",
    "        super(Comick, self).__init__()\n",
    "        \n",
    "        self.input_size_left_context = input_size_left_context\n",
    "        self.input_size_oov_context = input_size_oov_context\n",
    "        self.input_size_right_context = input_size_right_context\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.output_size = output_size\n",
    "        self.batch_first = batch_first\n",
    "        self.bidirectional = bidirectional\n",
    "        \n",
    "        self.bilstm_left_context_feature = nn.LSTM(\n",
    "            input_size = self.input_size_left_context,\n",
    "            hidden_size = self.hidden_size,\n",
    "            num_layers = self.num_layers,\n",
    "            batch_first = self.batch_first,\n",
    "            bidirectional = self.bidirectional\n",
    "        )\n",
    "        \n",
    "        self.bilstm_oov_context_feature = nn.LSTM(\n",
    "            input_size = self.input_size_oov_context,\n",
    "            hidden_size = self.hidden_size,\n",
    "            num_layers = self.num_layers,\n",
    "            batch_first = self.batch_first,\n",
    "            bidirectional = self.bidirectional\n",
    "        )\n",
    "        \n",
    "        self.bilstm_right_context_feature = nn.LSTM(\n",
    "            input_size = self.input_size_right_context,\n",
    "            hidden_size = self.hidden_size,\n",
    "            num_layers = self.num_layers,\n",
    "            batch_first = self.batch_first,\n",
    "            bidirectional = self.bidirectional\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(2 * self.hidden_size, 64),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "        self.oov_embedding = nn.Linear(in_features=3 * 64, out_features=64)\n",
    "        \n",
    "        self.embedding = np.empty((output_size, 64), dtype=np.float32)\n",
    "        \n",
    "        self.prob = nn.Sequential(\n",
    "            nn.Linear(64, self.output_size),\n",
    "            nn.LogSoftmax(dim=1)\n",
    "        )\n",
    "                \n",
    "        if init_wb_with_kaiming_normal:\n",
    "            self.init_wb()\n",
    "            \n",
    "    def init_wb(self):\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, (nn.Linear, nn.LSTM)):\n",
    "                for name, param in module.named_parameters():\n",
    "                    if \"weight\" in name:\n",
    "                        nn.init.kaiming_normal_(param)\n",
    "                    else:\n",
    "                        nn.init.kaiming_normal_(param.reshape(1, -1))\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_left_context,\n",
    "        input_oov_context,\n",
    "        input_right_context,\n",
    "        idxs_target,\n",
    "        hidden_left_context=None,\n",
    "        hidden_oov_context=None,\n",
    "        hidden_right_context=None,\n",
    "    ):\n",
    "        # BiLSTM left, oov, and right context\n",
    "        output_left_context, (hidden_left_context, memory_left_context) = self.bilstm_left_context_feature(input_left_context, hidden_left_context)\n",
    "        output_oov_context, (hidden_oov_context, memory_oov_context) = self.bilstm_oov_context_feature(input_oov_context, hidden_oov_context)\n",
    "        output_right_context, (hidden_right_context, memory_right_context) = self.bilstm_right_context_feature(input_right_context, hidden_right_context)\n",
    "                \n",
    "        # Concate hidden (forward and backward hidden BiLSTM)\n",
    "        hidden_left_bidirectional = torch.cat((hidden_left_context[0], hidden_left_context[-1]), dim=1)\n",
    "        hidden_oov_bidirectional = torch.cat((hidden_oov_context[0], hidden_oov_context[-1]), dim=1)\n",
    "        hidden_right_bidirectional = torch.cat((hidden_right_context[0], hidden_right_context[-1]), dim=1)\n",
    "        \n",
    "        # Fully connected\n",
    "        output_left_fc = self.fc(hidden_left_bidirectional)\n",
    "        output_oov_fc = self.fc(hidden_oov_bidirectional)\n",
    "        output_right_fc = self.fc(hidden_right_bidirectional)\n",
    "        \n",
    "        # Concate output left, oov, and right context feature\n",
    "        output = torch.cat((output_left_fc, output_oov_fc, output_right_fc), dim=1)\n",
    "        \n",
    "        # OOV embedding\n",
    "        output = self.oov_embedding(output)\n",
    "                \n",
    "        # save OOV embedding\n",
    "        self.embedding[idxs_target.tolist()] = output.cpu().detach().numpy()\n",
    "        \n",
    "        # Projection OOV embedding\n",
    "        prob = self.prob(output)\n",
    "        \n",
    "        return prob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992eb40b-9062-47f1-9703-65e80d6cb07d",
   "metadata": {},
   "source": [
    "# Model, Optimizer, Criterion, Metric, and Learning Rate Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b08d05fc-0bb5-426e-aa7b-eb930ba9f06b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Comick(\n",
       "  (bilstm_left_context_feature): LSTM(64, 128, batch_first=True, bidirectional=True)\n",
       "  (bilstm_oov_context_feature): LSTM(20, 128, batch_first=True, bidirectional=True)\n",
       "  (bilstm_right_context_feature): LSTM(64, 128, batch_first=True, bidirectional=True)\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (1): Tanh()\n",
       "  )\n",
       "  (oov_embedding): Linear(in_features=192, out_features=64, bias=True)\n",
       "  (prob): Sequential(\n",
       "    (0): Linear(in_features=64, out_features=3611, bias=True)\n",
       "    (1): LogSoftmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Comick().to(hyperparams.device)\n",
    "model.prob[0].requires_grad_ = False # disable gradient for projection layer\n",
    "optimizer = optim.Adam(model.parameters(), lr=hyperparams.lr)\n",
    "criterion = nn.NLLLoss(ignore_index=list(char_embedding_dict.keys()).index(\"PAD\")).to(hyperparams.device)\n",
    "metric = F1Score(ignore_index=list(char_embedding_dict.keys()).index(\"PAD\")).to(hyperparams.device)\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.5)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d463d75-dd43-4b45-9eec-8f4aca21b018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "814,427\n"
     ]
    }
   ],
   "source": [
    "print(f\"{sum([param.numel() for param in model.parameters() if param.requires_grad_]):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "494a567d-acbc-46c2-adc8-b9a512366c17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4.0447303e-32,  4.5581436e-41, -4.0447303e-32, ...,\n",
       "         4.5580035e-41,  1.1196655e-40,  0.0000000e+00],\n",
       "       [-1.1555155e+36,  4.5580035e-41, -1.8866469e+36, ...,\n",
       "         4.5580035e-41, -1.8867585e+36,  4.5580035e-41],\n",
       "       [ 1.1198196e-40,  0.0000000e+00, -1.1555434e+36, ...,\n",
       "         0.0000000e+00, -1.1555687e+36,  4.5580035e-41],\n",
       "       ...,\n",
       "       [-1.4009837e+35,  4.5580035e-41, -1.8488202e+36, ...,\n",
       "         4.5580035e-41, -1.8489115e+36,  4.5580035e-41],\n",
       "       [ 1.1803557e-40,  0.0000000e+00, -1.4010185e+35, ...,\n",
       "         0.0000000e+00, -1.4010502e+35,  4.5580035e-41],\n",
       "       [-1.8490231e+36,  4.5580035e-41,  1.1805099e-40, ...,\n",
       "         4.5580035e-41,  1.1806500e-40,  0.0000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b39ba3-b103-44da-ae1e-34fd12ad2d2f",
   "metadata": {},
   "source": [
    "# Training Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c51a3a6-a4af-425f-aa1f-34ffe9ff8248",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_step(dataloader, model, optimizer, criterion, metric, scheduler=None, path_name=None):\n",
    "    model.train()\n",
    "    \n",
    "    batch_losses = []\n",
    "    batch_metric_scores = []\n",
    "    \n",
    "    for batch, (input_left_context, input_oov_context, input_right_context, actual_label) in enumerate(tqdm(dataloader), 1):\n",
    "        # Forward Propagation\n",
    "        prob = model(\n",
    "            left_context_embedding(input_left_context).to(hyperparams.device),\n",
    "            oov_context_embedding(input_oov_context).to(hyperparams.device),\n",
    "            right_context_embedding(input_right_context).to(hyperparams.device),\n",
    "            actual_label.to(hyperparams.device)\n",
    "        )\n",
    "                \n",
    "        loss = criterion(prob, actual_label.to(hyperparams.device))\n",
    "        metric_score = metric(prob.argmax(dim=1), actual_label.to(hyperparams.device))\n",
    "        metric_score = metric.compute()\n",
    "        \n",
    "        if scheduler is not None:\n",
    "            scheduler.step(loss)\n",
    "        \n",
    "        batch_losses.append(loss.item())\n",
    "        batch_metric_scores.append(metric_score)\n",
    "        \n",
    "        if batch % 50 == 0 or batch == len(dataloader):\n",
    "            batch_name = \"Batch-\" + str(batch)\n",
    "            print(f\"{batch_name.ljust(9)}: {str(criterion).split('(')[0]}={(loss.item()):.4f} | {str(metric).split('(')[0]}={(metric_score):.4f}\")\n",
    "            with open(f\"../../logs/comick/{hyperparams.context_size}_contexts/{path_name}/training_history.txt\", \"a\") as f:\n",
    "                f.write(f\"{batch_name.ljust(9)}: {str(criterion).split('(')[0]}={(loss.item()):.4f} | {str(metric).split('(')[0]}={(metric_score):.4f}\\n\")\n",
    "\n",
    "        # Backward Propagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    return batch_losses, batch_metric_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3043a1-39cb-4b38-8024-54f909a565a9",
   "metadata": {},
   "source": [
    "# Looping Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e139244-b036-4d45-beca-1de5bd7b5e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH-1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a6d35bd8934458dacc62ed5b4200b83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=6.1326 | F1Score=0.2725\n",
      "Batch-100: NLLLoss=6.1231 | F1Score=0.2994\n",
      "Batch-150: NLLLoss=4.4804 | F1Score=0.3212\n",
      "Batch-200: NLLLoss=3.5206 | F1Score=0.3377\n",
      "Batch-250: NLLLoss=3.5622 | F1Score=0.3593\n",
      "Batch-300: NLLLoss=3.1662 | F1Score=0.3792\n",
      "Batch-350: NLLLoss=4.5824 | F1Score=0.3935\n",
      "Batch-400: NLLLoss=3.4164 | F1Score=0.4085\n",
      "Batch-450: NLLLoss=2.6339 | F1Score=0.4224\n",
      "Batch-500: NLLLoss=3.1520 | F1Score=0.4340\n",
      "Batch-518: NLLLoss=2.7964 | F1Score=0.4381\n",
      "\n",
      "Mean NLLLoss: 4.5123 | Mean F1Score: 0.3541\n",
      "==================================================\n",
      "\n",
      "EPOCH-2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dfa300affe6488489f574ed4fcf170d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=2.6918 | F1Score=0.5819\n",
      "Batch-100: NLLLoss=2.1554 | F1Score=0.5975\n",
      "Batch-150: NLLLoss=2.2141 | F1Score=0.6065\n",
      "Batch-200: NLLLoss=2.4957 | F1Score=0.6067\n",
      "Batch-250: NLLLoss=2.8140 | F1Score=0.6126\n",
      "Batch-300: NLLLoss=3.3044 | F1Score=0.6203\n",
      "Batch-350: NLLLoss=2.0840 | F1Score=0.6272\n",
      "Batch-400: NLLLoss=1.8783 | F1Score=0.6298\n",
      "Batch-450: NLLLoss=2.6806 | F1Score=0.6346\n",
      "Batch-500: NLLLoss=2.5200 | F1Score=0.6401\n",
      "Batch-518: NLLLoss=2.5665 | F1Score=0.6427\n",
      "\n",
      "Yeah ðŸŽ‰ðŸ˜„! Model improved.\n",
      "Mean NLLLoss: 2.6904 | Mean F1Score: 0.6142\n",
      "==================================================\n",
      "\n",
      "EPOCH-3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b01fc8013abb4abaa88b3b55cdc01ff8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=1.7898 | F1Score=0.7212\n",
      "Batch-100: NLLLoss=2.4818 | F1Score=0.7306\n",
      "Batch-150: NLLLoss=1.5190 | F1Score=0.7331\n",
      "Batch-200: NLLLoss=1.2977 | F1Score=0.7372\n",
      "Batch-250: NLLLoss=0.4020 | F1Score=0.7377\n",
      "Batch-300: NLLLoss=2.4987 | F1Score=0.7389\n",
      "Batch-350: NLLLoss=2.4006 | F1Score=0.7413\n",
      "Batch-400: NLLLoss=1.5320 | F1Score=0.7453\n",
      "Batch-450: NLLLoss=2.9819 | F1Score=0.7481\n",
      "Batch-500: NLLLoss=1.5421 | F1Score=0.7485\n",
      "Batch-518: NLLLoss=0.7335 | F1Score=0.7492\n",
      "\n",
      "Yeah ðŸŽ‰ðŸ˜„! Model improved.\n",
      "Mean NLLLoss: 1.7639 | Mean F1Score: 0.7389\n",
      "==================================================\n",
      "\n",
      "EPOCH-4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "708e39cb7c494daeb7022e3afdb6e6a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=1.2155 | F1Score=0.8096\n",
      "Batch-100: NLLLoss=0.7382 | F1Score=0.8108\n",
      "Batch-150: NLLLoss=1.1188 | F1Score=0.8120\n",
      "Batch-200: NLLLoss=0.8461 | F1Score=0.8135\n",
      "Batch-250: NLLLoss=0.8206 | F1Score=0.8137\n",
      "Batch-300: NLLLoss=1.7783 | F1Score=0.8135\n",
      "Batch-350: NLLLoss=1.2425 | F1Score=0.8147\n",
      "Batch-400: NLLLoss=1.0134 | F1Score=0.8161\n",
      "Batch-450: NLLLoss=1.1183 | F1Score=0.8184\n",
      "Batch-500: NLLLoss=0.9655 | F1Score=0.8195\n",
      "Batch-518: NLLLoss=0.6786 | F1Score=0.8208\n",
      "\n",
      "Yeah ðŸŽ‰ðŸ˜„! Model improved.\n",
      "Mean NLLLoss: 1.1317 | Mean F1Score: 0.8108\n",
      "==================================================\n",
      "\n",
      "EPOCH-5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03005191a03c45df928669c9d3f97160",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=0.5452 | F1Score=0.8994\n",
      "Batch-100: NLLLoss=0.7853 | F1Score=0.8894\n",
      "Batch-150: NLLLoss=0.3225 | F1Score=0.8848\n",
      "Batch-200: NLLLoss=0.9636 | F1Score=0.8825\n",
      "Batch-250: NLLLoss=0.4510 | F1Score=0.8825\n",
      "Batch-300: NLLLoss=0.5892 | F1Score=0.8786\n",
      "Batch-350: NLLLoss=0.6429 | F1Score=0.8784\n",
      "Batch-400: NLLLoss=0.4697 | F1Score=0.8768\n",
      "Batch-450: NLLLoss=0.3238 | F1Score=0.8779\n",
      "Batch-500: NLLLoss=0.9199 | F1Score=0.8773\n",
      "Batch-518: NLLLoss=0.6380 | F1Score=0.8770\n",
      "\n",
      "Yeah ðŸŽ‰ðŸ˜„! Model improved.\n",
      "Mean NLLLoss: 0.6615 | Mean F1Score: 0.8834\n",
      "==================================================\n",
      "\n",
      "EPOCH-6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16be7d75f7514bcf8885c96f1bea3a8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=0.1486 | F1Score=0.9531\n",
      "Batch-100: NLLLoss=0.2491 | F1Score=0.9592\n",
      "Batch-150: NLLLoss=0.3367 | F1Score=0.9572\n",
      "Batch-200: NLLLoss=0.1151 | F1Score=0.9574\n",
      "Batch-250: NLLLoss=0.2675 | F1Score=0.9551\n",
      "Batch-300: NLLLoss=0.1768 | F1Score=0.9539\n",
      "Batch-350: NLLLoss=0.5450 | F1Score=0.9524\n",
      "Batch-400: NLLLoss=0.2095 | F1Score=0.9509\n",
      "Batch-450: NLLLoss=0.4474 | F1Score=0.9479\n",
      "Batch-500: NLLLoss=0.0235 | F1Score=0.9475\n",
      "Batch-518: NLLLoss=0.0773 | F1Score=0.9466\n",
      "\n",
      "Yeah ðŸŽ‰ðŸ˜„! Model improved.\n",
      "Mean NLLLoss: 0.3088 | Mean F1Score: 0.9535\n",
      "==================================================\n",
      "\n",
      "EPOCH-7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74c313855a184b798e6b145f2e42b2f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=0.0991 | F1Score=0.9862\n",
      "Batch-100: NLLLoss=0.1290 | F1Score=0.9894\n",
      "Batch-150: NLLLoss=0.0814 | F1Score=0.9890\n",
      "Batch-200: NLLLoss=0.1601 | F1Score=0.9899\n",
      "Batch-250: NLLLoss=0.0951 | F1Score=0.9907\n",
      "Batch-300: NLLLoss=0.1635 | F1Score=0.9905\n",
      "Batch-350: NLLLoss=0.0694 | F1Score=0.9902\n",
      "Batch-400: NLLLoss=0.0844 | F1Score=0.9900\n",
      "Batch-450: NLLLoss=0.2535 | F1Score=0.9894\n",
      "Batch-500: NLLLoss=0.2433 | F1Score=0.9889\n",
      "Batch-518: NLLLoss=0.0770 | F1Score=0.9886\n",
      "\n",
      "Yeah ðŸŽ‰ðŸ˜„! Model improved.\n",
      "Mean NLLLoss: 0.1078 | Mean F1Score: 0.9887\n",
      "==================================================\n",
      "\n",
      "EPOCH-8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62662fa668d24708a98f144594ed1dc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=0.0122 | F1Score=0.9962\n",
      "Batch-100: NLLLoss=0.0123 | F1Score=0.9969\n",
      "Batch-150: NLLLoss=0.0335 | F1Score=0.9975\n",
      "Batch-200: NLLLoss=0.0221 | F1Score=0.9978\n",
      "Batch-250: NLLLoss=0.0212 | F1Score=0.9976\n",
      "Batch-300: NLLLoss=0.0080 | F1Score=0.9979\n",
      "Batch-350: NLLLoss=0.0172 | F1Score=0.9980\n",
      "Batch-400: NLLLoss=0.0554 | F1Score=0.9979\n",
      "Batch-450: NLLLoss=0.0216 | F1Score=0.9978\n",
      "Batch-500: NLLLoss=0.0248 | F1Score=0.9979\n",
      "Batch-518: NLLLoss=0.0139 | F1Score=0.9979\n",
      "\n",
      "Yeah ðŸŽ‰ðŸ˜„! Model improved.\n",
      "Mean NLLLoss: 0.0297 | Mean F1Score: 0.9975\n",
      "==================================================\n",
      "\n",
      "EPOCH-9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "684fd61ca58b4206a09de7d9906d8caf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=0.0089 | F1Score=0.9987\n",
      "Batch-100: NLLLoss=0.0226 | F1Score=0.9987\n",
      "Batch-150: NLLLoss=0.0060 | F1Score=0.9987\n",
      "Batch-200: NLLLoss=0.0065 | F1Score=0.9991\n",
      "Batch-250: NLLLoss=0.0109 | F1Score=0.9991\n",
      "Batch-300: NLLLoss=0.0023 | F1Score=0.9991\n",
      "Batch-350: NLLLoss=0.0029 | F1Score=0.9990\n",
      "Batch-400: NLLLoss=0.0113 | F1Score=0.9990\n",
      "Batch-450: NLLLoss=0.0126 | F1Score=0.9991\n",
      "Batch-500: NLLLoss=0.0056 | F1Score=0.9990\n",
      "Batch-518: NLLLoss=0.0127 | F1Score=0.9990\n",
      "\n",
      "Yeah ðŸŽ‰ðŸ˜„! Model improved.\n",
      "Mean NLLLoss: 0.0120 | Mean F1Score: 0.9990\n",
      "==================================================\n",
      "\n",
      "EPOCH-10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26d03f6315c84958ac6071003aa73604",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=0.0168 | F1Score=1.0000\n",
      "Batch-100: NLLLoss=0.0064 | F1Score=0.9994\n",
      "Batch-150: NLLLoss=0.0079 | F1Score=0.9994\n",
      "Batch-200: NLLLoss=0.0048 | F1Score=0.9992\n",
      "Batch-250: NLLLoss=0.0072 | F1Score=0.9994\n",
      "Batch-300: NLLLoss=0.0072 | F1Score=0.9992\n",
      "Batch-350: NLLLoss=0.0098 | F1Score=0.9992\n",
      "Batch-400: NLLLoss=0.0209 | F1Score=0.9993\n",
      "Batch-450: NLLLoss=0.0053 | F1Score=0.9992\n",
      "Batch-500: NLLLoss=0.0040 | F1Score=0.9992\n",
      "Batch-518: NLLLoss=0.0019 | F1Score=0.9993\n",
      "\n",
      "Yeah ðŸŽ‰ðŸ˜„! Model improved.\n",
      "Mean NLLLoss: 0.0081 | Mean F1Score: 0.9994\n",
      "==================================================\n",
      "\n",
      "EPOCH-11\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a7bc8c1cc154ba28007cbd82cfbe38a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=0.0046 | F1Score=1.0000\n",
      "Batch-100: NLLLoss=0.0037 | F1Score=0.9995\n",
      "Batch-150: NLLLoss=0.0051 | F1Score=0.9993\n",
      "Batch-200: NLLLoss=0.0076 | F1Score=0.9991\n",
      "Batch-250: NLLLoss=0.0144 | F1Score=0.9992\n",
      "Batch-300: NLLLoss=0.1955 | F1Score=0.9965\n",
      "Batch-350: NLLLoss=0.0456 | F1Score=0.9881\n",
      "Batch-400: NLLLoss=0.2838 | F1Score=0.9805\n",
      "Batch-450: NLLLoss=0.1075 | F1Score=0.9751\n",
      "Batch-250: NLLLoss=0.0017 | F1Score=0.9994\n",
      "Batch-500: NLLLoss=0.0019 | F1Score=0.9995\n",
      "Batch-518: NLLLoss=0.0016 | F1Score=0.9995\n",
      "\n",
      "Huft ðŸ˜¥! Model not improved.\n",
      "Mean NLLLoss: 0.0035 | Mean F1Score: 0.9994\n",
      "Patience = 2/20â—\n",
      "==================================================\n",
      "\n",
      "EPOCH-16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5517870df670467aa73c2e440e397975",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=0.0009 | F1Score=0.9991\n",
      "Batch-100: NLLLoss=0.0017 | F1Score=0.9991\n",
      "Batch-150: NLLLoss=0.0013 | F1Score=0.9994\n",
      "Batch-200: NLLLoss=0.0010 | F1Score=0.9994\n",
      "Batch-250: NLLLoss=0.0023 | F1Score=0.9995\n",
      "Batch-300: NLLLoss=0.0008 | F1Score=0.9996\n",
      "Batch-350: NLLLoss=0.0007 | F1Score=0.9996\n",
      "Batch-400: NLLLoss=0.0009 | F1Score=0.9997\n",
      "Batch-450: NLLLoss=0.0004 | F1Score=0.9997\n",
      "Batch-500: NLLLoss=0.0017 | F1Score=0.9997\n",
      "Batch-518: NLLLoss=0.0007 | F1Score=0.9998\n",
      "\n",
      "Yeah ðŸŽ‰ðŸ˜„! Model improved.\n",
      "Mean NLLLoss: 0.0024 | Mean F1Score: 0.9995\n",
      "==================================================\n",
      "\n",
      "EPOCH-17\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31641b5d2dfa4793aef7d2677eaacb85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=0.0009 | F1Score=1.0000\n",
      "Batch-100: NLLLoss=0.0009 | F1Score=0.9998\n",
      "Batch-150: NLLLoss=0.0009 | F1Score=0.9999\n",
      "Batch-200: NLLLoss=0.0007 | F1Score=0.9999\n",
      "Batch-250: NLLLoss=0.0005 | F1Score=0.9999\n",
      "Batch-300: NLLLoss=0.0005 | F1Score=0.9999\n",
      "Batch-350: NLLLoss=0.0005 | F1Score=0.9999\n",
      "Batch-400: NLLLoss=0.0005 | F1Score=0.9999\n",
      "Batch-450: NLLLoss=0.0005 | F1Score=0.9999\n",
      "Batch-500: NLLLoss=0.0006 | F1Score=0.9999\n",
      "Batch-518: NLLLoss=0.0006 | F1Score=0.9999\n",
      "\n",
      "Yeah ðŸŽ‰ðŸ˜„! Model improved.\n",
      "Mean NLLLoss: 0.0011 | Mean F1Score: 0.9999\n",
      "==================================================\n",
      "\n",
      "EPOCH-18\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8ffe371b53a429c93a3a5da8ddc3fcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=0.0004 | F1Score=1.0000\n",
      "Batch-100: NLLLoss=0.0007 | F1Score=1.0000\n",
      "Batch-150: NLLLoss=0.0004 | F1Score=1.0000\n",
      "Batch-200: NLLLoss=0.0005 | F1Score=1.0000\n",
      "Batch-250: NLLLoss=0.0005 | F1Score=1.0000\n",
      "Batch-300: NLLLoss=0.0006 | F1Score=0.9999\n",
      "Batch-350: NLLLoss=0.0009 | F1Score=1.0000\n",
      "Batch-400: NLLLoss=0.0004 | F1Score=0.9999\n",
      "Batch-450: NLLLoss=0.0008 | F1Score=0.9999\n",
      "Batch-500: NLLLoss=0.0012 | F1Score=0.9999\n",
      "Batch-518: NLLLoss=0.0010 | F1Score=0.9999\n",
      "\n",
      "Yeah ðŸŽ‰ðŸ˜„! Model improved.\n",
      "Mean NLLLoss: 0.0010 | Mean F1Score: 1.0000\n",
      "==================================================\n",
      "\n",
      "EPOCH-19\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0a112136bbc41129ca69171625469f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=0.0007 | F1Score=1.0000\n",
      "Batch-100: NLLLoss=0.0005 | F1Score=0.9998\n",
      "Batch-150: NLLLoss=0.0009 | F1Score=0.9997\n",
      "Batch-200: NLLLoss=0.0015 | F1Score=0.9996\n",
      "Batch-250: NLLLoss=0.0015 | F1Score=0.9996\n",
      "Batch-300: NLLLoss=0.1503 | F1Score=0.9993\n",
      "Batch-350: NLLLoss=0.3038 | F1Score=0.9942\n",
      "Batch-400: NLLLoss=0.1613 | F1Score=0.9815\n",
      "Batch-450: NLLLoss=0.3718 | F1Score=0.9743\n",
      "Batch-500: NLLLoss=0.1861 | F1Score=0.9711\n",
      "Batch-518: NLLLoss=0.0355 | F1Score=0.9710\n",
      "\n",
      "Huft ðŸ˜¥! Model not improved.\n",
      "Mean NLLLoss: 0.1152 | Mean F1Score: 0.9926\n",
      "Patience = 3/20â—\n",
      "==================================================\n",
      "\n",
      "EPOCH-20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc10a7d3ec554b9caedeae12bc0d8a94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=0.1513 | F1Score=0.9631\n",
      "Batch-100: NLLLoss=0.0658 | F1Score=0.9698\n",
      "Batch-150: NLLLoss=0.0449 | F1Score=0.9730\n",
      "Batch-200: NLLLoss=0.0170 | F1Score=0.9749\n",
      "Batch-250: NLLLoss=0.0679 | F1Score=0.9762\n",
      "Batch-300: NLLLoss=0.0430 | F1Score=0.9770\n",
      "Batch-350: NLLLoss=0.0558 | F1Score=0.9789\n",
      "Batch-400: NLLLoss=0.0318 | F1Score=0.9801\n",
      "Batch-450: NLLLoss=0.0977 | F1Score=0.9810\n",
      "Batch-500: NLLLoss=0.0179 | F1Score=0.9823\n",
      "Batch-518: NLLLoss=0.0152 | F1Score=0.9827\n",
      "\n",
      "Yeah ðŸŽ‰ðŸ˜„! Model improved.\n",
      "Mean NLLLoss: 0.0737 | Mean F1Score: 0.9755\n",
      "==================================================\n",
      "\n",
      "TRAINING SUMMARY\n",
      "Best NLLLoss      : 0.0737\n",
      "Best F1Score      : 0.9755\n",
      "Training duration : 17.467 minutes.\n",
      "Training date     : 2022-10-11 12:21:42.859413+08:00\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def looping_step(dataloader, model, optimizer, criterion, metric, n_epoch=hyperparams.n_epoch, patience=hyperparams.patience, monitor=\"loss\"):    \n",
    "    start_time = time()\n",
    "    \n",
    "    epoch_losses = []\n",
    "    epoch_metric_scores = []\n",
    "    patience_counter = 0\n",
    "    \n",
    "    now = datetime.now(pytz.timezone(\"Asia/Ujung_Pandang\"))\n",
    "    path_name = now.strftime(\"%m-%d-%Y_%H-%M-%S\")\n",
    "    os.makedirs(f\"../../logs/comick/{hyperparams.context_size}_contexts/{path_name}\")\n",
    "    \n",
    "    # Hyperparameters\n",
    "    with open(f\"../../logs/comick/{hyperparams.context_size}_contexts/{path_name}/training_history.txt\", \"a\") as f:\n",
    "        f.write(f\"HYPERPARAMETERS\\n\")\n",
    "        f.write(f\"{'-' * 50}\\n\")\n",
    "        for name, value in vars(hyperparams).items():\n",
    "            f.write(f\"{name}: {value}\\n\")\n",
    "        \n",
    "        f.write(\"\\n\\nTRAINING PROGRESS\\n\")\n",
    "        f.write(f\"{'-' * 50}\\n\")\n",
    "    \n",
    "    # Training Progress\n",
    "    for epoch in range(1, n_epoch + 1):\n",
    "        print(f\"EPOCH-{epoch}\")\n",
    "        with open(f\"../../logs/comick/{hyperparams.context_size}_contexts/{path_name}/training_history.txt\", \"a\") as f:\n",
    "            f.write(f\"EPOCH-{epoch}\\n\")\n",
    "        \n",
    "        batch_losses, batch_metric_scores = training_step(dataloader, model, optimizer, criterion, metric, path_name=path_name)\n",
    "        epoch_loss = torch.mean(torch.FloatTensor(batch_losses))\n",
    "\n",
    "        epoch_loss = torch.mean(torch.FloatTensor(batch_losses))\n",
    "        epoch_losses.append(epoch_loss.item())\n",
    "\n",
    "        epoch_metric_score = torch.mean(torch.FloatTensor(batch_metric_scores))\n",
    "        epoch_metric_scores.append(epoch_metric_score.item())\n",
    "        \n",
    "        with open(f\"../../logs/comick/{hyperparams.context_size}_contexts/{path_name}/training_history.txt\", \"a\") as f:\n",
    "            if monitor == \"loss\":\n",
    "                if epoch == 1:\n",
    "                    best_state_dict = model.state_dict()\n",
    "                    best_loss = (epoch_loss)\n",
    "                    best_metric = (epoch_metric_score)\n",
    "                    \n",
    "                    print(f\"\\nMean {str(criterion).split('(')[0]}: {(epoch_loss):.4f} | Mean {str(metric).split('(')[0]}: {(epoch_metric_score):.4f}\")\n",
    "                    \n",
    "                    f.write(f\"\\nMean {str(criterion).split('(')[0]}: {(epoch_loss):.4f} | Mean {str(metric).split('(')[0]}: {(epoch_metric_score):.4f}\\n\")\n",
    "                elif epoch_losses[-1] < epoch_losses[-2]:\n",
    "                    best_state_dict = model.state_dict()\n",
    "                    best_loss = (epoch_loss)\n",
    "                    best_metric = (epoch_metric_score)\n",
    "                    \n",
    "                    print(\"\\nYeah ðŸŽ‰ðŸ˜„! Model improved.\")\n",
    "                    print(f\"Mean {str(criterion).split('(')[0]}: {(epoch_loss):.4f} | Mean {str(metric).split('(')[0]}: {(epoch_metric_score):.4f}\")\n",
    "                    \n",
    "                    f.write(\"\\nYeah ðŸŽ‰ðŸ˜„! Model improved.\\n\")\n",
    "                    f.write(f\"Mean {str(criterion).split('(')[0]}: {(epoch_loss):.4f} | Mean {str(metric).split('(')[0]}: {(epoch_metric_score):.4f}\\n\")\n",
    "                else:\n",
    "                    patience_counter += 1\n",
    "                    \n",
    "                    print(\"\\nHuft ðŸ˜¥! Model not improved.\")\n",
    "                    print(f\"Mean {str(criterion).split('(')[0]}: {(epoch_loss):.4f} | Mean {str(metric).split('(')[0]}: {(epoch_metric_score):.4f}\")\n",
    "                    print(f\"Patience = {patience_counter}/{patience}â—\")\n",
    "                    \n",
    "                    f.write(\"\\nHuft ðŸ˜¥! Model not improved.\\n\")\n",
    "                    f.write(f\"Mean {str(criterion).split('(')[0]}: {(epoch_loss):.4f} | Mean {str(metric).split('(')[0]}: {(epoch_metric_score):.4f}\\n\")                    \n",
    "                    f.write(f\"Patience = {patience_counter}/{patience}â—\\n\")\n",
    "            else:\n",
    "                if epoch == 1:\n",
    "                    best_state_dict = model.state_dict()\n",
    "                    best_loss = (epoch_loss)\n",
    "                    best_metric = (epoch_metric_score)\n",
    "                    \n",
    "                    print(f\"\\nMean {str(criterion).split('(')[0]}: {(epoch_loss):.4f} | Mean {str(metric).split('(')[0]}: {(epoch_metric_score):.4f}\")\n",
    "                    \n",
    "                    f.write(f\"\\nMean {str(criterion).split('(')[0]}: {(epoch_loss):.4f} | Mean {str(metric).split('(')[0]}: {(epoch_metric_score):.4f}\\n\")\n",
    "                elif epoch_metric_scores[-1] > epoch_metric_scores[-2]:\n",
    "                    best_state_dict = model.state_dict()\n",
    "                    best_loss = (epoch_loss)\n",
    "                    best_metric = (epoch_metric_score)\n",
    "                    \n",
    "                    print(\"\\nYeah ðŸŽ‰ðŸ˜„! Model improved.\")\n",
    "                    print(f\"Mean {str(criterion).split('(')[0]}: {(epoch_loss):.4f} | Mean Mean {str(metric).split('(')[0]}: {(epoch_metric_score):.4f}\")\n",
    "                    \n",
    "                    f.write(\"\\nYeah ðŸŽ‰ðŸ˜„! Model improved.\\n\")\n",
    "                    f.write(f\"Mean {str(criterion).split('(')[0]}: {(epoch_loss):.4f} | Mean {str(metric).split('(')[0]}: {(epoch_metric_score):.4f}\\n\")\n",
    "                else:\n",
    "                    patience_counter += 1\n",
    "                    \n",
    "                    print(\"\\nHuft ðŸ˜¥! Model not improved.\")\n",
    "                    print(f\"Mean {str(criterion).split('(')[0]}: {(epoch_loss):.4f} | Mean {str(metric).split('(')[0]}: {(epoch_metric_score):.4f}\\n\")\n",
    "                    print(f\"Patience = {patience_counter}/{patience}â—\\n\")\n",
    "                    \n",
    "                    f.write(\"\\nHuft ðŸ˜¥! Model not improved.\\n\")\n",
    "                    f.write(f\"Mean {str(criterion).split('(')[0]}: {(epoch_loss):.4f} | Mean {str(metric).split('(')[0]}: {(epoch_metric_score):.4f}\\n\")\n",
    "                    f.write(f\"Patience = {patience_counter}/{patience}â—\\n\")\n",
    "                    \n",
    "            print(\"=\" * 50, end=\"\\n\\n\")\n",
    "            f.write(f\"{'=' * 50}\\n\\n\")\n",
    "            \n",
    "            if patience_counter == patience:\n",
    "                print(f\"Early stopping, patience = {patience_counter}/{patience}â—\\n\")\n",
    "                f.write(f\"Early stopping, patience = {patience_counter}/{patience}â—\\n\")\n",
    "                break\n",
    "        \n",
    "        metric.reset()\n",
    "    \n",
    "    finish_time = time()\n",
    "    \n",
    "    # Training plot \n",
    "    fig, (ax_loss, ax_metric_score) = plt.subplots(nrows=1, ncols=2, figsize=(15, 5))\n",
    "\n",
    "    fig.suptitle(f\"Training with context size = {hyperparams.context_size}\")\n",
    "\n",
    "    ax_loss.set_title(\"Loss\")\n",
    "    ax_loss.set_xlabel(\"Epoch\")\n",
    "    ax_loss.set_ylabel(\"Score\")\n",
    "    ax_loss.plot(epoch_losses, \"green\")\n",
    "    ax_loss.grid()\n",
    "\n",
    "    ax_metric_score.set_title(\"F1 Score\")\n",
    "    ax_metric_score.set_xlabel(\"Epoch\")\n",
    "    ax_metric_score.set_ylabel(\"Score\")\n",
    "    ax_metric_score.plot(epoch_metric_scores, \"orange\")\n",
    "    ax_metric_score.grid()\n",
    "\n",
    "    plt.savefig(f\"../../logs/comick/{hyperparams.context_size}_contexts/{path_name}/training_plot.jpg\", dpi=200)                        \n",
    "    \n",
    "    print(\"TRAINING SUMMARY\")\n",
    "    criterion_name = \"Best \" + str(criterion).split('(')[0]\n",
    "    metric_name = \"Best \" + str(metric).split('(')[0]\n",
    "    \n",
    "    print(f\"{criterion_name.ljust(18)}: {best_loss:.4f}\")\n",
    "    print(f\"{metric_name.ljust(18)}: {best_metric:.4f}\")\n",
    "    print(f\"{'Training duration'.ljust(18)}: {((finish_time - start_time) / 60):.3f} minutes.\")\n",
    "    print(f\"{'Training date'.ljust(18)}: {now}\")\n",
    "    \n",
    "    with open(f\"../../logs/comick/{hyperparams.context_size}_contexts/{path_name}/training_history.txt\", \"a\") as f:\n",
    "        f.write(\"\\nTRAINING SUMMARY\\n\")\n",
    "        f.write(f\"{'-' * 50}\\n\")\n",
    "        f.write(f\"{criterion_name.ljust(18)}: {best_loss:.4f}\\n\")\n",
    "        f.write(f\"{metric_name.ljust(18)}: {best_metric:.4f}\\n\")\n",
    "        f.write(f\"{'Training duration'.ljust(18)}: {((finish_time - start_time) / 60):.3f} minutes.\\n\")\n",
    "        f.write(f\"{'Training date'.ljust(18)}: {now}\\n\")\n",
    "    \n",
    "    # Save epoch losses, epoch metric scores, model, state dict, and oov embedding dict\n",
    "    filename_model_params = f\"../../logs/comick/{hyperparams.context_size}_contexts/{path_name}/model_params.pth\"\n",
    "    filename_oov_embedding_dict = open(f\"../../logs/comick/{hyperparams.context_size}_contexts/{path_name}/oov_embedding_dict.pkl\", \"ab\")\n",
    "    \n",
    "    pd.DataFrame(\n",
    "        data={\n",
    "            \"epoch\": list(range(1, len(epoch_losses) + 1)),\n",
    "            \"loss\": epoch_losses\n",
    "        }\n",
    "    ).to_csv(f\"../../logs/comick/{hyperparams.context_size}_contexts/{path_name}/epoch_losses.csv\", index=False)\n",
    "    \n",
    "    pd.DataFrame(\n",
    "        data={\n",
    "            \"epoch\": list(range(1, len(epoch_metric_scores) + 1)),\n",
    "            \"f1_score\": epoch_metric_scores\n",
    "        }\n",
    "    ).to_csv(f\"../../logs/comick/{hyperparams.context_size}_contexts/{path_name}/epoch_metric_scores.csv\", index=False)\n",
    "    \n",
    "    torch.save(best_state_dict, filename_model_params)\n",
    "    pickle.dump({token : embedding for token, embedding in zip(list(labels_to_idx.keys()), model.embedding)}, filename_oov_embedding_dict)\n",
    "    \n",
    "    return epoch_losses, epoch_metric_scores\n",
    "\n",
    "epoch_losses, epoch_metric_scores = looping_step(dataloader, model, optimizer, criterion, metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfef50c-e71c-4288-a9f3-6fd8831033b0",
   "metadata": {},
   "source": [
    "# END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92debcb3-d6ea-4299-a3e9-37be5b63d2b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.836333  ,  5.1457872 , -0.70575976, ...,  1.6785502 ,\n",
       "         5.4861546 , -1.0916687 ],\n",
       "       [-5.1700754 ,  3.0662746 , -5.668728  , ...,  3.8994646 ,\n",
       "         0.8507363 ,  3.8779163 ],\n",
       "       [-6.197447  ,  5.2060194 , -2.6800308 , ...,  0.30240765,\n",
       "         1.9603354 ,  1.1749065 ],\n",
       "       ...,\n",
       "       [ 1.9422084 , -0.45404607,  3.0809574 , ..., -0.9135041 ,\n",
       "        -3.41278   , -1.5020294 ],\n",
       "       [-2.647945  ,  3.3745258 ,  3.9040043 , ..., -7.433569  ,\n",
       "        -4.760192  , -8.314589  ],\n",
       "       [-0.35465878,  2.825566  ,  3.2326303 , ..., -3.7866511 ,\n",
       "         1.6287107 , -1.8595105 ]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ce78c3-ac2c-4a84-a8e8-4d8e85d26563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('bilstm_left_context_feature.weight_ih_l0',\n",
       "              tensor([[-7.3356e-02, -1.5861e-01,  6.3560e-02,  ..., -1.3457e-02,\n",
       "                        2.5719e-01, -7.1768e-01],\n",
       "                      [ 1.5370e-01,  4.5581e-02, -2.4139e-01,  ...,  1.8111e-01,\n",
       "                        1.8168e-01,  7.3891e-02],\n",
       "                      [-5.0386e-02, -6.1936e-02, -2.6157e-01,  ...,  4.1475e-02,\n",
       "                       -1.4666e-01,  8.7927e-02],\n",
       "                      ...,\n",
       "                      [ 4.2362e-01, -1.7678e-01,  3.4145e-02,  ..., -3.7615e-04,\n",
       "                        3.2845e-01, -2.9196e-01],\n",
       "                      [ 3.2598e-01,  6.3179e-02, -2.2997e-01,  ..., -2.6445e-01,\n",
       "                        2.2406e-01, -2.3448e-01],\n",
       "                      [-7.9119e-02,  6.9751e-02,  5.4297e-02,  ..., -3.1078e-01,\n",
       "                       -2.2610e-01, -3.6369e-01]])),\n",
       "             ('bilstm_left_context_feature.weight_hh_l0',\n",
       "              tensor([[-0.1246, -0.1336,  0.3429,  ...,  0.0293, -0.0701,  0.1313],\n",
       "                      [ 0.1541,  0.1721, -0.0629,  ..., -0.0766, -0.0621, -0.2544],\n",
       "                      [-0.0848,  0.0188,  0.0241,  ...,  0.1007, -0.0567, -0.0193],\n",
       "                      ...,\n",
       "                      [-0.1320, -0.0425, -0.1481,  ..., -0.0031, -0.1396,  0.2859],\n",
       "                      [ 0.3261, -0.1468,  0.0439,  ..., -0.1972,  0.1000,  0.1657],\n",
       "                      [-0.1073, -0.2653,  0.1640,  ...,  0.0926,  0.1041,  0.0457]])),\n",
       "             ('bilstm_left_context_feature.bias_ih_l0',\n",
       "              tensor([-1.2402e-01, -2.0743e-02, -1.6773e-01, -6.6539e-02, -1.3995e-01,\n",
       "                      -1.4852e-01, -2.0360e-01, -2.1050e-02, -1.8430e-01, -4.7815e-02,\n",
       "                      -1.6020e-01, -1.5059e-01, -1.3566e-01, -6.6475e-02, -2.8303e-01,\n",
       "                      -5.5440e-02, -2.2138e-02, -1.1906e-01, -1.7328e-02, -1.2207e-01,\n",
       "                      -1.7339e-01, -1.1535e-01, -1.7768e-01, -1.5847e-01, -2.5354e-01,\n",
       "                      -2.5443e-02, -2.4470e-02, -1.5186e-01, -7.6045e-02, -1.7164e-01,\n",
       "                      -9.2714e-03,  1.6109e-02, -2.0585e-01, -7.7199e-02, -3.8456e-02,\n",
       "                      -1.2404e-01, -2.2858e-01, -9.6956e-03, -1.4004e-01,  8.0311e-04,\n",
       "                      -7.2617e-02, -8.2185e-02, -2.2123e-01, -1.4639e-01, -2.1625e-01,\n",
       "                      -2.6006e-01, -1.1911e-01, -4.0960e-02, -3.6494e-01, -1.7370e-01,\n",
       "                      -2.6023e-01, -2.0056e-01, -2.0602e-01, -2.2282e-01, -8.8790e-02,\n",
       "                      -7.2506e-02, -1.8690e-01, -3.9206e-02, -7.1102e-02, -1.0804e-01,\n",
       "                      -1.1231e-01, -2.7287e-01, -1.3751e-02, -1.2194e-01, -1.9716e-02,\n",
       "                       1.5077e-01, -6.3328e-02,  5.0510e-02, -1.2805e-01, -1.7043e-01,\n",
       "                      -1.9898e-01, -1.9621e-01, -2.8798e-02,  2.6897e-02, -1.9722e-01,\n",
       "                      -8.0895e-03, -3.0210e-01, -1.6568e-01, -3.0398e-01, -1.9099e-01,\n",
       "                      -1.8871e-02, -2.8615e-01, -5.5610e-02, -7.8806e-02, -9.0517e-02,\n",
       "                      -1.4662e-01, -1.0366e-01, -1.0800e-01, -1.9538e-01, -1.6550e-01,\n",
       "                       3.8912e-03, -2.8734e-01,  9.0572e-02, -2.1861e-01, -7.5835e-02,\n",
       "                      -1.6916e-01, -1.2679e-01, -4.8034e-02, -2.8250e-01, -1.1175e-01,\n",
       "                      -1.0760e-01, -1.6842e-01, -9.4909e-02, -2.0216e-01, -1.1443e-01,\n",
       "                      -2.5877e-01, -2.1374e-01, -3.9956e-02, -3.9630e-02, -6.6554e-02,\n",
       "                      -2.2175e-01, -9.0079e-02, -2.6724e-01, -2.5340e-01, -1.2249e-01,\n",
       "                      -5.1706e-02, -1.1773e-01, -4.5605e-02, -1.8533e-01, -1.6405e-01,\n",
       "                      -8.9125e-02, -1.5624e-01, -2.0377e-01, -1.3880e-02, -1.5173e-01,\n",
       "                      -1.3497e-01, -1.8654e-01,  2.0969e-03, -1.5088e-01,  2.5277e-02,\n",
       "                      -1.0259e-01,  2.6714e-02,  7.1241e-02, -7.0716e-02, -1.6656e-01,\n",
       "                      -1.0117e-01, -1.4679e-01, -7.8464e-02, -9.9954e-02, -1.0492e-01,\n",
       "                      -1.6238e-01, -7.1671e-02, -2.7522e-01, -1.0549e-01, -2.2754e-02,\n",
       "                       5.4873e-02, -2.6188e-01, -2.7511e-02,  1.2302e-03, -9.1558e-02,\n",
       "                      -1.6466e-01, -2.6480e-01, -2.0350e-01, -3.2365e-02, -2.4188e-01,\n",
       "                      -1.3372e-01, -5.9784e-02, -1.6013e-01, -1.8793e-02,  5.9611e-02,\n",
       "                      -1.6678e-01, -6.3044e-03, -1.8179e-02, -2.6495e-01,  8.0555e-02,\n",
       "                      -1.5351e-01, -2.1988e-01, -1.3025e-02,  8.4865e-03,  2.7991e-02,\n",
       "                      -2.7320e-01, -7.3668e-02, -1.7783e-01, -5.2330e-02, -2.7949e-01,\n",
       "                       7.6919e-02, -1.9434e-01, -9.3536e-02, -2.1829e-01, -8.3099e-02,\n",
       "                      -5.4002e-02, -1.2879e-01, -6.2285e-03, -2.5423e-01, -1.7614e-01,\n",
       "                      -6.9074e-02, -5.6582e-02, -9.6931e-02, -1.3995e-01, -2.0653e-01,\n",
       "                       1.7108e-02, -8.2190e-02, -1.9967e-01, -1.4592e-01, -4.7826e-02,\n",
       "                      -2.2289e-01,  2.7593e-02, -8.7669e-02, -9.2106e-02, -1.7445e-01,\n",
       "                      -1.9838e-01, -1.4063e-01, -1.7301e-01, -4.7752e-02, -8.5824e-02,\n",
       "                      -2.4092e-01, -9.1179e-02, -2.5642e-01, -7.3505e-02, -2.2492e-01,\n",
       "                      -1.5454e-01, -8.6543e-02, -3.0622e-01, -2.2025e-01, -1.4814e-01,\n",
       "                      -9.9565e-02, -1.3343e-01, -1.1718e-01, -4.7800e-02, -4.7789e-02,\n",
       "                      -5.3539e-05, -1.3461e-01,  4.8930e-02, -1.3748e-01, -7.4294e-02,\n",
       "                      -1.6361e-01,  9.0569e-02, -1.0070e-01, -1.7544e-01, -3.6246e-02,\n",
       "                      -2.0051e-01, -1.1229e-01, -4.0484e-03, -2.4844e-01, -5.8826e-02,\n",
       "                      -8.0800e-02, -6.5620e-02, -9.4270e-02, -1.8932e-01, -1.5079e-01,\n",
       "                      -1.3092e-01, -1.8208e-01, -8.8739e-03, -5.4645e-02, -4.4383e-02,\n",
       "                      -6.4392e-02, -2.0096e-01, -1.9315e-01, -1.4718e-01, -5.5167e-02,\n",
       "                      -9.1199e-02, -1.8228e-01, -2.5564e-01, -1.0412e-01, -1.7384e-01,\n",
       "                      -7.5980e-02,  9.1306e-02, -9.8347e-02, -7.7632e-02,  6.9908e-02,\n",
       "                      -8.0610e-03, -1.4433e-01,  3.8050e-02, -1.7994e-02,  2.0010e-03,\n",
       "                       5.2190e-02, -3.7171e-02, -2.9752e-02,  1.9858e-02, -1.5045e-02,\n",
       "                      -1.1633e-01, -3.4989e-02, -4.2765e-02,  1.1920e-02,  1.0628e-02,\n",
       "                       1.2864e-01, -4.5382e-02,  5.6596e-02,  7.2574e-02, -6.0176e-02,\n",
       "                       4.5995e-02, -1.0760e-02, -4.2966e-03,  5.8007e-02,  5.0472e-02,\n",
       "                       1.1589e-02, -4.9110e-02,  5.8459e-02, -1.4105e-02,  1.0131e-01,\n",
       "                       1.7714e-02, -5.9244e-02,  2.1102e-02,  1.1573e-01, -2.1915e-02,\n",
       "                       1.2657e-01, -1.4015e-02, -6.5343e-02,  1.0851e-01, -9.3157e-02,\n",
       "                       5.4333e-03, -2.0316e-02, -2.2879e-02,  8.6310e-03, -2.5011e-03,\n",
       "                      -1.2835e-01, -1.7061e-01,  6.2037e-03, -3.1666e-02, -8.8797e-02,\n",
       "                      -2.9202e-02, -4.9456e-02,  7.9515e-02, -2.5678e-02, -5.1873e-02,\n",
       "                      -7.8545e-02, -1.1107e-01, -1.4187e-02,  1.9615e-02, -1.6166e-02,\n",
       "                       1.2810e-01,  3.0224e-02, -1.6464e-03,  9.2878e-02, -3.7220e-02,\n",
       "                       6.4360e-02, -6.6493e-02,  2.8715e-02, -1.1156e-01,  5.5046e-02,\n",
       "                      -5.3488e-02, -2.2389e-02,  3.4640e-02,  1.7023e-02, -3.1799e-02,\n",
       "                      -7.5659e-02, -1.0720e-02,  1.6844e-02, -5.7881e-02,  7.3019e-02,\n",
       "                      -7.4632e-02, -1.1072e-03, -8.2134e-02,  1.1744e-02, -5.9917e-02,\n",
       "                       1.1660e-01, -1.4484e-02, -1.0359e-01, -1.9737e-02, -3.8485e-02,\n",
       "                      -3.2231e-03, -7.1061e-03,  2.4355e-02, -2.6714e-02,  9.5333e-03,\n",
       "                      -7.3689e-02, -1.3074e-03,  2.3248e-03,  9.2132e-02,  7.9083e-02,\n",
       "                       3.1161e-02, -3.8419e-02,  1.7938e-02, -8.4539e-02,  6.7378e-02,\n",
       "                       8.1432e-02, -1.7634e-01,  3.3901e-02,  1.1411e-02, -7.6893e-02,\n",
       "                       9.9680e-02,  8.1027e-02,  3.8019e-02,  6.5849e-03,  9.7566e-02,\n",
       "                      -2.0630e-02, -1.1342e-01, -1.1427e-01, -1.7464e-02, -2.8546e-02,\n",
       "                       1.0467e-02,  5.5588e-02, -2.2836e-02, -1.3398e-02, -1.0425e-01,\n",
       "                      -1.5108e-02, -8.0106e-02, -1.1764e-01, -9.9675e-02, -1.1199e-01,\n",
       "                      -9.6556e-02, -6.8205e-02,  1.1923e-02, -4.2343e-02, -1.6351e-01,\n",
       "                      -2.6144e-01, -8.5031e-02, -2.4826e-01, -9.8822e-02, -2.3077e-01,\n",
       "                       2.8667e-04, -2.1332e-01, -7.2396e-02, -1.7472e-01,  5.4511e-02,\n",
       "                      -1.2769e-01, -1.8776e-01,  1.6888e-02, -1.9182e-01, -3.3677e-02,\n",
       "                      -2.7046e-02, -8.5626e-02,  3.0114e-02, -2.5490e-01,  4.3888e-02,\n",
       "                      -1.6124e-01, -1.9727e-01, -1.4002e-01, -1.0326e-01, -1.7537e-01,\n",
       "                      -2.4446e-01, -1.6655e-02, -9.4936e-02, -5.2551e-02, -2.0381e-01,\n",
       "                      -9.9273e-02, -1.1993e-01, -6.7986e-02, -1.7428e-01, -1.8544e-01,\n",
       "                      -5.5073e-02,  6.6101e-02, -1.6388e-01, -7.6586e-02, -2.0484e-01,\n",
       "                      -1.3692e-01, -1.8112e-01, -1.3341e-01, -2.3205e-03, -2.1056e-01,\n",
       "                      -1.2689e-01, -6.0650e-02,  2.2427e-02, -1.5561e-01, -1.7267e-01,\n",
       "                      -2.1499e-01,  5.2619e-03, -2.7773e-02,  1.1493e-01,  3.4224e-02,\n",
       "                      -1.3339e-01,  1.3837e-02, -7.1503e-02, -1.2268e-01, -3.3990e-02,\n",
       "                      -2.1869e-01,  1.4756e-02,  4.1359e-02, -1.7771e-01, -6.7926e-02,\n",
       "                      -1.4421e-01, -1.0678e-01, -5.7515e-02, -1.1121e-01, -1.0617e-01,\n",
       "                      -2.5866e-01, -2.2932e-01, -1.8996e-01, -1.7794e-01, -3.9774e-02,\n",
       "                      -5.5781e-02, -1.0119e-01, -1.2005e-01, -1.7365e-01,  5.9042e-02,\n",
       "                      -3.1232e-01,  2.0596e-01, -1.8136e-01, -6.7697e-02, -1.4270e-01,\n",
       "                      -1.9724e-01, -6.4247e-02,  1.3147e-01, -9.7253e-02, -1.2008e-01,\n",
       "                      -2.6366e-02, -1.8561e-01, -5.3180e-02,  2.9197e-02, -1.1066e-01,\n",
       "                      -1.8131e-01, -9.3493e-02, -5.6442e-02, -1.5822e-01, -2.6715e-01,\n",
       "                      -1.0768e-01, -1.1660e-01, -6.8115e-02, -2.9157e-01, -1.6717e-01,\n",
       "                      -1.3954e-01, -8.9955e-03, -2.3618e-01, -5.8451e-02, -1.4517e-01,\n",
       "                      -1.2056e-01,  2.3830e-02,  4.3881e-03, -4.9072e-02, -9.1676e-02,\n",
       "                      -8.9611e-02, -1.8263e-02])),\n",
       "             ('bilstm_left_context_feature.bias_hh_l0',\n",
       "              tensor([-0.1972,  0.0613, -0.0211, -0.2077, -0.3045, -0.0913, -0.1410, -0.0256,\n",
       "                      -0.0882, -0.1015, -0.0383, -0.1529, -0.0661, -0.2495, -0.1764, -0.2779,\n",
       "                      -0.0437, -0.0612, -0.0790, -0.0121, -0.0419, -0.1431, -0.3341, -0.1289,\n",
       "                      -0.2080, -0.2935, -0.0331, -0.1289, -0.1297, -0.1908, -0.1065, -0.1586,\n",
       "                      -0.1097,  0.0203, -0.0295, -0.1004, -0.2289, -0.2416, -0.1324,  0.0861,\n",
       "                      -0.0502, -0.1401, -0.2668, -0.1664, -0.0472, -0.2147, -0.0916,  0.0729,\n",
       "                      -0.2896, -0.1764, -0.1024, -0.1704, -0.0546, -0.2734,  0.0446, -0.0701,\n",
       "                      -0.1320,  0.0219, -0.0904, -0.0431, -0.0916, -0.1925, -0.0635, -0.2238,\n",
       "                      -0.0529,  0.0141, -0.1035,  0.0564, -0.1411, -0.0212, -0.0664, -0.0557,\n",
       "                       0.0637, -0.0119, -0.1433,  0.0779, -0.2859, -0.0032, -0.1625, -0.1571,\n",
       "                       0.0307, -0.2317, -0.0795, -0.0966, -0.0620, -0.1123, -0.1650, -0.0664,\n",
       "                      -0.2535, -0.2041, -0.0119, -0.2120,  0.0501, -0.1289, -0.0334, -0.2267,\n",
       "                      -0.2087,  0.0689, -0.1722, -0.0718, -0.1221, -0.2180, -0.1039, -0.2409,\n",
       "                      -0.2200, -0.2666, -0.2632, -0.1429,  0.0640, -0.2527, -0.2190, -0.1623,\n",
       "                      -0.1958, -0.1842, -0.0408, -0.2055, -0.0559, -0.1031, -0.1136, -0.1159,\n",
       "                      -0.0875, -0.0840, -0.1951, -0.1204, -0.2178, -0.1200, -0.0733, -0.0657,\n",
       "                      -0.0575, -0.0759, -0.0594,  0.1980, -0.0380, -0.1007, -0.2201, -0.1206,\n",
       "                      -0.0980, -0.1738, -0.1979, -0.2331, -0.1724, -0.0404, -0.2506,  0.0121,\n",
       "                      -0.0645, -0.0735, -0.2070,  0.0009, -0.0168, -0.2127, -0.0434, -0.1345,\n",
       "                      -0.1355,  0.0355, -0.1232, -0.2019, -0.0407, -0.0390, -0.0886, -0.0220,\n",
       "                      -0.2789,  0.0068,  0.0303, -0.2787,  0.0768, -0.0768, -0.1434, -0.0517,\n",
       "                       0.0261, -0.0836, -0.2358, -0.0392, -0.1161, -0.0739, -0.2411,  0.1225,\n",
       "                      -0.1954, -0.0265, -0.2133, -0.1112, -0.0832, -0.1341, -0.0034, -0.1881,\n",
       "                      -0.1017, -0.1241,  0.0874, -0.1381, -0.0968, -0.1534, -0.0946, -0.1030,\n",
       "                      -0.0614, -0.0642, -0.0575, -0.1722, -0.1947, -0.1181, -0.0045, -0.1085,\n",
       "                      -0.0987, -0.3023, -0.1982, -0.1968, -0.2336, -0.1405, -0.0392, -0.0594,\n",
       "                      -0.1305, -0.1232, -0.0382, -0.1792, -0.0462, -0.2119, -0.1601, -0.1024,\n",
       "                      -0.0639, -0.1671, -0.0691, -0.0156, -0.0839, -0.1696, -0.1363, -0.1851,\n",
       "                      -0.0279, -0.0425,  0.1027, -0.1417, -0.2268,  0.0479, -0.1200, -0.0639,\n",
       "                       0.1694, -0.0863, -0.0971, -0.1667, -0.1358, -0.1047, -0.0724, -0.2032,\n",
       "                      -0.1305, -0.0759,  0.0433, -0.1064,  0.0337, -0.2027, -0.2285, -0.0689,\n",
       "                      -0.2100, -0.1483, -0.0528, -0.0660, -0.2558, -0.0506, -0.1257, -0.0244,\n",
       "                      -0.0196,  0.1796, -0.0074, -0.0555,  0.0488, -0.0186, -0.0289,  0.0473,\n",
       "                      -0.1007, -0.0142,  0.0946,  0.0363,  0.0058, -0.1282, -0.0081,  0.0029,\n",
       "                       0.0093, -0.0129, -0.0282, -0.1248,  0.0565,  0.0142, -0.0023,  0.0805,\n",
       "                      -0.0248, -0.0117, -0.0270,  0.0603, -0.0165,  0.0251,  0.0566,  0.0616,\n",
       "                      -0.0008,  0.0172, -0.0621, -0.0450,  0.0574, -0.0793,  0.0429, -0.0017,\n",
       "                      -0.0551, -0.0435,  0.0817, -0.0321,  0.1269, -0.0185, -0.1035,  0.0456,\n",
       "                       0.0121, -0.0063,  0.0245,  0.0646,  0.0420, -0.0320, -0.0981, -0.0422,\n",
       "                       0.0041,  0.0156,  0.0907, -0.1071, -0.0465,  0.0697, -0.0385,  0.0803,\n",
       "                       0.0168,  0.0220, -0.1325,  0.0159,  0.0889, -0.0808,  0.0640,  0.0402,\n",
       "                       0.0709,  0.0028, -0.0607, -0.0255, -0.0008,  0.0259,  0.0515,  0.0231,\n",
       "                       0.0525,  0.0538, -0.0602, -0.0071, -0.0855, -0.0279, -0.0483, -0.0465,\n",
       "                      -0.0916,  0.0281, -0.0683,  0.0253, -0.0852,  0.0928, -0.0879,  0.0624,\n",
       "                      -0.0876,  0.0373,  0.0363,  0.0639,  0.0209,  0.0445, -0.0009, -0.0455,\n",
       "                       0.0370, -0.1364,  0.0434,  0.0286, -0.0751,  0.0629, -0.0356,  0.0395,\n",
       "                       0.0158,  0.0224,  0.0045, -0.1889,  0.0333, -0.0452, -0.0404, -0.0810,\n",
       "                       0.0363, -0.1319,  0.1058, -0.0019, -0.0238, -0.0098, -0.0165,  0.1016,\n",
       "                      -0.1752, -0.0746, -0.0296, -0.0999, -0.1642,  0.0565, -0.1317, -0.1406,\n",
       "                      -0.0511, -0.0996, -0.2135, -0.1751, -0.2624, -0.1015, -0.1272, -0.2122,\n",
       "                       0.0905, -0.1701, -0.0115, -0.1867,  0.0464, -0.0821, -0.1141, -0.2006,\n",
       "                      -0.1646,  0.0143, -0.1291, -0.0240,  0.0087, -0.1072, -0.0487, -0.1194,\n",
       "                      -0.1939, -0.1782, -0.2320, -0.0987, -0.0445, -0.0032, -0.1795,  0.0698,\n",
       "                      -0.1095, -0.0567, -0.2332, -0.1108, -0.2392, -0.0998,  0.0187, -0.1058,\n",
       "                      -0.3306, -0.2546, -0.1750, -0.0478, -0.1170, -0.1064, -0.0486, -0.0906,\n",
       "                      -0.2793, -0.0145,  0.0491,  0.0069, -0.0931, -0.2371,  0.0092, -0.1815,\n",
       "                       0.0765, -0.1006, -0.0519,  0.0281, -0.1377, -0.1415, -0.0923, -0.2438,\n",
       "                      -0.1405, -0.0163, -0.3021, -0.0809, -0.1786, -0.1449, -0.1030, -0.0480,\n",
       "                      -0.0604, -0.1574, -0.0927, -0.1178,  0.0106, -0.0301, -0.2062,  0.0176,\n",
       "                      -0.1592, -0.1765,  0.0645, -0.1398,  0.2527, -0.2379, -0.2086, -0.1535,\n",
       "                      -0.1674,  0.0461,  0.0956, -0.0588, -0.2316, -0.0491, -0.1541, -0.0993,\n",
       "                      -0.1428, -0.1455, -0.0990, -0.0833, -0.0435, -0.1035, -0.2795, -0.0701,\n",
       "                      -0.1893, -0.0816, -0.0930, -0.1672, -0.0675, -0.0217, -0.0093, -0.2084,\n",
       "                      -0.1864,  0.0145, -0.0468, -0.0944, -0.0292, -0.1359, -0.0785,  0.0180])),\n",
       "             ('bilstm_left_context_feature.weight_ih_l0_reverse',\n",
       "              tensor([[-0.1272, -0.2409,  0.2962,  ..., -0.1328,  0.1662, -0.1150],\n",
       "                      [ 0.6144,  0.4191,  0.0218,  ..., -0.3098,  0.3762, -0.1656],\n",
       "                      [-0.2675,  0.1249, -0.2993,  ...,  0.2916, -0.0297, -0.2461],\n",
       "                      ...,\n",
       "                      [ 0.1656, -0.2633, -0.1464,  ..., -0.1793, -0.2038, -0.2134],\n",
       "                      [ 0.2759,  0.4070,  0.0724,  ...,  0.0379, -0.3950,  0.0418],\n",
       "                      [-0.0654,  0.4617,  0.6106,  ...,  0.0361,  0.0433,  0.0430]])),\n",
       "             ('bilstm_left_context_feature.weight_hh_l0_reverse',\n",
       "              tensor([[-0.0133, -0.2156, -0.0405,  ...,  0.0516, -0.1039,  0.1771],\n",
       "                      [-0.0658, -0.2998,  0.0497,  ...,  0.1247, -0.0244, -0.0817],\n",
       "                      [ 0.0584,  0.4911, -0.3321,  ...,  0.1209, -0.1815,  0.1144],\n",
       "                      ...,\n",
       "                      [ 0.2330, -0.4226, -0.2294,  ...,  0.1849, -0.1269,  0.1523],\n",
       "                      [ 0.0297, -0.0758, -0.1086,  ..., -0.0513,  0.0133, -0.0876],\n",
       "                      [-0.0660,  0.1846, -0.0238,  ..., -0.2321, -0.1719, -0.1181]])),\n",
       "             ('bilstm_left_context_feature.bias_ih_l0_reverse',\n",
       "              tensor([ 3.3981e-02,  6.8112e-02, -9.6647e-02,  3.8794e-02,  1.5087e-01,\n",
       "                       8.2682e-02,  6.6975e-02, -4.0526e-02,  9.1434e-02,  6.4248e-02,\n",
       "                       3.0059e-02,  9.6348e-02,  8.3181e-02, -1.1460e-02, -1.4249e-01,\n",
       "                       7.1022e-02,  1.5558e-01, -1.5318e-01, -1.0348e-01, -6.8362e-02,\n",
       "                      -6.0324e-02,  5.1446e-02,  1.3649e-01, -1.2221e-01,  1.0647e-01,\n",
       "                       2.4139e-01, -1.7282e-01, -9.0446e-02, -3.8852e-02, -8.7189e-02,\n",
       "                       2.3902e-02,  1.3697e-01, -7.8413e-02, -2.0104e-02,  3.8422e-02,\n",
       "                      -3.4101e-02,  2.1892e-02, -1.0246e-01,  1.2713e-01,  1.7284e-01,\n",
       "                       1.4943e-02,  6.2394e-02,  4.6640e-02,  4.7135e-02,  4.5556e-02,\n",
       "                       1.3698e-01,  3.4444e-03,  4.9414e-02, -1.4290e-01, -6.4747e-02,\n",
       "                       6.3276e-03, -1.2193e-01,  9.6899e-02,  8.2550e-02,  1.3379e-02,\n",
       "                       1.0406e-01,  1.0150e-01,  1.0137e-01, -2.1246e-02, -4.1373e-02,\n",
       "                       1.9583e-01,  1.2432e-01,  4.4844e-02, -6.5476e-02,  9.7526e-03,\n",
       "                       1.3444e-05,  1.5090e-01,  2.5831e-02,  9.9562e-02,  1.3430e-01,\n",
       "                       8.4436e-02, -8.7210e-02, -9.8045e-02,  8.7437e-02,  1.0824e-01,\n",
       "                       5.6271e-02,  5.3236e-02,  1.4155e-01, -8.9513e-02, -2.2006e-02,\n",
       "                      -8.9052e-02,  1.1009e-01, -1.0544e-01,  8.9269e-02,  2.6294e-02,\n",
       "                      -1.5229e-01, -2.2545e-01, -1.5936e-02,  1.3476e-01,  4.6435e-02,\n",
       "                       6.8397e-02, -5.9770e-02, -1.1128e-01, -4.4142e-02,  6.6469e-02,\n",
       "                       6.7818e-02, -8.9964e-03,  5.0819e-02,  1.4369e-01,  1.0210e-01,\n",
       "                       7.7014e-02,  5.6721e-02,  7.5867e-02, -6.9909e-02, -5.3134e-02,\n",
       "                       1.7691e-02, -1.0580e-01,  5.2062e-02, -7.4592e-02, -2.8961e-02,\n",
       "                      -1.8307e-02,  2.0538e-01,  1.0876e-01,  1.2708e-01, -2.8658e-02,\n",
       "                       6.8376e-02,  2.1608e-02, -2.0456e-02, -1.4593e-01,  3.0585e-02,\n",
       "                       1.5123e-01, -1.6063e-01,  1.7943e-01,  5.0774e-02,  4.5912e-02,\n",
       "                       3.4387e-02, -9.8760e-03,  3.2001e-02, -1.0578e-01,  2.6920e-02,\n",
       "                      -1.3441e-01, -7.9683e-02,  1.0733e-01,  1.8135e-01, -1.1407e-02,\n",
       "                      -1.2277e-01, -3.2093e-02, -2.9853e-02, -1.3193e-01, -8.9918e-02,\n",
       "                       6.6338e-02, -3.8195e-02, -2.4542e-02, -1.0323e-01, -2.0968e-02,\n",
       "                      -1.0358e-01, -1.2719e-01, -4.5519e-02, -6.4683e-02, -1.3288e-01,\n",
       "                      -1.3047e-01, -2.5735e-02,  2.6326e-02, -9.2299e-02, -4.2892e-02,\n",
       "                       2.4589e-03, -1.0842e-01,  3.3083e-02,  2.2631e-02, -5.3753e-02,\n",
       "                       3.6531e-02,  4.5988e-03, -5.2816e-02, -2.1240e-02,  2.9030e-02,\n",
       "                       2.0428e-03,  9.6860e-02, -4.1783e-03, -4.7760e-02, -7.3929e-02,\n",
       "                      -5.7558e-02, -9.0348e-03, -2.3328e-02, -1.4337e-01, -2.6105e-01,\n",
       "                      -1.5037e-01, -8.8415e-02,  9.0029e-02, -5.4801e-02, -8.3251e-02,\n",
       "                       8.2745e-03,  4.3533e-02,  7.5288e-02,  1.7521e-01, -1.9152e-02,\n",
       "                      -5.2444e-03, -1.4492e-01, -5.3183e-02,  8.2069e-03, -1.9999e-01,\n",
       "                      -1.0613e-02, -9.6650e-02, -2.0522e-01, -9.7729e-02, -3.1087e-02,\n",
       "                      -9.1680e-02,  4.1274e-02,  3.5717e-02, -7.0380e-02,  1.4523e-01,\n",
       "                       1.7757e-01, -8.5299e-02, -1.6463e-01, -1.3580e-01,  7.3771e-02,\n",
       "                      -9.5243e-02, -3.3095e-01, -1.0118e-01,  4.7163e-02, -1.4970e-01,\n",
       "                      -2.3085e-01, -3.9495e-02, -1.6818e-01,  6.9763e-02, -5.9091e-02,\n",
       "                      -1.1073e-01, -1.0786e-01, -2.8562e-02, -1.6827e-01, -1.3484e-01,\n",
       "                      -1.3658e-01, -1.4649e-01, -1.8873e-01, -2.2857e-02, -3.1683e-02,\n",
       "                      -4.1658e-02, -1.5981e-01, -2.2253e-01, -3.8436e-02, -1.8076e-01,\n",
       "                      -1.0450e-01, -4.9446e-02,  5.9170e-02, -1.4108e-01, -1.1026e-01,\n",
       "                      -1.7897e-01, -3.8672e-02,  4.0356e-02, -1.5222e-01, -3.1103e-02,\n",
       "                      -1.3922e-02, -1.1929e-01, -4.4806e-02, -1.4063e-01,  5.1768e-03,\n",
       "                      -8.9373e-02,  1.0878e-01, -3.9692e-02, -3.5795e-02,  6.4337e-02,\n",
       "                       2.0963e-02, -1.3465e-01, -1.2410e-01, -5.4187e-02, -6.5833e-02,\n",
       "                      -2.7612e-01,  6.1034e-02, -2.4670e-02,  2.0608e-02,  5.3529e-02,\n",
       "                       5.6326e-02,  1.0463e-01,  1.3916e-01,  1.0461e-01,  5.6150e-02,\n",
       "                       4.7417e-02, -3.6370e-02,  9.6193e-02,  7.3858e-02,  3.4916e-02,\n",
       "                      -8.9534e-02,  3.4503e-02,  6.9980e-02, -7.9220e-03,  3.0915e-02,\n",
       "                      -8.6289e-02, -1.3935e-02, -1.1523e-02, -1.8391e-03,  3.4934e-02,\n",
       "                       9.2043e-02, -8.0866e-02, -8.0439e-03,  4.9106e-03,  5.6164e-02,\n",
       "                       8.7707e-03,  1.1023e-01, -3.1635e-02,  2.5416e-02, -2.9730e-02,\n",
       "                      -1.4349e-02,  2.6959e-02,  4.0271e-02, -8.3653e-02, -4.4208e-03,\n",
       "                      -3.8084e-02,  7.4850e-02, -2.6079e-02,  4.4488e-02, -1.0726e-01,\n",
       "                       9.3595e-02,  8.9238e-02, -3.0889e-02, -5.0851e-02, -2.8497e-02,\n",
       "                       1.5113e-02, -8.6299e-03, -1.0726e-01,  9.0240e-02, -9.6275e-02,\n",
       "                      -9.8421e-02, -1.0340e-01,  3.1440e-03, -6.4645e-02, -7.8036e-02,\n",
       "                      -3.2137e-03,  4.0638e-02,  8.8741e-02,  2.9515e-02,  3.5315e-02,\n",
       "                      -1.8863e-02, -4.0649e-02,  1.1031e-01, -2.9237e-02,  3.3107e-02,\n",
       "                      -1.5840e-02,  6.8125e-02, -1.0519e-01,  5.6886e-02,  3.6924e-02,\n",
       "                       8.7469e-02,  4.1002e-02,  8.3906e-03, -6.6964e-02,  1.4959e-03,\n",
       "                       4.2583e-02, -5.2942e-03,  1.5305e-02, -5.0280e-02,  5.9685e-02,\n",
       "                       2.3875e-02, -2.0313e-02,  1.9082e-02,  2.5765e-03, -1.0616e-01,\n",
       "                      -6.1217e-02,  1.5906e-02, -2.7237e-02, -1.3373e-01, -5.8495e-03,\n",
       "                       1.9098e-03,  3.9247e-02,  8.7116e-02,  8.9156e-03, -6.6156e-02,\n",
       "                      -5.1504e-02,  1.1597e-01, -6.3804e-02, -1.0632e-02, -5.5474e-02,\n",
       "                      -2.1067e-02,  2.6988e-02, -3.9549e-02,  3.6581e-02,  4.0143e-02,\n",
       "                       5.6120e-02,  2.0427e-02, -1.8516e-01, -2.3997e-02, -7.0051e-02,\n",
       "                       8.1835e-02, -1.5299e-02,  8.4273e-02, -5.8154e-02, -5.5231e-02,\n",
       "                       6.1639e-02,  1.7569e-02,  2.4727e-02,  4.4716e-02, -1.1438e-01,\n",
       "                      -7.0335e-02,  7.7132e-02, -8.7789e-02,  1.5082e-03,  6.0150e-02,\n",
       "                       2.6335e-02, -1.8432e-01,  7.2338e-02,  1.2379e-01, -1.1246e-01,\n",
       "                       3.0537e-02, -9.3258e-02, -7.2371e-02,  4.6161e-02,  9.4710e-02,\n",
       "                       7.9346e-02, -1.3992e-01, -1.3002e-01,  3.1147e-02, -1.5163e-01,\n",
       "                       1.4458e-01, -1.1464e-01, -3.1393e-02, -1.1745e-02, -1.8703e-02,\n",
       "                      -1.9926e-03,  1.2544e-01, -1.1746e-01,  5.7584e-02,  1.4195e-01,\n",
       "                      -5.4685e-02,  8.9641e-02, -6.0394e-02,  2.2817e-02,  1.6655e-01,\n",
       "                       1.5866e-01, -1.2183e-02, -1.6113e-01,  2.5967e-01,  5.4556e-02,\n",
       "                      -7.2017e-02, -1.8512e-03,  1.5774e-01,  3.6492e-01,  5.4867e-02,\n",
       "                       9.4672e-03,  6.8441e-02,  8.5763e-02,  1.3782e-02,  1.7264e-01,\n",
       "                      -2.8158e-02, -3.1522e-02, -4.6082e-02, -4.1184e-03,  2.0927e-02,\n",
       "                       1.3436e-02,  1.1821e-01, -7.7395e-02, -5.1540e-02,  9.5574e-02,\n",
       "                      -5.6252e-02,  1.2660e-01,  1.0748e-01, -1.1101e-01,  2.6947e-02,\n",
       "                       1.1097e-01,  8.4896e-02,  1.7655e-02,  6.9866e-02,  4.2423e-02,\n",
       "                       5.5650e-02,  9.4793e-02,  8.8548e-02,  1.5303e-01, -6.4297e-02,\n",
       "                       2.1676e-01,  2.3632e-02,  1.7380e-02,  8.4614e-02, -8.1475e-02,\n",
       "                       6.2240e-02,  4.4674e-02,  5.1956e-02,  8.3314e-02, -7.7768e-02,\n",
       "                      -3.6125e-03, -1.6026e-01,  8.0034e-02,  1.8268e-01, -8.2013e-02,\n",
       "                      -1.1225e-01,  1.9718e-02,  9.7956e-02, -4.7743e-02, -9.4763e-02,\n",
       "                      -3.3477e-02,  7.5761e-02, -1.1605e-01, -7.3861e-02, -8.9377e-03,\n",
       "                       4.0372e-04,  9.0203e-02,  1.8682e-01, -3.1086e-02,  1.4633e-01,\n",
       "                       1.8003e-01, -1.8554e-01,  3.2119e-02, -1.7347e-02, -1.0502e-01,\n",
       "                      -4.2161e-02, -7.2782e-02, -3.5397e-02,  1.7375e-01,  7.4083e-02,\n",
       "                       1.0641e-01,  1.1080e-02,  8.0429e-02, -1.2718e-01, -6.8840e-02,\n",
       "                       9.2461e-02,  5.4413e-02,  9.7074e-02, -2.1320e-02,  2.1540e-01,\n",
       "                       2.2774e-02,  7.0496e-02,  4.5018e-02,  7.4989e-02,  5.9862e-02,\n",
       "                       1.8679e-02,  4.6876e-02])),\n",
       "             ('bilstm_left_context_feature.bias_hh_l0_reverse',\n",
       "              tensor([-9.9625e-02,  1.3685e-01, -9.5867e-03,  3.9049e-02,  1.8178e-01,\n",
       "                       9.1322e-02, -9.2241e-02, -1.7675e-01,  5.4078e-02,  1.0401e-01,\n",
       "                      -8.2380e-02,  1.5800e-01, -2.6487e-02, -9.2362e-02, -6.6966e-02,\n",
       "                      -4.7850e-02,  1.1208e-01, -1.1755e-01, -1.9056e-01,  2.5444e-02,\n",
       "                      -7.7406e-02, -3.3551e-02,  1.0781e-01, -7.6661e-02, -1.4468e-02,\n",
       "                       1.2893e-01, -4.9755e-02, -1.2148e-01, -1.0119e-01,  1.2998e-01,\n",
       "                       6.4428e-02,  1.0143e-01, -1.1169e-02,  6.2889e-02,  1.7536e-01,\n",
       "                      -3.1031e-02,  1.4911e-02, -7.9054e-03, -1.8275e-02,  6.9067e-02,\n",
       "                       1.0590e-01,  2.1359e-01,  1.0770e-02, -4.3460e-02,  9.5004e-02,\n",
       "                       1.4012e-01,  2.5258e-02,  3.2842e-02, -4.2551e-02,  4.3994e-02,\n",
       "                      -1.8934e-02, -2.6914e-01,  1.9367e-01, -6.7625e-02, -1.2301e-02,\n",
       "                       1.0196e-01,  8.6531e-02,  1.6195e-02,  6.4166e-03, -1.3115e-01,\n",
       "                       1.0969e-01,  2.0753e-01,  1.4533e-01,  3.3433e-03,  1.1269e-01,\n",
       "                       8.9734e-02,  6.4159e-02,  1.5680e-01,  4.1900e-02,  2.7498e-01,\n",
       "                       1.3023e-01,  5.2336e-02, -5.6948e-02,  1.2874e-01,  9.9928e-02,\n",
       "                       2.6336e-02,  5.3962e-02,  8.0506e-02, -1.1919e-01,  3.6500e-02,\n",
       "                      -1.8477e-02,  3.2359e-02, -2.0654e-01,  3.6799e-02,  1.7735e-01,\n",
       "                      -8.4642e-02, -6.5783e-02,  4.6204e-02,  2.5403e-02,  2.2527e-02,\n",
       "                      -9.5947e-02, -4.4948e-02, -1.0704e-01,  2.8020e-03,  4.8107e-02,\n",
       "                      -3.0401e-02,  5.5728e-02, -6.8218e-03,  1.6543e-01,  1.3388e-01,\n",
       "                       1.8219e-01,  7.9904e-02, -3.0288e-02, -4.5160e-03,  1.2582e-02,\n",
       "                       2.3444e-03, -8.1452e-02, -3.7723e-02, -4.5315e-02, -1.0756e-01,\n",
       "                       8.3146e-02,  2.0897e-01,  1.0559e-01,  5.4046e-02,  3.9311e-02,\n",
       "                      -2.6382e-02, -3.0880e-02,  9.0802e-02,  1.1556e-02, -2.8851e-03,\n",
       "                       1.0046e-01, -1.9108e-01,  1.3052e-01,  5.4997e-03,  5.8173e-02,\n",
       "                       3.3766e-02,  2.9926e-02, -1.2831e-02, -3.6374e-02, -7.8080e-02,\n",
       "                      -4.7439e-02, -8.5231e-02, -3.0330e-02, -2.9772e-02, -1.0635e-01,\n",
       "                      -3.3279e-02, -7.5164e-02, -1.5596e-01, -1.3006e-01, -1.9022e-01,\n",
       "                      -5.1485e-02, -8.9019e-02, -1.3434e-02, -2.4872e-02,  8.7910e-02,\n",
       "                       3.4344e-03, -1.6485e-01, -6.6309e-02, -1.3096e-01, -5.0910e-02,\n",
       "                      -1.3342e-01, -1.5857e-02, -5.2351e-02, -9.6043e-02, -9.1886e-02,\n",
       "                      -6.7431e-02, -4.8649e-02,  3.7786e-03, -4.8667e-02,  6.4443e-03,\n",
       "                       1.0057e-01,  6.4460e-04, -9.8437e-02, -6.7363e-02,  2.1522e-02,\n",
       "                      -6.0247e-02, -4.6151e-02, -1.1754e-01, -1.2800e-01, -4.4433e-02,\n",
       "                       1.7190e-02,  9.2551e-02, -8.5192e-02, -7.6281e-02, -1.9532e-01,\n",
       "                      -7.0287e-02,  1.0951e-01,  5.0972e-02, -8.9339e-02, -2.9296e-02,\n",
       "                       3.9649e-03,  5.3169e-02,  1.6518e-02,  6.5215e-02, -8.0233e-02,\n",
       "                      -1.8951e-02, -6.9237e-02, -4.3061e-02, -4.4176e-02, -1.6645e-01,\n",
       "                      -4.1249e-03, -5.7933e-02, -9.4796e-02, -1.4656e-01, -9.9971e-02,\n",
       "                      -1.4669e-01,  4.5946e-02, -1.0197e-01,  6.3572e-02, -6.2588e-03,\n",
       "                       1.0755e-01, -1.0297e-01, -1.2515e-01, -1.0725e-02, -5.0123e-02,\n",
       "                      -1.3062e-02, -9.8392e-02, -1.0257e-01,  9.0949e-02, -2.6073e-01,\n",
       "                      -2.5513e-01, -1.3081e-01, -2.9439e-02, -1.0191e-01,  4.5406e-02,\n",
       "                       2.9266e-02, -4.4188e-02, -2.5312e-02, -1.2150e-01, -1.2633e-02,\n",
       "                      -1.3792e-01, -1.0995e-01, -1.8031e-01, -8.1564e-02, -7.9303e-02,\n",
       "                       9.4338e-02, -9.1487e-02, -1.0778e-01,  6.7079e-02, -9.6776e-02,\n",
       "                      -5.1516e-02,  4.1204e-02, -2.6604e-01, -6.2489e-02, -9.2003e-02,\n",
       "                      -8.2555e-02, -7.9664e-02, -7.7021e-02,  3.7593e-02, -4.7969e-02,\n",
       "                      -9.6007e-02, -9.2605e-02, -2.9104e-03, -5.8281e-02, -1.3296e-01,\n",
       "                      -1.9210e-01, -4.2441e-02, -4.4104e-02, -1.1049e-01, -1.3491e-01,\n",
       "                      -4.9522e-02, -1.0405e-01, -1.2234e-01, -1.3366e-01, -4.3041e-02,\n",
       "                      -2.3762e-01,  3.5159e-02,  9.5082e-02,  5.8052e-02,  1.1430e-02,\n",
       "                       1.4740e-02,  9.5391e-02,  2.0629e-03, -2.9404e-02,  7.1242e-02,\n",
       "                      -1.6584e-01, -1.3958e-02,  3.3510e-02, -9.1583e-02, -3.3518e-02,\n",
       "                       5.4711e-03, -2.5902e-02,  8.6263e-02, -2.7059e-02,  9.9894e-03,\n",
       "                      -2.1739e-03,  5.2307e-02, -8.9732e-02,  1.0474e-01,  5.5299e-02,\n",
       "                       9.3623e-02,  1.7918e-02,  2.0108e-02, -5.1175e-02,  9.4534e-03,\n",
       "                      -8.9900e-03,  5.1875e-02, -1.0837e-02, -4.7881e-02,  1.5820e-01,\n",
       "                       2.3686e-02, -5.7708e-02, -4.0014e-02, -5.0833e-02,  3.0886e-02,\n",
       "                       1.0408e-02,  5.9711e-02,  1.5773e-02, -4.2279e-02, -8.6697e-02,\n",
       "                       4.0896e-02,  6.1115e-02, -1.3284e-02, -7.5455e-02,  6.8902e-02,\n",
       "                       1.0945e-02, -4.4519e-02,  3.5815e-02,  4.5781e-02, -7.9051e-02,\n",
       "                      -5.0231e-02,  4.4733e-02, -2.6830e-03,  2.7889e-02,  2.8489e-02,\n",
       "                       9.7198e-02, -8.0894e-03,  8.7709e-02, -3.6218e-02,  2.9100e-02,\n",
       "                       3.0326e-02, -9.2729e-03,  7.6796e-02,  6.9199e-02,  9.0507e-02,\n",
       "                       1.7087e-01,  3.7876e-02,  2.8238e-02,  8.4127e-02,  5.7529e-02,\n",
       "                       5.1315e-02,  8.1072e-03, -3.6497e-02, -1.6436e-03, -2.8520e-02,\n",
       "                      -9.0935e-03,  1.8788e-02,  3.1591e-02,  1.1249e-02, -5.8462e-02,\n",
       "                       4.7843e-03,  5.9995e-02, -6.9625e-02,  4.9939e-02, -3.9909e-02,\n",
       "                      -7.8929e-02, -1.8451e-02, -3.8372e-03,  7.7565e-03,  6.3957e-02,\n",
       "                       2.5260e-03,  3.4237e-02, -8.0306e-02,  6.4180e-02, -3.4036e-02,\n",
       "                      -7.3292e-02,  8.6053e-02, -3.6504e-02, -7.1704e-02, -1.4857e-01,\n",
       "                       8.2966e-02,  9.5284e-02, -1.3905e-02, -8.6825e-02, -2.0825e-02,\n",
       "                      -9.5937e-02, -1.4314e-01, -1.3384e-01,  6.8696e-02,  2.1318e-02,\n",
       "                      -4.6051e-02, -1.6908e-02,  3.0165e-02, -1.0275e-01,  4.0371e-02,\n",
       "                       1.1818e-03,  2.5050e-02,  9.5667e-02,  5.7938e-02,  8.0618e-02,\n",
       "                      -2.5045e-02, -1.7364e-03, -4.6054e-02,  1.7924e-02, -8.5182e-02,\n",
       "                       1.0171e-01, -4.8541e-02,  3.7454e-02, -3.5765e-02, -1.3290e-02,\n",
       "                      -4.8728e-02,  1.7578e-03,  1.3665e-02,  1.1859e-01,  9.3094e-02,\n",
       "                       1.1605e-01, -3.9175e-02,  7.3144e-02,  4.1972e-02,  3.9354e-04,\n",
       "                       1.3808e-01, -9.4040e-02, -3.8484e-02, -3.1612e-02, -3.1747e-02,\n",
       "                      -6.7100e-02,  8.1345e-02, -1.2161e-01,  2.4355e-02,  1.0560e-01,\n",
       "                      -7.9935e-02,  8.1701e-02, -1.0952e-01,  7.0352e-02,  3.9615e-02,\n",
       "                       1.5255e-01, -4.5447e-02,  4.6445e-02,  2.5788e-01,  1.1998e-02,\n",
       "                       4.7879e-04,  4.7359e-03,  1.5046e-01,  2.8935e-01, -4.7432e-02,\n",
       "                       9.6285e-02, -9.0328e-02, -7.5681e-03,  2.2633e-02,  8.8872e-02,\n",
       "                       4.5666e-02, -4.5370e-02, -8.6392e-02,  1.0181e-01, -1.7120e-01,\n",
       "                      -1.1126e-01,  1.2322e-01, -6.4728e-02,  1.5579e-02,  8.9040e-02,\n",
       "                      -4.0547e-02,  4.9303e-02, -3.3866e-02, -9.9377e-02,  1.3104e-01,\n",
       "                       2.8252e-01, -3.3324e-02, -3.2687e-02,  9.7650e-02,  1.2717e-01,\n",
       "                      -8.8559e-03,  1.3106e-01, -1.8568e-02,  2.1980e-01,  6.5718e-02,\n",
       "                       2.1204e-01,  8.4683e-02,  3.2023e-02,  2.0053e-01, -3.9712e-02,\n",
       "                       1.8890e-01,  1.5912e-01, -1.0155e-01,  1.4723e-01, -5.7471e-02,\n",
       "                      -3.9178e-02, -1.0292e-01,  8.7147e-02,  8.2336e-02, -1.6698e-01,\n",
       "                       8.8397e-03,  1.1272e-01,  1.4939e-01,  7.5200e-02,  2.6857e-02,\n",
       "                      -8.7355e-02, -1.0197e-01, -7.0323e-02,  4.2045e-02,  5.3050e-02,\n",
       "                      -1.6155e-01,  4.7410e-02,  1.3785e-01, -6.1981e-02,  7.9495e-02,\n",
       "                       1.4146e-01,  6.7042e-02, -9.3883e-02, -2.2111e-02,  3.7604e-02,\n",
       "                      -1.6485e-02,  1.0830e-02, -1.9192e-02, -2.1604e-02, -4.0723e-03,\n",
       "                       1.4757e-01,  6.7670e-02, -5.1873e-05, -3.5374e-02,  6.8941e-03,\n",
       "                      -6.3372e-02,  2.0491e-05,  7.9693e-02,  4.9602e-02,  1.4310e-01,\n",
       "                       7.1315e-02,  2.4450e-01,  1.7547e-03,  1.2402e-01,  7.1325e-02,\n",
       "                      -6.2703e-02, -4.8153e-02])),\n",
       "             ('bilstm_oov_context_feature.weight_ih_l0',\n",
       "              tensor([[-0.7568, -0.1422,  0.4381,  ..., -0.1241, -0.3408, -0.2980],\n",
       "                      [-0.2724,  0.1494, -0.2181,  ..., -0.3246,  0.3699, -0.3492],\n",
       "                      [ 0.4038,  0.2154, -0.1154,  ...,  0.8716,  0.1251,  0.1346],\n",
       "                      ...,\n",
       "                      [-0.5896,  0.7351, -0.0764,  ...,  0.2921, -0.0702, -0.3354],\n",
       "                      [-0.6361,  0.1565, -0.3855,  ..., -0.4083,  0.3003, -0.2951],\n",
       "                      [-0.0694,  0.2734, -0.0380,  ...,  0.0951, -0.2338,  0.1425]])),\n",
       "             ('bilstm_oov_context_feature.weight_hh_l0',\n",
       "              tensor([[ 0.1505,  0.1046, -0.0953,  ..., -0.0345, -0.1537, -0.1652],\n",
       "                      [ 0.2475, -0.0150, -0.1326,  ...,  0.0528, -0.0943,  0.0515],\n",
       "                      [ 0.2002,  0.3032,  0.1961,  ...,  0.3206,  0.1137, -0.0317],\n",
       "                      ...,\n",
       "                      [ 0.0259, -0.1460, -0.1491,  ...,  0.1461, -0.0036, -0.1468],\n",
       "                      [-0.0575,  0.0550, -0.0394,  ...,  0.0993, -0.0008, -0.2876],\n",
       "                      [ 0.1362,  0.0396, -0.2084,  ...,  0.2746, -0.3916, -0.2139]])),\n",
       "             ('bilstm_oov_context_feature.bias_ih_l0',\n",
       "              tensor([-2.1481e-02, -1.0883e-01, -7.3559e-02, -1.2595e-01, -1.4521e-01,\n",
       "                      -2.0831e-01, -7.5015e-02, -1.4919e-01, -1.2537e-02, -1.3786e-01,\n",
       "                      -1.3306e-01, -9.5667e-02, -1.5070e-01, -2.4486e-01, -1.2356e-01,\n",
       "                      -1.2022e-01, -2.0492e-01, -7.2807e-02, -1.5779e-02, -1.3445e-01,\n",
       "                      -1.5805e-01, -1.5257e-01, -1.8847e-01, -8.1070e-02, -1.2576e-01,\n",
       "                      -2.0469e-01, -2.2506e-01, -5.6704e-02, -8.3839e-02, -6.1137e-02,\n",
       "                      -2.0740e-03, -1.5600e-01, -1.2425e-01, -1.0076e-01, -6.2236e-03,\n",
       "                      -1.4400e-01, -2.3346e-01, -8.7787e-02, -8.1155e-02, -1.9153e-01,\n",
       "                      -1.3211e-01, -2.0019e-01, -6.2638e-02, -2.5385e-01, -1.7110e-01,\n",
       "                      -1.4627e-01, -5.8647e-02, -9.7205e-02, -1.2428e-01, -7.0555e-02,\n",
       "                      -1.2421e-01, -8.1416e-02, -3.1746e-01, -1.0328e-01, -1.2428e-01,\n",
       "                      -1.1778e-01, -3.8811e-01, -2.5726e-01, -8.1866e-02, -1.2697e-01,\n",
       "                      -3.4751e-02, -4.9439e-03, -7.9990e-02, -7.5097e-02, -1.0627e-01,\n",
       "                      -4.8058e-02, -6.6548e-02, -2.5835e-01, -2.6078e-01, -2.4455e-01,\n",
       "                      -3.7783e-01, -1.3017e-01, -2.1234e-01, -1.3951e-01, -1.5787e-01,\n",
       "                      -1.5555e-01, -1.7535e-01, -2.1414e-01, -1.8830e-01, -8.3946e-02,\n",
       "                      -1.4412e-01, -7.6675e-02, -1.8266e-01, -1.5698e-01, -9.9021e-02,\n",
       "                      -2.1943e-01, -1.4288e-01, -1.4068e-01, -1.8714e-01, -1.6680e-01,\n",
       "                      -2.8568e-02, -1.3636e-01, -5.4761e-02, -7.5220e-03, -2.0341e-01,\n",
       "                      -1.5248e-01, -2.2079e-01, -2.1394e-01, -8.2516e-02, -1.6070e-01,\n",
       "                      -1.3565e-01, -7.5137e-02, -1.4044e-01, -2.1802e-01, -1.5699e-01,\n",
       "                      -1.0266e-01, -1.7319e-01,  1.1934e-01, -1.1259e-01, -1.1400e-01,\n",
       "                      -1.0302e-01, -1.0670e-01, -1.2521e-01, -1.1237e-01, -2.0126e-02,\n",
       "                      -1.7470e-01, -3.0104e-01, -8.9188e-02, -1.1969e-01, -1.0029e-01,\n",
       "                      -1.1343e-01, -8.8730e-02, -1.7258e-01, -1.1648e-01, -2.6431e-02,\n",
       "                      -1.6991e-01, -1.0246e-01, -1.0802e-01, -1.0444e-01,  1.2279e-01,\n",
       "                      -8.1535e-03, -2.8662e-02, -1.5119e-01, -9.0113e-02, -1.4753e-01,\n",
       "                      -8.2737e-02,  1.7201e-01, -1.0739e-01,  1.8719e-02, -8.1017e-02,\n",
       "                      -7.3561e-02, -1.1259e-01, -5.5353e-02, -8.0357e-02, -2.1410e-01,\n",
       "                      -1.0331e-01, -1.7388e-01, -1.1031e-01, -3.5424e-02, -2.7578e-02,\n",
       "                      -5.0468e-02, -2.2943e-01, -2.1966e-01, -3.3340e-02, -1.6784e-01,\n",
       "                      -5.1241e-02, -1.9934e-01, -2.4236e-01, -1.2747e-01,  9.8690e-02,\n",
       "                      -6.1037e-02, -1.2433e-01, -2.1635e-02, -1.5542e-01, -1.1353e-02,\n",
       "                      -3.2176e-01, -3.4367e-02, -5.6842e-02, -1.1624e-01, -3.4135e-02,\n",
       "                      -1.1518e-01, -9.1163e-02,  5.5414e-02, -1.1422e-01, -1.9869e-01,\n",
       "                      -5.5454e-02, -1.3473e-01, -1.2193e-01, -9.5549e-02, -5.1620e-02,\n",
       "                      -5.5139e-02, -6.6500e-02, -5.7561e-02, -1.1940e-01, -1.8373e-01,\n",
       "                      -4.1072e-02, -1.0744e-01,  4.2373e-02,  5.2647e-02, -1.0208e-01,\n",
       "                       1.5771e-03,  1.7572e-01,  1.4415e-01, -1.6222e-01,  1.3840e-03,\n",
       "                       5.9724e-02, -2.1760e-01, -4.0331e-02, -1.4195e-01, -1.1937e-01,\n",
       "                      -9.0203e-02, -2.7020e-03,  8.9019e-03,  5.7506e-02, -2.3986e-01,\n",
       "                      -1.3769e-01, -1.6634e-01, -2.5896e-02,  3.2610e-03, -4.0473e-02,\n",
       "                      -3.5946e-02, -1.4092e-01, -2.2113e-02, -2.0276e-01, -1.0925e-01,\n",
       "                      -2.2497e-02, -1.0923e-01, -1.5448e-01, -7.4722e-02, -9.2891e-02,\n",
       "                      -1.8861e-01,  1.0059e-01, -1.7892e-01, -8.3152e-02, -4.5558e-02,\n",
       "                      -2.6509e-01, -2.1711e-01, -1.4535e-01, -1.5675e-01,  5.7300e-02,\n",
       "                      -4.7517e-02, -1.9388e-01, -2.2558e-01, -6.4629e-02, -6.5988e-02,\n",
       "                       1.1486e-01, -2.5203e-01, -1.6313e-01, -9.9949e-02, -9.0801e-02,\n",
       "                      -2.3211e-02, -1.7234e-01, -7.8796e-02, -8.8227e-02, -5.8277e-03,\n",
       "                      -7.3605e-02, -1.0061e-01, -1.7857e-01, -9.5977e-02,  6.3105e-02,\n",
       "                      -9.2473e-02, -7.7942e-02,  4.5105e-02,  1.1914e-01, -2.2762e-01,\n",
       "                      -1.1808e-01, -6.3555e-04,  6.8162e-02, -3.8720e-02, -1.6770e-01,\n",
       "                       2.8048e-02,  1.4129e-01,  4.7457e-02, -1.1200e-01,  2.0957e-02,\n",
       "                       2.4414e-02, -2.6483e-02,  7.4748e-02,  1.0469e-01,  6.5748e-02,\n",
       "                      -1.4236e-02, -9.5080e-04,  3.4300e-02, -3.2057e-02,  3.1831e-02,\n",
       "                      -6.3924e-02, -2.5411e-04,  9.3336e-02,  1.1021e-01,  6.0275e-02,\n",
       "                       7.9837e-02, -7.5420e-03,  3.8835e-02, -7.1946e-02,  1.9932e-02,\n",
       "                      -4.5271e-02,  6.0520e-02,  3.7202e-02,  7.2851e-02, -1.2491e-01,\n",
       "                       5.4432e-03, -1.1223e-01,  4.6721e-03, -4.3394e-02, -1.8903e-02,\n",
       "                       6.3693e-02, -1.2765e-01,  4.5442e-03, -3.5370e-03, -5.4097e-02,\n",
       "                       6.4390e-02, -7.4703e-02,  5.5250e-02, -2.1367e-02, -9.4929e-02,\n",
       "                      -9.6616e-02,  9.8680e-02, -1.4714e-02, -2.9337e-02, -1.6992e-01,\n",
       "                      -5.0791e-02,  1.5205e-01,  5.0844e-02, -1.1165e-02, -8.9942e-05,\n",
       "                       1.6112e-01,  1.3483e-02,  3.7268e-03, -6.0815e-02,  2.8607e-02,\n",
       "                       1.8708e-03,  6.7778e-02, -8.6769e-02, -2.6008e-02,  7.9607e-02,\n",
       "                      -3.0883e-03, -8.3128e-02,  9.9665e-02, -2.0905e-02, -1.2865e-01,\n",
       "                       1.1520e-01, -1.5890e-01,  1.7598e-01,  1.3822e-01, -3.1916e-02,\n",
       "                       3.3660e-02,  6.2831e-02, -1.1879e-01,  1.0755e-01,  7.2830e-02,\n",
       "                       1.7373e-02,  8.7111e-02,  3.9055e-02,  5.3109e-02,  1.5775e-02,\n",
       "                       7.9731e-03, -8.5795e-02,  7.9502e-02, -3.8255e-02, -2.2887e-02,\n",
       "                      -1.4099e-01, -2.0457e-02, -2.5139e-02, -1.8152e-01,  1.0261e-01,\n",
       "                      -8.5803e-03, -1.5560e-02,  3.5935e-02,  3.4886e-02, -6.6942e-02,\n",
       "                       2.8464e-02, -8.3974e-03,  3.0611e-02, -5.5438e-02,  3.4733e-02,\n",
       "                      -2.8103e-02,  1.1261e-01,  1.0185e-01,  5.6950e-02, -1.6245e-01,\n",
       "                       4.5703e-02,  2.8374e-02, -5.2363e-03,  2.5941e-02,  6.1528e-02,\n",
       "                      -4.6100e-02, -6.2006e-02,  1.1919e-01,  4.1650e-02, -1.8994e-02,\n",
       "                       5.4333e-02,  2.0318e-02,  9.6259e-02, -6.0786e-02, -2.3783e-01,\n",
       "                      -8.8418e-02, -9.2538e-02, -6.4593e-03, -1.6862e-01, -2.1565e-01,\n",
       "                      -2.9636e-02, -6.9016e-02, -3.9674e-02, -1.1688e-01, -1.7347e-01,\n",
       "                      -4.1549e-02, -8.1865e-02, -1.4925e-01, -6.6652e-02, -1.0743e-01,\n",
       "                      -2.6074e-01, -4.3207e-02, -1.4277e-01, -8.9110e-02, -1.6922e-01,\n",
       "                      -1.8941e-01, -1.9953e-01, -1.4400e-01, -2.9703e-01, -1.9979e-01,\n",
       "                      -3.5111e-01,  4.2576e-02, -1.9241e-01, -5.9209e-04, -1.5178e-01,\n",
       "                      -7.3787e-02, -4.7969e-02, -2.5702e-01, -5.2867e-02, -1.8161e-01,\n",
       "                      -1.3456e-01, -5.7298e-02,  1.7029e-02, -1.0230e-01, -1.2709e-01,\n",
       "                      -2.3432e-01,  1.6931e-02, -3.0834e-01,  1.8301e-02, -9.4740e-02,\n",
       "                      -1.2470e-01, -1.3719e-01, -1.4897e-01, -1.8795e-01, -1.2555e-01,\n",
       "                      -7.1269e-02, -2.3824e-01, -3.4961e-01, -9.8679e-02, -1.8697e-01,\n",
       "                      -3.4578e-01, -6.5489e-02, -4.7157e-02,  3.0154e-02, -1.2364e-01,\n",
       "                      -8.4641e-03, -1.1805e-01,  2.0843e-02, -1.7624e-02, -1.0500e-01,\n",
       "                       5.5308e-03, -2.8030e-01, -1.3230e-01, -6.1198e-02, -3.5068e-01,\n",
       "                      -4.7349e-02, -8.1472e-02, -3.9752e-02, -5.5548e-02, -1.5372e-01,\n",
       "                      -8.4765e-02, -1.4369e-01, -1.8380e-01, -1.6093e-02, -1.6499e-01,\n",
       "                      -7.6832e-02,  5.1307e-02, -8.0853e-02, -1.3172e-01, -1.3159e-01,\n",
       "                      -1.9051e-01, -1.3169e-01, -1.1547e-01, -1.7017e-01, -1.1278e-01,\n",
       "                      -1.8089e-01, -1.8746e-01, -1.7923e-01, -1.3464e-01, -1.6029e-01,\n",
       "                      -8.4826e-02, -7.4298e-02, -1.5617e-01, -8.8463e-02, -4.9343e-02,\n",
       "                      -8.0507e-02, -1.0783e-01, -9.6736e-02, -1.6472e-01, -3.1804e-02,\n",
       "                      -1.0542e-01, -7.8452e-02, -1.4527e-01, -1.6151e-01, -3.0436e-01,\n",
       "                      -2.0985e-01, -5.8249e-02,  7.0686e-02,  7.8108e-03, -4.8367e-04,\n",
       "                      -1.3219e-01, -2.0643e-01, -5.1338e-02, -1.9925e-01, -3.6455e-02,\n",
       "                       3.4233e-02, -1.9566e-01, -9.9808e-02,  3.8121e-02, -6.3209e-03,\n",
       "                      -9.9415e-02, -1.4190e-01])),\n",
       "             ('bilstm_oov_context_feature.bias_hh_l0',\n",
       "              tensor([-1.2980e-01, -7.7363e-02, -6.6897e-03, -3.6569e-02, -1.8158e-01,\n",
       "                      -1.6461e-01, -1.0723e-01, -1.2171e-01, -2.5357e-01, -2.3938e-01,\n",
       "                      -2.3194e-02, -2.6015e-01, -1.2362e-01, -1.8644e-01, -4.0347e-02,\n",
       "                      -1.4209e-01, -1.7939e-01, -3.0312e-02, -1.1347e-01, -1.0755e-01,\n",
       "                      -4.3032e-02,  2.4678e-02, -4.5824e-02, -2.1265e-01, -2.2063e-01,\n",
       "                      -2.0464e-01, -1.9467e-01, -2.5287e-02, -2.7688e-01, -1.6132e-01,\n",
       "                      -1.2893e-01, -1.5354e-01, -8.2832e-02, -2.2943e-01, -8.7834e-02,\n",
       "                      -1.6389e-01, -2.3157e-01, -2.9048e-02, -1.1027e-01, -1.6597e-01,\n",
       "                      -1.0576e-01, -8.9454e-02, -2.7743e-01, -1.5065e-01, -2.6721e-02,\n",
       "                      -8.8522e-02, -2.0192e-01, -1.9861e-01, -1.1396e-01, -1.7680e-01,\n",
       "                      -1.2710e-01, -1.1128e-01, -2.1466e-01, -2.1293e-01, -1.6888e-01,\n",
       "                      -1.6221e-01, -1.7802e-01, -1.2967e-01, -1.2839e-01, -9.0080e-02,\n",
       "                      -9.4809e-03, -4.4520e-02, -8.7080e-02,  4.3498e-02, -1.3037e-01,\n",
       "                      -1.2570e-01, -7.9590e-02, -1.7082e-01, -5.1203e-02, -2.4247e-01,\n",
       "                      -4.0127e-01, -1.4444e-02, -1.3797e-01, -7.0389e-02, -3.7457e-02,\n",
       "                      -4.5054e-02, -1.6776e-01, -2.0106e-01, -1.1717e-01, -9.5585e-02,\n",
       "                       7.3198e-02, -4.2018e-02,  3.0249e-02, -1.5495e-01, -4.6394e-02,\n",
       "                      -1.3940e-01, -1.2302e-01, -1.4187e-01, -1.8843e-01, -1.6611e-01,\n",
       "                      -8.3166e-02, -1.3149e-01, -2.2765e-01, -7.9410e-02, -1.9194e-01,\n",
       "                      -6.5029e-02, -2.6216e-01, -1.7308e-01, -1.1183e-01, -7.8831e-02,\n",
       "                      -9.6982e-02,  1.0009e-02, -1.4579e-01, -7.9204e-02, -2.0702e-01,\n",
       "                      -6.4767e-02, -2.9203e-02, -3.1057e-02, -6.9727e-03, -1.3998e-01,\n",
       "                      -1.5953e-01, -1.4992e-01, -1.8341e-01, -8.4396e-02, -8.9735e-02,\n",
       "                      -8.9858e-02, -1.6301e-01, -1.0162e-01, -1.2229e-01, -2.4172e-01,\n",
       "                      -5.9706e-02, -6.0641e-02, -1.2739e-01, -1.5193e-01, -7.5329e-02,\n",
       "                      -7.7343e-02, -1.2014e-01, -1.6640e-01, -1.1624e-01,  3.6111e-02,\n",
       "                       1.0189e-01,  1.5552e-02, -1.3274e-01,  9.6117e-04, -8.7110e-02,\n",
       "                      -1.6664e-01,  2.6412e-02,  3.7557e-04, -8.6843e-02, -1.3323e-01,\n",
       "                      -8.8207e-02, -2.6688e-02, -4.2845e-03, -3.7355e-02, -2.8900e-01,\n",
       "                      -8.1771e-02, -1.1457e-01,  4.6742e-02, -1.9845e-02, -9.2282e-02,\n",
       "                      -6.5913e-02, -3.3154e-01, -2.9271e-01, -1.5094e-02, -1.5762e-01,\n",
       "                       5.6302e-02, -1.1723e-01, -8.4641e-02, -1.4218e-01,  6.4672e-02,\n",
       "                       3.6291e-02, -8.6380e-02,  2.6988e-03, -2.1617e-01, -1.3818e-01,\n",
       "                      -2.9356e-01, -6.5153e-02, -1.0236e-01,  3.2330e-02, -1.1682e-01,\n",
       "                      -1.8558e-01, -7.3774e-02,  1.9970e-02, -5.7331e-02, -9.2824e-02,\n",
       "                      -8.4537e-02, -1.2838e-01, -6.9532e-02, -1.0897e-01, -5.9039e-02,\n",
       "                      -1.2044e-01, -5.2990e-02, -4.6451e-02, -1.7633e-01, -1.7697e-01,\n",
       "                      -2.5425e-02, -6.6163e-02, -1.8124e-03, -1.9573e-01, -9.9777e-02,\n",
       "                      -6.8409e-02,  2.2670e-02,  7.7317e-02, -1.0584e-01, -9.6100e-02,\n",
       "                      -1.2615e-01, -2.3237e-01, -1.2925e-01, -9.3840e-02, -6.2203e-02,\n",
       "                      -3.3606e-02, -6.1697e-02, -1.0615e-01,  5.7149e-02, -6.1544e-02,\n",
       "                      -1.2010e-01, -9.3755e-02, -1.7198e-01,  5.2660e-02, -8.8456e-02,\n",
       "                      -4.0258e-02, -1.5655e-01,  1.9981e-02, -1.3370e-01, -9.0802e-02,\n",
       "                      -4.7430e-02, -1.4873e-01, -1.3745e-01, -1.9855e-01, -8.2233e-02,\n",
       "                      -2.2023e-01, -1.4058e-01, -1.6855e-01, -1.0540e-01, -1.5288e-01,\n",
       "                      -1.3993e-01,  1.1054e-04, -1.7014e-01, -1.2817e-01, -1.0568e-01,\n",
       "                      -8.0742e-02, -1.7322e-01, -2.5678e-01, -5.4768e-02, -3.7266e-02,\n",
       "                       1.0788e-01, -1.9069e-01, -5.9954e-02, -4.7465e-02, -1.2544e-01,\n",
       "                      -1.4349e-02, -1.1402e-01,  3.3217e-02, -1.1867e-01, -3.1208e-02,\n",
       "                      -7.4343e-02, -1.9244e-01, -1.3597e-01, -4.7891e-02,  8.1383e-03,\n",
       "                      -4.7579e-02, -8.2201e-02, -4.2393e-02, -1.2374e-01, -5.2837e-02,\n",
       "                      -4.6254e-02, -9.6532e-02, -2.2704e-02,  3.5260e-02, -1.1747e-01,\n",
       "                      -3.6740e-02,  2.4092e-02, -5.8679e-02, -3.1284e-02,  5.0642e-02,\n",
       "                       2.4381e-02,  2.2520e-02, -5.3039e-02, -1.5463e-01,  2.8802e-02,\n",
       "                      -3.8044e-02, -1.5524e-02, -7.4809e-03,  1.0626e-01,  1.1475e-01,\n",
       "                      -1.7194e-02, -7.9625e-02, -5.0437e-02,  6.1539e-03,  5.6309e-02,\n",
       "                       3.0671e-02, -4.0614e-02,  4.7757e-02,  1.9313e-01,  4.7880e-02,\n",
       "                       1.4278e-02,  3.1317e-02, -7.6630e-02, -3.6116e-02, -6.4101e-02,\n",
       "                      -2.4434e-02, -3.4065e-02, -4.4968e-02, -1.2951e-03,  3.3939e-03,\n",
       "                       4.1773e-02,  3.5532e-02, -5.5805e-02, -4.1272e-02, -1.4210e-02,\n",
       "                       8.6580e-02, -9.3699e-02, -1.3549e-02, -1.7343e-02, -8.5985e-02,\n",
       "                       1.4870e-01, -1.3233e-01,  4.4059e-02,  2.4512e-02, -8.1493e-02,\n",
       "                      -9.1535e-03,  8.0606e-02,  1.8902e-02,  2.5292e-02,  4.4298e-02,\n",
       "                       2.1299e-01, -6.9743e-02, -5.3286e-02,  8.6490e-04, -2.7078e-02,\n",
       "                       7.0213e-02,  2.9484e-02, -9.6361e-03,  8.3071e-03,  9.1306e-02,\n",
       "                       4.4406e-03, -1.0765e-02, -5.6300e-02,  8.4525e-02, -1.3350e-01,\n",
       "                       6.1503e-02,  2.2765e-02, -1.0381e-01,  3.9295e-02,  7.7306e-02,\n",
       "                      -9.6782e-03,  1.7807e-04, -8.1303e-02,  1.1529e-03,  3.9058e-02,\n",
       "                       4.8340e-02, -1.6566e-02,  1.2634e-01, -4.6126e-02,  5.0432e-02,\n",
       "                      -8.4866e-03, -1.3229e-01,  6.8570e-03,  1.4661e-02,  7.2504e-02,\n",
       "                       5.2369e-03, -1.0526e-01, -6.8405e-02, -2.0505e-02, -1.6369e-02,\n",
       "                      -1.0669e-01,  8.0985e-02,  1.5443e-01, -6.1606e-02, -1.1509e-01,\n",
       "                       1.1427e-01,  6.5871e-02, -2.1438e-02,  2.8361e-02, -2.8606e-02,\n",
       "                      -1.0879e-01,  6.0737e-02, -2.8202e-02, -7.8692e-02,  1.0140e-02,\n",
       "                      -8.5351e-02, -2.8560e-02, -1.2429e-02, -6.0446e-02,  8.8870e-02,\n",
       "                      -8.5603e-03, -1.9083e-02,  1.4268e-01,  4.9193e-02, -6.6464e-02,\n",
       "                      -1.0908e-01, -1.3850e-02,  1.0340e-02,  8.8337e-03, -9.7802e-02,\n",
       "                      -7.5177e-02, -5.5044e-02,  1.8147e-02, -9.5187e-02, -1.0624e-01,\n",
       "                       9.4515e-03, -6.8215e-02, -1.1884e-01, -1.2074e-01, -9.1158e-02,\n",
       "                      -9.2569e-02, -6.3057e-02, -2.5768e-01, -1.4858e-01, -1.8193e-02,\n",
       "                      -1.8831e-01, -6.9936e-02, -1.5773e-01, -7.8775e-02, -1.2738e-01,\n",
       "                      -1.9279e-01, -1.3133e-01, -1.2146e-01, -1.7851e-01, -1.8707e-01,\n",
       "                      -2.5403e-01, -1.3770e-01, -1.1446e-01,  2.2296e-02, -1.9826e-01,\n",
       "                      -1.1435e-01, -3.4184e-02, -1.4961e-01, -9.2859e-02, -1.1509e-01,\n",
       "                      -1.0507e-01, -6.4277e-03,  5.8492e-02, -1.8717e-01, -9.1900e-02,\n",
       "                      -4.0187e-02, -1.4215e-01, -2.8064e-01, -4.7084e-02, -9.7187e-02,\n",
       "                      -2.6852e-01, -1.7048e-01, -1.0396e-01, -6.4532e-02, -7.6761e-02,\n",
       "                      -8.2563e-02, -9.7036e-02, -1.2526e-01, -4.0792e-03, -1.5874e-01,\n",
       "                      -2.2944e-01, -1.1114e-01, -1.2868e-01, -2.9190e-02, -5.6605e-02,\n",
       "                      -6.8341e-02, -1.7232e-02,  4.2566e-02, -9.5014e-02, -1.8051e-02,\n",
       "                      -1.1491e-01, -1.3684e-02, -1.1653e-01, -1.3360e-01, -2.9884e-01,\n",
       "                      -3.8069e-03, -1.9826e-01, -1.5713e-01, -8.2199e-03, -1.5453e-01,\n",
       "                      -1.6670e-01, -7.8619e-02, -2.3532e-01, -9.7507e-02, -1.8214e-01,\n",
       "                      -8.7841e-02, -1.1163e-01, -5.2164e-02, -6.6128e-02, -2.2062e-01,\n",
       "                      -1.8322e-01, -1.7350e-01, -1.3746e-01, -1.6824e-01, -1.7097e-01,\n",
       "                      -1.0559e-01, -1.4768e-01, -5.8045e-02, -2.7753e-02, -1.0784e-01,\n",
       "                      -1.6057e-01, -2.2601e-01, -1.3114e-01, -3.7120e-02, -4.2392e-02,\n",
       "                      -2.5263e-02, -4.7683e-02, -1.1513e-01, -2.1154e-01, -1.6836e-01,\n",
       "                      -8.0868e-02,  2.6897e-03, -1.2047e-01, -1.9417e-01, -1.7029e-01,\n",
       "                      -2.4256e-01, -2.6038e-01, -4.3145e-02,  2.1462e-01,  7.9056e-02,\n",
       "                      -2.0561e-01, -1.6825e-01, -4.7888e-02, -9.7728e-02,  4.3904e-02,\n",
       "                      -9.2225e-02, -1.8645e-01, -7.4284e-02, -3.3017e-02,  4.0065e-02,\n",
       "                      -4.6181e-02, -6.2844e-02])),\n",
       "             ('bilstm_oov_context_feature.weight_ih_l0_reverse',\n",
       "              tensor([[ 0.5170,  0.0248,  0.2038,  ...,  0.0524, -0.6420, -0.0583],\n",
       "                      [-0.5085,  0.1076,  0.0231,  ..., -0.1446,  0.0787, -0.2488],\n",
       "                      [ 0.7117,  0.0188,  0.8043,  ...,  0.0540,  0.0959,  0.0587],\n",
       "                      ...,\n",
       "                      [ 0.0752,  0.0886, -0.1353,  ..., -0.1203, -0.3986, -0.1226],\n",
       "                      [ 0.1722,  0.1226,  0.1452,  ...,  0.1986,  0.3245, -0.3721],\n",
       "                      [ 0.1272,  0.6511, -0.4162,  ...,  0.1863,  0.3422, -0.6373]])),\n",
       "             ('bilstm_oov_context_feature.weight_hh_l0_reverse',\n",
       "              tensor([[ 0.1197,  0.2748, -0.1877,  ..., -0.1915,  0.0198, -0.1351],\n",
       "                      [ 0.1605,  0.1581, -0.3203,  ...,  0.0177, -0.0704,  0.2285],\n",
       "                      [-0.1717,  0.1502, -0.1764,  ..., -0.0761,  0.2980,  0.3043],\n",
       "                      ...,\n",
       "                      [ 0.0559,  0.2767,  0.4045,  ...,  0.1184, -0.0410,  0.0380],\n",
       "                      [ 0.2936,  0.1820,  0.0286,  ..., -0.0522,  0.0334, -0.0197],\n",
       "                      [-0.2198, -0.0134, -0.0020,  ...,  0.5053, -0.0748, -0.1310]])),\n",
       "             ('bilstm_oov_context_feature.bias_ih_l0_reverse',\n",
       "              tensor([ 0.2635,  0.1724,  0.1644,  0.1759,  0.2032,  0.1171,  0.1371, -0.0098,\n",
       "                      -0.0560,  0.1320,  0.0917,  0.2080,  0.2568,  0.0650,  0.3234,  0.2025,\n",
       "                       0.2490,  0.1302,  0.0504,  0.0251,  0.0708,  0.1324,  0.1909,  0.4030,\n",
       "                      -0.0533,  0.1337,  0.1261,  0.2425,  0.0634,  0.2233,  0.0755,  0.3137,\n",
       "                       0.0801, -0.1079,  0.2385,  0.2439,  0.0966,  0.2252,  0.2238,  0.1497,\n",
       "                       0.1834,  0.1601,  0.1937,  0.0789,  0.3562,  0.1780,  0.0638,  0.1323,\n",
       "                       0.2667,  0.2112,  0.1357,  0.1269,  0.1138,  0.3366,  0.0958, -0.0748,\n",
       "                       0.1261,  0.2038, -0.0156,  0.2895,  0.0035,  0.0957,  0.0161,  0.2478,\n",
       "                       0.1001,  0.1473,  0.1954, -0.0145,  0.1172,  0.0847,  0.1126,  0.0745,\n",
       "                       0.0634,  0.2103,  0.0881,  0.1510,  0.0124, -0.0929,  0.1458,  0.2334,\n",
       "                       0.1722,  0.2717,  0.0832,  0.1022,  0.0548,  0.2823,  0.0197,  0.1627,\n",
       "                       0.0318,  0.0006,  0.0581,  0.1984,  0.2136, -0.0372,  0.1844,  0.0216,\n",
       "                       0.2367,  0.1499,  0.0597,  0.1136,  0.0871,  0.1332,  0.2603,  0.0887,\n",
       "                       0.0418,  0.2250,  0.1970,  0.2349,  0.1375,  0.3948,  0.3316, -0.0395,\n",
       "                      -0.0866,  0.0566,  0.2099,  0.1189,  0.0040,  0.1806, -0.1727,  0.2452,\n",
       "                       0.2981, -0.0199,  0.0788,  0.1462, -0.0473, -0.0794,  0.1561,  0.1772,\n",
       "                       0.1637,  0.1007,  0.0996,  0.1117, -0.0254,  0.0935, -0.0838, -0.0131,\n",
       "                       0.0433,  0.1473,  0.1069,  0.0284, -0.0336, -0.0451, -0.0452, -0.0402,\n",
       "                      -0.0044,  0.0180,  0.0651,  0.0244,  0.1133,  0.0020,  0.0238, -0.0800,\n",
       "                       0.1179, -0.0245,  0.0086,  0.0367,  0.1035, -0.0444,  0.0896,  0.1412,\n",
       "                      -0.0802,  0.0835,  0.1018,  0.0493, -0.0414, -0.1250,  0.0571,  0.1502,\n",
       "                       0.0807,  0.1104,  0.0691,  0.0881,  0.0915,  0.1421,  0.0104, -0.0053,\n",
       "                       0.0201,  0.0353,  0.1239,  0.0208, -0.0753, -0.0066,  0.0114,  0.0224,\n",
       "                       0.1282,  0.0343, -0.0336,  0.0479,  0.0600, -0.1457, -0.0430,  0.0352,\n",
       "                      -0.0604, -0.0857,  0.0256, -0.0194,  0.0548,  0.0409, -0.0053,  0.1266,\n",
       "                       0.0919,  0.0504,  0.1029,  0.0513,  0.0092,  0.0522,  0.0712,  0.1213,\n",
       "                       0.1852,  0.1452, -0.0034, -0.0670,  0.0884,  0.0905,  0.1234,  0.2151,\n",
       "                      -0.0489, -0.0799, -0.0545, -0.0802,  0.0073,  0.0295, -0.0539,  0.0815,\n",
       "                      -0.0302, -0.1460, -0.0528, -0.1792,  0.0195,  0.2815,  0.0432,  0.0631,\n",
       "                       0.0832,  0.0265,  0.0846,  0.0076,  0.2014, -0.2112,  0.0254, -0.0757,\n",
       "                      -0.0280,  0.1982, -0.0140,  0.0260,  0.1874,  0.1306,  0.0869,  0.1427,\n",
       "                       0.0903,  0.0850,  0.0797,  0.0053, -0.0807,  0.0964,  0.0470, -0.0169,\n",
       "                      -0.0469, -0.0180,  0.0370, -0.0151, -0.0638,  0.1763, -0.0081,  0.0424,\n",
       "                       0.0083,  0.0610,  0.0138,  0.0200,  0.0267, -0.0313,  0.0198,  0.0298,\n",
       "                      -0.0012, -0.0209,  0.0232,  0.0177,  0.0282,  0.0390,  0.1323, -0.0024,\n",
       "                       0.1287,  0.0775, -0.0862, -0.0170,  0.0787,  0.0943,  0.0980, -0.0103,\n",
       "                      -0.0658,  0.0737,  0.0161,  0.0104,  0.0360,  0.0581,  0.0271, -0.1712,\n",
       "                      -0.0012,  0.1018, -0.0055, -0.1005,  0.0676, -0.0069,  0.0364, -0.0489,\n",
       "                       0.0231, -0.0067,  0.0270,  0.0554,  0.0256, -0.0606, -0.2321, -0.0190,\n",
       "                       0.0259, -0.0516,  0.0095,  0.0579,  0.0247,  0.0376,  0.0409, -0.0863,\n",
       "                       0.0133,  0.0174, -0.0099, -0.0213, -0.0547, -0.0275, -0.0459, -0.1103,\n",
       "                      -0.0765, -0.0551,  0.0303, -0.1643,  0.1355,  0.0218,  0.0424,  0.1141,\n",
       "                      -0.0693, -0.1623, -0.0840,  0.0760,  0.1149, -0.1076,  0.0734, -0.0906,\n",
       "                      -0.0660, -0.1669, -0.0395,  0.1440,  0.0830, -0.0298,  0.0964,  0.0173,\n",
       "                      -0.0465,  0.0584, -0.0460,  0.0617,  0.0137, -0.0053, -0.0335, -0.1370,\n",
       "                       0.0450,  0.0077, -0.0823, -0.0172, -0.1205,  0.0120, -0.0334, -0.0041,\n",
       "                      -0.0182, -0.0342, -0.0344, -0.0184,  0.0019, -0.0412,  0.0613,  0.0050,\n",
       "                       0.1177, -0.0718,  0.1469,  0.0233,  0.0368,  0.0959,  0.0270, -0.0506,\n",
       "                       0.0956,  0.0500,  0.2730,  0.2136,  0.1957,  0.0173,  0.0985,  0.0072,\n",
       "                      -0.0312,  0.2402,  0.3339,  0.0011,  0.1376,  0.0850,  0.2163, -0.0104,\n",
       "                       0.2979,  0.1857,  0.1077,  0.0567,  0.1521,  0.1340,  0.1141,  0.1694,\n",
       "                       0.1100, -0.0360,  0.1028,  0.1763,  0.1601,  0.3034,  0.0322,  0.0792,\n",
       "                       0.0222,  0.0108,  0.2771,  0.2295,  0.2632,  0.2578,  0.1821,  0.0144,\n",
       "                       0.0019,  0.1740,  0.2197,  0.3820,  0.3369,  0.4187, -0.0360,  0.2349,\n",
       "                       0.0800,  0.1987,  0.1697,  0.2361,  0.2283,  0.0535,  0.0498,  0.0635,\n",
       "                      -0.0337,  0.1721,  0.1113,  0.1403,  0.1066, -0.1213,  0.0537,  0.2481,\n",
       "                       0.0271,  0.0941,  0.0849,  0.0638,  0.2797,  0.3416,  0.1615,  0.1138,\n",
       "                       0.0178,  0.0863,  0.0135,  0.2026,  0.0271,  0.0732,  0.3227,  0.2844,\n",
       "                       0.2204,  0.2359,  0.0111,  0.0939,  0.3403,  0.1178, -0.1181,  0.1136,\n",
       "                       0.2518,  0.1394,  0.2190,  0.2672,  0.1610, -0.0837,  0.1060, -0.0322,\n",
       "                       0.1473,  0.2849,  0.1514,  0.2616,  0.1423,  0.0706,  0.2776, -0.0972,\n",
       "                       0.2912,  0.1497,  0.1113,  0.1902,  0.0525,  0.4244,  0.1877,  0.0527,\n",
       "                       0.0974, -0.0396,  0.3453, -0.1137,  0.1624,  0.1415, -0.0185,  0.0422,\n",
       "                       0.1331,  0.2744,  0.1608,  0.0827,  0.1435,  0.1535,  0.0654,  0.2242])),\n",
       "             ('bilstm_oov_context_feature.bias_hh_l0_reverse',\n",
       "              tensor([ 1.3803e-01,  2.4187e-01,  1.2018e-01,  5.1195e-02,  8.2745e-02,\n",
       "                       7.7092e-02,  8.5957e-02,  1.2665e-01, -1.3685e-01,  7.2947e-02,\n",
       "                       2.1543e-01,  2.4866e-01,  1.5063e-01,  4.6310e-02,  2.3868e-01,\n",
       "                       6.6137e-02,  2.2752e-01,  1.6256e-01,  3.9248e-02,  9.7958e-02,\n",
       "                       1.2577e-01,  2.4172e-02,  2.0622e-01,  3.3816e-01,  3.5372e-02,\n",
       "                       5.9425e-02,  1.0544e-01,  1.7590e-01,  1.1405e-01,  1.3373e-01,\n",
       "                       7.0942e-02,  1.6693e-01,  1.1973e-01,  1.1886e-01,  1.3830e-01,\n",
       "                       2.4801e-01,  3.2221e-01,  2.1529e-01,  6.8644e-02,  4.0379e-02,\n",
       "                       2.6294e-01,  2.2510e-01,  1.8768e-01, -1.5496e-02,  1.9213e-01,\n",
       "                       2.2718e-01,  1.5721e-01,  1.9576e-01,  1.5331e-01,  2.8578e-01,\n",
       "                       1.2957e-01,  1.3367e-01,  7.5251e-02,  2.6466e-01,  7.1963e-02,\n",
       "                      -3.6934e-02,  6.1577e-02,  1.8511e-01, -5.2299e-03,  1.9227e-01,\n",
       "                       2.3024e-02,  4.8202e-02,  1.1080e-02,  1.6179e-01,  1.9551e-02,\n",
       "                       5.9437e-02,  2.4705e-01,  2.5316e-02,  2.5789e-01,  1.9673e-01,\n",
       "                       1.5440e-01,  1.2309e-01,  1.5078e-01,  1.7748e-01,  2.9325e-02,\n",
       "                       6.3635e-02,  1.3040e-01, -4.7768e-02,  1.8814e-01,  1.8968e-01,\n",
       "                       9.2248e-02,  3.0712e-01,  8.2573e-02,  8.5846e-02,  1.1263e-01,\n",
       "                       3.4752e-01,  7.7359e-03,  7.0451e-02,  5.2613e-02,  3.1011e-02,\n",
       "                       1.2073e-01,  2.1165e-01,  4.7380e-02,  2.6359e-02,  1.3746e-01,\n",
       "                      -3.9226e-02,  2.9120e-01,  2.8221e-01, -1.3999e-01,  2.0176e-01,\n",
       "                       7.2442e-02,  1.4124e-01,  9.0360e-02,  1.5857e-01,  3.0380e-02,\n",
       "                       2.0583e-01,  1.7654e-01,  2.5401e-01,  1.4313e-01,  3.6022e-01,\n",
       "                       3.8100e-01,  7.3101e-02, -2.6982e-02,  1.4658e-01,  2.5927e-01,\n",
       "                       1.5971e-01, -3.4593e-02,  1.2876e-01,  1.0247e-01,  1.0998e-01,\n",
       "                       3.2281e-01,  2.9531e-02,  1.5366e-01,  6.6532e-02,  6.1183e-02,\n",
       "                       4.3768e-02, -9.3094e-03,  1.6053e-01,  4.3350e-02,  1.8839e-01,\n",
       "                       2.4058e-02,  1.7528e-01,  4.0408e-02,  4.6689e-02, -2.6840e-02,\n",
       "                       3.4769e-02,  5.3648e-02,  2.4092e-01,  1.2155e-01,  4.6331e-02,\n",
       "                       2.5868e-02, -1.1708e-01,  4.1742e-02,  4.2790e-02, -1.0837e-01,\n",
       "                      -1.8178e-02,  5.5645e-02,  1.8312e-01,  4.2752e-02,  2.8246e-02,\n",
       "                      -2.8998e-02, -1.8865e-01,  1.1687e-01,  3.3225e-02, -1.4633e-02,\n",
       "                      -8.3012e-02,  8.1341e-02,  1.5362e-05,  1.6567e-02,  1.8580e-01,\n",
       "                      -5.5367e-02,  2.2934e-01,  4.4674e-02, -4.3700e-03,  1.4866e-01,\n",
       "                      -1.1307e-01,  5.6868e-02,  6.4501e-02,  5.7563e-02,  1.0108e-01,\n",
       "                      -3.9152e-02,  1.6654e-01, -2.3901e-02, -2.1845e-02,  4.8678e-02,\n",
       "                       1.9891e-01,  9.2526e-02, -5.7037e-02,  9.8757e-02,  2.9496e-01,\n",
       "                       7.4075e-02,  2.9189e-02, -6.4966e-02,  1.3545e-01, -3.0592e-02,\n",
       "                       1.4774e-01, -1.1563e-02,  2.9144e-02,  7.4427e-02, -1.2100e-01,\n",
       "                       1.1568e-02, -1.9754e-01, -2.8626e-02, -1.2654e-02, -2.2385e-03,\n",
       "                       6.2626e-02, -4.4045e-02,  1.4343e-01,  6.9023e-03,  5.1283e-02,\n",
       "                      -1.1182e-01,  9.8672e-02,  1.0961e-01,  3.2723e-02,  8.5599e-02,\n",
       "                       1.0233e-01,  6.6678e-02,  5.7780e-02, -3.9531e-02, -1.5810e-02,\n",
       "                      -9.7134e-03,  5.2503e-02,  6.7862e-02,  3.4459e-02, -4.7371e-02,\n",
       "                       2.8018e-02, -1.3422e-01, -1.1390e-01,  3.0834e-02,  1.0932e-02,\n",
       "                       1.4167e-01,  9.4326e-02,  5.4077e-02, -1.8467e-02, -1.0431e-01,\n",
       "                      -1.6876e-02, -6.8326e-02, -8.8589e-02, -3.1455e-02,  7.2612e-02,\n",
       "                       1.1218e-01,  1.7175e-02,  1.2766e-01,  6.0287e-02,  7.8625e-02,\n",
       "                      -8.6072e-02,  1.9937e-01,  5.3637e-02,  2.1515e-02,  2.0650e-02,\n",
       "                       1.2299e-01,  6.4680e-02,  1.1659e-01, -4.5470e-03,  2.2018e-01,\n",
       "                       1.1261e-01,  8.4160e-02,  6.9428e-02, -3.7143e-02, -4.0399e-02,\n",
       "                       6.1510e-02, -7.8120e-02, -2.7468e-02, -1.1450e-02, -6.4278e-03,\n",
       "                       7.2711e-02,  7.4638e-02,  1.6362e-01,  6.2389e-02,  1.0014e-01,\n",
       "                       3.1804e-02,  1.4676e-01,  4.1524e-02,  3.2265e-02, -1.2840e-01,\n",
       "                      -9.6114e-02, -1.3385e-01, -1.1070e-01,  7.5518e-02,  1.0313e-01,\n",
       "                       1.4600e-01, -6.1774e-02, -5.3868e-02, -2.9965e-02, -2.0616e-02,\n",
       "                      -1.5038e-01, -6.5878e-02,  3.5333e-02, -2.1290e-02, -8.2819e-02,\n",
       "                       8.0067e-02,  2.5580e-02, -8.6455e-02, -9.2328e-02, -1.4397e-03,\n",
       "                       9.5524e-02, -2.8985e-02,  1.4305e-01,  1.0301e-02, -3.5399e-02,\n",
       "                      -5.0662e-02, -4.7263e-02, -3.5836e-02, -1.3938e-01,  4.7995e-02,\n",
       "                       3.5758e-02, -6.0517e-02, -7.6711e-02,  4.4798e-02, -1.3842e-01,\n",
       "                       3.1030e-02, -2.2781e-02,  8.5113e-02, -2.3783e-02,  8.5306e-02,\n",
       "                       1.1601e-01,  6.4195e-02,  1.2363e-02, -4.3179e-02, -7.9351e-02,\n",
       "                      -4.2175e-02,  7.2045e-02,  2.0595e-01, -5.1353e-02,  3.6328e-02,\n",
       "                      -5.8821e-02,  8.4138e-02,  3.1771e-02, -5.5593e-02, -8.4788e-02,\n",
       "                       5.1594e-02, -6.4026e-02, -2.3016e-02,  2.9261e-02,  4.4661e-02,\n",
       "                       8.9118e-02, -8.3358e-02, -4.6398e-02,  4.5996e-02,  1.7183e-02,\n",
       "                      -1.1038e-01,  3.0026e-02, -4.3991e-03, -1.9708e-02, -9.6238e-03,\n",
       "                      -1.3649e-02, -6.7936e-02, -8.3841e-02,  2.2858e-03,  1.2206e-01,\n",
       "                      -3.4778e-02, -6.4628e-02, -8.1899e-03,  6.3553e-02, -3.7737e-02,\n",
       "                       7.1903e-02, -1.7941e-02, -1.1285e-01, -7.0523e-03,  2.2965e-02,\n",
       "                       1.7546e-03, -4.7251e-02, -1.5565e-02, -6.9188e-02, -5.6482e-02,\n",
       "                       3.4316e-02,  6.5784e-02, -8.5569e-02, -3.2811e-02, -7.2400e-02,\n",
       "                      -5.7538e-02, -1.9660e-02,  6.2996e-02, -3.6862e-02, -8.5707e-02,\n",
       "                       5.3990e-02, -7.8799e-02, -1.0137e-02, -3.5389e-02,  1.0483e-01,\n",
       "                      -5.6438e-02,  3.4203e-02, -3.3543e-02, -5.8305e-02,  3.5234e-02,\n",
       "                      -1.1929e-01, -7.9258e-02,  1.4600e-02, -4.5189e-02, -6.7092e-02,\n",
       "                       4.0808e-02,  3.8799e-02,  1.0174e-01, -5.3614e-02,  1.2346e-01,\n",
       "                       8.3762e-02,  3.1359e-01,  3.4234e-01,  2.4133e-01,  4.8516e-02,\n",
       "                       1.0287e-01,  1.5847e-01,  1.0017e-01,  1.6886e-01,  2.6380e-01,\n",
       "                       1.4840e-01,  1.6920e-01,  3.4533e-02,  2.1296e-01,  9.7734e-02,\n",
       "                       2.8242e-01,  1.3782e-01,  1.9300e-01,  8.7616e-02, -3.1807e-02,\n",
       "                       1.0765e-01, -5.1827e-02,  5.9106e-02,  1.0471e-01,  1.0818e-02,\n",
       "                       1.7180e-01,  2.6240e-01,  8.4016e-02,  3.0731e-01, -2.0865e-02,\n",
       "                       1.6187e-01,  6.8989e-03,  6.2176e-02,  2.9077e-01,  1.3855e-01,\n",
       "                       3.0141e-01,  2.2059e-01,  1.4900e-01, -5.8703e-02,  6.1264e-03,\n",
       "                       1.8031e-01,  1.8192e-01,  1.6540e-01,  2.6153e-01,  3.8693e-01,\n",
       "                       5.3335e-03,  1.4204e-01,  1.1952e-01,  1.1450e-01,  1.5107e-01,\n",
       "                       1.3393e-01,  1.0216e-01,  6.1468e-02,  7.1808e-02,  2.1688e-03,\n",
       "                      -1.0989e-01,  2.2056e-01,  1.0058e-02,  1.8901e-01, -8.7838e-03,\n",
       "                       8.4433e-02,  1.3627e-01,  1.4070e-01,  9.1894e-02,  1.2422e-01,\n",
       "                       2.3386e-01,  2.2651e-01,  1.8880e-01,  1.9777e-01,  1.6849e-01,\n",
       "                       4.1705e-03,  8.3993e-02,  4.6062e-02,  9.3522e-02,  3.1762e-01,\n",
       "                       9.1464e-02,  2.4046e-02,  2.7156e-01,  2.7154e-01,  1.2721e-01,\n",
       "                       2.2141e-01,  4.4363e-02,  2.3300e-01,  9.2072e-02,  1.9930e-01,\n",
       "                      -1.4149e-02,  9.6785e-03,  2.0247e-01,  2.3931e-01,  2.2986e-01,\n",
       "                       2.0865e-01,  1.9939e-01,  4.8710e-02,  1.2158e-01, -1.3853e-01,\n",
       "                       2.4397e-01,  3.4140e-01,  6.9585e-03,  2.2719e-01,  2.5300e-01,\n",
       "                       1.1479e-01,  2.8106e-01, -2.4857e-02,  1.9395e-01,  1.0908e-01,\n",
       "                       2.1653e-01,  2.8170e-01, -3.4831e-02,  4.9300e-01,  1.6027e-01,\n",
       "                      -3.7074e-02,  2.4017e-02,  2.7903e-02,  3.3857e-01, -1.5303e-02,\n",
       "                       1.2822e-01,  1.0162e-01,  1.3261e-01,  1.5578e-01,  8.3536e-02,\n",
       "                       3.2438e-01,  1.2270e-01,  1.0962e-01,  1.0483e-01,  1.1377e-01,\n",
       "                       4.7274e-02,  2.8830e-01])),\n",
       "             ('bilstm_right_context_feature.weight_ih_l0',\n",
       "              tensor([[ 0.0113,  0.1047,  0.1864,  ..., -0.0387,  0.1932, -0.1484],\n",
       "                      [ 0.2964, -0.1114,  0.3796,  ..., -0.1368,  0.4424, -0.3852],\n",
       "                      [ 0.2671,  0.0666,  0.5075,  ..., -0.0213, -0.2810, -0.0318],\n",
       "                      ...,\n",
       "                      [-0.0436,  0.4626,  0.1047,  ..., -0.2087,  0.0261,  0.0164],\n",
       "                      [-0.0172,  0.0560, -0.0389,  ...,  0.0575, -0.0816, -0.0465],\n",
       "                      [ 0.1475, -0.0695,  0.4727,  ..., -0.2988, -0.0222, -0.0941]])),\n",
       "             ('bilstm_right_context_feature.weight_hh_l0',\n",
       "              tensor([[-0.0414,  0.0098, -0.1233,  ..., -0.0741,  0.2445, -0.0494],\n",
       "                      [ 0.0651, -0.1241, -0.1842,  ..., -0.0190,  0.4153, -0.2363],\n",
       "                      [ 0.0455,  0.0339,  0.2012,  ..., -0.1423,  0.2870, -0.0235],\n",
       "                      ...,\n",
       "                      [-0.0958, -0.1498, -0.2863,  ...,  0.0943, -0.0818, -0.1521],\n",
       "                      [-0.1333,  0.0725, -0.2290,  ..., -0.0435, -0.2205, -0.1235],\n",
       "                      [-0.0048,  0.0395, -0.0531,  ..., -0.1205, -0.1117, -0.0485]])),\n",
       "             ('bilstm_right_context_feature.bias_ih_l0',\n",
       "              tensor([-1.6009e-01, -4.8551e-02, -1.6901e-01,  9.1019e-02, -5.8973e-02,\n",
       "                       4.5570e-02, -1.2054e-01,  1.3672e-01, -6.1938e-02, -1.9949e-01,\n",
       "                      -2.5125e-01, -9.0957e-02, -7.4288e-03,  2.4667e-02, -5.1746e-02,\n",
       "                       1.3887e-02,  5.8389e-02, -7.5739e-02,  3.4968e-02, -1.7188e-01,\n",
       "                       1.1612e-02, -6.9631e-02, -1.8627e-01, -1.3527e-01, -3.0213e-01,\n",
       "                      -2.1212e-01, -1.3798e-01,  3.5005e-02, -8.2007e-02, -9.6273e-02,\n",
       "                      -2.2308e-01, -1.2905e-01, -2.3390e-01, -3.5899e-02, -1.0117e-01,\n",
       "                      -4.0861e-02,  6.2300e-02, -3.2984e-01, -2.1653e-01, -1.3682e-01,\n",
       "                      -5.0068e-02, -1.4011e-01, -2.8490e-02, -1.4161e-01, -8.4473e-02,\n",
       "                      -2.7996e-01, -1.6895e-02,  6.8589e-02, -1.2622e-01, -4.7683e-02,\n",
       "                      -1.4340e-01, -1.1650e-01, -2.0501e-01, -2.3025e-01, -7.7412e-02,\n",
       "                      -1.2949e-01, -5.6515e-02, -2.0924e-01, -2.0978e-02, -1.6080e-01,\n",
       "                      -1.8618e-01, -8.1676e-02, -5.3155e-02, -3.9589e-02, -9.3605e-02,\n",
       "                      -3.1967e-02, -3.7701e-02, -2.5275e-02, -2.0114e-01,  4.7127e-02,\n",
       "                      -2.7425e-02, -1.2847e-01, -1.8393e-02, -1.1371e-01, -1.1023e-01,\n",
       "                      -1.2435e-01, -2.4641e-01, -3.6581e-01,  1.1963e-02, -2.3660e-01,\n",
       "                      -1.6876e-01,  2.7602e-02, -2.9364e-02, -2.5306e-02, -1.3489e-01,\n",
       "                      -1.5554e-01, -9.8025e-02, -5.2707e-02,  7.5276e-02, -1.0961e-01,\n",
       "                      -6.2535e-02, -1.1951e-01, -1.6343e-01, -2.0334e-02, -1.5146e-02,\n",
       "                      -1.8893e-01, -2.0772e-01, -1.2719e-01, -1.2764e-01,  8.2697e-03,\n",
       "                      -2.3453e-01, -1.1704e-01, -1.4111e-01,  2.1946e-02, -2.1281e-02,\n",
       "                      -2.2701e-01, -1.3600e-02, -7.2631e-02, -7.1366e-02, -1.1284e-01,\n",
       "                      -3.0478e-01, -1.5440e-01, -1.1026e-01,  6.1909e-02, -6.3676e-02,\n",
       "                      -1.2378e-01, -1.3030e-01,  2.7645e-03, -1.0963e-01, -1.1797e-01,\n",
       "                      -1.6844e-01, -1.0661e-01,  4.6917e-02, -2.6441e-01,  2.9712e-02,\n",
       "                      -1.0446e-01, -2.1469e-01, -1.4332e-01, -1.5903e-01, -1.2831e-01,\n",
       "                       2.2841e-02,  1.2869e-02, -3.1110e-02,  2.6797e-03, -5.2375e-02,\n",
       "                      -3.6921e-02, -2.2002e-01, -1.5693e-01, -2.2214e-01,  5.8896e-02,\n",
       "                       2.1531e-02, -8.3658e-02, -1.2103e-01, -1.1558e-01, -2.4632e-01,\n",
       "                      -1.0691e-01, -4.9946e-02, -1.4357e-01, -4.8166e-02, -1.8034e-01,\n",
       "                      -1.8943e-01, -2.0071e-01, -1.0603e-01, -4.1615e-02, -8.2218e-02,\n",
       "                      -8.8469e-02, -9.8082e-02, -1.7493e-01, -8.9114e-02, -1.0744e-01,\n",
       "                      -2.2981e-01, -5.9155e-02,  2.3950e-02, -1.6627e-01, -2.3316e-02,\n",
       "                       1.2757e-02, -1.2547e-01, -1.2234e-01, -3.6143e-02, -1.6221e-01,\n",
       "                       3.0072e-02, -1.2683e-01, -1.4819e-01, -1.8417e-01, -4.6929e-03,\n",
       "                      -1.1901e-01, -6.3265e-03, -1.4768e-01, -4.3447e-02, -1.4493e-04,\n",
       "                      -3.8984e-02, -2.2546e-01, -1.1201e-01, -1.2245e-01, -9.9206e-02,\n",
       "                       2.9877e-02,  1.1467e-01, -6.8861e-02, -1.6320e-01, -7.8587e-02,\n",
       "                      -5.8958e-02, -1.7871e-01, -8.4585e-02, -1.6566e-01, -1.0194e-01,\n",
       "                      -8.9045e-02, -1.9973e-01, -1.7434e-01, -3.8861e-03, -2.9189e-01,\n",
       "                      -6.2972e-02,  6.5166e-02, -2.0707e-02, -2.0903e-01, -5.9794e-02,\n",
       "                      -7.4094e-02, -1.4962e-01, -1.6810e-01, -1.9133e-01, -9.5349e-02,\n",
       "                      -7.8176e-02, -2.5487e-01, -1.9055e-01, -1.5653e-01, -4.3681e-02,\n",
       "                      -1.6521e-01, -1.9894e-01, -1.0345e-01,  7.0301e-04, -7.9596e-02,\n",
       "                      -1.7197e-01, -3.5700e-02, -6.4803e-02, -2.4555e-01,  3.3105e-02,\n",
       "                      -4.1201e-02, -2.8984e-01, -2.7083e-02, -1.5788e-01, -1.2251e-01,\n",
       "                      -5.1183e-02, -6.3283e-02, -7.3254e-02, -3.9833e-02, -1.9765e-01,\n",
       "                       8.7886e-03,  5.7737e-03, -3.7655e-01, -1.0148e-01, -5.1486e-02,\n",
       "                      -1.4919e-01,  9.6487e-03, -1.5638e-01,  6.3424e-03, -6.3851e-02,\n",
       "                      -2.4338e-01, -2.4732e-01, -1.0647e-01,  3.7222e-02,  3.2515e-02,\n",
       "                      -4.2443e-02, -1.9117e-01, -9.2793e-03, -1.7868e-01, -1.7679e-01,\n",
       "                      -1.6102e-01,  4.4375e-02, -1.5851e-01,  2.6122e-02, -4.7677e-02,\n",
       "                       2.1634e-02, -5.1707e-03,  5.7853e-02, -1.6713e-02,  2.0100e-02,\n",
       "                       1.7696e-02,  1.0649e-01,  2.9123e-02,  4.6833e-02, -6.2591e-03,\n",
       "                       7.1214e-02, -7.9681e-02, -9.0057e-02,  1.1055e-02, -6.5953e-02,\n",
       "                       3.4085e-02, -4.2557e-03, -7.6511e-02,  2.4587e-02,  5.9243e-02,\n",
       "                       2.4312e-02, -7.2647e-02,  1.0489e-01,  2.1309e-02, -6.7273e-03,\n",
       "                      -7.3857e-02,  1.7775e-02, -5.1979e-03, -1.0189e-01, -8.9503e-02,\n",
       "                       6.6083e-02,  7.8309e-02,  9.6811e-03, -6.0202e-02,  1.0257e-01,\n",
       "                       1.2936e-03,  7.2942e-02,  7.6329e-02, -2.3866e-02, -2.7963e-02,\n",
       "                       1.2278e-01, -2.2511e-02,  4.8746e-02,  9.7636e-02, -4.4452e-03,\n",
       "                      -9.1076e-02, -2.0167e-02,  8.6460e-02, -5.1530e-02, -4.6034e-03,\n",
       "                       7.3750e-02,  9.2863e-02, -5.2623e-03,  1.1484e-02, -3.7364e-02,\n",
       "                       1.1893e-02, -4.5342e-02,  2.0849e-03, -2.7226e-02, -1.0598e-01,\n",
       "                       3.9183e-02,  9.4612e-02,  3.2736e-02,  5.5373e-02,  9.7430e-02,\n",
       "                      -5.9195e-02,  4.7947e-02, -2.3686e-02,  8.1095e-02,  2.3572e-02,\n",
       "                       5.4707e-02, -6.9690e-02, -7.7884e-02, -2.6539e-02,  1.8162e-01,\n",
       "                       3.8541e-02,  1.6295e-02, -4.7784e-03, -4.4294e-02, -3.0019e-02,\n",
       "                       4.1317e-02, -1.0864e-01,  1.6148e-02, -1.4086e-01, -2.8008e-02,\n",
       "                      -1.5076e-02,  4.0752e-02, -4.2613e-02, -8.7623e-03,  9.0414e-02,\n",
       "                      -8.7777e-02,  1.3265e-02,  1.5840e-02, -4.7481e-02, -9.6015e-02,\n",
       "                      -4.1146e-02,  3.1589e-02,  5.1287e-02,  1.8947e-03,  6.6342e-02,\n",
       "                       4.4258e-02,  7.6591e-02,  7.7755e-02, -2.4700e-02,  1.4585e-01,\n",
       "                       4.9931e-02,  7.0184e-02,  1.7804e-02,  4.9846e-02, -1.8347e-01,\n",
       "                       4.6795e-03,  6.3274e-02, -6.2136e-02, -3.1481e-02, -1.0263e-01,\n",
       "                       3.2099e-02,  8.5906e-03,  3.5413e-02,  2.2864e-02, -1.1470e-01,\n",
       "                       4.0599e-02,  1.7371e-02, -5.3174e-02, -3.0899e-03, -1.0973e-01,\n",
       "                      -9.8680e-02, -1.7035e-01,  3.4983e-02, -3.3266e-02, -7.3132e-02,\n",
       "                      -1.6419e-01,  9.4136e-03,  2.9286e-02, -8.4519e-02, -9.0488e-02,\n",
       "                       1.0198e-02,  3.6742e-02,  5.7134e-02, -6.0512e-02, -2.4750e-02,\n",
       "                      -1.0631e-01, -1.4869e-01, -9.4103e-02, -3.5338e-02, -1.5042e-01,\n",
       "                      -2.1109e-01, -2.4817e-01, -1.3234e-01, -2.2324e-01, -8.0730e-02,\n",
       "                      -2.2053e-01,  2.5637e-02, -1.6519e-01, -1.2375e-01, -1.5068e-01,\n",
       "                      -2.1732e-02, -1.4512e-01, -7.4265e-02, -1.5472e-01, -1.1495e-01,\n",
       "                      -7.0909e-03, -3.4228e-01, -9.3905e-02,  3.4833e-03,  1.5367e-02,\n",
       "                       2.9335e-02, -2.4512e-02, -1.6260e-01, -7.3928e-02, -1.0104e-01,\n",
       "                       3.8020e-02, -7.5784e-02, -5.3398e-02, -1.8653e-01, -1.7311e-01,\n",
       "                      -2.9579e-01, -1.7058e-01, -2.7788e-02, -7.8146e-02, -2.2394e-01,\n",
       "                      -1.4208e-01, -1.8131e-01, -1.9786e-02, -1.2690e-01, -1.6620e-01,\n",
       "                      -2.2684e-01,  3.3520e-02, -1.7651e-01, -3.8045e-02, -4.0029e-02,\n",
       "                      -5.7996e-02, -2.4654e-02, -2.5890e-01,  9.3601e-03, -1.3955e-01,\n",
       "                      -2.3917e-01, -1.0577e-01, -1.7177e-01, -9.1552e-02, -1.2187e-01,\n",
       "                      -1.9120e-01, -2.4100e-01, -1.1659e-01, -5.0283e-02, -1.8621e-01,\n",
       "                      -7.1292e-02, -1.1443e-01, -2.9964e-02, -8.5244e-02, -2.3312e-01,\n",
       "                       1.9857e-02,  5.8263e-02,  4.5270e-02, -1.3108e-01, -2.1905e-01,\n",
       "                      -2.5899e-01, -2.0744e-01, -1.6087e-01, -7.9178e-02, -1.6487e-01,\n",
       "                      -4.0851e-02, -1.4098e-01, -1.8244e-01, -2.2162e-01, -5.5208e-02,\n",
       "                      -6.2132e-02, -1.3190e-01, -5.6163e-03, -1.7909e-02, -2.0898e-01,\n",
       "                      -2.1461e-01, -1.6087e-01, -7.8974e-02, -1.0709e-02, -1.8738e-01,\n",
       "                      -7.1700e-02, -1.7282e-01,  2.9083e-02, -9.8558e-02, -8.6027e-02,\n",
       "                      -1.4344e-01, -3.2420e-02, -1.6239e-01, -9.3160e-02, -1.9814e-01,\n",
       "                      -6.5598e-02, -9.8585e-02, -2.8624e-01, -3.4865e-02,  3.9883e-03,\n",
       "                      -1.2601e-01,  1.3214e-02])),\n",
       "             ('bilstm_right_context_feature.bias_hh_l0',\n",
       "              tensor([-2.4237e-01, -7.5211e-02,  4.0646e-02,  8.4138e-02, -5.6309e-02,\n",
       "                      -3.9725e-02, -1.5775e-01, -4.9736e-02, -4.9287e-02, -9.0791e-02,\n",
       "                      -5.3193e-02, -2.6260e-02, -2.0184e-01, -1.0075e-01, -9.3697e-02,\n",
       "                       3.6882e-02, -1.1707e-01, -1.6821e-01,  3.9688e-03, -1.8290e-01,\n",
       "                      -1.1679e-01, -1.1261e-02, -5.6536e-02, -6.3022e-02, -2.5725e-01,\n",
       "                      -1.4120e-01, -1.2744e-01,  1.0786e-01, -1.6394e-01, -1.3008e-01,\n",
       "                      -2.0271e-01, -6.8006e-02, -5.0420e-02, -1.1179e-01, -1.1907e-01,\n",
       "                       4.1194e-02, -9.3197e-02, -2.4184e-01, -7.1026e-02, -4.3379e-02,\n",
       "                      -2.8507e-02, -1.8186e-01, -1.8603e-01, -1.2914e-01, -1.0903e-01,\n",
       "                      -2.1942e-01, -1.3519e-01,  1.9788e-03, -1.6230e-01, -1.4828e-01,\n",
       "                      -1.9917e-01, -1.5006e-01, -1.5102e-01, -2.2797e-01, -1.1998e-01,\n",
       "                      -2.4303e-01, -2.8686e-02, -1.7091e-01, -2.3784e-02, -3.6261e-02,\n",
       "                      -8.4734e-02, -9.7971e-02, -8.1315e-02, -8.6980e-02, -5.5824e-02,\n",
       "                      -1.4137e-01, -4.3479e-02, -1.3214e-01, -2.3884e-01, -1.8312e-02,\n",
       "                       7.3883e-02, -2.2914e-01, -1.3419e-01, -1.0270e-01, -6.7964e-02,\n",
       "                      -1.1314e-01, -1.6559e-01, -1.9338e-01, -1.2445e-01, -2.5068e-01,\n",
       "                      -2.3867e-01, -1.8181e-01, -1.0176e-01, -9.5290e-02,  3.5704e-02,\n",
       "                      -2.1108e-01, -2.2259e-02, -1.5374e-01,  7.8461e-02,  8.2869e-02,\n",
       "                      -9.2969e-02, -1.6364e-01, -3.0779e-01,  7.7455e-03, -1.1645e-01,\n",
       "                      -1.7989e-01, -1.5338e-01, -1.9121e-01, -7.8939e-02, -1.6726e-01,\n",
       "                      -1.7347e-01, -7.3065e-02, -1.1716e-01, -1.2769e-01, -1.6893e-01,\n",
       "                      -1.4120e-01, -6.7529e-02,  1.1288e-02, -4.4298e-02, -7.6035e-02,\n",
       "                      -1.7249e-01, -1.8695e-01, -7.2476e-02, -3.8803e-02, -1.6342e-01,\n",
       "                      -8.3870e-02, -1.1736e-01,  6.3529e-02, -2.4569e-01, -8.1610e-02,\n",
       "                      -1.3648e-01, -8.1816e-02, -4.4635e-02, -1.4224e-01, -7.5177e-02,\n",
       "                      -4.7869e-02, -7.3794e-02, -9.0839e-02, -1.7631e-01, -2.7731e-02,\n",
       "                       2.7522e-02, -1.2330e-02, -3.3510e-02, -8.1708e-03,  5.3649e-02,\n",
       "                       1.7884e-02, -1.5041e-01, -3.7094e-02, -1.5741e-01,  8.9045e-03,\n",
       "                      -4.4798e-02, -2.2527e-01, -9.7151e-02, -1.6726e-01, -2.6989e-01,\n",
       "                      -5.8235e-02, -6.0443e-02, -8.8143e-02, -1.0603e-01, -6.4890e-02,\n",
       "                      -1.2239e-01, -1.9917e-01, -1.4066e-01, -1.1312e-01, -1.6158e-02,\n",
       "                      -1.0727e-01, -2.1092e-01, -1.4071e-01, -1.0857e-01, -1.5769e-01,\n",
       "                      -1.7540e-01, -1.1497e-01, -2.5651e-02,  8.7302e-02, -1.8693e-01,\n",
       "                      -3.0869e-02, -1.8126e-02, -3.0971e-02, -2.1581e-02, -1.4478e-01,\n",
       "                       1.9721e-02, -1.8175e-01, -1.9852e-01, -2.9562e-01, -6.1588e-03,\n",
       "                      -1.8186e-01,  2.7065e-02, -8.2855e-02, -6.2335e-02, -6.4078e-02,\n",
       "                      -1.6618e-01, -2.1771e-01, -3.2551e-02, -1.5409e-01, -9.2013e-02,\n",
       "                      -1.2686e-01,  8.9352e-02, -1.1344e-01, -1.9040e-01, -1.4499e-01,\n",
       "                      -1.3425e-01, -1.9249e-01, -2.2929e-01, -4.8898e-02,  8.7718e-02,\n",
       "                       6.2486e-02, -1.9244e-01, -6.4214e-02, -7.1432e-02, -7.8614e-02,\n",
       "                      -6.8704e-02,  1.3403e-02,  2.9799e-02, -1.2653e-01, -4.0335e-02,\n",
       "                      -8.5655e-02, -4.8996e-03, -1.4000e-01, -3.2179e-01, -9.5897e-02,\n",
       "                      -2.5730e-02, -9.9775e-02, -1.6442e-01, -2.0625e-01, -6.0051e-02,\n",
       "                      -1.1513e-01, -1.4171e-01, -6.6621e-02, -5.1308e-02, -8.5948e-02,\n",
       "                      -1.9207e-01,  4.5936e-02, -7.3327e-02, -3.0999e-01, -8.8759e-02,\n",
       "                      -7.9050e-02, -2.1146e-01, -2.8010e-02, -1.3671e-01,  9.1504e-03,\n",
       "                      -1.7785e-01, -4.4888e-02, -1.9277e-01,  6.2062e-03, -5.2127e-02,\n",
       "                      -1.2864e-01,  1.8466e-04, -1.8922e-01, -8.9253e-02, -2.4741e-01,\n",
       "                      -1.6770e-01, -8.6862e-02, -1.5686e-01,  1.1531e-01, -1.1228e-01,\n",
       "                      -1.8560e-01, -1.0692e-01, -1.8923e-01, -1.4181e-01,  1.7937e-01,\n",
       "                      -1.0679e-01, -6.9094e-02, -2.0192e-02, -7.1813e-02, -2.1873e-01,\n",
       "                      -2.0971e-02, -1.5072e-01, -2.1791e-02,  1.5377e-02, -7.7267e-03,\n",
       "                      -2.6974e-02,  1.1214e-01, -1.2582e-01, -6.4595e-02,  6.5451e-04,\n",
       "                      -2.3214e-02,  1.2910e-01,  6.9658e-02,  1.3124e-01, -1.9421e-02,\n",
       "                       5.4249e-02, -4.5142e-02,  4.7756e-02,  5.5619e-02,  5.5236e-03,\n",
       "                      -1.1008e-01, -3.0033e-02,  1.4859e-01,  1.1694e-01, -5.9583e-02,\n",
       "                       1.3497e-02, -2.1037e-03, -2.0921e-04, -8.6104e-02, -2.5620e-02,\n",
       "                      -4.4957e-02,  5.2370e-02,  9.8348e-02, -1.9474e-01,  1.9707e-02,\n",
       "                      -2.8977e-02,  1.0109e-01, -7.8042e-02,  2.7611e-02, -3.1462e-02,\n",
       "                      -1.4933e-02,  1.0663e-01,  7.6841e-03,  9.4095e-02, -2.0774e-02,\n",
       "                      -1.0971e-01, -1.0430e-01, -5.9353e-02,  4.1610e-03, -4.6020e-03,\n",
       "                      -6.1777e-03,  4.9053e-02, -4.6137e-02, -1.9120e-02, -2.5342e-02,\n",
       "                       5.9307e-02, -6.2172e-02, -1.6251e-02, -2.0445e-02, -3.1341e-02,\n",
       "                      -6.1577e-02, -1.3740e-01, -1.3135e-02,  2.0212e-02,  4.8500e-02,\n",
       "                       1.9380e-02,  1.1390e-02, -2.9199e-02, -9.3688e-02,  7.5478e-02,\n",
       "                      -4.9206e-02,  1.0041e-01, -3.0946e-02,  7.9525e-02,  7.1612e-02,\n",
       "                       5.5278e-02, -5.3363e-02,  4.1033e-02,  1.0329e-02, -7.1413e-03,\n",
       "                       7.8216e-02,  5.2778e-02, -9.6876e-03, -5.5234e-02, -1.0969e-01,\n",
       "                      -1.0155e-01, -5.7975e-02,  1.2859e-02,  5.9389e-02,  9.7092e-02,\n",
       "                      -2.2789e-02, -1.5362e-03, -9.3447e-02, -6.1433e-02, -8.8030e-02,\n",
       "                      -2.1123e-02, -3.8200e-02, -1.5627e-02, -7.3237e-02, -1.0547e-01,\n",
       "                      -1.0380e-02,  1.1692e-01,  5.4082e-02,  5.1787e-02,  2.0572e-03,\n",
       "                      -9.0097e-02, -7.3290e-02,  8.3509e-02, -3.8554e-02, -9.4912e-02,\n",
       "                       4.2069e-02, -3.5177e-02, -3.4689e-02, -1.6247e-02, -1.8924e-03,\n",
       "                      -9.2840e-02, -7.5602e-02,  1.3567e-01,  1.4672e-02,  1.0956e-01,\n",
       "                      -1.2295e-01,  4.6168e-03,  1.6485e-02, -5.6388e-02, -9.7141e-02,\n",
       "                       9.1938e-02,  5.6988e-03, -6.2068e-02, -5.6175e-02, -1.6489e-01,\n",
       "                      -1.5943e-01, -1.1746e-01, -1.2925e-02, -1.4089e-01,  5.2173e-02,\n",
       "                      -1.8771e-01, -1.9237e-02, -5.1937e-02, -2.3075e-01, -4.6722e-02,\n",
       "                      -4.5337e-02, -7.3694e-02,  1.4837e-02, -8.4701e-03,  4.0796e-02,\n",
       "                      -9.0150e-02, -1.7479e-01, -3.9642e-02, -4.6602e-02, -9.1324e-02,\n",
       "                      -2.5361e-01, -1.5121e-01, -1.6802e-01, -2.7292e-01, -4.4660e-02,\n",
       "                      -2.3241e-01,  7.5185e-02, -1.2144e-01, -2.3168e-01, -1.3053e-01,\n",
       "                      -1.5963e-01, -9.0890e-02, -1.0570e-01, -1.7588e-01, -1.0719e-02,\n",
       "                      -1.7303e-01, -1.9161e-01, -7.6526e-02, -4.8446e-02, -9.5289e-02,\n",
       "                      -1.1979e-01, -8.5534e-02, -1.8551e-01, -7.7117e-02, -2.5364e-01,\n",
       "                      -1.1015e-01, -4.1811e-02, -1.3175e-01, -7.8528e-02, -2.1071e-01,\n",
       "                      -2.6111e-01, -2.7795e-01, -7.9069e-02,  2.3769e-02, -1.9636e-01,\n",
       "                      -1.8238e-02, -1.2159e-01, -3.5169e-02, -1.0598e-01, -1.7147e-01,\n",
       "                      -1.8897e-01,  3.4395e-02, -6.7488e-02, -1.5360e-04,  3.3544e-02,\n",
       "                      -1.5470e-01, -7.2221e-02, -1.6120e-01, -4.9604e-02, -1.6842e-01,\n",
       "                      -1.8531e-01, -6.6767e-02, -1.0348e-02, -9.6752e-02, -2.5191e-01,\n",
       "                      -8.9206e-02, -2.8478e-01, -4.8218e-02, -1.1609e-01, -2.6075e-01,\n",
       "                      -9.1474e-02, -8.1251e-02, -1.5245e-01, -3.0679e-02, -6.0146e-02,\n",
       "                       7.6952e-02, -7.3449e-02,  5.6211e-02, -1.0782e-01, -2.5747e-01,\n",
       "                      -1.1936e-01, -2.6710e-01, -1.8248e-01, -6.8494e-03, -1.2047e-01,\n",
       "                      -1.8591e-01, -4.0305e-02, -1.0669e-01, -1.9480e-01, -1.8461e-01,\n",
       "                      -7.4664e-02, -1.2020e-01, -2.9976e-02, -4.6837e-02, -1.8505e-01,\n",
       "                      -1.4466e-01, -5.2308e-02,  9.7940e-02,  1.2601e-02, -1.7790e-01,\n",
       "                      -1.1816e-01, -9.0867e-02, -7.6179e-02, -5.0422e-02,  6.5062e-03,\n",
       "                      -1.8016e-01, -4.7731e-02, -2.1690e-01, -6.8985e-02, -5.5091e-02,\n",
       "                      -1.6042e-02, -1.3610e-01, -1.6532e-01, -3.1943e-02, -9.9717e-02,\n",
       "                       2.6822e-02, -8.0663e-02])),\n",
       "             ('bilstm_right_context_feature.weight_ih_l0_reverse',\n",
       "              tensor([[-0.2168, -0.0412, -0.0206,  ..., -0.4532,  0.1627,  0.0975],\n",
       "                      [ 0.0863, -0.1447, -0.2201,  ..., -0.0318,  0.0883, -0.0987],\n",
       "                      [-0.0663,  0.0401,  0.2288,  ..., -0.3247,  0.1740,  0.0764],\n",
       "                      ...,\n",
       "                      [ 0.1014,  0.1898,  0.1844,  ...,  0.0176,  0.2524,  0.1762],\n",
       "                      [-0.0928, -0.3741, -0.1248,  ...,  0.2703, -0.1340, -0.1788],\n",
       "                      [ 0.7956,  0.5799, -0.2070,  ...,  0.0047,  0.2259, -0.4990]])),\n",
       "             ('bilstm_right_context_feature.weight_hh_l0_reverse',\n",
       "              tensor([[ 0.0319,  0.0437, -0.0250,  ..., -0.1509,  0.1267,  0.0488],\n",
       "                      [ 0.0250,  0.1550, -0.2572,  ..., -0.0452,  0.2535,  0.0491],\n",
       "                      [-0.0401,  0.3487, -0.1270,  ..., -0.3343, -0.1676, -0.1806],\n",
       "                      ...,\n",
       "                      [ 0.0177, -0.2482,  0.1825,  ...,  0.1873,  0.1328, -0.0778],\n",
       "                      [-0.0366,  0.0673,  0.0234,  ...,  0.0946,  0.1116, -0.1577],\n",
       "                      [ 0.0682,  0.2044, -0.3112,  ...,  0.0633, -0.0149,  0.1947]])),\n",
       "             ('bilstm_right_context_feature.bias_ih_l0_reverse',\n",
       "              tensor([-4.3528e-02,  4.4330e-02,  4.5229e-02, -5.7037e-02,  3.1983e-02,\n",
       "                       1.5610e-01,  5.1697e-02,  4.3298e-02,  6.8810e-02,  6.1574e-02,\n",
       "                      -5.5277e-02,  6.1240e-02,  7.3936e-02, -7.6364e-02, -7.8265e-02,\n",
       "                       1.3363e-01,  3.6238e-02,  4.7058e-02,  2.3384e-02, -7.8953e-03,\n",
       "                      -5.5246e-02, -5.5421e-03,  5.3666e-02,  1.9696e-01,  3.6747e-02,\n",
       "                       3.3861e-02,  1.1982e-01,  1.5898e-01,  9.3477e-02,  8.0548e-04,\n",
       "                       9.3867e-02, -2.2482e-02, -5.3479e-02,  2.6397e-02,  1.2573e-01,\n",
       "                      -2.2179e-02,  1.6240e-03,  3.1076e-02,  1.0676e-01,  1.1833e-01,\n",
       "                      -1.0002e-01,  2.2852e-02, -4.8084e-02,  1.6104e-01,  9.7607e-02,\n",
       "                      -3.8276e-02,  1.0380e-01, -6.5330e-02, -7.4846e-02, -3.3527e-02,\n",
       "                       1.7212e-01,  1.0788e-01,  1.3264e-01,  1.8857e-02,  2.9037e-02,\n",
       "                      -3.1030e-02,  1.5939e-02,  1.1856e-01,  1.1614e-01, -3.8715e-02,\n",
       "                       3.9253e-02,  5.6154e-02, -1.5138e-01,  2.3597e-01, -6.7463e-02,\n",
       "                      -1.3907e-01,  5.8322e-02,  1.0165e-01,  1.9634e-01,  3.3889e-02,\n",
       "                       7.8253e-02,  1.2100e-01,  1.3594e-01,  1.2355e-01,  1.0584e-01,\n",
       "                       1.7131e-01,  7.6953e-02,  1.2672e-01, -9.7201e-04,  4.1510e-03,\n",
       "                       3.6508e-02,  1.1501e-01, -6.0007e-02,  1.9115e-01,  1.5173e-01,\n",
       "                       2.2136e-02, -5.6268e-02, -1.1642e-01,  1.1381e-01,  2.1622e-01,\n",
       "                       9.6770e-02, -6.7298e-02, -9.9901e-03,  7.9309e-02, -3.7085e-02,\n",
       "                       1.3981e-01, -4.4171e-02, -2.8310e-02,  5.4368e-02,  1.9800e-01,\n",
       "                       5.7030e-02, -3.2501e-02,  9.5899e-02,  1.2404e-02,  1.3699e-01,\n",
       "                       1.7347e-01,  2.6990e-02,  4.0527e-02,  6.4292e-02,  1.6013e-01,\n",
       "                      -1.2824e-01,  1.3201e-04,  1.0727e-01,  2.7893e-01,  4.4310e-02,\n",
       "                       2.2061e-01,  2.0245e-02,  1.2108e-01,  6.6691e-02,  2.7666e-01,\n",
       "                       1.4672e-01, -9.9357e-02,  2.5360e-01, -6.3611e-03, -1.5357e-02,\n",
       "                      -1.5333e-03,  2.8977e-02,  1.5384e-01, -1.5899e-02, -3.6035e-02,\n",
       "                       2.8812e-02, -4.0604e-02, -2.0823e-01,  6.7790e-03, -2.6953e-01,\n",
       "                      -7.7018e-02, -6.3551e-02,  3.7537e-04, -5.6850e-02,  1.0864e-01,\n",
       "                      -5.5009e-02,  4.6273e-02, -2.3920e-02, -1.2891e-02,  4.5446e-02,\n",
       "                       4.2277e-02, -5.8607e-02, -8.7344e-02, -4.2797e-02, -2.4738e-01,\n",
       "                      -1.3980e-01, -9.2670e-02,  1.0161e-01, -2.0559e-01,  3.3394e-02,\n",
       "                      -1.3869e-02, -6.7113e-02,  7.1131e-02, -8.9897e-02, -9.1430e-02,\n",
       "                       6.0322e-02, -1.2481e-01, -8.7222e-02, -1.2607e-01, -9.9273e-02,\n",
       "                      -1.3184e-01, -6.0655e-02, -8.2427e-02, -1.1409e-01, -1.6954e-01,\n",
       "                       1.2148e-01, -1.3725e-01, -1.0028e-01, -2.3301e-02, -3.4607e-02,\n",
       "                      -1.0396e-01, -3.6558e-02,  7.6324e-02, -1.0675e-01,  6.0628e-02,\n",
       "                      -1.2236e-01, -8.7334e-02,  6.7064e-02,  2.3529e-03, -1.0104e-01,\n",
       "                      -4.0936e-02,  7.5995e-02, -1.6667e-01, -1.1404e-03,  1.8578e-02,\n",
       "                       5.7667e-03, -9.0696e-02, -1.2077e-01, -1.2156e-01,  6.1362e-02,\n",
       "                      -1.5593e-01, -8.8612e-03, -1.1408e-01, -3.9358e-02, -9.3066e-03,\n",
       "                      -1.4946e-02, -1.0020e-01, -1.0680e-01,  6.4449e-02,  9.8120e-02,\n",
       "                      -1.4836e-02, -1.0713e-01, -1.6584e-01,  1.3088e-02, -2.0182e-01,\n",
       "                      -8.7893e-02, -1.3881e-01, -1.2668e-02, -7.6175e-02, -1.3464e-02,\n",
       "                      -1.8241e-01, -1.2755e-01, -4.4563e-02, -1.3507e-01, -2.6786e-02,\n",
       "                      -1.1747e-01,  1.5855e-01, -1.9114e-01, -1.4539e-01, -8.3586e-02,\n",
       "                      -1.8053e-01, -2.7748e-02, -8.6231e-02,  3.0114e-04, -1.0811e-01,\n",
       "                      -2.8091e-02, -5.9295e-02, -1.5370e-01, -2.2900e-01, -7.6266e-02,\n",
       "                      -8.1838e-02, -5.5302e-02, -1.0602e-01, -9.7402e-02, -8.9417e-02,\n",
       "                      -6.7974e-02, -1.5536e-01,  5.4049e-02, -5.0571e-02, -6.7336e-02,\n",
       "                      -1.7116e-01, -8.8090e-02, -1.5706e-01, -2.2490e-01, -1.1361e-01,\n",
       "                      -1.2470e-01, -1.1497e-01,  2.7035e-02, -5.5665e-02, -9.9178e-02,\n",
       "                       4.3896e-02,  5.6386e-02,  5.2758e-02, -2.1199e-02, -2.9211e-02,\n",
       "                       4.1938e-02,  8.0610e-02,  4.3370e-02, -3.1023e-02, -1.5828e-02,\n",
       "                       1.4616e-02,  7.8177e-02, -7.6593e-02,  1.6301e-01,  7.6691e-03,\n",
       "                      -9.1958e-04, -4.2659e-02,  4.4671e-02,  4.4345e-02,  1.1565e-02,\n",
       "                      -5.6632e-03, -4.8299e-02, -7.9507e-02,  1.4852e-02, -1.3015e-01,\n",
       "                       3.5534e-02, -1.1880e-01, -3.2854e-04,  4.9751e-02,  7.6655e-04,\n",
       "                      -3.7757e-02,  1.8932e-01,  7.8429e-02, -3.4404e-02,  7.9798e-02,\n",
       "                      -4.0634e-02,  6.6475e-02, -9.7195e-02, -3.7510e-02,  8.4350e-02,\n",
       "                      -4.5255e-02,  1.4945e-02, -3.0055e-02,  5.1173e-02,  2.8701e-03,\n",
       "                       4.0074e-02, -1.1645e-01, -1.5784e-01, -1.0488e-01, -3.1240e-02,\n",
       "                      -3.3438e-02, -6.2101e-02, -8.0689e-02,  1.2376e-01,  5.5606e-03,\n",
       "                       1.7026e-03,  5.3051e-02,  5.5052e-03, -8.0455e-03, -6.4164e-02,\n",
       "                       1.3717e-01,  4.3786e-02, -6.5556e-02, -1.1470e-01, -4.8854e-02,\n",
       "                       1.0687e-01,  5.0083e-03,  5.2084e-02,  2.6538e-02, -1.1205e-01,\n",
       "                      -9.2797e-02, -3.2156e-02, -1.7976e-02, -5.0962e-02, -1.0697e-01,\n",
       "                       8.0695e-02, -7.7523e-03, -6.2638e-02,  4.0633e-03,  7.1822e-02,\n",
       "                       7.1640e-02, -9.0298e-02, -4.8186e-02,  4.6444e-02, -5.8282e-02,\n",
       "                       2.1528e-01, -5.9018e-02, -6.7883e-03, -9.2203e-02, -3.5616e-02,\n",
       "                      -5.6723e-03,  1.0400e-01,  7.2791e-03,  2.6039e-02, -3.2755e-02,\n",
       "                       1.0643e-01,  3.0601e-02, -6.7692e-02,  1.0969e-03,  1.2449e-01,\n",
       "                       1.2288e-01,  6.4428e-02, -3.5941e-02, -5.4872e-02,  1.6245e-01,\n",
       "                      -3.6484e-02,  1.2905e-01, -3.3102e-02,  1.1984e-02,  2.9118e-02,\n",
       "                       2.3847e-02,  8.9995e-02,  4.9759e-02, -1.2539e-02,  3.9567e-02,\n",
       "                       1.4460e-02, -2.6231e-02,  6.6290e-02, -7.3386e-02,  4.9564e-02,\n",
       "                      -6.1134e-02, -6.9325e-02,  7.4721e-03, -2.1470e-02,  5.8790e-03,\n",
       "                       2.1814e-02, -4.6358e-02,  7.7785e-04, -2.5964e-02,  1.6772e-03,\n",
       "                       3.9193e-04,  1.7427e-01,  1.4499e-03, -3.9101e-02,  1.3118e-01,\n",
       "                      -2.5040e-02,  5.7108e-02, -8.1709e-03,  1.4173e-01, -6.6156e-02,\n",
       "                      -1.2745e-01,  1.0057e-01,  4.3035e-03, -7.9039e-02,  2.1641e-02,\n",
       "                       1.4608e-01,  1.2252e-01, -9.5081e-03,  5.4682e-02,  7.6803e-02,\n",
       "                      -3.0522e-02,  6.1956e-03,  2.0101e-01, -1.3272e-01, -8.6557e-02,\n",
       "                       5.7605e-02,  1.7733e-01,  9.0175e-02, -1.8179e-02, -2.1008e-02,\n",
       "                      -1.3010e-02,  1.2428e-01,  6.5777e-02,  6.9065e-02,  7.1316e-02,\n",
       "                      -4.3704e-02,  7.2884e-02,  1.2723e-01,  7.1836e-02,  8.9806e-02,\n",
       "                      -4.3038e-02,  1.4785e-01,  2.3176e-01, -2.0263e-02, -3.3089e-02,\n",
       "                       2.1011e-01,  5.8266e-02,  1.6238e-02, -1.6705e-01,  9.8039e-02,\n",
       "                       1.8206e-01,  4.9484e-02,  3.6102e-02,  1.1073e-01,  7.2330e-02,\n",
       "                       1.2822e-01,  8.8124e-02,  6.6246e-02,  1.1543e-01,  1.4086e-02,\n",
       "                       2.5672e-01, -5.9061e-02,  2.9101e-01, -2.2540e-02, -7.0688e-02,\n",
       "                       9.5143e-02, -1.5911e-01,  9.8591e-02, -7.2310e-02,  2.7749e-02,\n",
       "                       6.3866e-02,  1.0806e-01,  2.2638e-01,  8.6417e-02,  7.5950e-02,\n",
       "                       1.1068e-02,  1.5522e-01,  1.6720e-01,  2.4753e-02,  5.1469e-02,\n",
       "                       1.1194e-01,  1.6004e-01,  1.0019e-01,  7.3786e-02,  4.4630e-02,\n",
       "                       7.8824e-02, -4.6833e-02,  9.3084e-02,  1.8632e-01,  6.6845e-02,\n",
       "                      -3.2335e-03,  1.0944e-01,  1.6581e-01,  1.8143e-03,  2.2373e-01,\n",
       "                      -1.7391e-01,  1.5617e-01,  2.3062e-02,  1.0691e-01,  1.7007e-01,\n",
       "                       6.9929e-02, -1.0761e-02, -1.9126e-02,  5.0425e-02,  1.7087e-01,\n",
       "                      -2.4894e-03,  5.1172e-03,  3.1179e-02,  2.9325e-02,  5.8529e-02,\n",
       "                       1.0706e-01,  1.8428e-01,  8.2358e-02,  7.6498e-02,  3.8773e-01,\n",
       "                      -1.6500e-02,  2.4590e-02,  1.0227e-02,  2.5688e-01, -1.2926e-02,\n",
       "                       1.2389e-02,  9.4706e-02, -6.6061e-03, -8.1035e-02, -3.9377e-02,\n",
       "                       6.4137e-03,  2.7934e-02])),\n",
       "             ('bilstm_right_context_feature.bias_hh_l0_reverse',\n",
       "              tensor([ 6.9665e-02,  3.4584e-04, -8.2673e-02, -1.5982e-01, -4.9710e-02,\n",
       "                       5.2529e-02,  6.8530e-02, -6.3140e-02, -5.1113e-02,  1.3191e-01,\n",
       "                      -9.8865e-02,  5.3003e-02, -3.1354e-04,  6.4975e-02, -2.0243e-02,\n",
       "                       9.4385e-02,  1.5146e-01,  1.7390e-01, -2.2039e-02, -4.3438e-02,\n",
       "                       5.9820e-02, -2.9317e-02,  1.0597e-02,  9.5890e-03,  8.2241e-02,\n",
       "                       3.2218e-02, -6.2924e-02,  1.0675e-01,  1.3540e-01,  1.7909e-03,\n",
       "                       3.4854e-02,  1.1854e-01, -6.4194e-02,  8.0583e-02,  1.1174e-01,\n",
       "                       1.3654e-01,  3.3666e-02,  6.0611e-02, -7.4167e-02, -3.5303e-02,\n",
       "                       1.0390e-02, -5.6313e-02, -4.9490e-02,  1.5081e-01, -6.3832e-03,\n",
       "                      -7.3050e-02,  1.2948e-02,  8.5472e-02,  3.2192e-03,  5.1665e-03,\n",
       "                       7.9262e-02,  1.2437e-01,  2.4762e-02, -1.0185e-02, -1.3304e-01,\n",
       "                      -7.7286e-03,  1.3447e-01,  1.0564e-01,  1.3604e-01,  7.7504e-02,\n",
       "                      -3.3725e-02,  1.4123e-02, -1.5245e-01,  2.8046e-01,  8.7590e-02,\n",
       "                       7.4666e-03,  5.0724e-02, -5.3874e-02,  2.0374e-01, -6.8326e-02,\n",
       "                       1.1358e-01,  4.5266e-02,  8.5071e-02,  1.0565e-01,  5.2348e-03,\n",
       "                       1.3145e-01,  9.2629e-02,  1.6605e-01,  1.5815e-01,  4.0383e-02,\n",
       "                      -5.6816e-02,  1.1069e-01,  5.7326e-02,  7.7666e-02,  2.3308e-01,\n",
       "                      -4.5368e-02, -1.0800e-01, -2.2995e-02,  1.3973e-01,  2.0167e-01,\n",
       "                       1.9105e-01, -5.5759e-02,  1.6688e-02,  1.0011e-01,  7.2198e-02,\n",
       "                       5.7793e-02, -1.3376e-02,  8.7140e-02,  3.6401e-02,  3.4658e-02,\n",
       "                       9.0580e-02,  6.3410e-02,  5.0907e-02, -1.6060e-02, -2.4946e-02,\n",
       "                       2.0999e-01,  1.0561e-01, -1.6182e-01, -2.8127e-02,  4.3537e-02,\n",
       "                      -4.6249e-02,  1.2374e-01,  1.4930e-01,  1.0761e-01,  1.6622e-01,\n",
       "                       2.4027e-01,  3.6293e-02,  1.6827e-01,  1.0055e-01,  1.9353e-01,\n",
       "                       1.2381e-01, -5.5980e-02,  1.0154e-01, -8.5414e-02, -1.7086e-01,\n",
       "                       7.0916e-03,  1.4237e-01,  1.2465e-01, -3.5939e-02, -7.1357e-02,\n",
       "                       1.2735e-02, -3.1343e-02, -7.6898e-02, -1.2921e-01, -2.1946e-01,\n",
       "                      -4.0817e-02,  6.1454e-02, -6.9620e-03, -4.9081e-03, -9.0027e-02,\n",
       "                      -2.8401e-01,  3.6046e-03, -8.8501e-02, -8.4797e-02, -3.3340e-02,\n",
       "                      -1.8817e-01,  1.3798e-01, -8.0767e-02, -9.7850e-02, -1.5112e-01,\n",
       "                      -1.2292e-02, -1.6197e-01,  1.4662e-01, -1.0855e-01, -5.1370e-02,\n",
       "                      -1.9724e-01,  1.5990e-01,  6.4589e-02,  3.9332e-02, -8.5326e-02,\n",
       "                       6.2008e-02, -2.7652e-02, -4.6819e-02,  6.5652e-02, -6.7378e-02,\n",
       "                      -6.9026e-02, -1.0945e-01, -2.6795e-02, -1.3715e-01, -3.2286e-01,\n",
       "                       8.8391e-03, -9.9508e-02, -1.3841e-02, -3.6950e-02, -4.0590e-02,\n",
       "                       6.3531e-03,  4.7087e-02, -1.1132e-01, -1.1426e-01, -1.1713e-01,\n",
       "                      -1.2244e-01, -4.3199e-03, -8.1352e-02,  2.6098e-02, -6.2553e-02,\n",
       "                       4.6482e-02, -4.2548e-02, -1.3393e-01, -1.4018e-01, -1.3270e-01,\n",
       "                      -7.0115e-02, -2.7562e-01, -8.3241e-02, -6.1148e-02,  1.7913e-01,\n",
       "                       2.0396e-02, -7.6060e-02, -5.4828e-02, -5.0529e-02, -1.4925e-01,\n",
       "                       6.1483e-02,  8.9661e-02, -1.4201e-01, -2.0810e-02,  5.1177e-03,\n",
       "                      -1.1686e-01, -1.7265e-01, -7.1125e-02, -2.3834e-02, -4.2941e-02,\n",
       "                       9.8666e-02, -1.0645e-01, -9.7806e-02, -1.3776e-01, -1.8087e-02,\n",
       "                      -1.0991e-01, -1.2336e-01,  4.7186e-02, -1.1683e-01, -1.0040e-01,\n",
       "                       3.8843e-03, -1.3072e-02, -9.4364e-02, -1.6113e-01, -1.7190e-01,\n",
       "                      -1.4276e-01, -6.1441e-02,  3.4092e-02,  6.0029e-02, -1.3517e-01,\n",
       "                      -6.6143e-02, -1.4285e-02, -2.1288e-01, -1.8752e-02, -1.3889e-01,\n",
       "                       2.5743e-02,  1.3641e-02, -1.6499e-01, -2.5161e-02,  6.1602e-02,\n",
       "                      -1.5521e-01,  1.5737e-02, -7.9662e-02, -1.2032e-01, -4.6992e-03,\n",
       "                      -2.0445e-01,  8.6235e-02, -1.0891e-01, -9.8157e-02,  3.5471e-02,\n",
       "                      -4.3197e-02, -8.6902e-02,  3.4155e-02,  2.8894e-02, -8.9719e-02,\n",
       "                      -2.1710e-01,  2.5183e-02, -3.5497e-02,  3.4914e-02, -1.5908e-02,\n",
       "                      -8.6133e-02, -3.1537e-02, -1.4566e-02, -1.0974e-01, -7.9159e-03,\n",
       "                      -2.2060e-01,  2.7580e-03, -5.3118e-02,  1.2764e-01,  2.3075e-02,\n",
       "                      -4.9982e-02, -2.9553e-02,  3.8153e-03,  1.2324e-02, -3.0039e-03,\n",
       "                       1.7434e-02,  2.9743e-02, -2.6237e-04, -3.6723e-02, -6.3090e-02,\n",
       "                       4.7538e-02,  4.9411e-02, -1.7430e-02, -4.6252e-02, -1.0397e-01,\n",
       "                       6.4736e-02,  1.3067e-02, -1.1016e-04, -4.0451e-02, -9.3090e-02,\n",
       "                      -2.2468e-02,  3.0930e-02, -6.7773e-02,  5.7652e-02,  1.2211e-02,\n",
       "                      -1.7510e-02,  4.2833e-02, -4.9584e-02,  1.6212e-02,  4.8416e-02,\n",
       "                      -3.5773e-02, -1.0845e-01,  1.5411e-01, -8.5455e-02, -3.0800e-02,\n",
       "                       1.2547e-04,  3.5873e-02,  1.0554e-01,  9.6224e-02, -8.3361e-02,\n",
       "                      -5.3055e-02, -1.7317e-02,  1.2154e-01,  1.2207e-02, -1.2688e-01,\n",
       "                      -2.3952e-02,  7.3745e-02,  1.0908e-01,  7.3039e-02,  6.1682e-03,\n",
       "                       8.7675e-02, -2.0448e-02,  5.5935e-02,  5.7801e-02,  1.5253e-02,\n",
       "                       1.0540e-01, -6.6326e-02,  3.1517e-02, -4.0265e-02, -5.4155e-02,\n",
       "                       1.5153e-01, -4.5117e-02,  7.0782e-02, -7.4827e-02,  1.7551e-01,\n",
       "                      -7.4737e-02, -3.9606e-02,  1.2848e-03, -1.7587e-02, -6.0719e-02,\n",
       "                       1.1221e-01,  4.1641e-02, -3.0972e-02, -5.1212e-02, -7.3196e-02,\n",
       "                      -9.3727e-02, -3.2462e-02, -2.5563e-03,  5.6470e-02,  5.2535e-02,\n",
       "                       8.0820e-02,  1.2704e-02, -8.7738e-02, -3.0875e-02,  7.7884e-02,\n",
       "                      -1.2334e-01,  1.6904e-01,  5.1686e-02,  3.1301e-02,  7.8396e-02,\n",
       "                      -3.0699e-02,  6.3432e-02,  2.3460e-03,  3.1077e-02,  4.3394e-02,\n",
       "                       2.8214e-02, -2.3232e-02,  2.7041e-02, -3.0607e-02,  4.4586e-02,\n",
       "                      -5.9042e-02, -2.7149e-04, -3.9436e-04,  6.4521e-02,  5.0346e-02,\n",
       "                       2.3302e-02, -7.9556e-02,  1.1914e-02,  2.6773e-02,  1.6149e-02,\n",
       "                      -4.3548e-02,  7.3306e-02, -3.2970e-02, -9.6882e-02, -4.1080e-02,\n",
       "                       2.8994e-03,  1.2313e-01, -9.0598e-02,  1.0439e-01,  3.2751e-02,\n",
       "                      -9.4496e-03,  7.1870e-02,  4.7768e-02, -4.6104e-02, -1.3518e-01,\n",
       "                       2.0946e-02,  1.1807e-01,  4.4006e-02,  5.0320e-02,  1.1352e-01,\n",
       "                       6.8735e-02,  1.5656e-01,  9.6479e-02,  9.6808e-03,  8.4434e-02,\n",
       "                      -1.3896e-01,  4.7440e-02,  1.0890e-01, -2.6344e-02, -6.3456e-02,\n",
       "                       1.0395e-01, -7.4962e-02,  1.6005e-01,  3.9915e-02, -4.6947e-02,\n",
       "                      -7.9278e-02, -3.1859e-03,  7.6790e-02,  2.7108e-02,  1.9323e-02,\n",
       "                       5.6412e-02,  1.4569e-01, -5.6092e-03,  4.1986e-02,  2.2494e-01,\n",
       "                       3.7408e-02, -5.9117e-02,  1.8720e-01,  8.4180e-02, -1.0279e-01,\n",
       "                       1.2018e-01,  1.8015e-01,  1.8003e-03, -2.9118e-04,  6.6570e-02,\n",
       "                       1.5340e-01,  1.8888e-02,  3.9265e-02, -2.7437e-02, -9.5584e-02,\n",
       "                       6.2499e-02,  1.6594e-04,  1.0481e-01,  1.7524e-01, -1.5659e-02,\n",
       "                       1.6121e-01, -1.0170e-01,  2.8390e-01,  2.3790e-02, -5.3172e-02,\n",
       "                       1.0760e-01, -2.2344e-02,  1.4050e-01, -9.6788e-02, -1.1717e-03,\n",
       "                       1.2942e-01,  2.2093e-01,  8.6195e-02,  1.0668e-01,  6.9851e-02,\n",
       "                       1.0195e-01,  8.2011e-02,  1.1291e-01,  1.6668e-01, -1.6479e-02,\n",
       "                      -6.7644e-02,  2.3466e-02,  6.1381e-02,  2.0926e-01,  1.4585e-02,\n",
       "                       1.0689e-01, -8.8993e-02,  2.9670e-02,  1.8993e-01,  2.4001e-02,\n",
       "                      -3.1701e-02,  3.4254e-02,  1.3559e-01,  1.0423e-01,  6.7343e-02,\n",
       "                       1.4217e-02,  5.6173e-02,  5.3110e-02,  2.3591e-01,  1.4845e-01,\n",
       "                      -1.4668e-03, -3.3781e-02,  1.4696e-01,  4.1654e-02,  1.8467e-01,\n",
       "                       4.7791e-02, -1.5448e-01,  1.0143e-01,  7.1325e-02,  7.8152e-02,\n",
       "                       7.5751e-03,  1.8548e-01,  3.3165e-01,  1.2311e-02,  4.7547e-01,\n",
       "                       2.7503e-02,  2.0350e-01,  1.2283e-01,  2.1689e-01,  1.4222e-01,\n",
       "                       2.3038e-02,  7.4569e-02, -2.1111e-01,  8.3309e-02,  1.9714e-02,\n",
       "                       9.2755e-02,  1.0418e-01])),\n",
       "             ('fc.0.weight',\n",
       "              tensor([[-0.0594, -0.0553, -0.0164,  ..., -0.0850,  0.1035, -0.0888],\n",
       "                      [-0.0117,  0.0923,  0.2043,  ...,  0.0559,  0.2153, -0.2421],\n",
       "                      [ 0.0113, -0.1302,  0.0955,  ..., -0.2297,  0.3051, -0.0898],\n",
       "                      ...,\n",
       "                      [ 0.1581,  0.0932, -0.0852,  ..., -0.0881, -0.0261,  0.4801],\n",
       "                      [-0.1432, -0.0734,  0.1169,  ..., -0.0910,  0.4320,  0.3356],\n",
       "                      [-0.0554, -0.0359,  0.1705,  ..., -0.2586, -0.0416, -0.3258]])),\n",
       "             ('fc.0.bias',\n",
       "              tensor([ 0.2672, -0.1656,  0.0868,  0.0383,  0.2118,  0.2075, -0.0176,  0.0019,\n",
       "                       0.3091, -0.1343, -0.0134, -0.3580, -0.0780,  0.0959,  0.2735,  0.0591,\n",
       "                       0.0010,  0.0710, -0.1957,  0.1475,  0.0013, -0.0139, -0.1949, -0.0309,\n",
       "                       0.0950, -0.0066, -0.1139, -0.1585,  0.1380,  0.0843, -0.0107, -0.0588,\n",
       "                       0.0879,  0.0477, -0.0133, -0.0006,  0.0859, -0.1137,  0.1890, -0.1828,\n",
       "                       0.1185, -0.0630,  0.0541,  0.0419, -0.0670,  0.3557, -0.0030, -0.0881,\n",
       "                      -0.0232, -0.4149,  0.0637,  0.1158,  0.1216, -0.0278,  0.1507, -0.0840,\n",
       "                      -0.0139, -0.2554,  0.0997,  0.1747, -0.2249,  0.0086, -0.0314, -0.0139])),\n",
       "             ('oov_embedding.weight',\n",
       "              tensor([[ 0.4181, -0.2069, -0.4258,  ..., -0.3545, -0.5112,  0.1872],\n",
       "                      [-0.1372,  0.1608,  0.1810,  ...,  0.2334,  0.1179, -0.0783],\n",
       "                      [ 0.3447, -0.1301,  0.0259,  ..., -0.0728, -0.1001,  0.2556],\n",
       "                      ...,\n",
       "                      [-0.1406,  0.1260,  0.1682,  ...,  0.0154, -0.0989,  0.1019],\n",
       "                      [ 0.2899,  0.0961, -0.0657,  ...,  0.1260, -0.1552,  0.1113],\n",
       "                      [-0.0528,  0.0591,  0.0345,  ..., -0.0411,  0.3558,  0.1663]])),\n",
       "             ('oov_embedding.bias',\n",
       "              tensor([ 0.3110, -0.0423, -0.1402, -0.0198,  0.1388, -0.3071, -0.0859,  0.0877,\n",
       "                       0.4017,  0.1190,  0.0714,  0.0255, -0.0864,  0.1281,  0.0965, -0.4818,\n",
       "                      -0.1143,  0.2610, -0.0286,  0.0747,  0.1987,  0.0303,  0.2369, -0.0307,\n",
       "                       0.0101,  0.2065,  0.2818,  0.0144,  0.1074,  0.3044,  0.1709,  0.1560,\n",
       "                       0.1539,  0.1623, -0.1681,  0.1057, -0.0548,  0.3184,  0.0325, -0.0694,\n",
       "                       0.0675,  0.0183,  0.0661, -0.2445, -0.3823, -0.0432,  0.0539,  0.2846,\n",
       "                      -0.1912,  0.1601, -0.2386, -0.1340,  0.0814,  0.2053, -0.1092, -0.0895,\n",
       "                       0.0136,  0.3212, -0.3507,  0.0934,  0.1562, -0.2124, -0.0606,  0.3407])),\n",
       "             ('prob.0.weight',\n",
       "              tensor([[ 0.1106, -0.0187, -0.0379,  ..., -0.1544, -0.1862, -0.0443],\n",
       "                      [ 0.1499,  0.1451, -0.3496,  ...,  0.1351, -0.2881, -0.3223],\n",
       "                      [-0.3530,  0.0514,  0.0189,  ..., -0.3628,  0.0375,  0.1010],\n",
       "                      ...,\n",
       "                      [ 0.0292,  0.1719,  0.1635,  ..., -0.0964, -0.1351, -0.0429],\n",
       "                      [ 0.0129,  0.0435,  0.0440,  ..., -0.3677, -0.2364, -0.1345],\n",
       "                      [ 0.2823,  0.2453,  0.3977,  ..., -0.2444,  0.1996, -0.1120]])),\n",
       "             ('prob.0.bias',\n",
       "              tensor([-0.4911, -0.0763, -0.1128,  ..., -0.3280, -0.0979,  0.0241]))])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1616de6-2ec1-4a77-980a-addd6d77d6d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
