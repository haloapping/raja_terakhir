{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13fc63c4-da08-43a8-9972-2615d377d1fa",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "313363b9-24d1-4b87-87cd-a0b7dd5fc128",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pytz\n",
    "import torch\n",
    "import timeit\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from itertools import chain\n",
    "from time import time\n",
    "from torch import nn, optim\n",
    "from torchmetrics import F1Score\n",
    "from torch.optim import lr_scheduler\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from polyglot.mapping import Embedding, CaseExpander, DigitExpander"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b49405-006a-4a45-ae79-0e22f6a7172e",
   "metadata": {},
   "source": [
    "# Hyperparameters Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68709d29-24a1-45bf-b549-804952fd1db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hyperparams:\n",
    "     def __init__(\n",
    "        self,\n",
    "        context_size=55,\n",
    "        input_size_left_context=64,\n",
    "        input_size_oov_context=20,\n",
    "        input_size_right_context=64,\n",
    "        batch_size=32,\n",
    "        num_hidden_layer=1,\n",
    "        hidden_size=128,\n",
    "        output_size=3611,\n",
    "        shuffle=True,\n",
    "        lr=0.001,\n",
    "        batch_first=True,\n",
    "        bidirectional=True,\n",
    "        init_wb_with_kaiming_normal=True,\n",
    "        n_epoch=20,\n",
    "        patience=20,\n",
    "        device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    ):\n",
    "        self.context_size = context_size\n",
    "        self.input_size_left_context = input_size_left_context\n",
    "        self.input_size_oov_context = input_size_oov_context\n",
    "        self.input_size_right_context = input_size_right_context\n",
    "        self.batch_size = batch_size\n",
    "        self.num_hidden_layer = num_hidden_layer\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.shuffle = shuffle\n",
    "        self.lr = lr\n",
    "        self.batch_first = batch_first\n",
    "        self.bidirectional = bidirectional\n",
    "        self.init_wb_with_kaiming_normal = init_wb_with_kaiming_normal\n",
    "        self.n_epoch = n_epoch\n",
    "        self.patience = patience\n",
    "        self.device = device\n",
    "        \n",
    "hyperparams = Hyperparams()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f750b1-d4a7-4a2a-9fe1-369a61f28a2b",
   "metadata": {},
   "source": [
    "# Prepare Feature Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f241f20b-fb34-4db2-b887-1687f137b141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left context shape: (16562, 55)\n",
      "OOV context shape: (16562, 28)\n",
      "Right context shape: (16562, 55)\n",
      "Actual lable shape: (16562,)\n"
     ]
    }
   ],
   "source": [
    "def convert_doc_to_idxs(docs, dict_vocabs):\n",
    "    doc_to_idx = []\n",
    "    \n",
    "    for doc in docs:\n",
    "        doc_to_idx.append([dict_vocabs[token] for token in doc])\n",
    "        \n",
    "    return np.array(doc_to_idx)\n",
    "\n",
    "# Left context\n",
    "left_context = open(f\"../../datasets/features/{hyperparams.context_size}_context/left_context_with_pad.pkl\", \"rb\")\n",
    "left_context = pickle.load(left_context)\n",
    "left_context_to_idx = open(f\"../../datasets/features/{hyperparams.context_size}_context/token2idx_left_context.pkl\", \"rb\")\n",
    "left_context_to_idx = pickle.load(left_context_to_idx)\n",
    "doc_left_context_to_idx = convert_doc_to_idxs(left_context, left_context_to_idx)\n",
    "\n",
    "# OOV context\n",
    "oov_context = open(f\"../../datasets/features/{hyperparams.context_size}_context/oov_context_with_pad.pkl\", \"rb\")\n",
    "oov_context = pickle.load(oov_context)\n",
    "oov_context_to_idx = open(f\"../../datasets/features/{hyperparams.context_size}_context/token2idx_oov_context.pkl\", \"rb\")\n",
    "oov_context_to_idx = pickle.load(oov_context_to_idx)\n",
    "doc_oov_context_to_idx = convert_doc_to_idxs(oov_context, oov_context_to_idx)\n",
    "\n",
    "# Right context\n",
    "right_context = open(f\"../../datasets/features/{hyperparams.context_size}_context/right_context_with_pad.pkl\", \"rb\")\n",
    "right_context = pickle.load(right_context)\n",
    "right_context_to_idx = open(f\"../../datasets/features/{hyperparams.context_size}_context/token2idx_right_context.pkl\", \"rb\")\n",
    "right_context_to_idx = pickle.load(right_context_to_idx)\n",
    "doc_right_context_to_idx = convert_doc_to_idxs(right_context, right_context_to_idx)\n",
    "\n",
    "# Actual labels\n",
    "labels_context = open(f\"../../datasets/features/{hyperparams.context_size}_context/lables.pkl\", \"rb\")\n",
    "labels_context = pickle.load(labels_context)\n",
    "labels_to_idx = open(f\"../../datasets/features/{hyperparams.context_size}_context/lable_vocabs.pkl\", \"rb\")\n",
    "labels_to_idx = pickle.load(labels_to_idx)\n",
    "doc_labels_to_idx = convert_doc_to_idxs(labels_context, labels_to_idx).flatten()\n",
    "\n",
    "print(f\"Left context shape: {doc_left_context_to_idx.shape}\")\n",
    "print(f\"OOV context shape: {doc_oov_context_to_idx.shape}\")\n",
    "print(f\"Right context shape: {doc_right_context_to_idx.shape}\")\n",
    "print(f\"Actual lable shape: {doc_labels_to_idx.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe386c1f-3e1d-4589-b18e-42e4bc4055ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to Tensor\n",
    "left_contexts = torch.LongTensor(doc_left_context_to_idx)\n",
    "oov_contexts = torch.LongTensor(doc_oov_context_to_idx)\n",
    "right_contexts = torch.LongTensor(doc_right_context_to_idx)\n",
    "actual_labels = torch.LongTensor(doc_labels_to_idx)\n",
    "dataset = TensorDataset(left_contexts, oov_contexts, right_contexts, actual_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8806cc8-c1d1-450a-833d-f25375c52949",
   "metadata": {},
   "source": [
    "# Char and Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86595b81-a95e-4469-acad-49b9ed2c9662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word Embedding\n",
    "word_embeddings = Embedding.load(\"../../word_embeddings/polyglot/idn_embeddings.tar.bz2\")\n",
    "word_embeddings.apply_expansion(DigitExpander)\n",
    "word_embeddings.apply_expansion(CaseExpander)\n",
    "\n",
    "left_vocabs = open(f\"../../datasets/features/{hyperparams.context_size}_context/left_context_vocabs.pkl\", \"rb\")\n",
    "left_vocabs = pickle.load(left_vocabs)\n",
    "\n",
    "right_vocabs = open(f\"../../datasets/features/{hyperparams.context_size}_context/right_context_vocabs.pkl\", \"rb\")\n",
    "right_vocabs = pickle.load(right_vocabs)\n",
    "\n",
    "left_word_embedding_dict = {left_context_to_idx[vocab] : word_embeddings[vocab] for vocab in left_vocabs}\n",
    "right_word_embedding_dict = {right_context_to_idx[vocab] : word_embeddings[vocab] for vocab in right_vocabs}\n",
    "\n",
    "# Char Embedding\n",
    "char_embedding_dict = open(\"../../word_embeddings/chars_embedding/char_embeddings.pkl\", \"rb\")\n",
    "char_embedding_dict = pickle.load(char_embedding_dict)\n",
    "\n",
    "# Context embedding\n",
    "left_context_embedding = nn.Embedding.from_pretrained(torch.FloatTensor(np.array(list(left_word_embedding_dict.values()))), padding_idx=left_vocabs.index(\"<PAD>\"), freeze=True)\n",
    "oov_context_embedding = nn.Embedding.from_pretrained(torch.FloatTensor(np.array(list(char_embedding_dict.values()))), padding_idx=list(char_embedding_dict.keys()).index(\"PAD\"), freeze=True)\n",
    "right_context_embedding = nn.Embedding.from_pretrained(torch.FloatTensor(np.array(list(right_word_embedding_dict.values()))), padding_idx=right_vocabs.index(\"<PAD>\"), freeze=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593ddcfe-1525-41ae-bf02-c9ebf3d957aa",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "998fb38d-da64-4b4c-9371-75e06ebfc8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=hyperparams.batch_size, shuffle=hyperparams.shuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5be550-2f41-41b4-9df4-ac67744041c5",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed852446-c649-4727-b9ff-64375cf7e966",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Comick(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size_left_context=hyperparams.input_size_left_context,\n",
    "        input_size_oov_context=hyperparams.input_size_oov_context,\n",
    "        input_size_right_context=hyperparams.input_size_right_context,\n",
    "        hidden_size=hyperparams.hidden_size,\n",
    "        num_layers=hyperparams.num_hidden_layer,\n",
    "        output_size=hyperparams.output_size,\n",
    "        batch_first=hyperparams.batch_first,\n",
    "        bidirectional=hyperparams.bidirectional,\n",
    "        init_wb_with_kaiming_normal=hyperparams.init_wb_with_kaiming_normal\n",
    "    ):\n",
    "        super(Comick, self).__init__()\n",
    "        \n",
    "        self.input_size_left_context = input_size_left_context\n",
    "        self.input_size_oov_context = input_size_oov_context\n",
    "        self.input_size_right_context = input_size_right_context\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.output_size = output_size\n",
    "        self.batch_first = batch_first\n",
    "        self.bidirectional = bidirectional\n",
    "        \n",
    "        self.bilstm_left_context_feature = nn.LSTM(\n",
    "            input_size = self.input_size_left_context,\n",
    "            hidden_size = self.hidden_size,\n",
    "            num_layers = self.num_layers,\n",
    "            batch_first = self.batch_first,\n",
    "            bidirectional = self.bidirectional\n",
    "        )\n",
    "        \n",
    "        self.bilstm_oov_context_feature = nn.LSTM(\n",
    "            input_size = self.input_size_oov_context,\n",
    "            hidden_size = self.hidden_size,\n",
    "            num_layers = self.num_layers,\n",
    "            batch_first = self.batch_first,\n",
    "            bidirectional = self.bidirectional\n",
    "        )\n",
    "        \n",
    "        self.bilstm_right_context_feature = nn.LSTM(\n",
    "            input_size = self.input_size_right_context,\n",
    "            hidden_size = self.hidden_size,\n",
    "            num_layers = self.num_layers,\n",
    "            batch_first = self.batch_first,\n",
    "            bidirectional = self.bidirectional\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(2 * self.hidden_size, 64),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "        self.oov_embedding = nn.Linear(in_features=3 * 64, out_features=64)\n",
    "        \n",
    "        self.embedding = np.empty((output_size, 64), dtype=np.float32)\n",
    "        \n",
    "        self.prob = nn.Sequential(\n",
    "            nn.Linear(64, self.output_size),\n",
    "            nn.LogSoftmax(dim=1)\n",
    "        )\n",
    "                \n",
    "        if init_wb_with_kaiming_normal:\n",
    "            self.init_wb()\n",
    "            \n",
    "    def init_wb(self):\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, (nn.Linear, nn.LSTM)):\n",
    "                for name, param in module.named_parameters():\n",
    "                    if \"weight\" in name:\n",
    "                        nn.init.kaiming_normal_(param)\n",
    "                    else:\n",
    "                        nn.init.kaiming_normal_(param.reshape(1, -1))\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_left_context,\n",
    "        input_oov_context,\n",
    "        input_right_context,\n",
    "        idxs_target,\n",
    "        hidden_left_context=None,\n",
    "        hidden_oov_context=None,\n",
    "        hidden_right_context=None,\n",
    "    ):\n",
    "        # BiLSTM left, oov, and right context\n",
    "        output_left_context, (hidden_left_context, memory_left_context) = self.bilstm_left_context_feature(input_left_context, hidden_left_context)\n",
    "        output_oov_context, (hidden_oov_context, memory_oov_context) = self.bilstm_oov_context_feature(input_oov_context, hidden_oov_context)\n",
    "        output_right_context, (hidden_right_context, memory_right_context) = self.bilstm_right_context_feature(input_right_context, hidden_right_context)\n",
    "                \n",
    "        # Concate hidden (forward and backward hidden BiLSTM)\n",
    "        hidden_left_bidirectional = torch.cat((hidden_left_context[0], hidden_left_context[-1]), dim=1)\n",
    "        hidden_oov_bidirectional = torch.cat((hidden_oov_context[0], hidden_oov_context[-1]), dim=1)\n",
    "        hidden_right_bidirectional = torch.cat((hidden_right_context[0], hidden_right_context[-1]), dim=1)\n",
    "        \n",
    "        # Fully connected\n",
    "        output_left_fc = self.fc(hidden_left_bidirectional)\n",
    "        output_oov_fc = self.fc(hidden_oov_bidirectional)\n",
    "        output_right_fc = self.fc(hidden_right_bidirectional)\n",
    "        \n",
    "        # Concate output left, oov, and right context feature\n",
    "        output = torch.cat((output_left_fc, output_oov_fc, output_right_fc), dim=1)\n",
    "        \n",
    "        # OOV embedding\n",
    "        output = self.oov_embedding(output)\n",
    "                \n",
    "        # save OOV embedding\n",
    "        self.embedding[idxs_target.tolist()] = output.cpu().detach().numpy()\n",
    "        \n",
    "        # Projection OOV embedding\n",
    "        prob = self.prob(output)\n",
    "        \n",
    "        return prob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992eb40b-9062-47f1-9703-65e80d6cb07d",
   "metadata": {},
   "source": [
    "# Model, Optimizer, Criterion, Metric, and Learning Rate Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b08d05fc-0bb5-426e-aa7b-eb930ba9f06b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Comick(\n",
       "  (bilstm_left_context_feature): LSTM(64, 128, batch_first=True, bidirectional=True)\n",
       "  (bilstm_oov_context_feature): LSTM(20, 128, batch_first=True, bidirectional=True)\n",
       "  (bilstm_right_context_feature): LSTM(64, 128, batch_first=True, bidirectional=True)\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (1): Tanh()\n",
       "  )\n",
       "  (oov_embedding): Linear(in_features=192, out_features=64, bias=True)\n",
       "  (prob): Sequential(\n",
       "    (0): Linear(in_features=64, out_features=3611, bias=True)\n",
       "    (1): LogSoftmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Comick().to(hyperparams.device)\n",
    "model.prob[0].requires_grad_ = False # disable gradient for projection layer\n",
    "optimizer = optim.Adam(model.parameters(), lr=hyperparams.lr)\n",
    "criterion = nn.NLLLoss(ignore_index=list(char_embedding_dict.keys()).index(\"PAD\")).to(hyperparams.device)\n",
    "metric = F1Score(ignore_index=list(char_embedding_dict.keys()).index(\"PAD\")).to(hyperparams.device)\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.5)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d463d75-dd43-4b45-9eec-8f4aca21b018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "814,427\n"
     ]
    }
   ],
   "source": [
    "print(f\"{sum([param.numel() for param in model.parameters() if param.requires_grad_]):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "494a567d-acbc-46c2-adc8-b9a512366c17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-6.1108802e-27,  4.5650100e-41, -6.1108802e-27, ...,\n",
       "         4.5650100e-41,  1.3638934e-36,  4.5650100e-41],\n",
       "       [ 1.0882344e-40,  0.0000000e+00,  3.6886122e-37, ...,\n",
       "         0.0000000e+00,  3.6886839e-37,  4.5650100e-41],\n",
       "       [ 1.3639623e-36,  4.5650100e-41,  1.0883885e-40, ...,\n",
       "         4.5650100e-41,  1.0885286e-40,  0.0000000e+00],\n",
       "       ...,\n",
       "       [ 1.3717741e-36,  4.5650100e-41,  1.1057086e-40, ...,\n",
       "         4.5650100e-41,  1.1058487e-40,  0.0000000e+00],\n",
       "       [ 5.3499288e-38,  4.5650100e-41,  1.3718372e-36, ...,\n",
       "         4.5650100e-41,  1.3718946e-36,  4.5650100e-41],\n",
       "       [ 1.1060028e-40,  0.0000000e+00,  5.3501261e-38, ...,\n",
       "         0.0000000e+00,  5.3503055e-38,  4.5650100e-41]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b39ba3-b103-44da-ae1e-34fd12ad2d2f",
   "metadata": {},
   "source": [
    "# Training Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c51a3a6-a4af-425f-aa1f-34ffe9ff8248",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_step(dataloader, model, optimizer, criterion, metric, scheduler=None, path_name=None):\n",
    "    model.train()\n",
    "    \n",
    "    batch_losses = []\n",
    "    batch_metric_scores = []\n",
    "    \n",
    "    for batch, (input_left_context, input_oov_context, input_right_context, actual_label) in enumerate(tqdm(dataloader), 1):\n",
    "        # Forward Propagation\n",
    "        prob = model(\n",
    "            left_context_embedding(input_left_context).to(hyperparams.device),\n",
    "            oov_context_embedding(input_oov_context).to(hyperparams.device),\n",
    "            right_context_embedding(input_right_context).to(hyperparams.device),\n",
    "            actual_label.to(hyperparams.device)\n",
    "        )\n",
    "                \n",
    "        loss = criterion(prob, actual_label.to(hyperparams.device))\n",
    "        metric_score = metric(prob.argmax(dim=1), actual_label.to(hyperparams.device))\n",
    "        metric_score = metric.compute()\n",
    "        \n",
    "        if scheduler is not None:\n",
    "            scheduler.step(loss)\n",
    "        \n",
    "        batch_losses.append(loss.item())\n",
    "        batch_metric_scores.append(metric_score)\n",
    "        \n",
    "        if batch % 50 == 0 or batch == len(dataloader):\n",
    "            batch_name = \"Batch-\" + str(batch)\n",
    "            print(f\"{batch_name.ljust(9)}: {str(criterion).split('(')[0]}={(loss.item()):.4f} | {str(metric).split('(')[0]}={(metric_score):.4f}\")\n",
    "            with open(f\"../../logs/comick/{hyperparams.context_size}_contexts/{path_name}/training_history.txt\", \"a\") as f:\n",
    "                f.write(f\"{batch_name.ljust(9)}: {str(criterion).split('(')[0]}={(loss.item()):.4f} | {str(metric).split('(')[0]}={(metric_score):.4f}\\n\")\n",
    "\n",
    "        # Backward Propagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    return batch_losses, batch_metric_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3043a1-39cb-4b38-8024-54f909a565a9",
   "metadata": {},
   "source": [
    "# Looping Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e139244-b036-4d45-beca-1de5bd7b5e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH-1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27c61dc039324074a156759f90f26962",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=6.6898 | F1Score=0.2831\n",
      "Batch-100: NLLLoss=5.7229 | F1Score=0.3097\n",
      "Batch-150: NLLLoss=5.7369 | F1Score=0.3306\n",
      "Batch-200: NLLLoss=4.4095 | F1Score=0.3500\n",
      "Batch-250: NLLLoss=3.8921 | F1Score=0.3717\n",
      "Batch-300: NLLLoss=4.4559 | F1Score=0.3844\n",
      "Batch-350: NLLLoss=4.4180 | F1Score=0.3978\n",
      "Batch-400: NLLLoss=3.0422 | F1Score=0.4092\n",
      "Batch-450: NLLLoss=4.0458 | F1Score=0.4211\n",
      "Batch-500: NLLLoss=2.1492 | F1Score=0.4328\n",
      "Batch-518: NLLLoss=4.7859 | F1Score=0.4369\n",
      "\n",
      "Mean NLLLoss: 4.5272 | Mean F1Score: 0.3571\n",
      "==================================================\n",
      "\n",
      "EPOCH-2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97a325c1f99942759eb1e274c2928290",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=2.8761 | F1Score=0.5900\n",
      "Batch-100: NLLLoss=2.3925 | F1Score=0.5947\n",
      "Batch-150: NLLLoss=2.6063 | F1Score=0.5890\n",
      "Batch-200: NLLLoss=2.7851 | F1Score=0.5991\n",
      "Batch-250: NLLLoss=3.3482 | F1Score=0.6072\n",
      "Batch-300: NLLLoss=2.3620 | F1Score=0.6193\n",
      "Batch-350: NLLLoss=2.1349 | F1Score=0.6231\n",
      "Batch-400: NLLLoss=2.5970 | F1Score=0.6279\n",
      "Batch-450: NLLLoss=2.1390 | F1Score=0.6328\n",
      "Batch-500: NLLLoss=1.8613 | F1Score=0.6363\n",
      "Batch-518: NLLLoss=2.8440 | F1Score=0.6387\n",
      "\n",
      "Yeah ðŸŽ‰ðŸ˜„! Model improved.\n",
      "Mean NLLLoss: 2.7032 | Mean F1Score: 0.6087\n",
      "==================================================\n",
      "\n",
      "EPOCH-3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5dd31f038754bc5be29cce3fe820a9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=2.1285 | F1Score=0.7300\n",
      "Batch-100: NLLLoss=1.6368 | F1Score=0.7322\n",
      "Batch-150: NLLLoss=1.7694 | F1Score=0.7238\n",
      "Batch-200: NLLLoss=2.8020 | F1Score=0.7293\n",
      "Batch-250: NLLLoss=1.8479 | F1Score=0.7274\n",
      "Batch-300: NLLLoss=2.2908 | F1Score=0.7273\n",
      "Batch-350: NLLLoss=1.6132 | F1Score=0.7290\n",
      "Batch-400: NLLLoss=1.4833 | F1Score=0.7352\n",
      "Batch-450: NLLLoss=0.5174 | F1Score=0.7404\n",
      "Batch-500: NLLLoss=2.0886 | F1Score=0.7430\n",
      "Batch-518: NLLLoss=2.0708 | F1Score=0.7440\n",
      "\n",
      "Yeah ðŸŽ‰ðŸ˜„! Model improved.\n",
      "Mean NLLLoss: 1.7863 | Mean F1Score: 0.7325\n",
      "==================================================\n",
      "\n",
      "EPOCH-4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23c934d48ccd46db9dd6c21fd47b6a40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=1.5221 | F1Score=0.8231\n",
      "Batch-100: NLLLoss=1.4136 | F1Score=0.8147\n",
      "Batch-150: NLLLoss=1.0058 | F1Score=0.8169\n",
      "Batch-200: NLLLoss=1.2895 | F1Score=0.8148\n",
      "Batch-250: NLLLoss=0.9902 | F1Score=0.8145\n",
      "Batch-300: NLLLoss=1.4562 | F1Score=0.8162\n",
      "Batch-350: NLLLoss=0.8650 | F1Score=0.8156\n",
      "Batch-400: NLLLoss=1.3459 | F1Score=0.8163\n",
      "Batch-450: NLLLoss=0.9655 | F1Score=0.8187\n",
      "Batch-500: NLLLoss=1.1633 | F1Score=0.8179\n",
      "Batch-518: NLLLoss=0.9565 | F1Score=0.8176\n",
      "\n",
      "Yeah ðŸŽ‰ðŸ˜„! Model improved.\n",
      "Mean NLLLoss: 1.1601 | Mean F1Score: 0.8182\n",
      "==================================================\n",
      "\n",
      "EPOCH-5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54a7e189df564feaa5648f902fc76fce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=0.7781 | F1Score=0.8869\n",
      "Batch-100: NLLLoss=0.7336 | F1Score=0.8866\n",
      "Batch-150: NLLLoss=1.0223 | F1Score=0.8834\n",
      "Batch-200: NLLLoss=0.6934 | F1Score=0.8801\n",
      "Batch-250: NLLLoss=0.4934 | F1Score=0.8801\n",
      "Batch-300: NLLLoss=0.5678 | F1Score=0.8780\n",
      "Batch-350: NLLLoss=0.5300 | F1Score=0.8748\n",
      "Batch-400: NLLLoss=0.5632 | F1Score=0.8735\n",
      "Batch-450: NLLLoss=1.1457 | F1Score=0.8743\n",
      "Batch-500: NLLLoss=0.2405 | F1Score=0.8749\n",
      "Batch-518: NLLLoss=1.2864 | F1Score=0.8745\n",
      "\n",
      "Yeah ðŸŽ‰ðŸ˜„! Model improved.\n",
      "Mean NLLLoss: 0.6915 | Mean F1Score: 0.8781\n",
      "==================================================\n",
      "\n",
      "EPOCH-6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9e5b49b37474159b79e9e109df1ceac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=0.5446 | F1Score=0.9488\n",
      "Batch-100: NLLLoss=0.1697 | F1Score=0.9478\n",
      "Batch-150: NLLLoss=0.2215 | F1Score=0.9467\n",
      "Batch-200: NLLLoss=0.3147 | F1Score=0.9468\n",
      "Batch-250: NLLLoss=0.4385 | F1Score=0.9459\n",
      "Batch-300: NLLLoss=0.2305 | F1Score=0.9424\n",
      "Batch-350: NLLLoss=0.4862 | F1Score=0.9408\n",
      "Batch-400: NLLLoss=0.2013 | F1Score=0.9399\n",
      "Batch-450: NLLLoss=0.3517 | F1Score=0.9393\n",
      "Batch-500: NLLLoss=0.2968 | F1Score=0.9377\n",
      "Batch-518: NLLLoss=0.6110 | F1Score=0.9371\n",
      "\n",
      "Yeah ðŸŽ‰ðŸ˜„! Model improved.\n",
      "Mean NLLLoss: 0.3431 | Mean F1Score: 0.9447\n",
      "==================================================\n",
      "\n",
      "EPOCH-7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c0e2d514da744f78f64089ff145de92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=0.1828 | F1Score=0.9919\n",
      "Batch-100: NLLLoss=0.0255 | F1Score=0.9925\n",
      "Batch-150: NLLLoss=0.2095 | F1Score=0.9928\n",
      "Batch-200: NLLLoss=0.0240 | F1Score=0.9913\n",
      "Batch-250: NLLLoss=0.0840 | F1Score=0.9902\n",
      "Batch-300: NLLLoss=0.1404 | F1Score=0.9899\n",
      "Batch-350: NLLLoss=0.2597 | F1Score=0.9896\n",
      "Batch-400: NLLLoss=0.2111 | F1Score=0.9883\n",
      "Batch-450: NLLLoss=0.0698 | F1Score=0.9879\n",
      "Batch-500: NLLLoss=0.0290 | F1Score=0.9876\n",
      "Batch-518: NLLLoss=0.2910 | F1Score=0.9872\n",
      "\n",
      "Yeah ðŸŽ‰ðŸ˜„! Model improved.\n",
      "Mean NLLLoss: 0.1144 | Mean F1Score: 0.9905\n",
      "==================================================\n",
      "\n",
      "EPOCH-8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3608d03ade1466c93f4fa0ed8cbb351",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=0.0187 | F1Score=0.9994\n",
      "Batch-100: NLLLoss=0.0254 | F1Score=0.9991\n",
      "Batch-150: NLLLoss=0.0821 | F1Score=0.9994\n",
      "Batch-200: NLLLoss=0.0141 | F1Score=0.9988\n",
      "Batch-250: NLLLoss=0.0227 | F1Score=0.9989\n",
      "Batch-300: NLLLoss=0.0223 | F1Score=0.9991\n",
      "Batch-350: NLLLoss=0.0239 | F1Score=0.9991\n",
      "Batch-400: NLLLoss=0.0508 | F1Score=0.9992\n",
      "Batch-450: NLLLoss=0.0318 | F1Score=0.9991\n",
      "Batch-500: NLLLoss=0.0251 | F1Score=0.9989\n",
      "Batch-518: NLLLoss=0.0276 | F1Score=0.9990\n",
      "\n",
      "Yeah ðŸŽ‰ðŸ˜„! Model improved.\n",
      "Mean NLLLoss: 0.0286 | Mean F1Score: 0.9991\n",
      "==================================================\n",
      "\n",
      "EPOCH-9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "673f4fc55d184639a2d08889bfb913d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=0.0063 | F1Score=0.9997\n",
      "Batch-100: NLLLoss=0.0166 | F1Score=0.9998\n",
      "Batch-150: NLLLoss=0.0127 | F1Score=0.9995\n",
      "Batch-200: NLLLoss=0.0170 | F1Score=0.9994\n",
      "Batch-250: NLLLoss=0.0168 | F1Score=0.9995\n",
      "Batch-300: NLLLoss=0.0173 | F1Score=0.9996\n",
      "Batch-350: NLLLoss=0.0050 | F1Score=0.9996\n",
      "Batch-400: NLLLoss=0.0102 | F1Score=0.9995\n",
      "Batch-450: NLLLoss=0.0304 | F1Score=0.9995\n",
      "Batch-500: NLLLoss=0.0086 | F1Score=0.9995\n",
      "Batch-518: NLLLoss=0.0084 | F1Score=0.9995\n",
      "\n",
      "Yeah ðŸŽ‰ðŸ˜„! Model improved.\n",
      "Mean NLLLoss: 0.0105 | Mean F1Score: 0.9995\n",
      "==================================================\n",
      "\n",
      "EPOCH-10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79658550c1b44892be7b31a145374132",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=0.0077 | F1Score=0.9994\n",
      "Batch-100: NLLLoss=0.0059 | F1Score=0.9987\n",
      "Batch-150: NLLLoss=0.1637 | F1Score=0.9990\n",
      "Batch-200: NLLLoss=0.0067 | F1Score=0.9990\n",
      "Batch-250: NLLLoss=0.0069 | F1Score=0.9992\n",
      "Batch-300: NLLLoss=0.0035 | F1Score=0.9993\n",
      "Batch-350: NLLLoss=0.0077 | F1Score=0.9993\n",
      "Batch-400: NLLLoss=0.0050 | F1Score=0.9994\n",
      "Batch-450: NLLLoss=0.0056 | F1Score=0.9995\n",
      "Batch-500: NLLLoss=0.0035 | F1Score=0.9995\n",
      "Batch-518: NLLLoss=0.0035 | F1Score=0.9995\n",
      "\n",
      "Yeah ðŸŽ‰ðŸ˜„! Model improved.\n",
      "Mean NLLLoss: 0.0076 | Mean F1Score: 0.9992\n",
      "==================================================\n",
      "\n",
      "EPOCH-11\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcd2a09088a944cabf6b28aca0aeeea7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=0.0044 | F1Score=1.0000\n",
      "Batch-100: NLLLoss=0.0025 | F1Score=1.0000\n",
      "Batch-150: NLLLoss=0.0025 | F1Score=0.9999\n",
      "Batch-200: NLLLoss=0.0041 | F1Score=0.9998\n",
      "Batch-250: NLLLoss=0.0038 | F1Score=0.9999\n",
      "Batch-300: NLLLoss=0.0034 | F1Score=0.9999\n",
      "Batch-350: NLLLoss=0.0036 | F1Score=0.9999\n",
      "Batch-400: NLLLoss=0.0031 | F1Score=0.9998\n",
      "Batch-450: NLLLoss=0.0018 | F1Score=0.9998\n",
      "Batch-500: NLLLoss=0.0047 | F1Score=0.9997\n",
      "Batch-518: NLLLoss=0.0035 | F1Score=0.9998\n",
      "\n",
      "Yeah ðŸŽ‰ðŸ˜„! Model improved.\n",
      "Mean NLLLoss: 0.0048 | Mean F1Score: 0.9999\n",
      "==================================================\n",
      "\n",
      "EPOCH-12\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48954e710dd4492993d5f01324f1e46b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=0.0035 | F1Score=0.9997\n",
      "Batch-100: NLLLoss=0.0029 | F1Score=0.9998\n",
      "Batch-150: NLLLoss=0.0025 | F1Score=0.9999\n",
      "Batch-200: NLLLoss=0.0039 | F1Score=0.9998\n",
      "Batch-250: NLLLoss=0.0024 | F1Score=0.9999\n",
      "Batch-300: NLLLoss=0.0011 | F1Score=0.9999\n",
      "Batch-350: NLLLoss=0.0029 | F1Score=0.9998\n",
      "Batch-400: NLLLoss=0.0039 | F1Score=0.9996\n",
      "Batch-450: NLLLoss=0.0099 | F1Score=0.9994\n",
      "Batch-500: NLLLoss=0.0043 | F1Score=0.9995\n",
      "Batch-518: NLLLoss=0.0028 | F1Score=0.9995\n",
      "\n",
      "Huft ðŸ˜¥! Model not improved.\n",
      "Mean NLLLoss: 0.0058 | Mean F1Score: 0.9997\n",
      "Patience = 1/20â—\n",
      "==================================================\n",
      "\n",
      "EPOCH-13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "896ff777a42b42d798d8f94bc821dee1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=0.2077 | F1Score=0.9984\n",
      "Batch-100: NLLLoss=0.0069 | F1Score=0.9989\n",
      "Batch-150: NLLLoss=0.0029 | F1Score=0.9989\n",
      "Batch-200: NLLLoss=0.0074 | F1Score=0.9991\n",
      "Batch-250: NLLLoss=0.0040 | F1Score=0.9992\n",
      "Batch-300: NLLLoss=0.0075 | F1Score=0.9993\n",
      "Batch-350: NLLLoss=0.0041 | F1Score=0.9994\n",
      "Batch-400: NLLLoss=0.0158 | F1Score=0.9995\n",
      "Batch-450: NLLLoss=0.0399 | F1Score=0.9994\n",
      "Batch-500: NLLLoss=0.7900 | F1Score=0.9912\n",
      "Batch-518: NLLLoss=0.5055 | F1Score=0.9876\n",
      "\n",
      "Huft ðŸ˜¥! Model not improved.\n",
      "Mean NLLLoss: 0.0594 | Mean F1Score: 0.9986\n",
      "Patience = 2/20â—\n",
      "==================================================\n",
      "\n",
      "EPOCH-14\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9e1485fac9240549dbc215aaf123393",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=0.7197 | F1Score=0.8865\n",
      "Batch-100: NLLLoss=0.4517 | F1Score=0.9064\n",
      "Batch-150: NLLLoss=0.2416 | F1Score=0.9118\n",
      "Batch-200: NLLLoss=0.2324 | F1Score=0.9234\n",
      "Batch-250: NLLLoss=0.1667 | F1Score=0.9281\n",
      "Batch-300: NLLLoss=0.2671 | F1Score=0.9322\n",
      "Batch-350: NLLLoss=0.0958 | F1Score=0.9367\n",
      "Batch-400: NLLLoss=0.0954 | F1Score=0.9387\n",
      "Batch-450: NLLLoss=0.0715 | F1Score=0.9408\n",
      "Batch-500: NLLLoss=0.0776 | F1Score=0.9435\n",
      "Batch-518: NLLLoss=0.1189 | F1Score=0.9441\n",
      "\n",
      "Huft ðŸ˜¥! Model not improved.\n",
      "Mean NLLLoss: 0.2308 | Mean F1Score: 0.9220\n",
      "Patience = 3/20â—\n",
      "==================================================\n",
      "\n",
      "EPOCH-15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e12efc6fdf25453fa5fe1c0de6171541",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=0.0522 | F1Score=0.9925\n",
      "Batch-100: NLLLoss=0.0218 | F1Score=0.9934\n",
      "Batch-150: NLLLoss=0.0079 | F1Score=0.9946\n",
      "Batch-200: NLLLoss=0.0065 | F1Score=0.9953\n",
      "Batch-250: NLLLoss=0.0031 | F1Score=0.9962\n",
      "Batch-300: NLLLoss=0.0097 | F1Score=0.9967\n",
      "Batch-350: NLLLoss=0.0156 | F1Score=0.9971\n",
      "Batch-400: NLLLoss=0.0028 | F1Score=0.9974\n",
      "Batch-450: NLLLoss=0.0304 | F1Score=0.9973\n",
      "Batch-500: NLLLoss=0.0182 | F1Score=0.9976\n",
      "Batch-518: NLLLoss=0.0051 | F1Score=0.9976\n",
      "\n",
      "Yeah ðŸŽ‰ðŸ˜„! Model improved.\n",
      "Mean NLLLoss: 0.0154 | Mean F1Score: 0.9955\n",
      "==================================================\n",
      "\n",
      "EPOCH-16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eace4be02f1d4e49affdfe1dc0c0e804",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=0.0011 | F1Score=0.9987\n",
      "Batch-100: NLLLoss=0.0018 | F1Score=0.9994\n",
      "Batch-150: NLLLoss=0.0017 | F1Score=0.9994\n",
      "Batch-200: NLLLoss=0.0008 | F1Score=0.9994\n",
      "Batch-250: NLLLoss=0.0021 | F1Score=0.9995\n",
      "Batch-300: NLLLoss=0.0018 | F1Score=0.9995\n",
      "Batch-350: NLLLoss=0.0015 | F1Score=0.9995\n",
      "Batch-400: NLLLoss=0.0018 | F1Score=0.9995\n",
      "Batch-450: NLLLoss=0.0015 | F1Score=0.9996\n",
      "Batch-500: NLLLoss=0.0019 | F1Score=0.9996\n",
      "Batch-518: NLLLoss=0.0003 | F1Score=0.9996\n",
      "\n",
      "Yeah ðŸŽ‰ðŸ˜„! Model improved.\n",
      "Mean NLLLoss: 0.0039 | Mean F1Score: 0.9994\n",
      "==================================================\n",
      "\n",
      "EPOCH-17\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "396007b92c584fc09956f0cbb93690fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=0.0021 | F1Score=0.9997\n",
      "Batch-100: NLLLoss=0.0016 | F1Score=0.9998\n",
      "Batch-150: NLLLoss=0.0016 | F1Score=0.9999\n",
      "Batch-200: NLLLoss=0.0020 | F1Score=0.9999\n",
      "Batch-250: NLLLoss=0.0010 | F1Score=0.9999\n",
      "Batch-300: NLLLoss=0.0016 | F1Score=0.9998\n",
      "Batch-350: NLLLoss=0.0013 | F1Score=0.9998\n",
      "Batch-400: NLLLoss=0.0007 | F1Score=0.9998\n",
      "Batch-450: NLLLoss=0.0012 | F1Score=0.9998\n",
      "Batch-500: NLLLoss=0.0005 | F1Score=0.9998\n",
      "Batch-518: NLLLoss=0.0018 | F1Score=0.9998\n",
      "\n",
      "Yeah ðŸŽ‰ðŸ˜„! Model improved.\n",
      "Mean NLLLoss: 0.0015 | Mean F1Score: 0.9998\n",
      "==================================================\n",
      "\n",
      "EPOCH-18\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f2f0f0e82c244dcb065f29f0da31bc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=0.0010 | F1Score=0.9997\n",
      "Batch-100: NLLLoss=0.0007 | F1Score=0.9997\n",
      "Batch-150: NLLLoss=0.0006 | F1Score=0.9998\n",
      "Batch-200: NLLLoss=0.0013 | F1Score=0.9998\n",
      "Batch-250: NLLLoss=0.0015 | F1Score=0.9999\n",
      "Batch-300: NLLLoss=0.0012 | F1Score=0.9998\n",
      "Batch-350: NLLLoss=0.0005 | F1Score=0.9998\n",
      "Batch-400: NLLLoss=0.0008 | F1Score=0.9998\n",
      "Batch-450: NLLLoss=0.0009 | F1Score=0.9998\n",
      "Batch-500: NLLLoss=0.0007 | F1Score=0.9998\n",
      "Batch-518: NLLLoss=0.0013 | F1Score=0.9998\n",
      "\n",
      "Huft ðŸ˜¥! Model not improved.\n",
      "Mean NLLLoss: 0.0017 | Mean F1Score: 0.9998\n",
      "Patience = 4/20â—\n",
      "==================================================\n",
      "\n",
      "EPOCH-19\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b3fda33852e41a980e2f2d70691678a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=0.0006 | F1Score=1.0000\n",
      "Batch-100: NLLLoss=0.0008 | F1Score=1.0000\n",
      "Batch-150: NLLLoss=0.0011 | F1Score=0.9999\n",
      "Batch-200: NLLLoss=0.0009 | F1Score=0.9999\n",
      "Batch-250: NLLLoss=0.0008 | F1Score=0.9998\n",
      "Batch-300: NLLLoss=0.0009 | F1Score=0.9998\n",
      "Batch-350: NLLLoss=0.0003 | F1Score=0.9998\n",
      "Batch-400: NLLLoss=0.0013 | F1Score=0.9998\n",
      "Batch-450: NLLLoss=0.0010 | F1Score=0.9998\n",
      "Batch-500: NLLLoss=0.0004 | F1Score=0.9998\n",
      "Batch-518: NLLLoss=0.0013 | F1Score=0.9998\n",
      "\n",
      "Huft ðŸ˜¥! Model not improved.\n",
      "Mean NLLLoss: 0.0018 | Mean F1Score: 0.9999\n",
      "Patience = 5/20â—\n",
      "==================================================\n",
      "\n",
      "EPOCH-20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a810a799ea4c47a6ac31c3d74b2a0647",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=0.0007 | F1Score=1.0000\n",
      "Batch-100: NLLLoss=0.0005 | F1Score=1.0000\n",
      "Batch-150: NLLLoss=0.0015 | F1Score=0.9997\n",
      "Batch-200: NLLLoss=0.0006 | F1Score=0.9998\n",
      "Batch-250: NLLLoss=0.0007 | F1Score=0.9998\n",
      "Batch-300: NLLLoss=0.0007 | F1Score=0.9998\n",
      "Batch-350: NLLLoss=0.0007 | F1Score=0.9998\n",
      "Batch-400: NLLLoss=0.0006 | F1Score=0.9998\n",
      "Batch-450: NLLLoss=0.0003 | F1Score=0.9998\n",
      "Batch-500: NLLLoss=0.0006 | F1Score=0.9997\n",
      "Batch-518: NLLLoss=0.0551 | F1Score=0.9997\n",
      "\n",
      "Yeah ðŸŽ‰ðŸ˜„! Model improved.\n",
      "Mean NLLLoss: 0.0012 | Mean F1Score: 0.9998\n",
      "==================================================\n",
      "\n",
      "TRAINING SUMMARY\n",
      "Best NLLLoss      : 0.0012\n",
      "Best F1Score      : 0.9998\n",
      "Training duration : 27.812 minutes.\n",
      "Training date     : 2022-10-11 16:08:07.936452+08:00\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def looping_step(dataloader, model, optimizer, criterion, metric, n_epoch=hyperparams.n_epoch, patience=hyperparams.patience, monitor=\"loss\"):    \n",
    "    start_time = time()\n",
    "    \n",
    "    epoch_losses = []\n",
    "    epoch_metric_scores = []\n",
    "    patience_counter = 0\n",
    "    \n",
    "    now = datetime.now(pytz.timezone(\"Asia/Ujung_Pandang\"))\n",
    "    path_name = now.strftime(\"%m-%d-%Y_%H-%M-%S\")\n",
    "    os.makedirs(f\"../../logs/comick/{hyperparams.context_size}_contexts/{path_name}\")\n",
    "    \n",
    "    # Hyperparameters\n",
    "    with open(f\"../../logs/comick/{hyperparams.context_size}_contexts/{path_name}/training_history.txt\", \"a\") as f:\n",
    "        f.write(f\"HYPERPARAMETERS\\n\")\n",
    "        f.write(f\"{'-' * 50}\\n\")\n",
    "        for name, value in vars(hyperparams).items():\n",
    "            f.write(f\"{name}: {value}\\n\")\n",
    "        \n",
    "        f.write(\"\\n\\nTRAINING PROGRESS\\n\")\n",
    "        f.write(f\"{'-' * 50}\\n\")\n",
    "    \n",
    "    # Training Progress\n",
    "    for epoch in range(1, n_epoch + 1):\n",
    "        print(f\"EPOCH-{epoch}\")\n",
    "        with open(f\"../../logs/comick/{hyperparams.context_size}_contexts/{path_name}/training_history.txt\", \"a\") as f:\n",
    "            f.write(f\"EPOCH-{epoch}\\n\")\n",
    "        \n",
    "        batch_losses, batch_metric_scores = training_step(dataloader, model, optimizer, criterion, metric, path_name=path_name)\n",
    "        epoch_loss = torch.mean(torch.FloatTensor(batch_losses))\n",
    "\n",
    "        epoch_loss = torch.mean(torch.FloatTensor(batch_losses))\n",
    "        epoch_losses.append(epoch_loss.item())\n",
    "\n",
    "        epoch_metric_score = torch.mean(torch.FloatTensor(batch_metric_scores))\n",
    "        epoch_metric_scores.append(epoch_metric_score.item())\n",
    "        \n",
    "        with open(f\"../../logs/comick/{hyperparams.context_size}_contexts/{path_name}/training_history.txt\", \"a\") as f:\n",
    "            if monitor == \"loss\":\n",
    "                if epoch == 1:\n",
    "                    best_state_dict = model.state_dict()\n",
    "                    best_loss = (epoch_loss)\n",
    "                    best_metric = (epoch_metric_score)\n",
    "                    \n",
    "                    print(f\"\\nMean {str(criterion).split('(')[0]}: {(epoch_loss):.4f} | Mean {str(metric).split('(')[0]}: {(epoch_metric_score):.4f}\")\n",
    "                    \n",
    "                    f.write(f\"\\nMean {str(criterion).split('(')[0]}: {(epoch_loss):.4f} | Mean {str(metric).split('(')[0]}: {(epoch_metric_score):.4f}\\n\")\n",
    "                elif epoch_losses[-1] < epoch_losses[-2]:\n",
    "                    best_state_dict = model.state_dict()\n",
    "                    best_loss = (epoch_loss)\n",
    "                    best_metric = (epoch_metric_score)\n",
    "                    \n",
    "                    print(\"\\nYeah ðŸŽ‰ðŸ˜„! Model improved.\")\n",
    "                    print(f\"Mean {str(criterion).split('(')[0]}: {(epoch_loss):.4f} | Mean {str(metric).split('(')[0]}: {(epoch_metric_score):.4f}\")\n",
    "                    \n",
    "                    f.write(\"\\nYeah ðŸŽ‰ðŸ˜„! Model improved.\\n\")\n",
    "                    f.write(f\"Mean {str(criterion).split('(')[0]}: {(epoch_loss):.4f} | Mean {str(metric).split('(')[0]}: {(epoch_metric_score):.4f}\\n\")\n",
    "                else:\n",
    "                    patience_counter += 1\n",
    "                    \n",
    "                    print(\"\\nHuft ðŸ˜¥! Model not improved.\")\n",
    "                    print(f\"Mean {str(criterion).split('(')[0]}: {(epoch_loss):.4f} | Mean {str(metric).split('(')[0]}: {(epoch_metric_score):.4f}\")\n",
    "                    print(f\"Patience = {patience_counter}/{patience}â—\")\n",
    "                    \n",
    "                    f.write(\"\\nHuft ðŸ˜¥! Model not improved.\\n\")\n",
    "                    f.write(f\"Mean {str(criterion).split('(')[0]}: {(epoch_loss):.4f} | Mean {str(metric).split('(')[0]}: {(epoch_metric_score):.4f}\\n\")                    \n",
    "                    f.write(f\"Patience = {patience_counter}/{patience}â—\\n\")\n",
    "            else:\n",
    "                if epoch == 1:\n",
    "                    best_state_dict = model.state_dict()\n",
    "                    best_loss = (epoch_loss)\n",
    "                    best_metric = (epoch_metric_score)\n",
    "                    \n",
    "                    print(f\"\\nMean {str(criterion).split('(')[0]}: {(epoch_loss):.4f} | Mean {str(metric).split('(')[0]}: {(epoch_metric_score):.4f}\")\n",
    "                    \n",
    "                    f.write(f\"\\nMean {str(criterion).split('(')[0]}: {(epoch_loss):.4f} | Mean {str(metric).split('(')[0]}: {(epoch_metric_score):.4f}\\n\")\n",
    "                elif epoch_metric_scores[-1] > epoch_metric_scores[-2]:\n",
    "                    best_state_dict = model.state_dict()\n",
    "                    best_loss = (epoch_loss)\n",
    "                    best_metric = (epoch_metric_score)\n",
    "                    \n",
    "                    print(\"\\nYeah ðŸŽ‰ðŸ˜„! Model improved.\")\n",
    "                    print(f\"Mean {str(criterion).split('(')[0]}: {(epoch_loss):.4f} | Mean Mean {str(metric).split('(')[0]}: {(epoch_metric_score):.4f}\")\n",
    "                    \n",
    "                    f.write(\"\\nYeah ðŸŽ‰ðŸ˜„! Model improved.\\n\")\n",
    "                    f.write(f\"Mean {str(criterion).split('(')[0]}: {(epoch_loss):.4f} | Mean {str(metric).split('(')[0]}: {(epoch_metric_score):.4f}\\n\")\n",
    "                else:\n",
    "                    patience_counter += 1\n",
    "                    \n",
    "                    print(\"\\nHuft ðŸ˜¥! Model not improved.\")\n",
    "                    print(f\"Mean {str(criterion).split('(')[0]}: {(epoch_loss):.4f} | Mean {str(metric).split('(')[0]}: {(epoch_metric_score):.4f}\\n\")\n",
    "                    print(f\"Patience = {patience_counter}/{patience}â—\\n\")\n",
    "                    \n",
    "                    f.write(\"\\nHuft ðŸ˜¥! Model not improved.\\n\")\n",
    "                    f.write(f\"Mean {str(criterion).split('(')[0]}: {(epoch_loss):.4f} | Mean {str(metric).split('(')[0]}: {(epoch_metric_score):.4f}\\n\")\n",
    "                    f.write(f\"Patience = {patience_counter}/{patience}â—\\n\")\n",
    "                    \n",
    "            print(\"=\" * 50, end=\"\\n\\n\")\n",
    "            f.write(f\"{'=' * 50}\\n\\n\")\n",
    "            \n",
    "            if patience_counter == patience:\n",
    "                print(f\"Early stopping, patience = {patience_counter}/{patience}â—\\n\")\n",
    "                f.write(f\"Early stopping, patience = {patience_counter}/{patience}â—\\n\")\n",
    "                break\n",
    "        \n",
    "        metric.reset()\n",
    "    \n",
    "    finish_time = time()\n",
    "    \n",
    "    # Training plot \n",
    "    fig, (ax_loss, ax_metric_score) = plt.subplots(nrows=1, ncols=2, figsize=(15, 5))\n",
    "\n",
    "    fig.suptitle(f\"Training with context size = {hyperparams.context_size}\")\n",
    "\n",
    "    ax_loss.set_title(\"Loss\")\n",
    "    ax_loss.set_xlabel(\"Epoch\")\n",
    "    ax_loss.set_ylabel(\"Score\")\n",
    "    ax_loss.plot(epoch_losses, \"green\")\n",
    "    ax_loss.grid()\n",
    "\n",
    "    ax_metric_score.set_title(\"F1 Score\")\n",
    "    ax_metric_score.set_xlabel(\"Epoch\")\n",
    "    ax_metric_score.set_ylabel(\"Score\")\n",
    "    ax_metric_score.plot(epoch_metric_scores, \"orange\")\n",
    "    ax_metric_score.grid()\n",
    "\n",
    "    plt.savefig(f\"../../logs/comick/{hyperparams.context_size}_contexts/{path_name}/training_plot.jpg\", dpi=200)                        \n",
    "    \n",
    "    print(\"TRAINING SUMMARY\")\n",
    "    criterion_name = \"Best \" + str(criterion).split('(')[0]\n",
    "    metric_name = \"Best \" + str(metric).split('(')[0]\n",
    "    \n",
    "    print(f\"{criterion_name.ljust(18)}: {best_loss:.4f}\")\n",
    "    print(f\"{metric_name.ljust(18)}: {best_metric:.4f}\")\n",
    "    print(f\"{'Training duration'.ljust(18)}: {((finish_time - start_time) / 60):.3f} minutes.\")\n",
    "    print(f\"{'Training date'.ljust(18)}: {now}\")\n",
    "    \n",
    "    with open(f\"../../logs/comick/{hyperparams.context_size}_contexts/{path_name}/training_history.txt\", \"a\") as f:\n",
    "        f.write(\"\\nTRAINING SUMMARY\\n\")\n",
    "        f.write(f\"{'-' * 50}\\n\")\n",
    "        f.write(f\"{criterion_name.ljust(18)}: {best_loss:.4f}\\n\")\n",
    "        f.write(f\"{metric_name.ljust(18)}: {best_metric:.4f}\\n\")\n",
    "        f.write(f\"{'Training duration'.ljust(18)}: {((finish_time - start_time) / 60):.3f} minutes.\\n\")\n",
    "        f.write(f\"{'Training date'.ljust(18)}: {now}\\n\")\n",
    "    \n",
    "    # Save epoch losses, epoch metric scores, model, state dict, and oov embedding dict\n",
    "    filename_model_params = f\"../../logs/comick/{hyperparams.context_size}_contexts/{path_name}/model_params.pth\"\n",
    "    filename_oov_embedding_dict = open(f\"../../logs/comick/{hyperparams.context_size}_contexts/{path_name}/oov_embedding_dict.pkl\", \"ab\")\n",
    "    \n",
    "    pd.DataFrame(\n",
    "        data={\n",
    "            \"epoch\": list(range(1, len(epoch_losses) + 1)),\n",
    "            \"loss\": epoch_losses\n",
    "        }\n",
    "    ).to_csv(f\"../../logs/comick/{hyperparams.context_size}_contexts/{path_name}/epoch_losses.csv\", index=False)\n",
    "    \n",
    "    pd.DataFrame(\n",
    "        data={\n",
    "            \"epoch\": list(range(1, len(epoch_metric_scores) + 1)),\n",
    "            \"f1_score\": epoch_metric_scores\n",
    "        }\n",
    "    ).to_csv(f\"../../logs/comick/{hyperparams.context_size}_contexts/{path_name}/epoch_metric_scores.csv\", index=False)\n",
    "    \n",
    "    torch.save(best_state_dict, filename_model_params)\n",
    "    pickle.dump({token : embedding for token, embedding in zip(list(labels_to_idx.keys()), model.embedding)}, filename_oov_embedding_dict)\n",
    "    \n",
    "    return epoch_losses, epoch_metric_scores\n",
    "\n",
    "epoch_losses, epoch_metric_scores = looping_step(dataloader, model, optimizer, criterion, metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfef50c-e71c-4288-a9f3-6fd8831033b0",
   "metadata": {},
   "source": [
    "# END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92debcb3-d6ea-4299-a3e9-37be5b63d2b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.9572573 , -5.9895067 ,  3.704153  , ..., -2.425081  ,\n",
       "         3.764498  , -0.8828489 ],\n",
       "       [ 4.25791   ,  3.4694314 ,  0.22771212, ...,  6.2428083 ,\n",
       "        -3.4105866 , -3.8448215 ],\n",
       "       [ 3.9319263 ,  0.05847259,  2.3278463 , ..., -1.0264643 ,\n",
       "        -2.3846827 , -6.9776335 ],\n",
       "       ...,\n",
       "       [-1.9927524 ,  0.5046115 , -0.1078063 , ...,  2.4813058 ,\n",
       "        -1.417194  , -0.44834864],\n",
       "       [-3.2021124 ,  6.7845936 , -3.3111973 , ..., -5.5867867 ,\n",
       "        -0.23915544, -0.8035184 ],\n",
       "       [ 5.5569854 ,  0.95947134,  3.4284139 , ..., -2.3504224 ,\n",
       "         1.7967895 , -1.6850154 ]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27ce78c3-ac2c-4a84-a8e8-4d8e85d26563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('bilstm_left_context_feature.weight_ih_l0',\n",
       "              tensor([[ 0.0994, -0.2944, -0.1384,  ..., -0.1281,  0.2891, -0.5773],\n",
       "                      [-0.0105, -0.0801, -0.0848,  ..., -0.2761, -0.0561, -0.2048],\n",
       "                      [ 0.0965, -0.2513,  0.0817,  ..., -0.1375,  0.0499, -0.2135],\n",
       "                      ...,\n",
       "                      [ 0.2852, -0.2841, -0.0708,  ..., -0.0554, -0.1704, -0.0486],\n",
       "                      [ 0.0816,  0.0260, -0.0069,  ..., -0.2999,  0.0531, -0.1345],\n",
       "                      [ 0.1332, -0.3470, -0.0159,  ..., -0.4874,  0.0090, -0.1769]])),\n",
       "             ('bilstm_left_context_feature.weight_hh_l0',\n",
       "              tensor([[-0.1329,  0.1957,  0.0161,  ..., -0.2849,  0.1471,  0.0172],\n",
       "                      [ 0.1092,  0.1125, -0.0512,  ...,  0.0329,  0.1109,  0.2373],\n",
       "                      [-0.0173, -0.0354, -0.2383,  ..., -0.1559,  0.2220,  0.0297],\n",
       "                      ...,\n",
       "                      [-0.2955, -0.0481,  0.0063,  ..., -0.1221,  0.0022, -0.0984],\n",
       "                      [ 0.0439, -0.1305,  0.1168,  ..., -0.1723,  0.1419,  0.0568],\n",
       "                      [-0.0578, -0.0752, -0.2661,  ..., -0.0472, -0.0075,  0.0112]])),\n",
       "             ('bilstm_left_context_feature.bias_ih_l0',\n",
       "              tensor([-3.3262e-02, -9.3061e-02, -1.4207e-01, -1.6862e-01, -2.4248e-01,\n",
       "                      -2.3275e-01, -2.6903e-01, -2.6502e-01, -1.1755e-01, -4.1168e-02,\n",
       "                      -1.8797e-01, -1.4175e-01, -1.9787e-01, -2.4885e-01, -8.5843e-02,\n",
       "                      -6.8478e-02, -2.3349e-01, -2.2061e-01, -6.6367e-02, -1.8201e-01,\n",
       "                       1.5340e-02, -3.3357e-02, -1.1442e-01, -1.0141e-01,  2.4757e-02,\n",
       "                      -1.1824e-01, -4.7017e-02, -2.2272e-01, -3.5182e-02, -1.5284e-01,\n",
       "                      -2.4712e-01, -4.8661e-02, -2.1322e-01, -1.8387e-01, -6.1037e-02,\n",
       "                      -1.3616e-01, -9.3561e-02, -1.2964e-01, -3.8429e-02, -1.0446e-01,\n",
       "                      -9.6481e-02, -7.8453e-03, -3.3775e-01, -1.1034e-01, -1.3155e-01,\n",
       "                      -1.4188e-01, -1.8994e-01, -2.8815e-01, -2.8122e-01, -1.4927e-01,\n",
       "                      -2.1650e-01, -2.6028e-01, -6.5610e-02, -2.7392e-01,  9.9044e-03,\n",
       "                       6.6371e-04, -1.2799e-01, -1.1245e-01, -1.9046e-01, -1.5235e-01,\n",
       "                      -1.8050e-01, -2.2988e-01, -2.5232e-01, -2.4130e-01, -2.1469e-01,\n",
       "                      -1.7396e-01, -9.9833e-02, -2.5048e-01, -3.0627e-01, -1.4716e-01,\n",
       "                      -8.8906e-02, -2.9731e-01, -1.3010e-01, -9.1207e-02, -1.7306e-01,\n",
       "                      -5.6723e-02, -1.0514e-01, -4.7494e-02, -2.1914e-01,  7.7130e-02,\n",
       "                      -3.4093e-01, -1.2718e-01, -1.5087e-01, -1.3969e-01, -1.1244e-01,\n",
       "                      -9.4843e-02, -1.5951e-01, -1.5899e-01, -1.0586e-01, -1.4938e-01,\n",
       "                      -1.7101e-02, -1.6115e-01, -1.6516e-01, -1.5785e-01, -1.4502e-01,\n",
       "                      -2.0548e-01, -1.2935e-01,  1.4320e-02, -1.5455e-01, -2.1360e-01,\n",
       "                      -4.3696e-02, -7.2519e-02, -1.5391e-01, -9.5112e-02, -1.1744e-01,\n",
       "                      -1.2446e-01, -1.2893e-01, -8.9004e-02, -2.4603e-01, -1.7303e-01,\n",
       "                      -2.6801e-02, -2.4038e-01, -1.9700e-01, -1.2671e-01, -1.9388e-01,\n",
       "                       2.5116e-02, -1.6509e-01, -1.3629e-01, -1.2549e-01, -5.1576e-02,\n",
       "                      -5.5080e-02, -1.5982e-01, -1.4516e-01, -3.0757e-01, -2.2435e-01,\n",
       "                      -1.1491e-01, -5.2674e-02, -5.0101e-02, -9.7310e-02, -2.0193e-01,\n",
       "                      -2.1820e-01, -7.9088e-02, -1.3258e-01, -1.9471e-01, -2.6003e-01,\n",
       "                      -9.5505e-02, -1.3120e-01, -7.8356e-02, -1.1615e-01, -7.4340e-02,\n",
       "                      -4.3779e-02, -6.3653e-02, -1.9007e-03,  7.5124e-02, -7.8660e-02,\n",
       "                      -1.8690e-01, -2.2939e-01, -5.3447e-02, -4.1858e-02, -9.2600e-02,\n",
       "                      -2.0076e-01, -1.2801e-01, -9.3194e-02, -1.5641e-01, -2.1158e-01,\n",
       "                      -1.8158e-01, -6.7285e-02, -7.1964e-02, -5.9325e-02, -2.0101e-01,\n",
       "                      -1.3620e-01, -1.3016e-01, -1.1351e-01, -1.2656e-01, -3.6924e-02,\n",
       "                      -1.0178e-01, -1.5821e-01, -1.6914e-01, -1.4740e-01, -6.5720e-02,\n",
       "                      -1.7308e-01, -4.3454e-02, -1.5656e-01, -1.9919e-01, -1.1035e-01,\n",
       "                      -1.6461e-01, -1.1916e-01, -1.3173e-01, -1.7008e-01, -1.6570e-01,\n",
       "                      -8.6606e-02, -1.1888e-01,  2.3359e-02, -2.3680e-01,  9.3951e-03,\n",
       "                      -2.8257e-01, -1.9090e-01, -1.1526e-01, -5.9887e-02, -1.7869e-01,\n",
       "                      -1.5601e-01, -1.9617e-01, -4.0519e-02,  3.7920e-02, -4.4356e-02,\n",
       "                      -8.3084e-02, -1.5955e-01, -2.3768e-01,  2.2589e-02, -1.1716e-01,\n",
       "                      -8.3223e-02,  5.9958e-03, -1.5115e-01, -6.2052e-02, -7.4109e-02,\n",
       "                      -3.8523e-02, -1.2251e-01, -8.9275e-02, -1.1890e-01, -3.1303e-02,\n",
       "                      -2.6143e-01, -1.3159e-01, -1.6472e-01, -1.5532e-01, -8.2798e-02,\n",
       "                      -4.3488e-02, -9.7240e-02, -1.6354e-01, -1.8599e-01, -1.6645e-01,\n",
       "                      -6.3813e-02, -1.7283e-01, -1.3410e-01, -1.7129e-01, -1.9326e-01,\n",
       "                      -2.2196e-02, -1.7518e-01, -1.0066e-01, -2.0633e-01, -1.6607e-01,\n",
       "                      -7.5112e-02, -2.2332e-02, -8.4857e-02, -6.3891e-02, -2.6597e-02,\n",
       "                      -7.2050e-02, -8.7631e-02, -7.7841e-02, -1.9113e-01, -2.5949e-01,\n",
       "                      -6.6931e-02, -1.1177e-01, -2.3926e-01, -5.2576e-02, -3.2821e-02,\n",
       "                      -2.9072e-02, -1.9887e-01, -2.1801e-03, -6.8372e-02, -1.2059e-01,\n",
       "                      -1.8355e-01, -2.9725e-01, -2.5957e-01,  4.7022e-02, -4.0316e-02,\n",
       "                      -1.4975e-01,  2.1099e-02, -1.5361e-02,  4.3268e-02,  2.5097e-02,\n",
       "                       2.2180e-02,  7.5193e-03, -1.5516e-02, -1.2511e-02,  3.3721e-02,\n",
       "                      -9.0324e-02,  1.1932e-01,  1.7817e-02,  6.3238e-03, -3.6398e-02,\n",
       "                       3.9495e-02,  7.5813e-05, -5.4094e-02, -1.7376e-02, -5.6271e-02,\n",
       "                       1.4157e-03, -1.0063e-01,  4.5135e-02, -8.9649e-02,  5.3706e-02,\n",
       "                       6.9241e-02,  4.3104e-02, -5.2581e-03, -6.3866e-02,  4.3259e-02,\n",
       "                       1.0523e-01, -5.0265e-02, -2.3161e-02,  5.0152e-02,  8.2558e-02,\n",
       "                       2.5212e-02, -7.9190e-02, -7.2638e-02,  9.3806e-03,  1.0192e-02,\n",
       "                       1.0004e-01, -5.7371e-03,  3.8977e-02,  1.4350e-01, -4.7102e-02,\n",
       "                      -8.2408e-02,  2.4563e-02,  6.1283e-02, -6.7380e-02, -4.5086e-03,\n",
       "                       5.4616e-02, -1.0806e-01, -2.5175e-02, -1.5154e-02, -2.5560e-02,\n",
       "                       1.2402e-01,  4.4428e-02, -1.1321e-03, -7.6437e-02,  2.5342e-02,\n",
       "                      -1.8456e-02, -3.8227e-02,  4.0606e-02,  9.1725e-02, -2.0401e-02,\n",
       "                      -5.0437e-02,  6.2425e-02,  9.5309e-02,  3.2437e-02, -5.2114e-02,\n",
       "                      -2.9346e-02,  3.6188e-02,  1.0197e-02, -5.1929e-02, -2.5667e-02,\n",
       "                      -1.9310e-02,  7.0801e-03,  3.2540e-02, -3.3871e-02, -7.1870e-02,\n",
       "                       1.6573e-02,  7.2205e-02, -6.6851e-02, -3.3461e-02, -2.4531e-02,\n",
       "                      -9.1162e-03, -5.7434e-02,  5.1072e-02,  9.8443e-02,  7.7090e-02,\n",
       "                       6.2843e-02,  9.2254e-02,  5.7348e-02,  1.9029e-02, -1.1143e-01,\n",
       "                       1.0439e-01, -6.3600e-04,  5.6526e-02, -1.2827e-02,  3.0822e-02,\n",
       "                      -2.2635e-03, -1.5205e-03,  6.6356e-02,  1.1044e-01,  2.0241e-03,\n",
       "                       5.0094e-03,  1.5529e-02, -6.9989e-03,  1.0546e-02, -2.3823e-02,\n",
       "                       1.3949e-02,  9.0673e-02, -7.9014e-02, -2.5857e-03,  3.3394e-02,\n",
       "                       2.0417e-03,  8.6806e-02, -1.5465e-03, -7.7739e-02,  9.6239e-02,\n",
       "                       4.3256e-02, -8.5156e-02,  5.5288e-02,  4.3528e-02, -1.6899e-01,\n",
       "                       1.9314e-02, -2.4593e-02,  5.1292e-02,  1.1235e-02, -1.7577e-01,\n",
       "                      -9.9676e-02, -2.0803e-01, -8.3537e-02, -1.7641e-01, -1.0686e-01,\n",
       "                      -2.2816e-01, -1.9713e-01, -1.2989e-01, -4.9392e-02, -1.4284e-01,\n",
       "                      -1.0851e-01, -4.1084e-02, -1.2363e-01, -1.3563e-01, -6.0458e-02,\n",
       "                      -1.2283e-01, -8.5141e-02, -2.3242e-01, -1.3154e-01, -5.0093e-02,\n",
       "                      -4.2352e-02, -2.3005e-01, -5.9908e-03, -1.7393e-01, -1.4780e-01,\n",
       "                      -8.1501e-02, -1.1718e-01, -1.0718e-01, -9.4135e-03, -8.5574e-02,\n",
       "                      -1.7204e-01, -2.2276e-01, -2.3144e-01, -9.4333e-02, -1.3910e-01,\n",
       "                      -5.7748e-02, -1.8868e-01, -1.4426e-01, -1.6245e-01, -9.2829e-02,\n",
       "                      -6.1672e-02, -1.4094e-01, -4.0141e-02, -1.2097e-01, -1.5740e-01,\n",
       "                      -1.3634e-01, -1.8299e-01, -1.5789e-01, -1.0838e-01, -1.2506e-01,\n",
       "                      -5.5741e-02, -1.0420e-01, -1.9868e-01, -1.1700e-01, -1.5145e-01,\n",
       "                      -1.1233e-01, -1.6736e-01, -2.0368e-01, -1.2291e-01, -1.2484e-01,\n",
       "                      -2.3959e-01, -1.7251e-01, -2.9787e-01, -1.8731e-01, -7.0277e-02,\n",
       "                      -6.0494e-02, -1.2795e-01, -2.6752e-01, -1.9818e-02, -1.4854e-01,\n",
       "                      -2.8151e-01, -1.6817e-01, -3.6707e-02, -1.1251e-01, -1.0959e-01,\n",
       "                      -1.2711e-01, -9.1669e-02, -1.4263e-01, -1.8291e-01, -1.3843e-01,\n",
       "                      -1.6926e-01, -2.9271e-01, -1.7756e-01, -8.3070e-02, -8.5380e-02,\n",
       "                      -1.4102e-01, -9.0414e-02, -5.7868e-02, -1.2953e-01, -1.2994e-01,\n",
       "                      -1.6234e-01, -1.8654e-01, -1.3347e-01, -1.2017e-01, -1.9673e-01,\n",
       "                      -2.2775e-01, -6.7308e-02, -9.8934e-02, -1.5133e-01, -7.4837e-02,\n",
       "                      -1.7859e-01, -1.0154e-01, -2.0838e-01,  4.0256e-02, -1.0274e-01,\n",
       "                      -8.5324e-02, -5.0838e-02, -1.2394e-01, -1.0816e-01, -1.9618e-01,\n",
       "                      -2.1839e-01, -7.3750e-02, -1.4995e-01, -1.7643e-01, -5.4050e-02,\n",
       "                      -1.7877e-01, -3.1770e-02, -7.5893e-02, -1.5032e-01, -5.3815e-02,\n",
       "                      -1.0915e-01, -2.2205e-01, -1.2804e-01, -1.6114e-01, -1.2980e-01,\n",
       "                      -1.9384e-01, -1.0153e-01])),\n",
       "             ('bilstm_left_context_feature.bias_hh_l0',\n",
       "              tensor([-1.5799e-01, -9.8814e-02, -1.5943e-01, -1.2436e-01, -2.6272e-01,\n",
       "                      -1.6900e-01, -3.0136e-01, -1.4926e-01, -6.5004e-02, -1.2254e-01,\n",
       "                      -1.1185e-01, -9.0438e-02, -1.1822e-01, -6.4677e-02, -2.2220e-01,\n",
       "                      -1.7640e-01, -8.1710e-02, -8.6236e-02, -8.0867e-02, -2.0417e-01,\n",
       "                       6.8888e-02, -7.1096e-02, -1.5786e-01, -1.1474e-01, -1.1187e-01,\n",
       "                      -4.6723e-02, -7.2994e-02, -2.7758e-02, -7.9043e-02, -3.7867e-02,\n",
       "                      -1.8709e-01, -1.6369e-01, -1.5207e-01, -2.0075e-01, -5.9926e-02,\n",
       "                      -2.2519e-01, -1.0512e-01, -2.0580e-01, -2.3498e-01, -2.7059e-01,\n",
       "                      -8.1809e-02, -2.3328e-01, -1.3475e-01, -1.2067e-01, -1.1044e-01,\n",
       "                      -1.4843e-01, -2.9183e-02, -1.9613e-01, -2.7022e-01, -7.1600e-02,\n",
       "                      -1.1841e-01, -7.2424e-02, -2.4554e-01, -7.1114e-02, -1.3041e-01,\n",
       "                      -1.3706e-01, -5.7424e-02, -8.4813e-02, -2.1442e-01, -1.1165e-01,\n",
       "                      -1.8913e-01, -2.0662e-01, -1.7835e-01, -7.7604e-02, -9.9017e-02,\n",
       "                      -1.1067e-01, -1.9658e-01, -1.1772e-01, -1.9459e-01, -1.8065e-01,\n",
       "                      -7.6797e-02, -2.9201e-01, -1.6058e-01, -1.2868e-01, -1.0165e-01,\n",
       "                      -2.0637e-01, -8.7895e-02, -1.2141e-01, -1.4500e-01, -5.5517e-02,\n",
       "                      -3.3234e-01, -1.2240e-01, -3.0635e-01, -1.6676e-01, -1.1885e-01,\n",
       "                      -1.0481e-01, -2.4766e-02, -1.6795e-01, -1.8837e-01, -2.0882e-01,\n",
       "                      -1.2166e-01, -8.8684e-02, -1.5209e-01, -2.5050e-01, -1.7531e-01,\n",
       "                      -2.4202e-01, -1.6863e-01, -9.9015e-02, -2.1227e-01, -7.0661e-02,\n",
       "                      -9.4125e-02, -1.5845e-01, -1.7325e-01, -1.0881e-01, -2.6890e-02,\n",
       "                       4.1466e-02, -1.3246e-01, -1.3045e-01, -1.2056e-01, -2.2609e-01,\n",
       "                      -2.9954e-01, -1.8637e-01, -6.9716e-02, -2.2468e-01, -7.7487e-02,\n",
       "                      -5.0962e-02, -1.6207e-01, -1.3097e-01, -2.2246e-01, -1.1845e-01,\n",
       "                      -1.3077e-01, -1.8954e-01, -1.6031e-01, -2.0927e-01, -8.3587e-02,\n",
       "                      -2.8245e-02, -2.0913e-01, -3.2554e-02, -1.2320e-01, -1.7247e-01,\n",
       "                      -1.1722e-01, -7.1111e-02, -5.9248e-02, -2.3110e-01, -1.7652e-01,\n",
       "                      -9.3118e-02, -2.1167e-01, -1.1038e-01, -1.2666e-01, -1.1607e-01,\n",
       "                      -1.5519e-02, -1.3989e-01, -1.1203e-01, -1.0037e-01, -9.1435e-02,\n",
       "                      -9.0196e-02, -1.0698e-01, -1.5913e-01, -1.9767e-02,  4.0698e-03,\n",
       "                      -1.9899e-01, -6.1094e-02,  2.1861e-02, -2.8632e-01, -1.6573e-01,\n",
       "                      -9.4721e-02, -1.8563e-01, -1.7360e-02, -1.6519e-01, -1.3824e-01,\n",
       "                      -1.5104e-01, -1.2107e-01, -8.0020e-02, -1.3107e-01, -2.0312e-02,\n",
       "                      -1.6012e-01, -2.0542e-01, -1.2811e-01, -1.8025e-01,  2.2729e-02,\n",
       "                      -1.3837e-01, -1.4456e-01, -2.1200e-01, -1.7579e-01, -5.9000e-02,\n",
       "                      -1.9629e-01, -1.5355e-01,  4.4457e-02, -1.4246e-01, -1.6373e-01,\n",
       "                      -8.6146e-02, -1.0533e-01, -1.2135e-01, -2.4420e-01, -1.1396e-01,\n",
       "                      -7.5963e-02, -1.0331e-01, -4.4328e-02, -2.3299e-01, -7.2636e-02,\n",
       "                      -1.1267e-01, -3.2185e-02, -1.7763e-01, -9.2088e-02, -2.9230e-02,\n",
       "                      -5.9295e-02, -7.3658e-02, -7.3601e-02, -7.2685e-02, -2.0977e-01,\n",
       "                      -5.5671e-02, -8.0218e-03, -1.0116e-01, -1.4665e-01, -1.5083e-01,\n",
       "                      -1.5559e-01,  3.3387e-02, -1.0944e-02, -1.7660e-01, -3.5586e-02,\n",
       "                      -1.6490e-01, -7.6705e-02, -5.8394e-02, -7.5423e-02, -6.4176e-03,\n",
       "                      -4.8225e-02, -3.8049e-02, -8.7635e-02, -1.9195e-01, -1.1093e-01,\n",
       "                      -1.1370e-01, -1.4403e-01, -1.5035e-01, -1.3132e-01, -2.1113e-01,\n",
       "                      -3.1119e-02, -2.0188e-01, -2.1969e-02, -9.4731e-02, -2.0606e-01,\n",
       "                      -1.0984e-01, -6.6323e-02, -9.6866e-02, -1.1366e-01,  3.0443e-02,\n",
       "                      -1.0968e-01, -7.0969e-02, -4.5344e-03, -1.2967e-01, -2.3410e-01,\n",
       "                      -1.5104e-01, -4.3566e-02, -1.9059e-02, -8.3258e-02, -1.2974e-01,\n",
       "                      -1.2691e-01, -3.7559e-02, -1.7855e-01,  3.0315e-02,  2.5319e-03,\n",
       "                      -1.6303e-01, -1.5643e-01, -1.2565e-01, -1.5148e-01, -6.6931e-02,\n",
       "                      -4.6936e-02, -3.6776e-02, -2.5662e-02,  1.0609e-01,  5.4399e-03,\n",
       "                      -5.4789e-02,  4.6545e-02, -5.1841e-02,  5.2933e-02, -6.8495e-03,\n",
       "                       1.4002e-02, -1.0041e-02,  1.4485e-02, -9.2609e-02,  4.1729e-02,\n",
       "                      -4.5171e-02, -8.2718e-02, -3.1359e-03,  1.1199e-01,  9.1715e-02,\n",
       "                      -1.1133e-03,  8.5298e-03,  5.9758e-02, -1.4918e-04,  4.0864e-02,\n",
       "                       1.0984e-01, -5.4779e-02, -2.2737e-02,  4.8647e-02,  1.5590e-01,\n",
       "                       1.7635e-03, -1.9798e-02,  3.9479e-03,  5.0704e-04, -8.8172e-03,\n",
       "                       3.3726e-02, -2.5005e-02,  2.8262e-02,  5.9621e-02, -1.1665e-01,\n",
       "                      -9.7399e-02, -6.6604e-02, -2.7661e-02, -3.7090e-03, -4.5030e-02,\n",
       "                       3.2360e-02,  5.8990e-02, -4.1603e-03,  8.5220e-02, -6.0266e-03,\n",
       "                       6.9485e-03,  2.1245e-02, -1.8711e-02, -8.8026e-02,  1.0314e-01,\n",
       "                       1.0565e-02, -9.4708e-02, -4.6173e-02,  2.1554e-02, -8.4248e-03,\n",
       "                      -5.0403e-02, -7.0768e-02,  1.5133e-02,  4.9308e-02, -4.9005e-02,\n",
       "                       9.2624e-02, -6.4112e-02, -5.8382e-02,  1.7322e-02, -2.1082e-02,\n",
       "                       1.9960e-02, -8.1123e-02,  2.3473e-02, -4.2946e-02, -6.5364e-03,\n",
       "                      -7.1485e-02, -6.8275e-02, -2.8346e-02,  6.1012e-02, -4.6183e-02,\n",
       "                      -8.7930e-02, -4.2670e-02,  3.7457e-02,  3.5415e-02, -3.3517e-02,\n",
       "                       3.7794e-02,  1.9259e-02, -5.2157e-02,  5.1632e-02,  8.0055e-03,\n",
       "                      -6.6288e-02,  1.0331e-01,  1.7560e-02, -7.9126e-03,  2.3155e-02,\n",
       "                       9.9155e-03, -5.7583e-03, -1.0182e-01,  1.2387e-02, -2.7874e-02,\n",
       "                      -7.1589e-02,  4.8556e-02, -1.6442e-01, -1.6898e-02,  3.4760e-02,\n",
       "                       1.6758e-02,  4.5492e-02, -4.9025e-02,  7.0885e-03,  1.6598e-01,\n",
       "                       1.7864e-02,  2.0941e-02, -4.6968e-02,  4.5499e-02, -1.9057e-02,\n",
       "                      -6.0869e-02,  3.2555e-02,  3.5666e-02, -3.5397e-03,  1.1593e-01,\n",
       "                      -7.2983e-02, -5.3665e-02, -8.6082e-02,  4.0421e-03,  3.7724e-02,\n",
       "                      -8.4659e-02,  5.8915e-02, -4.6646e-02,  1.1654e-02, -2.2407e-01,\n",
       "                      -1.5235e-01, -6.5630e-02, -1.7405e-01, -1.7784e-01, -1.9776e-01,\n",
       "                      -1.6887e-01, -2.2941e-01, -7.8810e-02,  7.2492e-05, -1.1676e-01,\n",
       "                       6.1067e-04, -1.2244e-01, -6.6243e-02, -9.2938e-02, -1.2658e-01,\n",
       "                      -1.1961e-01, -3.1759e-01, -2.8228e-01, -9.0993e-02, -2.8909e-02,\n",
       "                      -5.3917e-02, -1.7016e-01, -1.3087e-01, -1.7905e-01, -2.0985e-01,\n",
       "                      -1.7746e-01, -5.1315e-02, -1.3835e-01,  1.0105e-01, -1.6557e-01,\n",
       "                      -2.1431e-01, -1.6319e-01,  1.6063e-02, -1.5724e-01, -4.3962e-02,\n",
       "                      -8.0771e-02, -1.9933e-01, -1.4062e-01, -2.5321e-01, -3.6686e-02,\n",
       "                      -7.6632e-03, -1.7970e-01, -8.6187e-02, -1.5211e-01, -1.9484e-01,\n",
       "                      -6.5750e-02, -1.1643e-01, -2.7602e-01, -7.1086e-02, -2.1063e-01,\n",
       "                      -1.0019e-01, -4.5671e-02, -2.6411e-01, -1.6178e-01, -1.1674e-01,\n",
       "                      -1.6200e-01, -1.4682e-01, -2.3837e-01, -1.2171e-01, -7.9785e-03,\n",
       "                      -1.1393e-01, -1.0224e-01, -1.4745e-01, -1.1871e-01, -7.3806e-02,\n",
       "                      -1.6482e-01, -6.0500e-02, -2.2355e-01, -8.1510e-02, -4.9700e-02,\n",
       "                      -2.4183e-01, -1.5272e-01, -1.6104e-01, -1.3707e-01, -1.7448e-03,\n",
       "                      -7.5646e-02, -1.2301e-01, -1.6805e-01, -9.8509e-02, -1.6200e-01,\n",
       "                      -5.7236e-02, -4.3835e-01, -1.3899e-01, -1.8100e-01, -1.8016e-01,\n",
       "                      -1.7045e-01, -7.9127e-02, -8.1219e-02, -1.2250e-01, -1.7529e-01,\n",
       "                      -1.3581e-01, -1.4921e-01, -7.9771e-02, -2.3300e-01, -1.9394e-01,\n",
       "                      -1.4818e-01, -8.5127e-02, -1.2072e-01, -1.5939e-01, -7.5006e-02,\n",
       "                      -5.9799e-02, -1.4923e-01, -1.7047e-01, -9.0143e-02, -1.1102e-01,\n",
       "                      -1.6952e-01, -2.0275e-01, -1.2349e-01, -1.7148e-01, -1.8201e-01,\n",
       "                      -1.2098e-01, -2.1412e-02, -3.9248e-02, -1.5517e-01, -1.0863e-01,\n",
       "                      -6.4401e-02, -1.2984e-01, -1.5546e-01, -1.0208e-01, -9.9713e-02,\n",
       "                      -1.9895e-01, -1.0607e-01, -1.5959e-01, -1.5186e-01, -2.3683e-02,\n",
       "                      -1.7230e-01, -9.0523e-02])),\n",
       "             ('bilstm_left_context_feature.weight_ih_l0_reverse',\n",
       "              tensor([[-0.1698, -0.1066,  0.1608,  ...,  0.0275,  0.0664,  0.0208],\n",
       "                      [ 0.0017,  0.1834,  0.1311,  ..., -0.0750,  0.0264, -0.4244],\n",
       "                      [ 0.4043, -0.0327,  0.1851,  ...,  0.1410, -0.1612, -0.1220],\n",
       "                      ...,\n",
       "                      [ 0.2124, -0.0582, -0.0642,  ..., -0.0169, -0.0320, -0.0760],\n",
       "                      [-0.0915,  0.4154,  0.2581,  ..., -0.1407, -0.2981, -0.4745],\n",
       "                      [ 0.1916,  0.3635, -0.0861,  ..., -0.2106,  0.1737, -0.2650]])),\n",
       "             ('bilstm_left_context_feature.weight_hh_l0_reverse',\n",
       "              tensor([[ 0.0512,  0.2357, -0.0705,  ..., -0.0864, -0.0378, -0.3890],\n",
       "                      [-0.0893, -0.0256,  0.2579,  ...,  0.0274, -0.0961, -0.0809],\n",
       "                      [-0.0039, -0.0856, -0.0748,  ..., -0.1676,  0.0109,  0.1615],\n",
       "                      ...,\n",
       "                      [ 0.2724, -0.1850, -0.2175,  ...,  0.3615, -0.0625, -0.0835],\n",
       "                      [ 0.0196,  0.2457,  0.0266,  ..., -0.1760, -0.0044,  0.0254],\n",
       "                      [ 0.0668, -0.1054, -0.0948,  ...,  0.1933,  0.0924, -0.0561]])),\n",
       "             ('bilstm_left_context_feature.bias_ih_l0_reverse',\n",
       "              tensor([ 1.4672e-01,  1.6852e-01, -1.9563e-01,  1.7273e-01,  6.9320e-02,\n",
       "                       6.8601e-02,  3.7827e-03,  1.6519e-01,  4.2461e-02,  2.1568e-01,\n",
       "                      -4.5356e-02,  1.2578e-01, -1.7851e-01,  9.9932e-02,  5.6855e-02,\n",
       "                      -5.6296e-02,  4.3164e-02,  6.8059e-02,  5.5675e-02,  8.8651e-02,\n",
       "                       4.2178e-02, -1.2392e-01,  1.2521e-03,  1.2752e-01,  1.0994e-01,\n",
       "                       9.2716e-02,  1.6920e-01,  1.9495e-02,  6.7035e-03,  1.5194e-01,\n",
       "                      -1.1243e-02,  8.1921e-02,  1.8001e-01,  1.4936e-01,  2.1573e-01,\n",
       "                       3.4275e-02,  7.2641e-02,  4.0710e-02,  9.4908e-02,  1.3016e-01,\n",
       "                       2.5876e-02,  7.1340e-02, -8.2612e-02, -4.3601e-02,  8.2514e-02,\n",
       "                       7.3162e-02,  1.8072e-01,  6.5227e-02, -1.3519e-02,  3.8743e-02,\n",
       "                       5.5928e-02,  9.3639e-03,  1.5613e-02,  2.6687e-01,  5.2029e-02,\n",
       "                      -4.4607e-04,  8.6695e-02, -2.5873e-02,  3.5901e-02, -6.9696e-02,\n",
       "                       2.1978e-01,  1.8290e-02,  5.7041e-02,  1.3609e-01, -1.0947e-02,\n",
       "                       9.7101e-03,  3.0633e-02, -1.2047e-02,  5.1522e-02,  3.9243e-02,\n",
       "                       1.3774e-01,  1.3981e-01, -4.2046e-02, -4.6324e-02,  8.2116e-02,\n",
       "                       4.9039e-02, -4.1440e-02,  5.4760e-02, -9.6708e-04,  1.6422e-01,\n",
       "                       1.1058e-02,  3.5643e-02,  8.1378e-03,  6.1042e-02,  2.1072e-01,\n",
       "                       1.9467e-01,  2.0160e-03,  3.0627e-03, -6.9405e-02,  1.1837e-01,\n",
       "                       1.2383e-01,  1.8268e-01, -2.2534e-02,  1.2621e-01,  1.0236e-01,\n",
       "                      -4.2916e-02,  1.2381e-01,  1.1153e-01,  4.9676e-02,  3.8496e-02,\n",
       "                       8.7076e-02,  4.3390e-02,  4.9244e-02,  2.3325e-01,  3.0605e-01,\n",
       "                       1.2981e-01, -2.0574e-02, -4.6725e-03,  1.0135e-01,  9.7356e-03,\n",
       "                      -4.1164e-02, -5.8457e-02, -6.7280e-02,  1.0265e-01, -5.6343e-02,\n",
       "                       1.3943e-02,  1.8092e-02, -6.6872e-02,  1.0081e-01, -1.8043e-02,\n",
       "                       2.5640e-02,  1.7675e-01,  1.6476e-01,  2.5984e-02,  1.0295e-01,\n",
       "                       1.7343e-01,  7.3705e-02,  1.9214e-02, -1.3713e-02, -1.5581e-01,\n",
       "                      -2.2241e-01, -9.0517e-02, -5.8109e-02, -3.0440e-02, -4.1495e-02,\n",
       "                      -2.3351e-02,  9.8103e-03, -6.6545e-02, -1.1067e-01, -6.8528e-02,\n",
       "                       3.1455e-02, -1.8116e-01,  8.0837e-02,  2.7907e-02,  8.1313e-02,\n",
       "                       3.9634e-02,  1.9978e-02, -1.0324e-01, -1.2421e-01, -1.3463e-01,\n",
       "                      -1.3681e-01, -1.8785e-02,  3.0013e-03,  8.0726e-02, -6.7958e-02,\n",
       "                      -3.3575e-02, -3.7266e-02, -5.8091e-02, -1.0459e-02, -1.4707e-01,\n",
       "                      -1.4232e-01,  1.5526e-02, -5.1523e-02, -9.9352e-02, -1.9875e-02,\n",
       "                      -1.4762e-01,  1.8946e-02, -3.4867e-02, -1.1927e-01,  3.8338e-02,\n",
       "                      -1.9757e-01,  1.4452e-01,  2.3569e-02, -1.0542e-01, -3.3755e-02,\n",
       "                      -1.9686e-01,  1.7430e-02, -1.4141e-01, -9.9732e-02, -1.8913e-01,\n",
       "                       1.5932e-01,  1.4299e-02,  1.1221e-01,  4.6478e-02,  1.8380e-02,\n",
       "                      -8.1798e-02, -7.5768e-03, -8.0264e-02,  4.7539e-02, -2.8908e-02,\n",
       "                      -3.5297e-02, -9.0390e-02,  2.2837e-02,  8.6465e-02, -2.3917e-02,\n",
       "                      -6.8315e-02, -1.2915e-01, -6.4567e-02, -1.4117e-01,  9.6673e-02,\n",
       "                      -1.1876e-01, -1.1481e-01, -2.1161e-01,  7.7680e-02,  1.2408e-01,\n",
       "                      -1.6149e-01,  7.6139e-02, -2.1941e-01,  7.3966e-02, -8.4895e-02,\n",
       "                       4.4430e-05,  2.3281e-02, -1.3701e-01, -4.7190e-02,  8.2289e-02,\n",
       "                      -4.5468e-02,  6.0905e-02,  7.8713e-02, -1.1723e-01,  7.2675e-03,\n",
       "                      -3.6559e-02, -5.1439e-02, -1.6331e-02, -1.1639e-01, -6.8094e-03,\n",
       "                      -4.1903e-02, -1.3732e-01, -1.0909e-01, -9.5699e-02, -7.7392e-02,\n",
       "                      -1.3741e-01, -1.0937e-01,  1.6731e-03, -1.6186e-01, -2.6266e-02,\n",
       "                      -1.6764e-01, -8.7906e-02, -1.1380e-01,  2.6575e-03,  1.0032e-01,\n",
       "                       3.8943e-02, -1.4839e-02, -6.0134e-02,  6.2887e-03,  5.9796e-02,\n",
       "                       9.2050e-03,  1.3972e-01,  3.4260e-02,  1.1212e-01, -6.0233e-02,\n",
       "                      -3.3388e-02,  3.3685e-02, -1.2481e-01, -1.6470e-01, -1.0291e-01,\n",
       "                      -1.0103e-01,  9.8678e-02, -1.3932e-01,  4.3263e-02,  2.3847e-02,\n",
       "                      -2.6964e-02, -1.1106e-02, -9.9273e-02,  4.8987e-02,  1.1983e-03,\n",
       "                       2.1670e-02, -2.7126e-02,  2.0122e-02,  8.6311e-02,  8.3966e-02,\n",
       "                      -1.3485e-02,  1.2857e-01, -5.2386e-02,  6.3874e-02, -6.8464e-02,\n",
       "                      -1.4118e-02,  5.9761e-02, -2.9410e-02, -3.1527e-02, -1.3236e-02,\n",
       "                       2.4451e-02, -1.0693e-01,  3.6908e-02,  1.2366e-01,  2.2142e-02,\n",
       "                       5.2258e-02, -3.9784e-02, -1.1571e-01,  4.9090e-02,  7.8499e-02,\n",
       "                       1.0524e-02, -1.9299e-02,  1.6907e-02,  1.3323e-01, -1.0771e-01,\n",
       "                      -9.5331e-02, -7.8272e-02,  2.7479e-02, -3.3574e-02,  1.3086e-02,\n",
       "                       4.1733e-02, -2.7978e-02,  7.8693e-02,  3.2181e-02,  3.6509e-02,\n",
       "                       4.3032e-02, -4.3844e-03, -9.3360e-03,  9.2577e-04,  1.2798e-01,\n",
       "                       4.4109e-02, -3.6785e-02,  8.7351e-02, -8.4205e-02, -1.3850e-01,\n",
       "                       1.0554e-03,  1.4479e-01, -1.3460e-01,  1.2872e-02, -9.6793e-02,\n",
       "                       1.2843e-01, -6.7223e-02,  5.8953e-02, -1.7378e-02, -1.7867e-02,\n",
       "                      -1.9627e-01,  9.2006e-04, -7.2364e-02, -5.0824e-02, -3.6105e-02,\n",
       "                       7.1119e-02,  1.2749e-01,  4.6178e-02, -2.0459e-02, -9.1158e-02,\n",
       "                       1.8224e-02, -2.3396e-02, -2.2615e-02,  6.6184e-02,  8.4722e-02,\n",
       "                      -1.0786e-01, -2.5312e-01, -4.1960e-02, -9.4150e-02, -1.8255e-02,\n",
       "                      -1.1888e-01,  1.5215e-02, -9.8676e-03, -9.4542e-04, -7.1962e-02,\n",
       "                      -1.5011e-01, -2.9894e-02, -3.1215e-02, -1.0141e-02,  6.6407e-02,\n",
       "                       1.0781e-01,  1.3077e-02,  6.8892e-02,  1.2870e-01, -8.2379e-02,\n",
       "                       2.9867e-02, -5.0240e-02, -1.1239e-02, -6.0067e-02,  1.0192e-01,\n",
       "                      -4.0522e-02, -5.1033e-02,  1.0593e-01,  7.4576e-02,  1.8675e-02,\n",
       "                       4.7338e-02, -2.8066e-02,  4.8699e-02,  4.6350e-03,  5.0457e-02,\n",
       "                       2.7842e-03, -9.1278e-02, -4.7509e-02,  4.6055e-04, -7.1018e-02,\n",
       "                       3.1907e-02, -1.3476e-02,  5.0230e-02, -6.8557e-02,  1.0275e-02,\n",
       "                       4.4726e-02, -1.1033e-01, -7.1015e-02,  6.8070e-02, -3.1601e-02,\n",
       "                       1.1406e-02,  1.8895e-01, -5.5388e-02,  5.3072e-02,  2.8283e-02,\n",
       "                       1.6414e-01,  2.4073e-02,  8.6675e-02, -4.2392e-02, -6.9355e-02,\n",
       "                       1.4552e-01,  1.6625e-01, -4.0054e-02, -1.1943e-02,  1.1592e-01,\n",
       "                      -1.2495e-01,  9.0015e-02,  7.3386e-02,  1.0024e-01, -1.1242e-03,\n",
       "                       6.0521e-02,  3.6301e-02, -4.8817e-02,  1.0623e-01, -6.5744e-02,\n",
       "                      -8.1474e-04,  2.3976e-01,  8.8343e-02,  1.5521e-01,  5.9412e-02,\n",
       "                       1.3489e-01,  1.2488e-01, -9.8885e-03,  6.0877e-02,  5.2278e-02,\n",
       "                       2.4249e-02, -1.6003e-01, -5.2337e-03, -2.9367e-02,  1.0057e-01,\n",
       "                       2.3546e-02, -3.9144e-02,  1.1695e-01, -7.6608e-03,  1.2029e-01,\n",
       "                       6.3983e-02,  1.4580e-01,  3.3103e-01,  9.5306e-02,  5.7514e-02,\n",
       "                      -3.1618e-02, -2.3523e-02,  5.9439e-02, -6.2126e-03,  1.8950e-01,\n",
       "                      -9.0668e-02,  1.8256e-01,  2.3424e-02, -9.0131e-02, -5.1835e-02,\n",
       "                       9.9679e-02,  1.5528e-01,  3.7594e-02,  2.9199e-03,  1.3042e-01,\n",
       "                       3.5986e-02,  2.5024e-02,  2.0178e-02,  1.3050e-01, -7.1254e-03,\n",
       "                       7.0436e-02,  8.2387e-02, -3.2766e-03, -7.7944e-03, -6.8916e-02,\n",
       "                       1.0378e-01, -2.7201e-02,  1.5073e-01,  1.7543e-01,  2.1038e-01,\n",
       "                      -2.5483e-02,  2.2459e-01, -1.5654e-01,  1.5389e-01,  1.6749e-02,\n",
       "                       1.5511e-01, -8.2699e-02,  6.2108e-02,  1.9038e-01,  9.1151e-03,\n",
       "                       1.7802e-01,  2.0079e-01,  1.7599e-01,  8.8664e-02,  1.3192e-02,\n",
       "                       1.4302e-01,  1.6033e-02,  2.2808e-01,  1.6414e-01,  1.0902e-01,\n",
       "                      -4.8610e-02,  1.3503e-01, -4.8411e-02,  1.4641e-01,  4.1656e-04,\n",
       "                      -1.4716e-01,  3.0104e-02,  2.8549e-02,  1.3975e-02, -1.0479e-01,\n",
       "                      -8.6142e-03,  1.9389e-02,  1.0804e-01,  7.4804e-02,  1.3181e-01,\n",
       "                       1.3845e-01, -4.2976e-02,  1.5606e-01,  1.2263e-01,  1.8369e-01,\n",
       "                      -2.8685e-02,  2.3527e-02])),\n",
       "             ('bilstm_left_context_feature.bias_hh_l0_reverse',\n",
       "              tensor([ 1.4156e-01,  1.8779e-02, -8.6126e-02,  3.4125e-02,  1.0621e-01,\n",
       "                       4.2870e-02, -2.7691e-02,  1.1087e-01, -4.4307e-02,  1.5399e-02,\n",
       "                      -1.2289e-01,  7.3976e-02,  2.1711e-02,  3.4715e-02, -4.3110e-02,\n",
       "                      -1.6682e-02,  4.7723e-02,  3.7437e-02, -2.8029e-02, -7.5098e-02,\n",
       "                      -8.1216e-02, -4.0616e-02,  3.9754e-02,  1.6133e-01,  4.3266e-02,\n",
       "                      -1.9171e-02,  2.2834e-02,  8.5564e-02, -1.2692e-01,  2.3485e-01,\n",
       "                       1.0098e-01, -2.2616e-02, -5.0343e-02,  1.2984e-01,  5.9197e-02,\n",
       "                       2.1788e-02,  1.6028e-01, -5.6758e-02, -5.2450e-02,  2.0832e-01,\n",
       "                      -4.8608e-02, -6.0401e-03, -1.1562e-01,  6.6746e-02, -6.7139e-02,\n",
       "                       1.1222e-01,  5.7840e-02,  5.8735e-02,  3.4047e-02,  8.3432e-02,\n",
       "                       2.6987e-02,  5.0791e-02, -9.4778e-02,  2.6164e-01, -2.3007e-03,\n",
       "                       3.4951e-02, -1.1534e-03, -2.7190e-02,  1.3269e-01,  6.0279e-02,\n",
       "                       1.4770e-01, -7.1545e-03,  5.9726e-02,  1.3843e-01,  8.7713e-02,\n",
       "                       1.2926e-01,  1.3345e-01,  6.4656e-02,  5.2243e-02,  1.7936e-01,\n",
       "                       2.4572e-02,  1.8606e-01, -1.0569e-01, -3.0820e-02,  1.4026e-01,\n",
       "                       1.1483e-01,  3.0219e-02,  6.4925e-02,  4.0459e-02,  1.6839e-01,\n",
       "                       5.2415e-02, -7.2320e-03,  2.5256e-02, -8.4674e-03,  1.7953e-01,\n",
       "                       7.9067e-02, -2.5922e-02,  1.4294e-01, -1.0756e-01,  1.4723e-01,\n",
       "                       6.1012e-03,  1.9732e-01, -6.3601e-02,  3.1897e-02, -2.1386e-02,\n",
       "                      -7.7264e-02,  7.9927e-02,  5.8134e-02,  1.1496e-01,  1.4051e-02,\n",
       "                       4.9081e-02,  3.8370e-02,  2.0497e-01,  2.5122e-01,  1.7561e-01,\n",
       "                       1.4970e-01,  3.8703e-02,  8.7614e-03,  6.2140e-02,  1.1728e-01,\n",
       "                      -3.9669e-02, -1.0604e-01, -1.0684e-01,  2.9106e-02, -1.4520e-01,\n",
       "                       7.7235e-02,  4.5473e-03, -1.8710e-01,  2.4001e-03,  5.0697e-02,\n",
       "                       8.1285e-02,  1.7485e-01,  1.5700e-01, -2.5106e-02,  1.1227e-02,\n",
       "                       1.7778e-01,  5.6301e-02,  5.2608e-02, -1.0029e-01, -9.7292e-02,\n",
       "                      -1.2041e-01, -2.3142e-02, -5.1982e-02, -6.5551e-02, -5.3870e-02,\n",
       "                      -7.0578e-02, -5.1126e-03,  4.0246e-02, -7.0251e-02, -2.6281e-02,\n",
       "                      -3.7024e-02, -2.3947e-01, -2.1854e-02, -3.3513e-02, -1.2446e-02,\n",
       "                      -3.8056e-02,  1.1906e-02,  2.0711e-02, -1.8391e-01, -4.2512e-02,\n",
       "                      -7.2914e-02,  6.0566e-02, -1.7781e-01,  1.4323e-01, -1.0730e-01,\n",
       "                       1.0858e-01, -7.6200e-03, -2.6391e-02, -1.0561e-01, -1.5431e-01,\n",
       "                      -7.9354e-02, -3.8921e-03, -1.1216e-01, -1.7178e-01, -1.3700e-01,\n",
       "                      -9.5834e-02,  8.6662e-02, -2.0466e-01, -3.3994e-02,  3.7294e-02,\n",
       "                      -1.1380e-01, -3.4752e-03, -1.4400e-01, -4.0590e-02, -8.7780e-02,\n",
       "                      -4.7353e-02, -1.3516e-02,  4.7706e-05, -8.3768e-02, -2.4298e-01,\n",
       "                       5.5950e-02, -1.4150e-01,  2.2971e-02,  2.4913e-02, -1.5546e-01,\n",
       "                      -8.6430e-02, -8.4702e-02, -5.7177e-02, -1.0015e-01,  2.0428e-02,\n",
       "                       6.9024e-02, -4.6974e-02, -1.5636e-02,  6.5051e-02,  1.4971e-03,\n",
       "                       5.9817e-02, -6.2439e-02, -7.2361e-02, -6.8995e-02,  8.2084e-02,\n",
       "                      -4.0578e-02,  4.1984e-03, -7.3456e-02,  4.6765e-02,  3.4337e-02,\n",
       "                       5.8361e-03, -1.1475e-01, -2.7298e-01, -7.8658e-02, -5.1437e-02,\n",
       "                      -4.6692e-02,  3.6335e-03, -8.2657e-03, -1.5803e-01, -2.3901e-02,\n",
       "                      -7.9722e-02,  3.0808e-02, -1.5893e-01, -1.3364e-01, -4.0820e-02,\n",
       "                      -9.7098e-02, -3.0528e-02, -6.7572e-03, -9.9895e-02, -1.5477e-01,\n",
       "                       4.2410e-02, -3.8259e-02, -3.3657e-02, -7.8864e-02, -5.4609e-02,\n",
       "                      -1.8622e-01,  3.3912e-03,  5.4972e-02, -2.0445e-01, -1.0583e-01,\n",
       "                      -1.4083e-01, -2.2713e-02, -2.9240e-02,  2.1392e-02, -6.9027e-02,\n",
       "                      -3.0060e-02,  1.3501e-01, -4.5469e-02,  5.4458e-02,  9.1621e-03,\n",
       "                      -8.3401e-03, -5.4961e-02,  1.0852e-02,  1.3048e-02, -1.4413e-02,\n",
       "                      -1.3191e-02, -1.2533e-01,  4.9741e-02, -4.6334e-02,  1.3329e-01,\n",
       "                      -1.7084e-02,  8.6279e-02, -1.6116e-02, -1.5209e-02,  3.3624e-02,\n",
       "                       5.4872e-02,  9.2327e-02, -1.9034e-02,  4.9651e-02,  9.1751e-02,\n",
       "                      -2.6548e-02, -3.7174e-02,  8.8249e-02,  8.4794e-02,  3.4805e-03,\n",
       "                      -2.5375e-02,  5.6936e-02,  1.7445e-02,  7.9597e-02,  2.3687e-02,\n",
       "                       1.1705e-01, -7.5117e-02,  2.1497e-02, -1.0824e-01,  6.1537e-02,\n",
       "                      -1.6650e-02,  1.1030e-01, -6.1601e-02, -2.4299e-02, -4.5494e-04,\n",
       "                       7.3833e-02,  5.7485e-02, -1.3150e-02,  1.8393e-02, -1.1697e-02,\n",
       "                      -1.0061e-01,  7.1195e-04,  7.3548e-03, -6.8929e-02,  7.6326e-02,\n",
       "                      -3.4824e-02, -9.3151e-03,  1.2079e-02,  5.4381e-02, -5.7013e-04,\n",
       "                       1.2680e-02,  5.2030e-02,  4.2012e-03,  7.0598e-02, -6.9753e-02,\n",
       "                      -1.4308e-02, -2.0891e-01,  2.9429e-02,  8.9492e-02,  4.3522e-02,\n",
       "                       4.1066e-02,  6.6684e-02,  5.3435e-02, -1.0975e-01,  4.4453e-02,\n",
       "                      -9.0549e-02, -7.4531e-02,  8.6807e-02,  6.9711e-03, -2.2574e-02,\n",
       "                       6.1669e-03, -9.1757e-02, -1.4220e-02,  6.6922e-02, -4.8550e-03,\n",
       "                       1.0397e-01, -1.3702e-02, -1.3457e-01, -1.9277e-02, -8.3471e-02,\n",
       "                       9.3010e-02, -7.0318e-02, -8.0539e-02, -3.3827e-02, -9.1651e-02,\n",
       "                       3.4315e-02,  7.3050e-02,  1.6566e-01,  6.2075e-03,  2.3330e-02,\n",
       "                      -2.6456e-02,  1.5473e-01, -1.5948e-03, -7.1545e-02, -3.9454e-02,\n",
       "                       1.9545e-02, -6.2089e-03,  1.0829e-02,  2.1384e-02, -2.5560e-02,\n",
       "                       6.7832e-03,  8.5712e-04,  1.0853e-01,  3.4608e-02,  4.8108e-02,\n",
       "                      -1.3256e-01,  1.1211e-01, -7.3085e-02, -5.6430e-02, -4.0965e-02,\n",
       "                       1.8314e-01,  8.2533e-02, -8.7900e-02, -4.0225e-02,  1.5342e-01,\n",
       "                       1.5306e-02, -7.9748e-02,  1.3717e-02,  4.4184e-02, -5.9566e-02,\n",
       "                       8.5595e-02,  2.5601e-02,  2.6666e-02,  1.0785e-01, -4.6802e-02,\n",
       "                       4.4308e-04, -4.0060e-02, -6.4082e-02,  5.7421e-02, -1.1147e-01,\n",
       "                       7.0135e-02, -3.4210e-02,  4.8361e-02, -5.0021e-02,  1.6066e-01,\n",
       "                      -1.6096e-03, -1.1066e-01, -1.1499e-01,  1.5622e-01, -1.8630e-02,\n",
       "                      -4.0134e-02,  7.7114e-02,  8.2483e-03,  6.8995e-02, -8.1673e-02,\n",
       "                       8.9474e-03,  4.8489e-02,  2.1824e-01, -4.4107e-02, -1.1645e-01,\n",
       "                       9.8522e-02,  1.8346e-01,  1.8689e-01,  1.1669e-01,  3.7719e-02,\n",
       "                       4.3597e-02, -4.1790e-02,  1.5014e-01,  4.9468e-02,  3.7193e-02,\n",
       "                      -4.0807e-02,  1.5246e-01,  4.9872e-02,  2.7337e-01, -1.9647e-03,\n",
       "                       9.3027e-02,  1.5195e-01,  1.4793e-01,  1.0356e-01, -2.6229e-02,\n",
       "                       1.9874e-03, -2.0557e-02,  1.0073e-01,  9.0287e-02,  4.9492e-02,\n",
       "                       8.2076e-02, -1.8053e-01,  1.5043e-01,  1.0590e-01,  1.6487e-01,\n",
       "                       1.1878e-01,  1.6168e-01,  3.7355e-02, -2.2826e-03,  6.1585e-02,\n",
       "                       7.7141e-02,  1.0439e-02,  3.3925e-01,  1.4322e-01,  1.0286e-01,\n",
       "                       8.2901e-02,  3.8241e-02,  7.7922e-02, -3.6298e-02,  1.7364e-01,\n",
       "                      -6.1391e-03,  2.1707e-02,  3.9875e-02, -5.2335e-02, -1.0204e-01,\n",
       "                       1.3046e-02,  2.1869e-02, -2.2356e-02,  1.8856e-01,  1.3891e-01,\n",
       "                       1.7516e-01, -8.5409e-02,  5.0779e-02,  1.5791e-01, -6.9220e-02,\n",
       "                       4.1575e-03,  5.6645e-02,  1.1331e-01, -2.9983e-02,  1.7362e-01,\n",
       "                       4.7624e-02,  2.8908e-02,  2.8642e-02,  8.8214e-02,  2.3712e-01,\n",
       "                       2.1082e-02,  3.0927e-02, -5.0235e-02,  2.0118e-01, -3.2505e-02,\n",
       "                       1.1351e-01,  1.5515e-03,  8.8304e-02,  1.4923e-01, -5.1556e-02,\n",
       "                       1.0340e-01,  1.3747e-01,  3.2138e-01,  1.6876e-01,  3.2571e-02,\n",
       "                       2.1109e-01,  1.4744e-01,  2.1918e-01,  1.2244e-01,  5.0901e-02,\n",
       "                       4.2659e-02, -6.6593e-04,  5.3143e-02,  1.1220e-01,  4.1102e-02,\n",
       "                      -1.3306e-01,  1.2046e-01,  1.0709e-01, -4.8769e-02, -3.7036e-02,\n",
       "                       1.1835e-01, -3.3559e-02,  1.6282e-02, -1.3599e-01,  1.2348e-01,\n",
       "                       1.5956e-01,  1.1766e-01,  1.9564e-02,  7.2461e-02,  2.3651e-01,\n",
       "                       1.9847e-02,  6.4575e-02])),\n",
       "             ('bilstm_oov_context_feature.weight_ih_l0',\n",
       "              tensor([[-0.2655, -0.0364, -0.1620,  ..., -0.6776,  0.5802,  0.2362],\n",
       "                      [-0.6600,  0.6225,  0.5645,  ..., -0.0055, -0.1474, -0.2272],\n",
       "                      [-0.3046,  0.1113, -0.2306,  ...,  0.1725,  0.4445, -0.0568],\n",
       "                      ...,\n",
       "                      [-0.4358,  0.0789,  0.3767,  ..., -0.0517,  0.3392, -0.3010],\n",
       "                      [-0.5020,  0.2812,  0.6711,  ...,  0.1561, -0.0860, -0.5933],\n",
       "                      [-0.4399,  0.1881,  0.1115,  ..., -0.5486,  0.7718,  0.4079]])),\n",
       "             ('bilstm_oov_context_feature.weight_hh_l0',\n",
       "              tensor([[-0.1433, -0.0121, -0.1498,  ...,  0.0440, -0.1683, -0.2494],\n",
       "                      [-0.0635, -0.0425,  0.2131,  ..., -0.1337, -0.0861, -0.0549],\n",
       "                      [-0.1465,  0.0016,  0.1994,  ...,  0.0046, -0.0711, -0.1509],\n",
       "                      ...,\n",
       "                      [-0.0980, -0.2474, -0.0109,  ..., -0.0481, -0.0424,  0.1400],\n",
       "                      [-0.0566, -0.0037,  0.0228,  ...,  0.0843,  0.1940, -0.0707],\n",
       "                      [ 0.0728, -0.0607,  0.1752,  ..., -0.0378,  0.1333, -0.2203]])),\n",
       "             ('bilstm_oov_context_feature.bias_ih_l0',\n",
       "              tensor([-0.1213, -0.0998, -0.1925, -0.2469, -0.0983, -0.1705, -0.1243, -0.1205,\n",
       "                      -0.0356, -0.0426, -0.0958, -0.2407, -0.1930, -0.1205, -0.0190, -0.0939,\n",
       "                      -0.1113, -0.1171, -0.0469, -0.1540, -0.0685, -0.0659, -0.1094, -0.1569,\n",
       "                      -0.1202, -0.0424, -0.1466, -0.0653, -0.0935, -0.1775,  0.1105, -0.1388,\n",
       "                       0.0524, -0.0688, -0.0657, -0.0395, -0.1608, -0.1991, -0.0550, -0.0327,\n",
       "                      -0.1288, -0.0488, -0.0704, -0.0644, -0.0845, -0.1436, -0.1003, -0.1493,\n",
       "                      -0.0822, -0.0333, -0.1326, -0.1410, -0.2047, -0.1935, -0.0681, -0.1297,\n",
       "                      -0.1723, -0.1256, -0.1082, -0.1646, -0.0225,  0.0315, -0.0963, -0.2399,\n",
       "                      -0.1507, -0.1100, -0.1961, -0.1424, -0.0545, -0.1928, -0.1551, -0.0929,\n",
       "                      -0.1272, -0.1577, -0.0294, -0.1583, -0.1538, -0.1901, -0.0171, -0.1147,\n",
       "                      -0.0607, -0.1979, -0.1731, -0.0399, -0.0493, -0.2108, -0.1808, -0.0979,\n",
       "                      -0.1237, -0.0480, -0.1011, -0.1417, -0.2206, -0.0868, -0.0562, -0.0674,\n",
       "                      -0.2289, -0.1637, -0.1044, -0.0703, -0.0775, -0.0631,  0.0121, -0.1265,\n",
       "                      -0.1766, -0.0858, -0.1734, -0.0731, -0.0141, -0.0691, -0.0634, -0.0403,\n",
       "                      -0.1569, -0.1486, -0.0548, -0.0309, -0.1692, -0.0576, -0.0702, -0.2003,\n",
       "                       0.0496, -0.1118, -0.0562, -0.1236, -0.1724, -0.0464, -0.1146, -0.1636,\n",
       "                      -0.0698,  0.0791, -0.1051,  0.0338, -0.1722, -0.0535, -0.0736, -0.0477,\n",
       "                      -0.0908,  0.0632, -0.0656,  0.0617, -0.1228,  0.0409, -0.0738, -0.0617,\n",
       "                      -0.1377, -0.1099, -0.1021, -0.1450, -0.1432, -0.1572, -0.0152, -0.0694,\n",
       "                      -0.1097, -0.1469, -0.0598,  0.0252, -0.2271, -0.0486, -0.1149, -0.0555,\n",
       "                      -0.1897, -0.1877, -0.1564,  0.0816, -0.1940,  0.0760, -0.0731, -0.2421,\n",
       "                       0.0328, -0.0890,  0.0315, -0.1210,  0.1830, -0.0212, -0.0601, -0.0045,\n",
       "                      -0.1185, -0.0999, -0.0805, -0.0881,  0.1356, -0.0704, -0.1231,  0.0828,\n",
       "                      -0.1023, -0.1285, -0.1122, -0.1099, -0.0500,  0.1022, -0.0782, -0.0537,\n",
       "                       0.0082, -0.0751, -0.0955,  0.0226,  0.0116, -0.0818, -0.0525, -0.1386,\n",
       "                      -0.1414,  0.0717,  0.0422, -0.0091, -0.0358, -0.0627, -0.0482, -0.0930,\n",
       "                      -0.1144, -0.1478, -0.1381, -0.1135,  0.0688, -0.1736, -0.1387, -0.1108,\n",
       "                      -0.0800,  0.0297, -0.0452, -0.0888, -0.0492,  0.0300, -0.0739, -0.0281,\n",
       "                      -0.1297, -0.1156, -0.0920, -0.1267,  0.0173, -0.0384, -0.1442, -0.1037,\n",
       "                       0.0682, -0.0148, -0.1318, -0.0975, -0.0089,  0.0369, -0.1221, -0.0143,\n",
       "                      -0.0779, -0.1787, -0.0155, -0.1676, -0.1220, -0.1451, -0.0348, -0.0864,\n",
       "                      -0.0664,  0.0256, -0.1021,  0.0046, -0.1359, -0.0298, -0.1302, -0.1621,\n",
       "                      -0.0542,  0.0291,  0.0220, -0.0479, -0.0356, -0.0162,  0.0697, -0.0087,\n",
       "                       0.0230,  0.0991,  0.0135, -0.0555,  0.1383, -0.0231, -0.0604, -0.0713,\n",
       "                      -0.1946, -0.0226,  0.1155,  0.0938,  0.0589, -0.0079,  0.0041,  0.0032,\n",
       "                      -0.1093,  0.0741,  0.0858, -0.0641, -0.0286,  0.1211, -0.1324,  0.0767,\n",
       "                       0.1066, -0.0739, -0.0846,  0.1317,  0.0967,  0.1112, -0.0943,  0.0921,\n",
       "                       0.1491,  0.0251, -0.0702, -0.0345, -0.0863,  0.0186, -0.0783, -0.0834,\n",
       "                      -0.0239, -0.1460,  0.0930,  0.0674, -0.0140, -0.0167,  0.1479, -0.0092,\n",
       "                       0.0437, -0.0132, -0.0134,  0.0302,  0.0424, -0.0667, -0.0069,  0.0573,\n",
       "                      -0.0886,  0.0462, -0.0297,  0.0729,  0.0661, -0.0058, -0.0671,  0.1069,\n",
       "                      -0.0704,  0.0734, -0.0864, -0.0757, -0.0004,  0.0514,  0.0329,  0.0002,\n",
       "                       0.0629,  0.0692, -0.0595,  0.0471, -0.0895, -0.1167,  0.0191,  0.0358,\n",
       "                       0.1055, -0.1107, -0.1096, -0.0500, -0.1056, -0.0872, -0.0605,  0.0577,\n",
       "                       0.0016,  0.0226, -0.1089, -0.1222, -0.0109,  0.0256,  0.0782, -0.1305,\n",
       "                       0.0594, -0.0835,  0.0542,  0.0195, -0.0568,  0.0154,  0.0542, -0.1174,\n",
       "                       0.0880, -0.0098, -0.0908, -0.0510,  0.0919,  0.0449, -0.1403, -0.0503,\n",
       "                      -0.0068,  0.0567,  0.0070, -0.0486, -0.0303, -0.0919, -0.1031, -0.0924,\n",
       "                      -0.0059, -0.0008, -0.1010, -0.0890, -0.1660, -0.1863, -0.0075, -0.0623,\n",
       "                      -0.0926, -0.0481, -0.1833,  0.0065, -0.0863, -0.1178, -0.0567, -0.1846,\n",
       "                      -0.2006, -0.0850, -0.1549, -0.0524, -0.1523, -0.0981, -0.1212, -0.0712,\n",
       "                      -0.1491, -0.1592, -0.1520, -0.1433, -0.1715, -0.0739,  0.0092, -0.1226,\n",
       "                       0.0181, -0.1121, -0.1392,  0.0944, -0.1962, -0.1017, -0.0434, -0.0083,\n",
       "                      -0.0021, -0.1610, -0.1993, -0.1070,  0.1010, -0.0033, -0.1584, -0.1186,\n",
       "                      -0.0541, -0.1506, -0.0482, -0.1763, -0.1239, -0.0393, -0.1100, -0.0286,\n",
       "                      -0.1107, -0.1099, -0.1767, -0.2364, -0.0289, -0.1042, -0.1811, -0.1010,\n",
       "                      -0.0301, -0.0899, -0.1601, -0.0388, -0.0801, -0.0735, -0.1156, -0.2287,\n",
       "                      -0.0337, -0.1507, -0.1303, -0.0977, -0.0739, -0.0591, -0.0991, -0.0520,\n",
       "                      -0.0138, -0.1936, -0.0656, -0.0336,  0.0357, -0.1223, -0.0517, -0.2254,\n",
       "                      -0.1981, -0.0816, -0.1037,  0.0634,  0.0075, -0.1470, -0.0543, -0.0906,\n",
       "                      -0.2051, -0.1526, -0.1761, -0.2091, -0.0037, -0.0599, -0.1065, -0.1046,\n",
       "                      -0.0770, -0.0855, -0.0944, -0.1992, -0.1241, -0.0045,  0.1457, -0.0424,\n",
       "                      -0.0681, -0.1621, -0.1091, -0.0519, -0.1341, -0.0477, -0.0690, -0.0471,\n",
       "                      -0.2429, -0.0417, -0.1816, -0.0540, -0.1893, -0.0091, -0.1101, -0.0629])),\n",
       "             ('bilstm_oov_context_feature.bias_hh_l0',\n",
       "              tensor([-9.2360e-02, -2.1567e-01, -1.0744e-01, -8.0681e-02, -1.7110e-01,\n",
       "                      -8.9182e-02, -7.3028e-02, -1.8089e-01, -1.6043e-01,  1.2322e-03,\n",
       "                      -1.2368e-01, -6.3952e-02, -1.0898e-01, -1.6998e-01, -1.3493e-01,\n",
       "                      -1.4393e-01, -3.2026e-01, -1.0194e-01, -3.8421e-02, -1.4946e-01,\n",
       "                      -2.0185e-01,  1.2376e-03, -9.8689e-02, -4.1188e-02, -1.6161e-01,\n",
       "                      -7.5947e-02, -1.6168e-01, -8.5265e-02, -1.0898e-01, -6.6667e-02,\n",
       "                       9.1765e-03, -6.5200e-02, -9.1985e-02, -1.7228e-01, -8.8724e-02,\n",
       "                      -5.6073e-02, -1.5134e-01, -9.5438e-02, -5.7875e-02,  1.8610e-02,\n",
       "                      -2.2127e-01, -1.5196e-01, -1.1440e-01,  2.0879e-02, -2.2667e-01,\n",
       "                       3.7507e-02, -3.4425e-02, -2.5296e-02, -2.1412e-02, -1.8595e-01,\n",
       "                      -6.2446e-02, -1.3218e-01, -1.9696e-01, -1.4336e-01, -8.8865e-02,\n",
       "                      -1.5185e-01, -1.3078e-01, -1.1108e-01, -1.1530e-01, -1.3264e-01,\n",
       "                      -7.1582e-02,  3.1294e-02, -1.2591e-01, -1.7091e-01, -1.2311e-01,\n",
       "                      -5.0686e-02, -1.0131e-01, -1.2948e-01, -1.1670e-01, -1.3540e-01,\n",
       "                      -1.7177e-01, -4.5873e-02,  4.3105e-03, -1.3532e-01, -1.0454e-01,\n",
       "                      -6.4501e-02, -1.0185e-01, -1.1329e-01, -9.9157e-02, -2.0996e-01,\n",
       "                      -8.4091e-02, -2.6285e-01, -1.4134e-01, -1.3304e-01,  3.9840e-02,\n",
       "                      -2.0255e-01, -1.0448e-01, -1.3347e-01, -2.5738e-01,  4.5613e-02,\n",
       "                      -8.2320e-02, -1.1840e-01, -1.5370e-01, -5.6886e-03, -5.8061e-02,\n",
       "                      -1.6964e-01, -2.2344e-01, -7.9059e-02, -2.1147e-01, -5.8295e-02,\n",
       "                      -1.5941e-01, -1.3429e-01,  1.3712e-02, -1.4559e-01, -1.8372e-01,\n",
       "                      -7.6755e-02, -1.7091e-02, -6.3213e-02, -2.3646e-01, -1.5010e-01,\n",
       "                      -6.3488e-02, -1.0716e-01, -1.1139e-01, -2.0346e-01,  3.9874e-02,\n",
       "                      -9.4071e-02, -1.5086e-01, -1.2172e-01, -8.2511e-02, -1.1651e-01,\n",
       "                      -7.8023e-02, -1.7740e-01, -1.4856e-01, -2.9116e-01, -2.7477e-01,\n",
       "                      -1.6453e-02, -1.8574e-01, -2.5683e-01, -1.1701e-02,  8.8872e-05,\n",
       "                      -1.8407e-01, -4.3557e-02, -4.6282e-02, -3.0065e-02, -2.1346e-02,\n",
       "                      -1.1925e-01, -7.2476e-03, -4.3967e-02, -7.6152e-02,  1.5532e-01,\n",
       "                      -1.1467e-01, -4.1687e-02,  9.8225e-03, -8.6666e-04, -5.6129e-02,\n",
       "                      -7.7765e-02, -1.1346e-01, -1.0691e-01, -5.4052e-02, -2.0262e-02,\n",
       "                      -1.0904e-01, -1.4219e-01, -1.3981e-01,  3.0337e-03, -9.4049e-02,\n",
       "                      -2.0128e-01, -1.1631e-02, -2.1202e-01, -1.2586e-01, -6.6011e-02,\n",
       "                      -7.6657e-02, -2.1273e-01,  4.6412e-02,  1.1016e-01, -3.7154e-02,\n",
       "                      -6.9775e-02, -8.0178e-02, -2.3915e-01, -4.2787e-02,  2.5133e-02,\n",
       "                      -1.3771e-03,  1.7390e-01,  1.0405e-01,  4.8637e-02, -3.6308e-02,\n",
       "                      -1.4456e-01, -5.4809e-02, -2.3995e-02, -5.8742e-03, -6.9146e-02,\n",
       "                      -7.2037e-02, -3.0967e-02, -2.5481e-02, -1.0783e-01, -2.8767e-03,\n",
       "                       6.6537e-03, -8.5657e-02, -1.1454e-01, -3.2170e-02, -1.3090e-01,\n",
       "                      -7.5178e-02, -7.9919e-02, -4.5603e-02,  8.7616e-03, -1.3264e-01,\n",
       "                      -1.1733e-01, -9.1738e-03, -1.5191e-01, -1.7175e-01, -3.4443e-02,\n",
       "                       2.7654e-02, -6.8016e-02, -1.9872e-01, -3.0421e-02, -2.0167e-01,\n",
       "                      -9.5233e-02, -1.0062e-01, -2.6843e-02, -1.7321e-01, -7.3776e-02,\n",
       "                      -7.0675e-02, -6.8310e-02,  1.3851e-01, -1.3239e-01, -1.6961e-01,\n",
       "                      -1.2862e-01, -7.5970e-02,  6.4664e-02, -6.0460e-02, -2.0068e-01,\n",
       "                       6.6406e-02, -1.1276e-01, -2.4368e-02, -1.9663e-02, -7.4100e-02,\n",
       "                      -1.2486e-01, -1.4545e-01, -7.6656e-02,  4.1150e-02, -6.4090e-02,\n",
       "                      -1.6460e-02,  1.1503e-02, -1.0629e-02, -5.2242e-02, -1.3839e-01,\n",
       "                      -1.3774e-01, -1.0643e-01, -9.1931e-03,  4.2284e-02, -5.9507e-02,\n",
       "                       5.1932e-02, -1.1102e-01,  7.7154e-02, -8.8783e-02, -1.0171e-01,\n",
       "                      -5.0685e-02, -1.2227e-01, -3.8057e-02, -4.7977e-02, -5.6052e-02,\n",
       "                      -5.9619e-02,  4.2009e-02, -7.5813e-02, -3.0639e-02, -1.1804e-01,\n",
       "                      -1.2926e-01, -1.3156e-01, -1.0429e-01,  9.4960e-02, -2.7558e-02,\n",
       "                      -3.9935e-02,  1.7000e-02,  5.2299e-02, -3.0705e-02,  9.6037e-02,\n",
       "                       2.8008e-02, -1.1166e-02, -5.4089e-02,  3.4575e-02,  1.3401e-02,\n",
       "                      -3.5943e-02, -6.7135e-03, -1.3845e-01, -5.5227e-02, -4.4124e-02,\n",
       "                      -1.7259e-02,  4.3988e-02,  7.6432e-02,  2.8911e-02,  6.1325e-02,\n",
       "                      -5.7490e-02,  9.8086e-02, -3.0093e-02,  7.7565e-02, -1.6531e-02,\n",
       "                      -2.1635e-02, -3.5700e-02, -2.3035e-02,  4.6946e-02,  1.3677e-02,\n",
       "                       9.8564e-03, -9.5323e-02,  1.3167e-01, -1.4734e-02, -1.5916e-01,\n",
       "                       8.3627e-02,  1.6464e-01, -4.3406e-02,  1.0285e-01, -1.9924e-02,\n",
       "                      -1.0317e-02, -7.8885e-02, -6.1393e-02, -7.2816e-03,  9.6452e-02,\n",
       "                      -7.2397e-02,  5.2383e-03, -4.3750e-02,  8.9419e-02,  8.7919e-03,\n",
       "                       1.8182e-02, -5.6020e-02,  8.5096e-02, -1.9495e-02, -6.8002e-02,\n",
       "                      -4.7400e-02,  6.5470e-02,  4.9520e-02, -1.0627e-01, -5.3720e-02,\n",
       "                      -3.3860e-02, -1.9106e-03, -9.2780e-02, -5.8051e-03, -5.6870e-02,\n",
       "                       1.6757e-02, -1.2239e-01, -2.7328e-02, -1.2706e-01, -8.3566e-02,\n",
       "                      -4.9743e-02, -9.9489e-02,  2.7050e-02,  9.1785e-03, -1.2090e-01,\n",
       "                       1.1311e-01, -3.8960e-02,  5.1347e-02,  4.3705e-02,  7.4288e-02,\n",
       "                       4.5953e-02,  9.8787e-02,  2.3244e-02,  6.1632e-02, -1.2159e-02,\n",
       "                      -9.9361e-02,  4.3665e-02,  6.1880e-02, -3.7633e-02,  5.3542e-02,\n",
       "                      -9.2372e-02, -1.2572e-02, -3.5158e-03, -6.5275e-03, -2.9519e-02,\n",
       "                      -5.0853e-02,  9.5447e-02,  3.9802e-02, -1.6446e-02, -1.1694e-01,\n",
       "                       1.3324e-02, -2.9940e-02,  1.1460e-01, -5.2668e-02, -7.6789e-03,\n",
       "                      -1.8137e-02,  1.3122e-02, -4.4108e-02, -8.7834e-02,  1.0090e-02,\n",
       "                      -5.9199e-02,  8.4824e-02,  2.3522e-02, -5.5730e-02,  8.0254e-02,\n",
       "                      -1.0730e-01, -5.5770e-02, -1.8431e-02,  4.5700e-02, -1.2572e-02,\n",
       "                      -1.7837e-02,  4.9940e-02, -1.9612e-02, -1.5611e-01,  2.7259e-04,\n",
       "                      -1.3634e-01, -6.5036e-02, -6.5500e-02, -4.3292e-02, -1.3167e-01,\n",
       "                      -9.6072e-02, -1.1667e-01, -2.0387e-01, -1.5612e-01, -9.8855e-02,\n",
       "                      -4.4119e-02, -1.9641e-01, -8.5641e-02,  4.6651e-02, -1.5941e-01,\n",
       "                      -1.5535e-01, -2.2265e-01, -1.0556e-01, -1.5501e-01, -5.0264e-02,\n",
       "                      -2.3676e-01, -9.9111e-02, -1.8515e-01, -1.2069e-01, -2.0404e-01,\n",
       "                      -8.1392e-02,  1.8202e-02,  2.1370e-02, -7.6320e-02, -9.6892e-03,\n",
       "                      -3.4387e-02, -2.6151e-02, -4.4453e-02,  6.1400e-02,  5.0872e-02,\n",
       "                      -9.2509e-02, -2.0176e-01, -5.2527e-03, -2.0491e-01, -1.8468e-01,\n",
       "                      -4.6817e-02, -2.6523e-02, -9.7129e-02,  9.7904e-02, -1.1912e-01,\n",
       "                      -1.3391e-01, -2.1914e-02, -2.0596e-01, -1.4829e-01,  5.9490e-02,\n",
       "                      -1.4148e-01, -1.4734e-01,  6.5450e-03, -9.1077e-02, -2.0378e-01,\n",
       "                      -2.4445e-01, -6.6346e-02, -8.2556e-02, -1.8568e-01, -1.4658e-01,\n",
       "                      -7.6030e-02,  1.3737e-01, -1.5418e-01, -1.4944e-01, -1.7478e-01,\n",
       "                      -1.1976e-01, -1.1537e-01,  4.5482e-02, -9.5061e-02, -1.6356e-01,\n",
       "                       5.5699e-02, -3.7442e-03, -1.1221e-01, -1.9330e-01, -7.0988e-02,\n",
       "                      -8.4064e-02, -1.4262e-01, -1.1262e-01, -1.5474e-01, -1.2657e-01,\n",
       "                      -1.9400e-01, -1.5300e-01,  5.0455e-02, -4.2273e-03, -5.9626e-02,\n",
       "                       3.3425e-02, -2.0412e-01, -2.1691e-01, -1.1631e-01, -9.5655e-02,\n",
       "                      -1.2114e-01,  8.4712e-02, -5.5760e-02, -1.6428e-01, -7.6121e-02,\n",
       "                      -1.9469e-01, -6.5506e-02, -1.3068e-01, -1.1223e-02, -1.6103e-01,\n",
       "                      -1.1204e-01,  3.4623e-03, -3.8340e-02, -5.4634e-02, -1.2006e-01,\n",
       "                      -1.3464e-01, -9.8567e-02, -8.7756e-02,  2.7199e-02, -9.1485e-02,\n",
       "                      -1.1314e-01, -1.7291e-01, -1.3564e-01, -2.7544e-02, -1.1254e-01,\n",
       "                      -4.2683e-02, -3.2973e-02, -1.1531e-01, -5.2693e-02, -7.1189e-03,\n",
       "                      -7.7768e-02, -9.8629e-02, -3.2632e-03, -1.2796e-01, -2.8812e-02,\n",
       "                      -9.7735e-02, -6.5552e-02])),\n",
       "             ('bilstm_oov_context_feature.weight_ih_l0_reverse',\n",
       "              tensor([[ 0.1775, -0.0592, -0.2894,  ...,  0.3889, -0.0981,  0.0111],\n",
       "                      [ 0.4693,  0.2022, -0.2434,  ..., -0.3261,  0.2395,  0.2919],\n",
       "                      [-0.6481, -0.1854,  0.5724,  ...,  0.2396, -0.1054,  0.4224],\n",
       "                      ...,\n",
       "                      [-0.1034, -0.1813, -0.1712,  ..., -0.4172, -0.1217,  0.4773],\n",
       "                      [-0.1890,  0.0299, -0.7622,  ...,  0.0599,  0.1960, -0.1470],\n",
       "                      [-0.1709, -0.6425, -0.1120,  ..., -0.2481, -0.2469,  0.0117]])),\n",
       "             ('bilstm_oov_context_feature.weight_hh_l0_reverse',\n",
       "              tensor([[ 0.0921,  0.2084, -0.0876,  ...,  0.3245, -0.4809,  0.1909],\n",
       "                      [ 0.0564, -0.0837,  0.0402,  ...,  0.2053, -0.4668, -0.2355],\n",
       "                      [ 0.0483,  0.1141, -0.4290,  ...,  0.0037,  0.1216, -0.1068],\n",
       "                      ...,\n",
       "                      [ 0.1934,  0.1599, -0.0324,  ...,  0.0606, -0.2695, -0.1447],\n",
       "                      [-0.0830, -0.2689,  0.1099,  ...,  0.0886, -0.0188,  0.0017],\n",
       "                      [-0.4377,  0.2324,  0.0072,  ...,  0.1912, -0.0840, -0.0093]])),\n",
       "             ('bilstm_oov_context_feature.bias_ih_l0_reverse',\n",
       "              tensor([ 2.1069e-03, -1.1824e-02,  2.0589e-01, -4.7624e-02,  1.0296e-01,\n",
       "                       6.0557e-03,  2.1015e-01,  7.9800e-02,  1.7236e-01,  1.5684e-01,\n",
       "                       1.0528e-01,  5.6975e-02, -2.2777e-02,  1.9854e-01,  8.8601e-02,\n",
       "                      -4.4555e-02, -3.3658e-03,  1.9458e-01,  2.4178e-01,  7.0363e-04,\n",
       "                       2.9868e-01, -2.7431e-02,  1.9839e-01,  1.4273e-01,  5.8408e-02,\n",
       "                       4.1761e-03, -3.1132e-02,  2.9279e-01,  1.6285e-01, -1.9082e-02,\n",
       "                      -1.2608e-01,  2.5614e-01,  2.3595e-01,  2.2454e-01,  1.5299e-01,\n",
       "                       2.3019e-01,  2.4749e-01,  1.5230e-01,  1.1668e-01,  2.8560e-02,\n",
       "                       1.9414e-01,  3.8473e-02,  1.2258e-01,  1.8642e-02,  1.5597e-01,\n",
       "                       9.1648e-02,  3.4003e-01, -1.7516e-02,  1.4055e-02,  3.0018e-01,\n",
       "                       1.4084e-01,  3.0028e-01,  8.6725e-02,  9.1305e-02,  1.1894e-01,\n",
       "                      -1.1418e-02,  9.4491e-02, -7.0959e-04,  1.1392e-01,  9.5792e-02,\n",
       "                       2.2415e-01,  9.0060e-02,  3.9689e-02,  1.2116e-01,  1.2563e-01,\n",
       "                      -2.1222e-02,  4.9846e-02,  1.1296e-01,  2.5096e-01,  1.5780e-01,\n",
       "                       1.8486e-02,  7.8929e-02,  2.2082e-01,  2.4888e-01,  2.4910e-01,\n",
       "                       5.1601e-02,  1.7012e-01,  2.1866e-01,  5.6713e-02,  2.0687e-01,\n",
       "                       2.1287e-01, -1.1148e-02,  2.7406e-01,  4.0060e-03,  1.6913e-01,\n",
       "                       8.6260e-02,  1.6674e-01, -1.0677e-03,  1.3187e-01, -8.2001e-02,\n",
       "                       4.3864e-02,  4.3147e-01,  1.3142e-01,  2.1495e-01,  2.6759e-01,\n",
       "                      -5.8347e-02, -2.1769e-02,  2.0603e-01,  9.5911e-02,  9.7022e-02,\n",
       "                       1.5007e-01, -3.5898e-02, -2.2885e-02,  1.5031e-01,  1.0894e-01,\n",
       "                       1.8598e-01,  1.5978e-01,  1.9977e-01, -4.3237e-02,  2.3688e-01,\n",
       "                       1.4401e-01, -6.7881e-03,  2.6410e-02,  1.3865e-01,  1.6091e-01,\n",
       "                      -3.3711e-02,  5.5982e-02,  1.4144e-01,  1.8313e-01,  7.3772e-02,\n",
       "                       1.9180e-01,  2.3247e-01,  2.4229e-01,  1.8446e-01,  1.5182e-01,\n",
       "                      -3.1465e-02,  4.0194e-02,  4.3914e-02,  1.2122e-01,  3.1986e-02,\n",
       "                       4.0936e-02, -1.8060e-01, -3.9864e-02, -4.8456e-03,  4.3345e-02,\n",
       "                      -4.0930e-02,  5.2996e-02, -3.5745e-02,  8.0323e-02,  2.3406e-02,\n",
       "                       8.9228e-02,  7.3723e-02,  9.3264e-02, -4.5748e-02,  1.2292e-01,\n",
       "                       1.4639e-01, -1.3773e-01,  1.0830e-01,  1.3555e-01, -4.0007e-02,\n",
       "                      -2.4896e-02,  7.1505e-02,  4.0308e-02,  5.5458e-02, -8.3003e-02,\n",
       "                      -1.9501e-02,  3.3490e-02, -7.9385e-02, -2.4484e-02,  4.6936e-02,\n",
       "                       2.2243e-01,  1.5095e-01, -7.6145e-02, -7.2496e-03,  1.1252e-01,\n",
       "                      -1.0558e-02,  3.8129e-02,  1.4220e-01,  3.6061e-02,  7.4038e-02,\n",
       "                       8.2193e-02,  2.3250e-02, -4.7780e-02,  1.1351e-01,  1.1216e-01,\n",
       "                       1.5484e-02,  6.9591e-02,  1.0598e-01,  2.0267e-01,  6.8901e-05,\n",
       "                      -1.4414e-02, -1.8793e-02,  4.4938e-02,  1.2622e-01,  3.6780e-02,\n",
       "                       1.3998e-01, -6.5350e-03, -3.8847e-03,  1.9295e-01,  2.0866e-02,\n",
       "                       5.7529e-02,  6.0372e-02,  5.3406e-02, -5.4060e-02,  1.0671e-01,\n",
       "                      -5.2258e-02,  3.0457e-02,  5.2896e-02,  1.4424e-01, -5.2992e-02,\n",
       "                      -8.1458e-02,  7.7639e-03,  1.4913e-01, -4.7936e-02,  1.0626e-01,\n",
       "                      -4.3405e-02,  1.1380e-01, -9.1721e-03, -1.1305e-01, -1.0408e-02,\n",
       "                       1.4025e-02,  1.9136e-01, -9.5522e-02, -6.4334e-03,  2.2984e-02,\n",
       "                       6.2374e-02, -9.6951e-03,  1.8458e-02,  1.9418e-01, -6.9315e-02,\n",
       "                      -4.5099e-02,  4.3143e-02,  1.4114e-01,  2.5869e-02, -5.1508e-03,\n",
       "                      -2.6883e-02, -1.5362e-01,  1.6935e-01, -5.3705e-02,  1.4634e-01,\n",
       "                       1.2720e-01,  1.2230e-01,  9.2540e-02,  3.6443e-03,  1.4930e-01,\n",
       "                      -8.0762e-02,  9.9097e-02,  4.7143e-02,  5.9989e-02, -7.5535e-03,\n",
       "                       2.6929e-02,  1.0714e-03,  1.9447e-02, -4.3011e-02,  5.1790e-02,\n",
       "                      -1.2185e-01,  3.0528e-02, -2.1905e-03,  1.2794e-01, -7.4811e-03,\n",
       "                       3.8583e-02,  2.3932e-02, -9.9501e-02,  2.0234e-01,  6.4312e-02,\n",
       "                      -3.5444e-02, -3.7581e-02, -8.0804e-02, -2.2347e-01, -7.9199e-02,\n",
       "                       1.7739e-02, -1.3786e-02, -1.8840e-02,  1.2611e-01, -4.3101e-02,\n",
       "                       1.1743e-01,  7.2461e-02,  4.0275e-02, -5.3766e-02,  1.0832e-01,\n",
       "                       1.0520e-02,  1.1685e-01, -2.1716e-03, -2.5548e-02,  9.1176e-02,\n",
       "                      -4.7961e-02, -6.0407e-03, -2.6846e-02, -8.1095e-02, -9.4382e-02,\n",
       "                       3.4220e-02,  2.3660e-02, -1.1403e-01,  2.2490e-02,  1.2264e-03,\n",
       "                       7.4589e-02,  3.4883e-02, -2.9091e-02, -1.6429e-02,  7.3400e-02,\n",
       "                       2.4725e-02, -1.4843e-01, -3.0030e-02, -5.0312e-02, -1.0555e-01,\n",
       "                      -1.3076e-01,  7.3952e-02, -6.4077e-02,  2.3544e-02, -1.6582e-02,\n",
       "                      -3.0229e-03,  7.1793e-05,  1.0751e-01,  4.2567e-02, -1.5239e-01,\n",
       "                      -5.8044e-02, -1.6061e-02, -1.2526e-02,  4.9573e-02, -1.0598e-02,\n",
       "                      -3.7256e-02,  2.9307e-02, -5.4539e-02, -1.4243e-01, -3.8839e-02,\n",
       "                       3.8284e-02,  2.5983e-02, -3.6884e-02, -1.2763e-02, -7.4160e-02,\n",
       "                      -4.9431e-02, -3.1096e-02, -7.4945e-02, -8.7021e-03,  3.4732e-02,\n",
       "                       1.7751e-01, -2.2711e-02,  2.9108e-02,  8.8006e-02,  1.1234e-01,\n",
       "                      -1.0537e-01,  4.3079e-02,  6.4339e-02, -1.3762e-01,  9.9999e-02,\n",
       "                      -5.7455e-02, -1.0862e-03, -2.9220e-02,  1.4555e-01,  3.2111e-02,\n",
       "                       9.8722e-02, -6.6069e-03, -7.7654e-02,  4.8931e-02,  1.9580e-02,\n",
       "                      -1.0054e-01, -3.2212e-02,  2.4101e-02, -7.0340e-02, -5.3649e-03,\n",
       "                      -2.6488e-02, -5.0820e-02,  6.9034e-02,  1.1964e-01, -7.8711e-02,\n",
       "                      -1.2500e-01, -1.0135e-01,  3.1570e-02, -1.0789e-01, -5.0549e-02,\n",
       "                       7.0137e-02,  3.8112e-02,  2.6072e-02,  1.1121e-01,  6.3937e-02,\n",
       "                      -1.0296e-01,  1.6798e-01,  1.1494e-01,  2.3973e-02, -1.7374e-02,\n",
       "                      -2.1206e-02, -2.6628e-02, -1.1687e-02,  1.1857e-01, -2.4516e-02,\n",
       "                      -1.6700e-01, -8.3833e-02,  6.0699e-02, -4.3590e-02,  4.2998e-02,\n",
       "                       1.1159e-02, -8.3639e-03,  5.8893e-02, -1.1216e-01,  4.9054e-02,\n",
       "                       2.7683e-01,  2.7334e-01,  1.2708e-01,  7.8921e-02, -6.6036e-02,\n",
       "                       2.1080e-01,  7.3530e-02,  8.1783e-02,  1.4130e-01,  2.5130e-01,\n",
       "                       6.0118e-02,  1.2104e-01,  1.7957e-01, -8.5563e-02,  9.8086e-02,\n",
       "                       1.7463e-01,  2.4357e-01,  7.4974e-02,  2.0138e-01,  3.8526e-02,\n",
       "                      -3.4928e-03,  3.4236e-01,  2.9484e-02,  9.2591e-02,  2.0314e-01,\n",
       "                      -4.1345e-02,  2.7615e-01,  1.1686e-01,  5.0003e-02,  1.5328e-01,\n",
       "                       2.5098e-01,  1.9959e-01,  1.8753e-01,  1.8123e-01,  8.4808e-02,\n",
       "                       1.1364e-01,  1.2654e-01,  2.8356e-01,  1.7369e-01,  3.7220e-02,\n",
       "                       1.1352e-01, -1.1841e-02,  4.1516e-02,  1.1759e-01,  1.0746e-01,\n",
       "                       1.4806e-01,  1.5558e-01, -4.1075e-02,  5.2948e-02,  1.6051e-01,\n",
       "                       2.4398e-01,  2.1697e-01, -3.6594e-02,  2.3293e-01, -7.3349e-02,\n",
       "                       8.5037e-02,  2.3748e-01,  7.8376e-02,  1.5535e-01, -2.7630e-02,\n",
       "                       1.3026e-01,  6.1235e-02,  2.8486e-01,  7.5692e-02,  1.9545e-01,\n",
       "                       7.5838e-02,  2.9318e-01,  2.1939e-01, -4.7669e-03,  2.1271e-01,\n",
       "                      -1.8423e-01,  2.0114e-01,  1.7925e-01,  3.1961e-01, -3.7636e-02,\n",
       "                       1.0647e-01,  2.5658e-01,  1.5719e-02,  1.2331e-01,  2.9144e-01,\n",
       "                       3.5461e-02,  3.2412e-01,  3.3617e-01,  1.0496e-01, -2.6822e-02,\n",
       "                       2.9685e-02, -1.1173e-01,  2.6669e-02,  1.1864e-01,  4.7525e-02,\n",
       "                       3.4510e-01,  9.0659e-02,  1.8484e-01,  2.4773e-01,  1.8470e-01,\n",
       "                       7.8920e-02,  3.0444e-01,  1.2712e-01,  4.1830e-01,  2.0974e-01,\n",
       "                       9.3477e-02,  1.6332e-01,  1.1886e-01,  1.3798e-01,  1.8737e-01,\n",
       "                       3.3935e-02,  2.1572e-01,  9.5023e-02,  1.2116e-01,  1.7145e-01,\n",
       "                       1.7729e-01,  9.4728e-02,  1.0958e-01,  5.3029e-02,  8.4429e-02,\n",
       "                       1.7444e-01,  1.6397e-01,  3.5034e-02,  3.7131e-01,  2.2108e-02,\n",
       "                       1.0221e-01,  1.6010e-01,  1.2275e-01,  6.7782e-02,  2.4269e-01,\n",
       "                       9.7120e-02,  6.3776e-02])),\n",
       "             ('bilstm_oov_context_feature.bias_hh_l0_reverse',\n",
       "              tensor([-3.4601e-02,  2.0514e-01,  1.9799e-01, -1.3688e-01,  1.1855e-01,\n",
       "                      -1.2482e-03,  1.8404e-01,  9.6421e-02,  4.3856e-02,  1.1503e-01,\n",
       "                       9.6011e-02,  5.7509e-02, -3.2872e-02,  1.8026e-01,  1.3731e-01,\n",
       "                      -6.4452e-02,  2.0949e-02,  1.9777e-01,  1.3352e-01,  8.4845e-02,\n",
       "                       3.5741e-01,  3.0030e-02,  1.2244e-01,  1.9230e-01,  1.1739e-01,\n",
       "                       1.1400e-01, -1.4239e-02,  1.6800e-01,  8.8675e-02,  1.3638e-01,\n",
       "                       8.4520e-02,  2.7623e-01,  1.4696e-01,  1.5025e-01,  1.1709e-01,\n",
       "                       2.0330e-01,  1.8638e-01,  3.4803e-02,  7.6869e-02, -2.8369e-02,\n",
       "                       3.3900e-01,  1.2992e-02,  1.7043e-01,  2.7448e-02, -8.1418e-02,\n",
       "                      -4.0005e-03,  2.9700e-01,  7.8974e-02,  1.7305e-01,  2.0861e-01,\n",
       "                       4.7251e-02,  2.4119e-01,  2.0511e-01,  1.2619e-01,  8.7349e-02,\n",
       "                      -6.4175e-02,  9.5946e-02,  7.2537e-02,  9.8814e-02,  8.5308e-02,\n",
       "                       1.6117e-01,  1.4943e-01,  1.5407e-02,  2.1085e-01,  2.3498e-01,\n",
       "                      -4.3319e-02,  9.4244e-02,  1.5015e-01,  1.2922e-01,  1.1127e-01,\n",
       "                       1.2253e-01,  1.5437e-01,  2.4812e-01,  2.2236e-01,  1.7475e-01,\n",
       "                       4.8889e-02,  6.9420e-02,  3.0461e-01,  2.0911e-01,  1.5070e-01,\n",
       "                       1.6064e-01,  2.7601e-02,  2.1497e-01, -7.4489e-02,  1.8102e-01,\n",
       "                       2.3110e-01,  1.8248e-01, -3.1799e-02,  9.1834e-02,  1.3076e-02,\n",
       "                       1.7006e-01,  2.5070e-01,  4.3051e-02,  1.8271e-01,  3.3474e-01,\n",
       "                       1.5763e-01,  1.0331e-01,  2.0888e-01,  1.6023e-01,  2.7416e-01,\n",
       "                       2.7910e-01,  2.6296e-02,  1.1197e-01,  1.3547e-01,  2.0530e-01,\n",
       "                       2.0784e-01,  5.3269e-02,  1.7188e-01,  9.1896e-02,  3.0453e-02,\n",
       "                       1.7560e-01, -5.9296e-02,  5.6087e-02,  1.6273e-01,  1.2339e-01,\n",
       "                       1.0491e-02,  3.7977e-04,  8.3066e-02,  7.6698e-02,  1.3747e-01,\n",
       "                       2.6000e-02,  2.1557e-01,  1.9512e-01,  3.9405e-02,  1.3013e-01,\n",
       "                       1.2219e-01,  5.7851e-02, -1.0373e-01,  1.4798e-01, -6.0297e-04,\n",
       "                       9.5519e-03,  3.8183e-02,  7.2400e-02,  7.3283e-02,  1.4928e-01,\n",
       "                       4.2299e-02, -2.9010e-02, -3.7176e-03, -1.6839e-02,  5.5629e-02,\n",
       "                       9.7996e-03,  6.3018e-02, -2.7195e-02, -4.2296e-02,  1.4322e-02,\n",
       "                       2.3011e-02, -1.0274e-02,  1.3668e-01,  1.9644e-01,  1.0854e-01,\n",
       "                      -9.2909e-02,  1.2843e-01,  1.5937e-02,  7.8713e-02,  2.3554e-02,\n",
       "                       6.8139e-02,  7.7061e-02, -1.6744e-02, -3.2324e-02,  8.9974e-02,\n",
       "                       1.3061e-01,  2.5101e-03, -9.0887e-03, -1.0860e-01,  5.8046e-02,\n",
       "                       1.2792e-01,  1.1779e-01,  4.7496e-03,  8.2127e-02,  2.3613e-02,\n",
       "                       1.3956e-02,  8.6884e-03,  3.4385e-02,  2.8722e-02,  4.9214e-02,\n",
       "                      -6.2449e-02,  5.7144e-02, -1.8606e-02,  2.2980e-01, -1.3813e-01,\n",
       "                       4.8163e-02, -5.2445e-02,  7.7829e-03,  1.4196e-01,  6.4909e-02,\n",
       "                      -1.0551e-02,  8.0636e-02,  1.3858e-03,  1.3943e-01,  8.9607e-02,\n",
       "                       7.4085e-02, -5.0602e-02,  3.4315e-04, -1.5964e-02,  2.7223e-02,\n",
       "                       6.0019e-03, -8.0874e-03, -5.2272e-03,  4.5393e-02, -1.4793e-02,\n",
       "                      -1.5207e-01,  6.5872e-02,  8.0669e-02, -4.0193e-02, -1.8549e-02,\n",
       "                       7.2284e-02,  3.9869e-02,  1.6854e-02,  2.2025e-02, -4.6335e-03,\n",
       "                       1.4410e-02,  9.5832e-02, -5.1748e-02,  1.0325e-01, -3.0907e-03,\n",
       "                       1.8860e-01, -4.3924e-02,  5.3452e-02,  6.6350e-02,  4.0304e-02,\n",
       "                       4.7242e-02,  2.4161e-02,  8.0516e-02,  8.2939e-02,  1.2569e-01,\n",
       "                       5.6093e-02, -8.0319e-02,  5.6506e-02, -8.4397e-02,  6.2170e-02,\n",
       "                       5.1993e-02,  1.2334e-01, -1.9983e-02, -6.2673e-02,  9.3259e-02,\n",
       "                      -4.6659e-02, -1.3782e-01,  1.2047e-02,  9.1251e-02, -1.1039e-01,\n",
       "                      -7.4833e-03,  6.3634e-02, -3.8512e-02, -9.2124e-02, -4.8893e-02,\n",
       "                      -8.8611e-02,  1.1217e-01, -8.1027e-02,  1.9790e-01,  7.9457e-02,\n",
       "                       6.9589e-02, -9.4914e-02, -4.9973e-02,  8.4818e-02,  1.2983e-01,\n",
       "                       2.0049e-02, -8.3422e-02, -6.2972e-02,  3.5063e-02, -1.1892e-02,\n",
       "                      -9.3721e-03,  2.7717e-03, -7.5079e-03,  6.1010e-02, -6.2458e-02,\n",
       "                       1.3256e-01,  8.4671e-02,  4.5811e-02, -1.0603e-01, -8.2959e-02,\n",
       "                       1.6773e-02,  1.0747e-01, -7.6860e-02,  2.6660e-02, -2.5078e-03,\n",
       "                      -7.4487e-02, -1.1052e-01, -2.2324e-02, -3.1788e-02,  4.2965e-02,\n",
       "                       8.2568e-03, -1.0544e-01,  1.8251e-02,  9.0528e-02, -8.9063e-02,\n",
       "                      -2.1033e-02,  7.5983e-02,  8.6380e-03, -5.8086e-02,  7.5492e-03,\n",
       "                       1.0969e-02, -1.5654e-01, -6.4847e-02,  6.4783e-03,  1.1942e-02,\n",
       "                      -9.5456e-02,  7.2390e-02,  4.8427e-02, -3.2691e-03, -5.6224e-04,\n",
       "                       2.2424e-02, -6.3939e-02,  1.2773e-01, -9.7625e-02,  9.3976e-02,\n",
       "                      -6.5790e-02, -9.5092e-02,  4.5367e-02,  1.8725e-02, -8.0832e-02,\n",
       "                       3.3925e-02, -1.3058e-02,  1.2436e-02, -1.3213e-01, -1.1415e-01,\n",
       "                      -2.2500e-02,  6.5290e-02,  8.2135e-02, -4.0486e-02,  5.0108e-03,\n",
       "                       6.0144e-02,  3.4542e-02,  2.7004e-02,  5.8868e-03,  6.3677e-02,\n",
       "                       1.3079e-01, -8.6969e-02, -1.3617e-02,  6.1437e-02,  5.0107e-02,\n",
       "                      -7.4246e-02,  5.0639e-02, -2.0095e-02, -3.0358e-02, -8.3710e-02,\n",
       "                       4.5283e-02, -1.3420e-01,  5.9165e-02,  3.2354e-02, -5.2975e-04,\n",
       "                      -6.1992e-02,  3.0994e-02, -7.0614e-02,  1.3981e-02,  6.2565e-02,\n",
       "                       1.3626e-03, -4.8473e-02, -4.6986e-02, -3.9660e-02,  1.7953e-02,\n",
       "                      -1.6467e-01, -5.9527e-02, -1.2390e-01, -7.0856e-02, -3.1068e-03,\n",
       "                      -3.4693e-02, -3.3424e-02,  8.9949e-02, -1.4085e-02,  8.6535e-02,\n",
       "                       5.9526e-02,  3.4505e-02, -1.0468e-01,  7.4621e-02, -3.5865e-02,\n",
       "                       1.0043e-02,  1.8298e-02, -8.8598e-03,  6.1468e-02, -1.8966e-02,\n",
       "                       9.7427e-03, -1.4739e-02, -2.7387e-02, -3.4516e-02,  1.4180e-02,\n",
       "                      -9.4149e-02, -9.3221e-02,  1.0579e-02,  1.8107e-02, -6.0774e-02,\n",
       "                       5.8142e-02,  5.5462e-02,  4.1762e-02, -2.6000e-02,  1.0038e-01,\n",
       "                       1.0962e-01,  2.1054e-01,  1.6261e-02,  9.0737e-02, -1.3791e-02,\n",
       "                       4.0361e-02,  1.3070e-01, -3.9180e-03,  2.7404e-01,  3.0197e-01,\n",
       "                       1.6854e-01,  2.0412e-01,  2.7054e-01, -1.0686e-02, -7.7988e-02,\n",
       "                       1.4201e-01,  2.6321e-01,  1.5901e-01,  1.9247e-01,  1.4043e-01,\n",
       "                      -8.1226e-02,  4.7262e-01,  6.7352e-02,  1.3846e-01,  1.4766e-01,\n",
       "                      -7.1674e-02,  1.7574e-01,  6.1166e-02,  2.6060e-01,  2.2149e-02,\n",
       "                       2.8623e-01,  1.9366e-01,  1.2900e-01,  2.1670e-01,  1.4731e-01,\n",
       "                       2.4986e-01,  1.5780e-01,  1.6334e-01,  2.1601e-01,  1.4506e-01,\n",
       "                       8.1054e-02, -1.5886e-02,  3.6621e-03,  1.4719e-01,  1.7823e-01,\n",
       "                       1.0295e-01,  1.3650e-01,  4.4586e-02, -1.3225e-02,  6.7944e-02,\n",
       "                       1.8814e-01,  1.5027e-01,  8.2947e-02,  1.5757e-01,  5.6710e-02,\n",
       "                      -1.8600e-02,  1.6078e-01,  1.7265e-01,  1.1822e-01, -5.6681e-02,\n",
       "                       6.1428e-02,  1.1422e-01,  3.1599e-01,  1.9360e-01, -1.1406e-02,\n",
       "                       2.1020e-01,  2.2521e-01,  3.5349e-01, -7.4002e-02,  8.9056e-02,\n",
       "                      -3.9648e-02,  7.3996e-02,  1.5321e-01,  2.9416e-01, -8.5388e-04,\n",
       "                       9.9213e-02,  6.7431e-02, -3.7514e-02,  6.7440e-02,  3.0652e-01,\n",
       "                       1.2714e-01,  2.1009e-01,  1.1052e-01,  1.6478e-01,  8.6292e-02,\n",
       "                       1.2252e-01,  3.0739e-02,  1.1450e-01,  7.4699e-02, -7.2903e-02,\n",
       "                       1.6355e-01, -5.9772e-02,  1.1594e-01,  3.3106e-01,  9.9863e-02,\n",
       "                       1.5434e-01,  2.8941e-01,  6.8659e-02,  2.9604e-01,  1.6201e-01,\n",
       "                       1.0054e-01,  1.0490e-01,  7.2586e-02,  8.0369e-02,  1.9214e-01,\n",
       "                       4.0401e-02,  2.2991e-01,  5.4198e-02,  6.2645e-02,  1.6088e-01,\n",
       "                       1.2462e-01,  6.9268e-02,  7.6449e-02,  7.2132e-02,  4.8415e-02,\n",
       "                       1.8450e-01,  6.5537e-02,  1.7928e-01,  2.8798e-01, -2.3929e-02,\n",
       "                       7.6064e-02,  1.7958e-01,  8.3870e-02,  2.7365e-01,  1.5910e-01,\n",
       "                       1.1476e-01,  6.2302e-02])),\n",
       "             ('bilstm_right_context_feature.weight_ih_l0',\n",
       "              tensor([[ 0.2898, -0.2649, -0.2013,  ..., -0.3377,  0.2895, -0.0768],\n",
       "                      [ 0.2250, -0.1690,  0.1950,  ...,  0.0416,  0.1348, -0.2946],\n",
       "                      [ 0.3079, -0.1817,  0.0133,  ...,  0.0101,  0.4149, -0.4472],\n",
       "                      ...,\n",
       "                      [ 0.1844,  0.2320,  0.0068,  ...,  0.2566,  0.0256, -0.2390],\n",
       "                      [ 0.0895, -0.1964, -0.0121,  ..., -0.0958,  0.1624, -0.3019],\n",
       "                      [-0.0231, -0.2958,  0.2418,  ..., -0.3691,  0.2847,  0.0524]])),\n",
       "             ('bilstm_right_context_feature.weight_hh_l0',\n",
       "              tensor([[-0.2772, -0.0268, -0.2189,  ..., -0.1177,  0.1816,  0.0994],\n",
       "                      [ 0.1857, -0.0518, -0.1244,  ..., -0.1094,  0.0568,  0.1670],\n",
       "                      [ 0.1352,  0.1538, -0.0790,  ...,  0.0268,  0.1358,  0.1627],\n",
       "                      ...,\n",
       "                      [-0.0066,  0.1703, -0.1722,  ...,  0.5038, -0.0547, -0.0927],\n",
       "                      [-0.0582,  0.0803,  0.1405,  ...,  0.1994,  0.0703,  0.0055],\n",
       "                      [ 0.0110,  0.0232,  0.2492,  ..., -0.0560, -0.0141,  0.1665]])),\n",
       "             ('bilstm_right_context_feature.bias_ih_l0',\n",
       "              tensor([-3.1635e-01, -1.1748e-01, -2.2964e-01, -9.5147e-02, -1.6791e-01,\n",
       "                      -2.1338e-01, -4.2160e-02, -1.7130e-01, -7.6802e-02, -1.2474e-01,\n",
       "                      -1.0408e-01,  7.4146e-02, -2.2790e-01, -5.9004e-02, -5.1402e-02,\n",
       "                      -2.8214e-01, -2.4362e-01, -1.5130e-01, -2.2080e-01, -5.7407e-02,\n",
       "                       1.1777e-02, -4.7422e-03, -1.6107e-01, -1.6608e-01, -1.2544e-01,\n",
       "                      -1.3079e-01, -9.8052e-02, -1.4153e-02, -7.7714e-02, -2.2476e-01,\n",
       "                      -1.7198e-01, -1.6500e-01, -1.9367e-01, -3.3824e-02, -2.4507e-01,\n",
       "                      -1.3126e-01, -1.1431e-01, -1.4157e-01, -9.1216e-02, -1.7466e-01,\n",
       "                      -1.2185e-01, -1.4087e-01, -1.2654e-01, -9.3167e-02, -6.7785e-02,\n",
       "                      -7.5549e-02, -1.8554e-01, -8.9731e-02, -1.7564e-01, -1.6540e-01,\n",
       "                      -1.5354e-01, -2.0374e-01, -8.2407e-02, -8.6060e-02, -2.6010e-01,\n",
       "                      -2.1974e-01, -2.7575e-01, -1.5422e-01, -1.4434e-02, -1.6769e-01,\n",
       "                      -1.2227e-01, -1.2800e-01, -5.1336e-02,  1.6010e-02, -1.4578e-01,\n",
       "                      -1.4741e-01, -1.8349e-01, -1.8606e-01, -1.5429e-01, -1.6356e-01,\n",
       "                      -3.1978e-02, -1.5693e-02, -1.3892e-01, -2.5208e-01, -1.9836e-01,\n",
       "                      -7.5228e-02, -1.7106e-01, -1.5566e-01, -1.5700e-01, -1.9169e-01,\n",
       "                      -1.1231e-01, -1.3796e-01, -1.3697e-01,  3.1177e-02, -1.5735e-01,\n",
       "                      -9.1046e-02, -1.4338e-01, -2.0957e-01, -8.0872e-02, -2.7454e-01,\n",
       "                      -7.8184e-02, -1.9196e-02, -1.9329e-01, -1.4480e-01, -1.3803e-02,\n",
       "                      -1.9553e-01, -1.4899e-01, -1.9025e-01, -1.0517e-01, -1.1395e-01,\n",
       "                      -7.4309e-02, -1.1304e-01, -9.2785e-02, -1.7239e-01, -1.4982e-01,\n",
       "                      -1.1709e-01, -1.0364e-01, -4.6209e-02, -2.2550e-01, -2.6698e-01,\n",
       "                      -1.6359e-01, -3.4629e-02, -9.9577e-02, -1.3794e-01, -3.1024e-02,\n",
       "                      -1.3447e-01, -1.5895e-01, -1.4434e-01, -2.4128e-01, -7.7342e-02,\n",
       "                      -1.7812e-02, -1.4931e-01, -9.2795e-02, -2.3619e-01, -1.0596e-01,\n",
       "                      -8.6544e-02, -2.3104e-01, -2.2197e-01, -2.8754e-01, -1.2789e-01,\n",
       "                      -8.2630e-02, -8.7937e-02, -1.0724e-01, -1.8184e-01, -5.9736e-02,\n",
       "                      -1.3750e-01, -1.6371e-01, -1.6152e-01, -1.8810e-01, -1.2812e-01,\n",
       "                      -1.5084e-01, -2.7145e-01, -2.2347e-01, -1.6504e-01, -1.7406e-01,\n",
       "                      -2.7865e-01, -1.0862e-01, -1.9408e-02, -9.8155e-02, -9.6754e-02,\n",
       "                      -1.0872e-01, -1.3136e-01, -1.3667e-01, -4.4372e-02, -5.8972e-02,\n",
       "                      -4.0056e-02, -6.4183e-02, -1.4602e-01, -1.2648e-01, -1.6767e-01,\n",
       "                      -1.3975e-01, -3.1391e-02, -2.0800e-01,  2.4892e-02, -2.0997e-01,\n",
       "                      -1.2505e-01, -1.3190e-01, -1.3140e-01,  3.5560e-02, -1.8037e-02,\n",
       "                      -9.1773e-02, -8.9250e-02, -1.2999e-01, -2.7459e-02, -7.7617e-02,\n",
       "                      -9.7169e-02, -9.5937e-02, -3.6712e-02, -1.1383e-01, -4.0198e-02,\n",
       "                      -2.0588e-02, -1.6932e-01, -1.5983e-01, -2.7394e-01, -1.3188e-01,\n",
       "                      -1.3489e-01, -1.8164e-01, -1.0290e-01, -2.0517e-01, -1.0163e-01,\n",
       "                      -2.0599e-01, -1.5592e-01, -1.4616e-01, -9.4160e-02, -1.5682e-01,\n",
       "                      -1.3359e-01, -1.1180e-01, -9.4493e-02, -8.0293e-02, -1.2937e-01,\n",
       "                       7.2465e-02, -2.0987e-01, -8.2427e-02, -9.7875e-02,  2.4643e-02,\n",
       "                      -1.6540e-01,  2.0891e-02, -4.1679e-02, -1.3161e-01, -1.0175e-02,\n",
       "                      -1.4287e-01, -9.3256e-02, -1.2358e-01, -1.1918e-01, -1.8208e-01,\n",
       "                      -1.2182e-01, -1.8144e-01, -5.4685e-02, -1.8506e-01, -8.3500e-02,\n",
       "                      -9.2501e-02, -7.6498e-02, -2.3265e-01, -9.3857e-02, -9.8019e-02,\n",
       "                      -6.7088e-02, -1.0326e-02, -1.2235e-01, -6.0731e-02, -1.1291e-01,\n",
       "                      -6.5855e-02,  3.1184e-02, -5.2614e-02, -1.7630e-01, -1.1113e-01,\n",
       "                      -6.7136e-02, -1.0248e-01,  2.5702e-03, -1.0082e-01, -2.3598e-01,\n",
       "                      -1.1439e-01, -1.2248e-01, -1.4881e-01, -1.5474e-02, -1.2331e-01,\n",
       "                      -1.0535e-01, -1.4813e-02, -8.5742e-02,  1.1244e-03, -1.8772e-01,\n",
       "                      -1.2593e-01, -1.6211e-01, -2.3809e-01, -1.5382e-01, -1.3539e-01,\n",
       "                      -9.6377e-02,  2.4815e-02,  1.1233e-01, -1.0709e-01, -2.8633e-02,\n",
       "                       7.6572e-02,  3.2499e-02, -4.6374e-02,  2.0271e-02,  1.2746e-01,\n",
       "                      -4.8562e-02, -4.1184e-02, -2.5504e-02, -2.7573e-03,  2.8096e-02,\n",
       "                       4.6680e-02,  8.5155e-02, -6.7331e-03, -7.1293e-03,  6.1343e-02,\n",
       "                      -2.3978e-02, -4.9447e-02, -5.7961e-02, -3.5076e-02, -8.5256e-03,\n",
       "                       6.0720e-02, -3.0906e-02, -8.1055e-02, -3.1919e-02,  6.0498e-02,\n",
       "                      -9.5603e-02, -2.6726e-02, -1.1481e-01, -1.4482e-01, -7.9649e-02,\n",
       "                      -2.9905e-02,  1.0794e-02, -2.6052e-02,  2.1266e-02,  6.8093e-02,\n",
       "                      -2.0751e-02, -1.0889e-02, -6.0231e-02,  8.6387e-02,  4.3069e-02,\n",
       "                       7.7142e-02,  3.3659e-02,  1.3411e-01, -5.1065e-02,  2.0159e-03,\n",
       "                      -1.0980e-01, -9.4249e-02, -2.1340e-02,  2.2993e-02,  1.5119e-02,\n",
       "                      -3.7375e-02,  8.6341e-04, -7.5883e-02, -5.7588e-02,  9.6430e-02,\n",
       "                      -2.9901e-02,  6.5342e-02,  1.7069e-02, -7.1316e-02, -8.1185e-02,\n",
       "                      -6.2728e-03,  7.4863e-02,  2.6171e-02, -2.0024e-02, -7.1591e-03,\n",
       "                      -2.7112e-02,  7.1737e-02,  4.5635e-02,  5.6910e-04, -1.1385e-01,\n",
       "                       2.0456e-02,  1.9629e-02, -9.6413e-03, -8.6391e-02,  1.0243e-02,\n",
       "                      -3.1907e-02, -1.2675e-02, -2.0173e-03,  4.2820e-02, -1.1311e-02,\n",
       "                       1.5564e-02, -2.5022e-02, -7.2193e-02, -1.4773e-01,  1.6611e-02,\n",
       "                       3.5226e-02,  7.1007e-03, -5.7283e-03,  1.0363e-01,  4.6570e-02,\n",
       "                       6.0311e-03,  5.7948e-02, -5.4698e-02, -5.3402e-02,  5.8968e-02,\n",
       "                      -2.6775e-02, -4.7376e-02,  3.2499e-02, -2.8758e-02,  4.4043e-02,\n",
       "                       8.9306e-02,  2.3653e-04,  4.7594e-03,  9.3543e-02,  1.8868e-02,\n",
       "                       3.0812e-02,  7.8039e-02, -1.3996e-02, -1.2590e-02, -3.6505e-02,\n",
       "                      -9.1825e-02, -3.2544e-02, -3.6835e-02, -3.2825e-02, -1.3854e-01,\n",
       "                      -4.1165e-02,  8.5344e-02,  3.2328e-03,  7.2780e-02,  8.6906e-02,\n",
       "                       4.2483e-02, -8.1405e-02,  3.2309e-02, -1.5087e-02, -2.4577e-01,\n",
       "                      -1.5520e-02, -8.4099e-02, -1.3675e-01, -2.2258e-01, -2.7533e-01,\n",
       "                      -1.5259e-01, -1.9567e-01, -4.8216e-02, -6.6127e-02, -1.5169e-01,\n",
       "                      -1.0062e-01, -6.1314e-03, -9.8627e-02, -1.4576e-01, -1.1763e-01,\n",
       "                      -2.1671e-01, -7.8334e-02, -1.0157e-01, -1.6803e-01, -1.5376e-01,\n",
       "                      -1.8335e-01, -3.3095e-02, -1.1124e-01, -1.8692e-01, -6.4797e-02,\n",
       "                      -1.9856e-01, -4.4560e-03, -5.2050e-02, -9.2711e-02,  6.5621e-02,\n",
       "                      -1.2754e-01, -1.4160e-01, -6.7996e-02, -1.2264e-01,  1.4464e-03,\n",
       "                      -1.5788e-01, -2.7139e-02, -5.4677e-02, -2.5278e-01, -1.6328e-01,\n",
       "                      -3.4512e-01, -1.3183e-01, -4.3148e-02, -2.4343e-01, -1.4795e-01,\n",
       "                      -1.9253e-01, -1.4562e-01, -1.0493e-01, -1.4281e-01, -1.6691e-01,\n",
       "                      -1.7345e-01, -2.0187e-01, -1.4883e-01, -1.0789e-01, -1.5132e-01,\n",
       "                      -1.8433e-01, -1.2868e-01, -1.7250e-01, -1.0582e-02, -1.7759e-01,\n",
       "                      -1.1761e-01, -1.5701e-01, -2.7611e-02, -2.0458e-01, -1.4713e-01,\n",
       "                      -1.1337e-01, -9.0340e-02, -1.5210e-01, -1.3669e-01, -1.3766e-01,\n",
       "                      -2.0963e-01, -5.8785e-02, -1.2817e-01, -1.4279e-01, -2.4610e-01,\n",
       "                      -1.0963e-01, -5.8658e-02, -4.0320e-02, -2.0532e-01, -1.2870e-01,\n",
       "                      -1.3515e-01, -1.1343e-01, -8.2446e-02, -5.5304e-02, -3.0942e-02,\n",
       "                      -3.5676e-02, -2.4078e-01, -1.1255e-01, -7.5034e-02, -7.5447e-02,\n",
       "                      -1.6207e-01, -3.1669e-02, -1.2469e-01, -2.7680e-01, -1.6189e-01,\n",
       "                      -7.8824e-02, -1.3075e-01, -2.3217e-01, -1.4755e-01, -1.0683e-01,\n",
       "                      -1.4910e-01, -1.9945e-01, -9.0872e-02, -2.2255e-01, -1.5907e-01,\n",
       "                      -5.4619e-02, -5.6873e-02, -1.8804e-01, -2.2768e-01, -1.9621e-01,\n",
       "                      -5.1772e-02, -1.2846e-01, -8.1045e-02, -2.2078e-01, -8.3326e-02,\n",
       "                      -1.5299e-01, -1.3254e-01, -1.1060e-01, -1.1828e-01, -2.4733e-01,\n",
       "                      -1.7607e-01, -4.0844e-03, -1.8273e-01, -1.3884e-01, -1.2100e-01,\n",
       "                      -1.9645e-01, -1.2330e-01])),\n",
       "             ('bilstm_right_context_feature.bias_hh_l0',\n",
       "              tensor([-1.4977e-01, -2.1391e-01, -4.4072e-02, -6.9422e-02, -1.7929e-01,\n",
       "                      -2.3511e-01, -1.0993e-01, -1.3024e-01, -1.7032e-01, -1.2955e-01,\n",
       "                      -2.6248e-01, -8.4168e-02, -1.4716e-01, -7.1959e-02, -6.1531e-02,\n",
       "                      -3.8766e-02, -2.0566e-01, -3.8363e-02, -1.7925e-01, -1.0741e-01,\n",
       "                      -3.5463e-02, -2.2039e-02, -1.4163e-01, -1.2243e-01, -1.3053e-01,\n",
       "                      -1.6831e-01, -2.0952e-01, -1.0951e-01, -2.2441e-01, -1.1198e-01,\n",
       "                      -1.0784e-01, -1.8995e-01, -8.2886e-02, -1.5241e-02, -2.2896e-01,\n",
       "                      -1.0250e-01, -2.1745e-01, -7.7500e-02, -6.3995e-02, -2.0945e-01,\n",
       "                       4.4935e-03, -1.5067e-01, -1.3565e-01, -7.7428e-02, -7.5747e-02,\n",
       "                      -5.0238e-02, -2.1820e-01, -1.2333e-01, -5.4858e-02, -8.5286e-02,\n",
       "                      -6.6265e-02, -7.7407e-02, -2.3957e-01, -1.4331e-01, -2.1003e-01,\n",
       "                      -2.3872e-01, -2.1452e-01, -1.7862e-01, -1.4301e-01, -1.3539e-01,\n",
       "                      -1.1427e-01, -9.1256e-02, -1.4940e-01, -1.1934e-01, -1.4317e-01,\n",
       "                      -1.8888e-01, -6.2025e-02, -2.6081e-01, -1.2601e-01, -1.8404e-01,\n",
       "                      -1.5695e-01, -1.0792e-01, -5.6765e-02, -1.8598e-01, -2.3046e-01,\n",
       "                      -1.0974e-01, -9.1027e-02, -8.9828e-02, -1.1185e-01, -1.7196e-01,\n",
       "                      -2.0022e-01, -1.5422e-01, -7.9056e-02, -1.8223e-01, -2.2437e-02,\n",
       "                      -5.8910e-02, -1.1709e-04, -9.5827e-02,  2.4729e-03, -2.1774e-01,\n",
       "                      -3.2765e-02, -4.0563e-02, -8.3608e-02, -1.1834e-01, -1.4949e-01,\n",
       "                      -1.6526e-01, -2.6216e-02, -7.1489e-02, -2.0979e-01, -6.5792e-02,\n",
       "                      -1.4002e-01, -8.1093e-02, -1.7029e-01, -5.3656e-02, -1.4991e-01,\n",
       "                      -1.4374e-01, -1.2983e-01, -1.3951e-01, -2.4958e-01, -2.4626e-01,\n",
       "                      -1.1731e-01, -7.7698e-02, -6.0788e-02, -1.1927e-01, -1.5233e-01,\n",
       "                      -1.7938e-01,  2.3653e-02, -1.6214e-01, -1.2474e-01, -1.3309e-01,\n",
       "                       9.1671e-03, -1.6657e-01, -1.1962e-01, -2.0558e-01, -1.8817e-01,\n",
       "                      -1.8374e-01, -2.9818e-01, -1.7657e-01, -2.1415e-01, -3.1189e-02,\n",
       "                      -7.3909e-02, -3.8739e-02, -5.1372e-02, -8.5674e-02, -1.5163e-01,\n",
       "                      -1.6182e-01, -1.1569e-01, -2.3546e-01, -1.8350e-01, -4.2664e-02,\n",
       "                      -1.9847e-01, -1.7298e-01, -1.5494e-01, -1.9183e-01, -2.2974e-01,\n",
       "                      -2.4674e-02, -2.9631e-01, -1.1822e-01, -7.2522e-02, -1.2045e-01,\n",
       "                      -1.4393e-01, -2.1038e-01, -6.3100e-02, -1.5125e-01, -6.3269e-02,\n",
       "                      -1.1913e-03, -3.9920e-02, -1.0354e-01, -1.7474e-01, -2.3085e-01,\n",
       "                      -7.4931e-02, -3.8417e-02, -3.2822e-02, -8.6360e-02,  3.0330e-02,\n",
       "                      -2.2256e-01, -6.4634e-02, -1.2639e-01, -1.0827e-01, -1.8034e-01,\n",
       "                      -6.9531e-02, -1.0161e-01, -1.0324e-01, -7.3480e-02, -1.5994e-01,\n",
       "                      -9.7389e-02, -1.7929e-01, -8.6719e-02, -1.1490e-01, -9.0358e-02,\n",
       "                      -9.3648e-02, -1.9623e-01, -9.4979e-02, -1.8826e-01, -1.6793e-01,\n",
       "                      -8.3556e-02, -2.2164e-01, -5.1747e-02, -1.6664e-01, -9.1775e-03,\n",
       "                      -1.5344e-01, -2.1151e-02, -1.0552e-01, -1.9481e-01, -1.2750e-01,\n",
       "                      -1.0515e-01,  8.7160e-05, -1.8152e-01, -2.8508e-02, -1.1214e-01,\n",
       "                      -1.9115e-01, -1.3876e-01, -2.6423e-01, -7.2985e-02, -6.8982e-02,\n",
       "                      -1.5944e-01, -1.3207e-02, -2.0168e-02, -1.3465e-02, -1.8938e-01,\n",
       "                      -1.0063e-01, -9.0227e-02, -1.0273e-01, -1.1439e-01, -1.3041e-01,\n",
       "                      -7.2166e-02, -1.4487e-01, -8.1918e-02, -7.3108e-02,  1.5727e-02,\n",
       "                      -1.1289e-01, -3.4824e-02, -1.2957e-01, -7.3781e-02, -8.0950e-02,\n",
       "                      -1.3478e-01, -2.0025e-01, -1.7239e-01, -2.6040e-02, -1.7376e-01,\n",
       "                      -2.0045e-01, -1.2313e-02, -4.7055e-02, -2.1403e-02, -5.5369e-02,\n",
       "                      -1.7208e-01, -1.6501e-01, -1.5490e-01, -1.3079e-01, -5.4045e-02,\n",
       "                      -4.4677e-02, -1.6711e-01, -1.0477e-01, -8.2577e-02, -7.7888e-02,\n",
       "                      -4.4303e-02, -1.8565e-01, -7.1912e-02, -1.2798e-01, -9.5174e-02,\n",
       "                      -1.1900e-01, -1.5591e-01, -2.3873e-01, -1.1450e-01, -1.9490e-01,\n",
       "                      -9.9673e-02,  9.4610e-02,  2.3904e-03,  1.1856e-02, -3.1248e-02,\n",
       "                       2.2525e-02, -7.2629e-03,  2.2086e-02,  2.7948e-02, -1.0105e-01,\n",
       "                      -5.5729e-02,  8.0240e-03, -1.7570e-02, -4.4736e-02, -6.6595e-02,\n",
       "                       3.0944e-02, -1.3861e-03,  5.1454e-02,  5.3785e-02,  5.2277e-03,\n",
       "                       8.3463e-03,  3.9560e-02,  9.7376e-02,  1.6552e-02, -3.1396e-02,\n",
       "                       9.7899e-02, -1.0818e-02,  4.5934e-02, -1.1193e-01,  1.1444e-01,\n",
       "                       1.3756e-02,  5.1023e-02,  1.8008e-02,  4.0426e-02, -1.1417e-01,\n",
       "                       3.3366e-02, -7.5320e-03,  1.0554e-01, -7.9525e-04,  5.6291e-02,\n",
       "                      -5.2138e-02, -3.4307e-02, -1.9979e-02,  3.7392e-02,  2.0343e-02,\n",
       "                      -9.3182e-02,  6.8131e-02,  1.7085e-03,  3.5107e-02,  1.0163e-02,\n",
       "                       9.2266e-03, -8.7064e-02,  1.0097e-02, -7.0654e-02, -3.3500e-02,\n",
       "                       3.8167e-02, -1.5961e-02, -7.4648e-02, -2.0995e-02, -8.0227e-02,\n",
       "                       1.0003e-02, -4.3446e-02,  4.7549e-02,  6.2728e-02,  7.7195e-02,\n",
       "                       3.8962e-02,  7.1537e-02, -1.4702e-01,  1.7748e-02, -3.5409e-02,\n",
       "                       2.0860e-02, -9.0057e-02, -7.4928e-02, -4.4391e-02, -7.7243e-03,\n",
       "                       5.1405e-02, -7.9199e-02,  1.5947e-01,  1.5359e-02, -2.5440e-02,\n",
       "                      -7.1355e-02, -3.7676e-02, -1.1398e-01, -6.5109e-02, -1.4037e-01,\n",
       "                       1.5816e-02, -8.0891e-03,  2.3017e-02,  6.0733e-04,  4.2477e-03,\n",
       "                       5.3878e-02, -4.7752e-02,  6.2714e-03,  4.3852e-04, -2.0998e-02,\n",
       "                      -1.9229e-02, -8.8647e-02, -1.0764e-01,  7.7016e-02, -1.4638e-01,\n",
       "                      -5.8464e-02, -3.0728e-02,  4.6475e-02,  5.3634e-02, -3.1323e-02,\n",
       "                       3.6202e-02, -1.4569e-02,  1.0655e-01, -9.4672e-02,  2.8520e-02,\n",
       "                       2.9539e-02, -2.3390e-02, -2.1775e-01, -8.5226e-02,  1.0944e-01,\n",
       "                       1.3298e-01,  9.7512e-02, -3.5900e-02, -5.3136e-02,  8.4918e-02,\n",
       "                       7.4114e-02, -5.2031e-03,  5.9328e-02,  5.7134e-02, -6.3287e-02,\n",
       "                      -9.0702e-02, -1.7493e-01,  1.3399e-02, -1.1438e-01, -2.1863e-01,\n",
       "                      -1.3526e-01, -1.2641e-01, -1.4536e-01, -8.2372e-02, -1.8217e-01,\n",
       "                      -1.0802e-01, -9.0122e-02, -1.3809e-01, -1.4932e-01, -1.8082e-01,\n",
       "                      -8.6966e-02, -1.2664e-01, -1.4460e-01, -5.0981e-02, -9.2267e-02,\n",
       "                      -5.8981e-02, -9.8479e-02, -2.1475e-01, -9.9822e-02, -1.0126e-01,\n",
       "                      -1.6428e-01, -6.8826e-02, -1.9622e-01, -1.5789e-01, -9.6868e-02,\n",
       "                      -1.1541e-01, -1.2804e-01, -9.9815e-02, -1.1619e-01, -1.2237e-01,\n",
       "                      -1.8807e-01, -2.6703e-02, -7.9105e-02, -1.5937e-01, -1.0588e-01,\n",
       "                      -1.2734e-01, -8.6683e-02, -2.2488e-01, -1.2464e-01, -1.0691e-01,\n",
       "                      -8.3400e-02, -1.9184e-01, -3.2354e-02, -2.0098e-01, -1.2509e-01,\n",
       "                      -1.4125e-01, -8.9708e-02, -4.1727e-02, -1.8239e-01, -8.1461e-02,\n",
       "                      -1.4135e-01, -6.9028e-02, -2.1725e-01, -1.1002e-01, -7.6242e-02,\n",
       "                      -1.9247e-01, -1.3418e-01, -9.3724e-02, -5.6005e-02, -1.6433e-01,\n",
       "                      -1.5471e-01, -1.5348e-01, -1.4317e-01, -6.8746e-02, -8.7150e-02,\n",
       "                      -2.4493e-02, -8.8641e-02, -1.7815e-01, -8.4899e-02, -7.7491e-02,\n",
       "                      -1.2388e-01, -5.5199e-02, -1.6903e-01, -2.0416e-01, -1.2284e-01,\n",
       "                      -1.6030e-01, -1.3477e-01, -8.5362e-02, -1.1815e-01, -1.2752e-01,\n",
       "                      -8.9583e-02, -1.5302e-01, -1.6431e-01, -1.4178e-01, -8.1706e-02,\n",
       "                      -1.7604e-01, -1.9288e-01, -9.9819e-02, -1.9624e-01,  2.0418e-02,\n",
       "                      -1.6884e-01, -1.7456e-01, -1.0664e-01, -1.3495e-01, -6.7331e-02,\n",
       "                      -1.1477e-01, -7.9171e-02, -1.9935e-01, -1.7189e-01, -5.5165e-02,\n",
       "                      -2.5991e-02, -2.4010e-01, -4.9683e-02, -7.7191e-02, -3.3695e-01,\n",
       "                      -1.2172e-01, -1.3176e-01, -8.9504e-02, -1.1060e-01, -2.2731e-01,\n",
       "                      -7.9438e-02, -3.6689e-02, -1.7371e-01, -1.6949e-01, -1.4525e-02,\n",
       "                      -1.0675e-01, -1.6014e-01, -2.2074e-01, -1.1657e-02, -6.8403e-02,\n",
       "                      -1.1889e-01, -1.7528e-01, -1.5053e-01, -2.3709e-01, -4.6495e-02,\n",
       "                      -1.3629e-01, -1.7723e-01])),\n",
       "             ('bilstm_right_context_feature.weight_ih_l0_reverse',\n",
       "              tensor([[-0.0917,  0.2373,  0.0720,  ..., -0.2079, -0.1993, -0.0199],\n",
       "                      [ 0.0330, -0.2375, -0.2488,  ...,  0.1652, -0.1981,  0.0732],\n",
       "                      [ 0.2880,  0.1408, -0.0806,  ..., -0.1189, -0.2414, -0.4607],\n",
       "                      ...,\n",
       "                      [-0.1056, -0.2242,  0.0685,  ..., -0.5946,  0.0714,  0.2208],\n",
       "                      [-0.1456,  0.2100, -0.0233,  ...,  0.0179,  0.3042, -0.0932],\n",
       "                      [-0.1479, -0.2009,  0.1327,  ..., -0.2530, -0.0309, -0.1529]])),\n",
       "             ('bilstm_right_context_feature.weight_hh_l0_reverse',\n",
       "              tensor([[ 0.0302, -0.2212, -0.0327,  ..., -0.0199, -0.0081, -0.2357],\n",
       "                      [ 0.0769,  0.0378,  0.2506,  ...,  0.0545, -0.0426,  0.0454],\n",
       "                      [-0.1959, -0.1769, -0.0821,  ...,  0.2380, -0.1526,  0.0832],\n",
       "                      ...,\n",
       "                      [ 0.0047,  0.0744,  0.1364,  ...,  0.1300, -0.0925, -0.0796],\n",
       "                      [ 0.0022, -0.0620, -0.1808,  ...,  0.2067,  0.0930,  0.0684],\n",
       "                      [-0.2590, -0.2262,  0.1769,  ...,  0.0685, -0.0405, -0.0687]])),\n",
       "             ('bilstm_right_context_feature.bias_ih_l0_reverse',\n",
       "              tensor([-9.7693e-05,  1.4714e-01,  9.0185e-02,  6.3321e-02, -4.3872e-02,\n",
       "                       2.3279e-01,  4.6508e-02,  1.1405e-01,  3.9483e-02,  5.8449e-02,\n",
       "                       6.6394e-02, -5.2123e-02,  1.7287e-01,  2.7046e-02, -2.3402e-03,\n",
       "                       9.5343e-02,  1.2151e-01, -5.3385e-02,  2.0575e-01,  7.3315e-02,\n",
       "                       1.7694e-01,  1.4572e-01,  1.8924e-01,  2.8670e-02, -1.6534e-02,\n",
       "                       9.7140e-02,  1.3902e-01,  4.1899e-02,  9.4559e-04,  8.8006e-02,\n",
       "                      -8.5377e-03,  1.8282e-01, -5.1361e-03, -9.6859e-03, -1.3463e-01,\n",
       "                       5.8708e-03,  4.3620e-02,  5.5293e-02,  1.2034e-03,  5.1020e-02,\n",
       "                      -8.5750e-02,  1.2892e-01,  1.5221e-01,  9.7408e-02, -5.6108e-03,\n",
       "                       8.1313e-02, -5.5983e-02, -2.9343e-02, -2.7849e-02,  5.3056e-02,\n",
       "                       9.3202e-02,  5.6892e-02,  1.7259e-01,  4.7228e-02, -6.6904e-03,\n",
       "                       4.8160e-02, -1.8743e-02,  1.7970e-01,  1.5451e-01,  3.8849e-02,\n",
       "                       1.1925e-01, -1.4124e-02,  7.4938e-02,  7.1904e-02,  9.0320e-02,\n",
       "                      -1.5734e-02,  8.0207e-02,  1.2546e-01,  4.8035e-03,  1.8618e-01,\n",
       "                       7.3478e-02, -1.9954e-02,  1.1645e-01, -2.7769e-01,  2.1605e-02,\n",
       "                       1.4014e-01,  2.0732e-01,  1.2819e-01, -4.9217e-02,  2.2740e-01,\n",
       "                      -1.5834e-01,  2.3868e-01,  1.2642e-01,  1.2414e-03, -3.2015e-02,\n",
       "                       5.2220e-02,  4.3081e-02,  1.8762e-01,  3.9918e-02,  1.7505e-01,\n",
       "                       6.3207e-02,  1.6882e-01, -2.5164e-02,  9.1249e-02,  8.5530e-02,\n",
       "                       1.8251e-03,  2.2173e-01,  7.3296e-02,  4.0753e-02, -3.4293e-02,\n",
       "                      -8.5446e-02, -1.7833e-01,  1.8113e-02,  4.5740e-02,  1.0143e-01,\n",
       "                       5.9229e-02,  1.5731e-02,  3.0099e-01,  5.1475e-02, -1.3453e-02,\n",
       "                       2.1695e-01,  6.7216e-02,  1.7395e-02,  2.9609e-01,  2.1253e-01,\n",
       "                       1.7574e-01,  1.1824e-01,  2.4132e-01,  1.2402e-01,  1.4679e-01,\n",
       "                      -3.0779e-02,  7.1201e-02,  7.9264e-02,  1.3562e-01,  6.1796e-02,\n",
       "                       1.2685e-01, -3.2402e-02, -1.4341e-02,  4.5950e-02, -5.0847e-02,\n",
       "                      -1.4096e-01, -3.3563e-02, -8.8832e-02, -8.6108e-02,  3.6182e-02,\n",
       "                      -8.9757e-02, -6.6168e-02, -1.9512e-01,  5.9504e-03, -6.6664e-02,\n",
       "                      -4.3926e-02, -3.8612e-02,  6.6885e-02,  4.6400e-02,  3.2641e-02,\n",
       "                      -7.8006e-02, -9.0511e-02,  6.9347e-02, -2.1534e-01,  9.0362e-02,\n",
       "                      -1.3819e-01, -2.2629e-02, -4.1467e-02, -6.8212e-02, -6.6434e-02,\n",
       "                      -6.3313e-02, -2.2867e-02, -1.8620e-01, -2.3288e-02,  1.2136e-02,\n",
       "                       7.0002e-02,  2.8112e-02,  8.8112e-03, -1.6753e-02, -8.4572e-02,\n",
       "                      -1.3218e-01, -4.4766e-02, -1.0162e-01, -1.0308e-02, -1.2238e-02,\n",
       "                      -7.0611e-02, -9.8323e-02,  1.5772e-01,  2.3684e-02, -3.8891e-02,\n",
       "                      -1.7923e-01, -2.4173e-01, -9.6871e-02,  2.2440e-01, -1.4753e-01,\n",
       "                      -7.9286e-02, -1.5034e-01, -9.5487e-02,  2.8800e-02, -1.0195e-01,\n",
       "                      -1.6900e-01, -6.7353e-02, -2.7108e-01,  2.0789e-02,  1.1707e-01,\n",
       "                      -6.7696e-02, -3.1885e-01, -1.0401e-01, -2.6125e-02,  3.9518e-02,\n",
       "                      -1.0267e-01,  1.2480e-01,  4.0107e-02, -5.6205e-02, -1.5576e-01,\n",
       "                      -1.2325e-01, -3.4513e-02,  4.6018e-02, -1.2348e-01, -1.8447e-01,\n",
       "                      -8.2325e-02,  7.6149e-03, -2.5775e-02,  2.2958e-02,  5.1974e-02,\n",
       "                      -3.1938e-02, -5.3837e-02, -1.3162e-02, -3.8466e-03, -1.2194e-01,\n",
       "                      -1.1374e-02, -1.1802e-01, -6.2388e-02, -1.1058e-01, -5.2036e-02,\n",
       "                      -8.8122e-02,  1.9453e-01, -1.9063e-01, -1.1794e-01, -9.5509e-02,\n",
       "                      -2.4003e-02,  3.3864e-03, -3.4715e-02, -6.8435e-02,  5.7030e-02,\n",
       "                      -8.1681e-02, -1.6322e-02, -3.3457e-02,  2.6397e-02,  2.1595e-02,\n",
       "                      -1.4637e-01, -7.5360e-02, -2.2352e-01, -3.9608e-02, -4.2171e-02,\n",
       "                      -2.5759e-03, -2.2551e-02, -1.0888e-01, -1.6537e-02,  3.2512e-02,\n",
       "                      -1.1249e-01, -4.3502e-02,  3.6585e-02, -9.6574e-02, -9.1147e-03,\n",
       "                      -1.1351e-02,  5.1868e-02, -2.1677e-02, -7.4033e-03, -5.5645e-02,\n",
       "                       6.6097e-02, -5.2621e-02, -9.7197e-02,  4.0112e-02,  4.9591e-02,\n",
       "                       8.1818e-02,  2.6425e-02, -7.3360e-02, -3.1448e-02, -5.0443e-02,\n",
       "                       2.8908e-02, -7.6773e-02, -1.0777e-01, -3.2962e-02,  3.4686e-02,\n",
       "                       3.4965e-03, -6.4399e-02, -4.9757e-02, -7.6316e-03, -6.9717e-02,\n",
       "                       3.3583e-02,  1.1193e-01,  4.2803e-02, -1.6919e-02,  5.9780e-02,\n",
       "                      -1.0255e-02,  3.4593e-02, -1.1305e-01,  6.4926e-02, -5.2368e-02,\n",
       "                       8.0278e-02,  8.7633e-02, -3.3802e-02, -6.3310e-03, -3.5194e-02,\n",
       "                      -3.5289e-02, -5.4419e-02, -7.5141e-02, -8.3186e-02,  5.6487e-02,\n",
       "                       2.0318e-02, -3.9243e-02,  2.1137e-02, -5.4008e-02,  1.1268e-01,\n",
       "                      -3.7497e-02,  2.2124e-02, -4.1410e-02,  6.5264e-03, -6.0037e-02,\n",
       "                       3.8986e-03,  5.2284e-02,  7.0541e-02,  1.8193e-02,  2.8877e-02,\n",
       "                      -2.1324e-02, -1.3632e-03, -2.9734e-02,  3.2977e-02,  8.4956e-02,\n",
       "                      -2.4388e-02,  1.8167e-02, -6.6343e-02,  1.2939e-01, -6.9591e-02,\n",
       "                       6.7799e-02, -4.1304e-02,  1.7194e-01, -5.9609e-02,  7.2902e-03,\n",
       "                      -4.6114e-02,  1.0206e-01, -8.9680e-03, -6.1681e-02, -1.1518e-02,\n",
       "                      -8.4681e-03, -2.9715e-02, -2.3567e-02, -7.0936e-02, -4.8330e-02,\n",
       "                       1.0411e-01, -1.6988e-01, -1.2447e-01, -8.1814e-02, -9.0268e-03,\n",
       "                       4.7049e-02,  9.0499e-02, -9.9322e-02, -1.0935e-01, -5.9613e-02,\n",
       "                      -3.6775e-02,  8.6104e-02,  6.6221e-03,  7.0285e-02, -1.8819e-02,\n",
       "                       1.1949e-02,  1.0477e-01,  1.9202e-03, -1.0883e-02, -4.1388e-02,\n",
       "                       3.1082e-03,  4.3027e-03, -1.1466e-01,  1.6950e-03, -7.9001e-02,\n",
       "                      -4.5336e-03,  2.7174e-02,  5.8989e-03, -1.1314e-01, -2.5642e-02,\n",
       "                       4.0392e-02,  4.3659e-02,  5.3638e-02, -3.9954e-02, -2.4703e-02,\n",
       "                       2.1932e-02, -2.1213e-02, -1.4223e-02, -9.1059e-02,  3.9369e-02,\n",
       "                      -7.0682e-02, -1.8363e-03, -6.2316e-03,  1.6867e-01,  9.6017e-02,\n",
       "                       3.8166e-03,  4.2564e-02, -6.6772e-03, -2.5963e-02, -1.4936e-02,\n",
       "                       6.7337e-02,  1.5816e-01,  2.5470e-02,  9.7595e-03,  1.9535e-01,\n",
       "                       8.3213e-02, -1.2219e-02,  1.0172e-01,  1.6327e-01,  4.7602e-02,\n",
       "                       4.3944e-02,  5.7414e-02,  1.1936e-01,  7.0620e-02,  7.8618e-02,\n",
       "                      -3.0187e-02,  3.2604e-03,  1.2120e-01, -2.8335e-02,  1.6637e-01,\n",
       "                       9.6557e-02,  1.1302e-01,  4.8482e-02,  4.2599e-02,  1.5436e-01,\n",
       "                       1.9986e-01,  6.4273e-02,  7.5157e-02,  9.8510e-03, -1.8115e-02,\n",
       "                       4.8908e-02,  9.8270e-02,  1.2110e-02, -8.6564e-02, -5.4733e-02,\n",
       "                      -8.9093e-02,  1.5217e-01, -1.3467e-02,  1.6610e-01, -1.2036e-01,\n",
       "                       8.1229e-02,  4.5139e-02,  1.0812e-01,  5.7811e-02,  4.6290e-02,\n",
       "                       6.9440e-02,  2.1495e-01,  1.2879e-01,  3.6564e-02, -6.7554e-02,\n",
       "                       1.3093e-01,  2.2693e-01,  7.5551e-02, -7.6958e-02, -5.1502e-02,\n",
       "                       3.7466e-02,  5.5714e-02,  2.4736e-01,  1.0493e-01,  1.7997e-01,\n",
       "                      -1.5657e-02,  1.0213e-01,  3.3448e-02,  1.6366e-01, -9.5576e-02,\n",
       "                      -1.3314e-02,  1.1751e-01,  3.6445e-02,  2.6246e-01, -7.0473e-02,\n",
       "                       2.0826e-01,  6.9397e-02,  2.2682e-02, -1.8628e-02,  1.2210e-01,\n",
       "                       1.3680e-01,  8.2845e-02,  4.2832e-02,  1.6773e-01,  6.1008e-04,\n",
       "                       8.1758e-02,  1.4171e-01,  4.4392e-02, -7.1895e-02,  9.9316e-02,\n",
       "                       8.2081e-02,  1.8303e-01,  9.9705e-02,  2.9831e-02, -8.3685e-02,\n",
       "                       2.4026e-01,  5.2621e-02,  1.1703e-01,  3.9930e-02,  1.9580e-02,\n",
       "                       3.3833e-01,  1.1549e-01,  1.5663e-01,  1.6692e-02,  1.3407e-02,\n",
       "                       9.4122e-02,  9.4177e-02,  1.0220e-01,  2.6865e-01,  4.5532e-02,\n",
       "                       5.9916e-02,  2.2195e-01,  9.1355e-02, -6.8972e-02,  3.3166e-01,\n",
       "                       2.3694e-02,  2.8876e-02,  7.2707e-02,  1.0604e-01, -9.7658e-02,\n",
       "                       1.0032e-01,  4.9225e-02,  6.2248e-02,  5.6842e-03, -2.1615e-02,\n",
       "                       1.1711e-01,  5.0376e-02, -4.4508e-02,  6.6721e-02,  1.0894e-01,\n",
       "                       6.4579e-02,  4.5891e-02])),\n",
       "             ('bilstm_right_context_feature.bias_hh_l0_reverse',\n",
       "              tensor([ 1.3575e-02,  8.8695e-02,  2.1252e-01,  4.6821e-02,  1.2004e-01,\n",
       "                       9.0250e-02,  3.4689e-02,  6.6581e-02,  4.3667e-02,  1.9311e-01,\n",
       "                       1.6295e-01, -2.4111e-02,  7.7823e-02,  1.5311e-02,  5.7094e-02,\n",
       "                       1.8542e-01, -4.7281e-02, -6.4930e-02,  1.1950e-01,  1.1050e-01,\n",
       "                       1.9287e-01,  4.3869e-02,  9.3018e-02,  4.4134e-02,  3.4305e-02,\n",
       "                       2.0789e-01,  1.7281e-01,  6.5263e-02, -1.0469e-02,  3.8697e-02,\n",
       "                      -1.9020e-02,  8.9995e-02, -1.2588e-02,  1.6257e-01, -5.5787e-02,\n",
       "                       7.6583e-02, -9.9197e-03,  1.5153e-01,  1.3903e-02,  1.3222e-01,\n",
       "                      -8.2204e-02,  9.1792e-02,  2.0613e-01,  1.7844e-01,  2.9530e-02,\n",
       "                      -8.2592e-02, -8.8318e-02, -1.0195e-02, -3.9255e-02,  3.5930e-02,\n",
       "                      -3.2428e-02,  1.1061e-01, -2.7038e-02,  7.0509e-02,  9.3515e-03,\n",
       "                      -5.7398e-02,  1.1357e-01,  2.0150e-01,  2.4369e-01,  6.8657e-02,\n",
       "                       7.8076e-02,  7.5008e-02, -2.0391e-02,  2.2684e-02,  1.9025e-01,\n",
       "                      -1.6668e-02,  5.5425e-02, -5.7636e-03, -1.1706e-01,  6.6152e-02,\n",
       "                       1.9100e-02,  5.5985e-02,  1.6475e-01, -2.8520e-02, -1.2029e-01,\n",
       "                       1.5178e-01,  2.4882e-01,  1.5326e-01, -5.6529e-02,  7.8312e-02,\n",
       "                      -6.7019e-02,  1.0617e-01,  1.9825e-01,  4.5862e-02,  2.0290e-01,\n",
       "                       8.6107e-02,  6.2424e-02,  1.6326e-01,  3.5419e-02,  5.5592e-02,\n",
       "                      -2.5287e-02,  6.8580e-02, -3.3901e-02,  1.0139e-01,  1.6189e-01,\n",
       "                      -5.4759e-03,  2.1704e-01,  8.4832e-02,  1.4233e-01, -4.3274e-03,\n",
       "                       6.1549e-02, -7.5586e-02,  1.7334e-02,  1.4220e-01,  1.6331e-01,\n",
       "                       2.0728e-02,  6.5195e-02,  1.3110e-01,  1.8646e-01,  6.2014e-02,\n",
       "                       2.4275e-01, -4.4991e-02, -1.3241e-01,  1.2383e-01,  1.0238e-01,\n",
       "                       1.4892e-01,  3.5252e-02,  1.6984e-01,  8.2117e-02,  1.1095e-01,\n",
       "                       6.5683e-02,  2.1118e-01,  6.0396e-02,  1.0005e-01, -4.3076e-03,\n",
       "                       2.1522e-01, -9.6540e-04,  8.9345e-02,  4.4556e-02,  6.8319e-02,\n",
       "                      -1.4893e-01, -5.4420e-02, -2.2899e-02, -1.6490e-03,  1.2235e-01,\n",
       "                       4.1096e-04,  5.8175e-02, -1.3548e-01,  9.4120e-02, -9.9574e-02,\n",
       "                      -7.4446e-03,  1.6253e-02,  2.9940e-02,  3.8069e-02,  8.6435e-03,\n",
       "                       5.0438e-03, -8.5209e-02, -8.1010e-03, -2.8530e-02,  2.0251e-02,\n",
       "                      -2.0975e-01,  1.5997e-02,  9.1865e-02, -2.6524e-02, -8.8636e-02,\n",
       "                       1.4001e-02, -9.1525e-02, -1.0659e-01, -1.9491e-02, -4.0413e-03,\n",
       "                      -4.9752e-02, -5.7474e-02, -6.2443e-03,  3.3070e-02, -6.6685e-02,\n",
       "                      -6.1932e-02, -3.6436e-02,  1.2284e-02, -6.5599e-02, -1.2569e-01,\n",
       "                      -6.5082e-02, -6.6108e-02,  1.2459e-02, -1.6155e-02,  1.4209e-01,\n",
       "                      -1.8787e-01, -1.8806e-01, -1.2947e-01, -6.9822e-02, -1.1772e-01,\n",
       "                      -1.3911e-01, -8.3541e-02, -2.5650e-02, -1.3241e-01, -2.5808e-02,\n",
       "                      -8.9379e-02, -1.6818e-03, -6.4535e-02,  1.0214e-02,  3.6091e-02,\n",
       "                      -7.4119e-02, -1.1074e-01, -1.9831e-01,  2.4343e-02, -8.4048e-03,\n",
       "                       6.7062e-02,  1.0622e-01, -3.8448e-03,  8.2765e-03, -1.7176e-01,\n",
       "                      -9.2259e-02, -6.2020e-02, -4.3148e-02, -1.1072e-01, -1.6585e-01,\n",
       "                       4.0720e-02,  4.9847e-02, -4.7222e-02,  2.4614e-02, -5.3586e-02,\n",
       "                      -4.0687e-03, -3.4424e-02, -5.8687e-03, -1.3110e-02, -6.5360e-02,\n",
       "                      -1.3562e-01, -5.5434e-02, -1.2709e-01, -7.9106e-02, -8.1817e-02,\n",
       "                      -1.1230e-01,  4.0134e-02, -4.8082e-02, -6.1625e-02, -5.7880e-02,\n",
       "                      -5.3348e-02, -1.3676e-01, -7.8204e-02, -1.2845e-03, -4.4280e-02,\n",
       "                      -1.2669e-02, -1.9728e-01,  6.2876e-02, -7.1253e-02, -1.0712e-01,\n",
       "                      -3.4049e-02, -4.3899e-02, -1.2082e-01, -1.1232e-03, -3.2339e-02,\n",
       "                       1.6147e-02, -1.2323e-01, -1.0985e-01, -2.1992e-02, -1.2148e-01,\n",
       "                      -1.3006e-02, -8.1261e-02,  1.9383e-02, -2.0346e-02, -3.9429e-02,\n",
       "                       7.9619e-02, -5.8073e-03, -3.3139e-02, -3.1956e-02, -3.1334e-02,\n",
       "                       7.9680e-02,  6.6678e-02, -1.2038e-01,  6.2097e-02, -6.2163e-02,\n",
       "                      -8.8395e-02,  8.2037e-02,  6.7655e-03, -7.0084e-03, -9.7599e-02,\n",
       "                       1.8763e-02, -1.7503e-02,  1.0089e-01, -3.6360e-02, -3.7069e-04,\n",
       "                       7.1185e-02, -2.8758e-02,  1.5954e-01,  2.3795e-02, -5.9866e-02,\n",
       "                      -4.6178e-02,  2.7737e-03, -1.4117e-01,  3.1605e-02, -2.1419e-02,\n",
       "                       6.0358e-02,  1.1035e-01, -1.5947e-02,  3.7145e-02,  7.5291e-02,\n",
       "                       3.6883e-02,  3.5002e-02,  1.1184e-01,  4.5410e-02,  4.7100e-02,\n",
       "                       9.5110e-02, -1.4641e-02,  1.7091e-04, -1.0056e-01,  8.6906e-02,\n",
       "                      -1.3088e-01,  5.1348e-03, -6.8356e-02,  8.0251e-02, -4.1006e-02,\n",
       "                       1.6548e-02, -2.6375e-02, -1.4105e-03, -2.8837e-02, -3.9796e-02,\n",
       "                      -7.3822e-02,  1.5681e-03, -7.9510e-02, -6.6940e-02,  1.1148e-02,\n",
       "                       4.4923e-02, -1.0680e-01,  2.6399e-02,  4.6003e-02,  1.7165e-02,\n",
       "                      -9.1545e-02,  2.4455e-02,  3.4964e-02, -1.0021e-01, -6.7281e-02,\n",
       "                      -4.2279e-02,  6.7745e-02,  1.6285e-02, -3.9011e-02,  5.9832e-02,\n",
       "                       2.9930e-03,  2.7238e-02, -4.7890e-02, -2.5939e-02, -3.0525e-02,\n",
       "                      -6.8357e-02, -1.1695e-02,  9.8794e-02,  1.6436e-02, -1.7190e-02,\n",
       "                       1.4999e-01,  9.5779e-02,  5.1364e-02, -1.3799e-01, -2.2919e-02,\n",
       "                       5.1659e-02,  7.3723e-02, -1.2055e-01, -6.9811e-04,  7.9128e-02,\n",
       "                      -3.4188e-02,  3.3337e-02, -5.2361e-02,  1.6179e-03, -9.3130e-02,\n",
       "                       2.1254e-03,  8.7951e-02, -2.8426e-02,  1.4483e-02,  9.8423e-02,\n",
       "                      -1.1706e-01,  6.3188e-02, -8.0488e-03, -1.6736e-02, -6.5826e-02,\n",
       "                      -3.1407e-02,  9.4716e-03, -1.0252e-01, -9.0921e-02,  1.5784e-03,\n",
       "                       1.7986e-02,  3.5036e-03, -4.8221e-02, -1.6287e-03, -1.3250e-01,\n",
       "                      -8.4344e-02, -1.5308e-01,  3.1371e-02, -3.8325e-02,  2.8133e-02,\n",
       "                      -1.4665e-03, -3.6472e-02, -3.6462e-02, -1.0092e-02,  8.1879e-02,\n",
       "                      -2.5460e-02, -7.3467e-02,  2.0694e-01, -5.8238e-02, -5.4332e-02,\n",
       "                       4.8746e-02,  2.1079e-01, -3.4957e-03,  7.0383e-02,  2.1927e-01,\n",
       "                       2.1045e-02,  1.0803e-01,  5.3025e-02,  3.8824e-02,  8.3141e-02,\n",
       "                       7.5280e-02,  1.0999e-01,  6.7469e-02,  7.9500e-02,  1.0689e-01,\n",
       "                       2.2591e-02,  5.0062e-02,  1.3712e-01,  3.0419e-02,  3.6422e-02,\n",
       "                       1.1352e-01,  1.0536e-01,  9.1085e-02,  5.6026e-02,  2.0977e-03,\n",
       "                       2.2281e-01, -1.0364e-01, -1.5353e-01, -1.9263e-02,  1.5033e-01,\n",
       "                      -5.1709e-02, -6.3350e-02, -2.4483e-02,  1.4908e-01,  4.8484e-02,\n",
       "                       6.2786e-02, -4.0298e-02,  8.1522e-02,  9.2454e-02, -1.2770e-01,\n",
       "                       1.6525e-01,  1.0092e-01,  6.5101e-02, -5.3335e-02,  1.6789e-01,\n",
       "                       8.2495e-02,  1.7167e-01, -2.6637e-02,  6.8702e-02,  8.2822e-02,\n",
       "                      -1.0147e-01, -1.1014e-02,  1.3520e-01,  4.6076e-02, -6.0646e-02,\n",
       "                       9.5835e-02,  2.0357e-01,  1.6415e-01,  1.3202e-01,  2.1552e-01,\n",
       "                       7.6191e-02,  7.8722e-02, -5.8674e-02,  1.5126e-01,  7.9412e-02,\n",
       "                      -2.4365e-02, -1.0517e-01, -1.3161e-01,  1.2300e-01,  6.8090e-02,\n",
       "                       1.5433e-01,  6.8793e-02, -9.4089e-03, -6.5723e-02,  1.0603e-01,\n",
       "                       2.8766e-01,  7.8389e-02, -6.2437e-02,  1.4933e-01, -1.2867e-02,\n",
       "                       1.0012e-01,  1.4695e-01, -1.0970e-02,  1.7281e-01,  4.0238e-02,\n",
       "                       3.9079e-02,  1.9777e-01,  1.8837e-01, -5.1860e-02,  9.8925e-03,\n",
       "                       1.3456e-01, -3.5378e-02,  2.2543e-02,  5.6193e-02,  3.9022e-02,\n",
       "                       1.4558e-01,  8.0965e-02,  1.4613e-01,  1.9939e-02,  1.5775e-02,\n",
       "                       6.8274e-03,  1.7849e-01,  2.1495e-01,  3.8351e-02,  3.1656e-02,\n",
       "                       4.4542e-02,  1.2241e-01,  4.8458e-02, -9.9643e-03,  2.2891e-01,\n",
       "                       8.1379e-02,  4.3673e-02,  1.6336e-01,  1.1599e-01,  1.5418e-01,\n",
       "                       1.2301e-01,  1.4837e-01,  1.3902e-01,  4.3385e-02, -3.9571e-02,\n",
       "                       2.0023e-01,  1.3726e-01,  1.6614e-02,  7.8471e-02,  9.9585e-02,\n",
       "                      -1.8617e-02,  3.9492e-02])),\n",
       "             ('fc.0.weight',\n",
       "              tensor([[-0.0680,  0.0867, -0.0579,  ..., -0.1909,  0.0914,  0.1549],\n",
       "                      [-0.1206, -0.1119, -0.0813,  ..., -0.3010,  0.4710,  0.2987],\n",
       "                      [-0.0106,  0.1335,  0.1149,  ..., -0.3640,  0.1313,  0.2245],\n",
       "                      ...,\n",
       "                      [ 0.1307, -0.1090, -0.0697,  ...,  0.0527, -0.1687, -0.0463],\n",
       "                      [-0.0710,  0.1157,  0.0419,  ...,  0.1753, -0.3204, -0.0786],\n",
       "                      [ 0.0408, -0.2307,  0.0006,  ..., -0.4354, -0.2374, -0.3603]])),\n",
       "             ('fc.0.bias',\n",
       "              tensor([ 0.0230,  0.2790,  0.1106, -0.1999, -0.1271,  0.0463, -0.0610,  0.1960,\n",
       "                       0.4622,  0.0535,  0.0617,  0.3935, -0.1218, -0.0087, -0.1156, -0.1159,\n",
       "                      -0.3026, -0.0788,  0.0127, -0.2256, -0.0543, -0.1347, -0.1438,  0.2304,\n",
       "                      -0.0671, -0.0316,  0.2020, -0.0078,  0.3018, -0.0924, -0.1789,  0.0143,\n",
       "                       0.1136, -0.0694,  0.2080, -0.0034, -0.1585,  0.1954,  0.2372,  0.3275,\n",
       "                      -0.2351, -0.0135, -0.1501,  0.1193, -0.0585,  0.0590, -0.0591,  0.0502,\n",
       "                       0.0697, -0.2510, -0.0574,  0.0890,  0.2195,  0.4026, -0.0908, -0.0938,\n",
       "                      -0.0019,  0.1870,  0.1530,  0.1024,  0.1955, -0.0644, -0.0111,  0.0899])),\n",
       "             ('oov_embedding.weight',\n",
       "              tensor([[-0.1560,  0.3470,  0.0291,  ..., -0.2102, -0.1427,  0.0387],\n",
       "                      [ 0.2882,  0.0920,  0.2875,  ..., -0.0599, -0.2018,  0.0985],\n",
       "                      [-0.1505,  0.0660,  0.1116,  ..., -0.1787, -0.0384, -0.0669],\n",
       "                      ...,\n",
       "                      [ 0.2497, -0.3242, -0.1438,  ...,  0.2208, -0.1360,  0.2776],\n",
       "                      [-0.0982,  0.0494, -0.0595,  ..., -0.0107, -0.0630, -0.2166],\n",
       "                      [-0.0838, -0.0603,  0.0152,  ..., -0.0802,  0.0193,  0.1563]])),\n",
       "             ('oov_embedding.bias',\n",
       "              tensor([-0.0623, -0.1360,  0.1204,  0.0608,  0.3278, -0.0293, -0.2836,  0.0592,\n",
       "                       0.0196, -0.0246, -0.1826,  0.3621, -0.0998,  0.2998,  0.1226,  0.2427,\n",
       "                       0.1175, -0.1533, -0.0710, -0.0157, -0.3780, -0.1096, -0.1914,  0.0688,\n",
       "                      -0.2398, -0.1041, -0.1629, -0.1063, -0.1088,  0.0307,  0.0906, -0.5325,\n",
       "                      -0.1135,  0.0049, -0.0835,  0.0575,  0.0284, -0.0423,  0.1186, -0.3268,\n",
       "                       0.2452, -0.0264, -0.0320, -0.1054,  0.1800,  0.1326,  0.3232,  0.2297,\n",
       "                       0.1407,  0.1089, -0.2036,  0.2048, -0.3050,  0.0948,  0.2144,  0.0497,\n",
       "                      -0.0340,  0.1065,  0.2774, -0.0886, -0.1471, -0.0880, -0.3587, -0.2264])),\n",
       "             ('prob.0.weight',\n",
       "              tensor([[-0.1112, -0.0303,  0.0022,  ...,  0.2401, -0.2280, -0.0389],\n",
       "                      [ 0.1103,  0.1979, -0.0536,  ..., -0.1321,  0.1912, -0.3022],\n",
       "                      [ 0.0828,  0.0097,  0.0427,  ...,  0.0048, -0.1521, -0.2979],\n",
       "                      ...,\n",
       "                      [ 0.2809, -0.0469, -0.1441,  ...,  0.2649,  0.0506, -0.2673],\n",
       "                      [-0.0898, -0.0181,  0.2601,  ..., -0.1649,  0.2185, -0.0824],\n",
       "                      [ 0.0551,  0.2069,  0.2905,  ..., -0.1884,  0.1492,  0.2528]])),\n",
       "             ('prob.0.bias',\n",
       "              tensor([-0.7906,  0.0127, -0.2846,  ..., -0.4093, -0.0475, -0.0941]))])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1616de6-2ec1-4a77-980a-addd6d77d6d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
