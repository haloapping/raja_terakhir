{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13fc63c4-da08-43a8-9972-2615d377d1fa",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "313363b9-24d1-4b87-87cd-a0b7dd5fc128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "import timeit\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime\n",
    "from itertools import chain\n",
    "from time import time\n",
    "from torch import nn, optim\n",
    "from torchmetrics import F1Score\n",
    "from torch.optim import lr_scheduler\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from polyglot.mapping import Embedding, CaseExpander, DigitExpander\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b49405-006a-4a45-ae79-0e22f6a7172e",
   "metadata": {},
   "source": [
    "# Hyperparameters Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68709d29-24a1-45bf-b549-804952fd1db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HyperparamsDataset:\n",
    "    def __init__(\n",
    "        self,\n",
    "        left_context_seq_len = None,\n",
    "        oov_context_seq_len = None,\n",
    "        right_context_seq_len = None,\n",
    "        n_features_left_context = None,\n",
    "        n_features_oov_context = None,\n",
    "        n_features_right_context = None,\n",
    "        device=device\n",
    "    ):\n",
    "        self.left_context_seq_len = left_context_seq_len\n",
    "        self.oov_context_seq_len = oov_context_seq_len\n",
    "        self.right_context_seq_len = right_context_seq_len\n",
    "        self.n_features_left_context = n_features_left_context,\n",
    "        self.n_features_oov_context = n_features_oov_context,\n",
    "        self.n_features_right_context = n_features_right_context,\n",
    "        self.device = device\n",
    "        \n",
    "        \n",
    "class HyperparamsModel:\n",
    "     def __init__(\n",
    "        self,\n",
    "        num_hidden_layer=None,\n",
    "        hidden_size=None,\n",
    "        device=device\n",
    "    ):\n",
    "        self.num_hidden_layer = num_hidden_layer\n",
    "        self.hidden_size = hidden_size\n",
    "        self.device = device\n",
    "        \n",
    "dataset_hyperparams_config = HyperparamsDataset(\n",
    "    left_context_seq_len = 79,\n",
    "    oov_context_seq_len = 30,\n",
    "    right_context_seq_len = 79,\n",
    "    n_features_left_context = 64,\n",
    "    n_features_oov_context = 20,\n",
    "    n_features_right_context = 64,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "context_size = 79"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f750b1-d4a7-4a2a-9fe1-369a61f28a2b",
   "metadata": {},
   "source": [
    "# Prepare Feature Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f241f20b-fb34-4db2-b887-1687f137b141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left context shape: (16562, 71)\n",
      "OOV context shape: (16562, 28)\n",
      "Right context shape: (16562, 79)\n",
      "Actual lable shape: (16562,)\n"
     ]
    }
   ],
   "source": [
    "def convert_doc_to_idxs(docs, dict_vocabs):\n",
    "    doc_to_idx = []\n",
    "    \n",
    "    for doc in docs:\n",
    "        doc_to_idx.append([dict_vocabs[token] for token in doc])\n",
    "        \n",
    "    return np.array(doc_to_idx)\n",
    "\n",
    "# Left context\n",
    "left_context = open(\"../../datasets/features/79_context/left_context_with_pad.pkl\", \"rb\")\n",
    "left_context = pickle.load(left_context)\n",
    "left_context_to_idx = open(\"../../datasets/features/79_context/token2idx_left_context.pkl\", \"rb\")\n",
    "left_context_to_idx = pickle.load(left_context_to_idx)\n",
    "doc_left_context_to_idx = convert_doc_to_idxs(left_context, left_context_to_idx)\n",
    "\n",
    "# OOV context\n",
    "oov_context = open(\"../../datasets/features/79_context/oov_context_with_pad.pkl\", \"rb\")\n",
    "oov_context = pickle.load(oov_context)\n",
    "oov_context_to_idx = open(\"../../datasets/features/79_context/token2idx_oov_context.pkl\", \"rb\")\n",
    "oov_context_to_idx = pickle.load(oov_context_to_idx)\n",
    "doc_oov_context_to_idx = convert_doc_to_idxs(oov_context, oov_context_to_idx)\n",
    "\n",
    "# Right context\n",
    "right_context = open(\"../../datasets/features/79_context/right_context_with_pad.pkl\", \"rb\")\n",
    "right_context = pickle.load(right_context)\n",
    "right_context_to_idx = open(\"../../datasets/features/79_context/token2idx_right_context.pkl\", \"rb\")\n",
    "right_context_to_idx = pickle.load(right_context_to_idx)\n",
    "doc_right_context_to_idx = convert_doc_to_idxs(right_context, right_context_to_idx)\n",
    "\n",
    "# Actual labels\n",
    "labels_context = open(\"../../datasets/features/79_context/lables.pkl\", \"rb\")\n",
    "labels_context = pickle.load(labels_context)\n",
    "labels_to_idx = open(\"../../datasets/features/79_context/lable_vocabs.pkl\", \"rb\")\n",
    "labels_to_idx = pickle.load(labels_to_idx)\n",
    "doc_labels_to_idx = convert_doc_to_idxs(labels_context, labels_to_idx).flatten()\n",
    "\n",
    "print(f\"Left context shape: {doc_left_context_to_idx.shape}\")\n",
    "print(f\"OOV context shape: {doc_oov_context_to_idx.shape}\")\n",
    "print(f\"Right context shape: {doc_right_context_to_idx.shape}\")\n",
    "print(f\"Actual lable shape: {doc_labels_to_idx.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe386c1f-3e1d-4589-b18e-42e4bc4055ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 2968, 10710,  1320,  1320,  1320,  1320,  1320,  1320,  1320,  1320,\n",
       "          1320,  1320,  1320,  1320,  1320,  1320,  1320,  1320,  1320,  1320,\n",
       "          1320,  1320,  1320,  1320,  1320,  1320,  1320,  1320,  1320,  1320,\n",
       "          1320,  1320,  1320,  1320,  1320,  1320,  1320,  1320,  1320,  1320,\n",
       "          1320,  1320,  1320,  1320,  1320,  1320,  1320,  1320,  1320,  1320,\n",
       "          1320,  1320,  1320,  1320,  1320,  1320,  1320,  1320,  1320,  1320,\n",
       "          1320,  1320,  1320,  1320,  1320,  1320,  1320,  1320,  1320,  1320,\n",
       "          1320]),\n",
       " tensor([19, 31, 19, 32, 29, 19, 32, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "         17, 17, 17, 17, 17, 17, 17, 17, 17, 17]),\n",
       " tensor([1929, 1929, 1929, 1929, 1929, 1929, 1929, 1929, 1929, 1929, 1929, 1929,\n",
       "         1929, 1929, 1929, 1929, 1929, 1929, 1929, 1929, 1929, 1929, 1929, 1929,\n",
       "         1929, 1929, 1929, 1929, 1929, 1929, 1929, 1929, 1929, 1929, 1929, 1929,\n",
       "         1929, 1929, 1929, 1929, 1929, 1929, 1929, 1929, 1929, 1929, 1929, 1929,\n",
       "         1929, 1929, 1929, 1929, 1929, 1929, 1929, 1929, 1929, 1929, 1929, 1929,\n",
       "         1929, 1929, 1929, 1929, 1929, 1929, 1929, 1929, 1929, 1929, 1929, 1929,\n",
       "         1929, 1929, 1929, 1929, 1929, 1929, 1929]),\n",
       " tensor(171))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to Tensor\n",
    "left_contexts = torch.LongTensor(doc_left_context_to_idx)\n",
    "oov_contexts = torch.LongTensor(doc_oov_context_to_idx)\n",
    "right_contexts = torch.LongTensor(doc_right_context_to_idx)\n",
    "actual_labels = torch.LongTensor(doc_labels_to_idx)\n",
    "dataset = TensorDataset(left_contexts, oov_contexts, right_contexts, actual_labels)\n",
    "\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8806cc8-c1d1-450a-833d-f25375c52949",
   "metadata": {},
   "source": [
    "# Char and Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86595b81-a95e-4469-acad-49b9ed2c9662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word Embedding\n",
    "word_embeddings = Embedding.load(\"../../word_embeddings/polyglot/idn_embeddings.tar.bz2\")\n",
    "word_embeddings.apply_expansion(DigitExpander)\n",
    "word_embeddings.apply_expansion(CaseExpander)\n",
    "\n",
    "left_vocabs = open(\"../../datasets/features/79_context/left_context_vocabs.pkl\", \"rb\")\n",
    "left_vocabs = pickle.load(left_vocabs)\n",
    "\n",
    "right_vocabs = open(\"../../datasets/features/79_context/right_context_vocabs.pkl\", \"rb\")\n",
    "right_vocabs = pickle.load(right_vocabs)\n",
    "\n",
    "left_word_embedding_dict = {left_context_to_idx[vocab] : word_embeddings[vocab] for vocab in left_vocabs}\n",
    "right_word_embedding_dict = {right_context_to_idx[vocab] : word_embeddings[vocab] for vocab in right_vocabs}\n",
    "\n",
    "# Char Embedding\n",
    "char_embedding_dict = open(\"../../word_embeddings/chars_embedding/char_embeddings.pkl\", \"rb\")\n",
    "char_embedding_dict = pickle.load(char_embedding_dict)\n",
    "\n",
    "# Context embedding\n",
    "left_context_embedding = nn.Embedding.from_pretrained(torch.FloatTensor(np.array(list(left_word_embedding_dict.values()))), freeze=True)\n",
    "oov_context_embedding = nn.Embedding.from_pretrained(torch.FloatTensor(np.array(list(char_embedding_dict.values()))), freeze=True)\n",
    "right_context_embedding = nn.Embedding.from_pretrained(torch.FloatTensor(np.array(list(right_word_embedding_dict.values()))), freeze=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593ddcfe-1525-41ae-bf02-c9ebf3d957aa",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "998fb38d-da64-4b4c-9371-75e06ebfc8f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 3119,  1320,  1320,  ...,  1320,  1320,  1320],\n",
       "         [ 4147,  7061, 10790,  ...,  1320,  1320,  1320],\n",
       "         [ 3837,  1320,  1320,  ...,  1320,  1320,  1320],\n",
       "         ...,\n",
       "         [ 2857,  5130,  9377,  ...,  1320,  1320,  1320],\n",
       "         [ 2655,  7481,  1320,  ...,  1320,  1320,  1320],\n",
       "         [ 1857,  2205,  2734,  ...,  1320,  1320,  1320]]),\n",
       " tensor([[22, 37, 30, 32, 25, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "         [34, 33, 31, 19, 30, 19, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "         [34, 27, 32, 28, 19, 31, 19, 32, 18, 30, 39, 32, 19, 29, 17, 17, 17, 17,\n",
       "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "         [31, 23, 30, 19, 36, 27, 29, 19, 32, 18, 22, 27, 36, 27, 17, 17, 17, 17,\n",
       "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "         [36, 33, 21, 26, 19, 22, 27, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "         [22, 27, 18, 31, 19, 32, 19, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "         [29, 23, 20, 27, 28, 19, 29, 19, 32, 18, 23, 29, 33, 32, 33, 31, 27, 17,\n",
       "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "         [38, 33, 29, 33, 26,  3, 38, 33, 29, 33, 26, 17, 17, 17, 17, 17, 17, 17,\n",
       "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "         [20, 23, 42, 27, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "         [ 3, 32, 43, 19, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "         [28, 19, 34, 23, 42, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "         [30, 39, 29, 19,  3, 30, 39, 29, 19, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "         [ 3, 32, 43, 19, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "         [20, 33, 28, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "         [34, 23, 32, 21, 19, 22, 19, 32, 25, 19, 32, 17, 17, 17, 17, 17, 17, 17,\n",
       "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "         [37, 29, 19, 30, 19, 18, 36, 27, 21, 26, 38, 23, 36, 17, 17, 17, 17, 17,\n",
       "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "         [43, 39, 21, 23, 30, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "         [37, 23, 32, 27, 30, 19, 25, 19, 29, 19, 30, 27, 17, 17, 17, 17, 17, 17,\n",
       "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "         [ 3, 32, 43, 19, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "         [19, 37, 26, 37, 26, 19, 36, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "         [27, 32, 21, 33, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "         [ 3, 32, 43, 19, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "         [34, 23, 36, 38, 39, 31, 20, 39, 26, 19, 32, 18, 23, 29, 33, 32, 33, 31,\n",
       "          27, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "         [37, 23, 29, 36, 23, 38, 19, 36, 27, 37, 18, 28, 23, 32, 22, 23, 36, 19,\n",
       "          30, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "         [22, 27, 18, 37, 27, 32, 27, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "         [ 3, 32, 43, 19, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "         [30, 23, 34, 19, 37, 18, 34, 19, 32, 38, 19, 27, 17, 17, 17, 17, 17, 17,\n",
       "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "         [19, 38, 19, 37, 18, 32, 19, 31, 19, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "         [20, 19, 38, 39, 18, 20, 19, 36, 19, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "         [40, 19, 36, 27, 19, 20, 23, 30,  3, 40, 19, 36, 27, 19, 20, 23, 30, 17,\n",
       "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "         [ 3, 32, 43, 19, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "         [20, 20, 32, 27, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17]]),\n",
       " tensor([[   11,  1929,  1929,  ...,  1929,  1929,  1929],\n",
       "         [    9,  8538,  6758,  ...,  1929,  1929,  1929],\n",
       "         [10329,  5418, 10560,  ...,  1929,  1929,  1929],\n",
       "         ...,\n",
       "         [ 6774,  9706,  7829,  ...,  1929,  1929,  1929],\n",
       "         [10507,  7737,  7180,  ...,  1929,  1929,  1929],\n",
       "         [ 5832,  9798,  8670,  ...,  1929,  1929,  1929]]),\n",
       " tensor([ 906, 2654, 2618, 1987, 2833,  796, 1590, 3393,  502,    8, 1436, 1872,\n",
       "            8,  538, 2468, 3095, 3584, 2995,    8,  278, 1328,    8, 2568, 2971,\n",
       "          800,    8, 1823,  290,  407, 3495,    8,  425])]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5be550-2f41-41b4-9df4-ac67744041c5",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed852446-c649-4727-b9ff-64375cf7e966",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Comick(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size_left_context=64,\n",
    "        input_size_oov_context=20,\n",
    "        input_size_right_context=64,\n",
    "        hidden_size = 128,\n",
    "        num_layers = 2,\n",
    "        output_size = len(labels_to_idx),\n",
    "        batch_first = True,\n",
    "        bidirectional = True,\n",
    "        init_wb_with_kaiming_normal=True\n",
    "    ):\n",
    "        super(Comick, self).__init__()\n",
    "        \n",
    "        self.input_size_left_context = input_size_left_context\n",
    "        self.input_size_oov_context = input_size_oov_context\n",
    "        self.input_size_right_context = input_size_right_context\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.output_size = output_size\n",
    "        self.batch_first = batch_first\n",
    "        self.bidirectional = bidirectional\n",
    "        \n",
    "        self.bilstm_left_context_feature = nn.LSTM(\n",
    "            input_size = self.input_size_left_context,\n",
    "            hidden_size = self.hidden_size,\n",
    "            num_layers = self.num_layers,\n",
    "            batch_first = self.batch_first,\n",
    "            bidirectional = self.bidirectional\n",
    "        )\n",
    "        \n",
    "        self.bilstm_oov_context_feature = nn.LSTM(\n",
    "            input_size = self.input_size_oov_context,\n",
    "            hidden_size = self.hidden_size,\n",
    "            num_layers = self.num_layers,\n",
    "            batch_first = self.batch_first,\n",
    "            bidirectional = self.bidirectional\n",
    "        )\n",
    "        \n",
    "        self.bilstm_right_context_feature = nn.LSTM(\n",
    "            input_size = self.input_size_right_context,\n",
    "            hidden_size = self.hidden_size,\n",
    "            num_layers = self.num_layers,\n",
    "            batch_first = self.batch_first,\n",
    "            bidirectional = self.bidirectional\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(2 * self.hidden_size, 64),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "        self.oov_embedding = nn.Linear(in_features=3 * 64, out_features=64)\n",
    "        \n",
    "        self.embedding = np.empty((output_size, 64), dtype=np.float32)\n",
    "        \n",
    "        self.output = nn.Sequential(\n",
    "            nn.Linear(64, self.output_size),\n",
    "            nn.LogSoftmax(dim=1)\n",
    "        )\n",
    "                \n",
    "        if init_wb_with_kaiming_normal:\n",
    "            self.init_wb()\n",
    "            \n",
    "    def init_wb(self):\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, (nn.Linear, nn.LSTM)):\n",
    "                for name, param in module.named_parameters():\n",
    "                    if \"weight\" in name:\n",
    "                        nn.init.kaiming_normal_(param)\n",
    "                    else:\n",
    "                        nn.init.kaiming_normal_(param.reshape(1, -1))\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_left_context,\n",
    "        input_oov_context,\n",
    "        input_right_context,\n",
    "        idxs_target,\n",
    "        hidden_left_context=None,\n",
    "        hidden_oov_context=None,\n",
    "        hidden_right_context=None,\n",
    "    ):\n",
    "        # BiLSTM left, oov, and right context\n",
    "        output_left_context, (hidden_left_context, memory_left_context) = self.bilstm_left_context_feature(input_left_context, hidden_left_context)\n",
    "        output_oov_context, (hidden_oov_context, memory_oov_context) = self.bilstm_oov_context_feature(input_oov_context, hidden_oov_context)\n",
    "        output_right_context, (hidden_right_context, memory_right_context) = self.bilstm_right_context_feature(input_right_context, hidden_right_context)\n",
    "        \n",
    "        # Concate hidden (forward and backward hidden BiLSTM)\n",
    "        hidden_left_bidirectional = torch.cat((hidden_left_context[0], hidden_left_context[-1]), dim=1)\n",
    "        hidden_oov_bidirectional = torch.cat((hidden_oov_context[0], hidden_oov_context[-1]), dim=1)\n",
    "        hidden_right_bidirectional = torch.cat((hidden_right_context[0], hidden_right_context[-1]), dim=1)\n",
    "        \n",
    "        # Fully connected\n",
    "        output_left_fc = self.fc(hidden_left_bidirectional)\n",
    "        output_oov_fc = self.fc(hidden_oov_bidirectional)\n",
    "        output_right_fc = self.fc(hidden_right_bidirectional)\n",
    "        \n",
    "        # Concate output left, oov, and right context feature\n",
    "        output = torch.cat((output_left_fc, output_oov_fc, output_right_fc), dim=1)\n",
    "        \n",
    "        # OOV embedding\n",
    "        output = self.oov_embedding(output)\n",
    "                \n",
    "        # save OOV embedding\n",
    "        self.embedding[idxs_target.tolist()] = output.detach().numpy()\n",
    "        \n",
    "        # Projection OOV embedding\n",
    "        output = self.output(output)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992eb40b-9062-47f1-9703-65e80d6cb07d",
   "metadata": {},
   "source": [
    "# Model, Optimizer, Criterion, Metric, and Learning Rate Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b08d05fc-0bb5-426e-aa7b-eb930ba9f06b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Comick(\n",
       "  (bilstm_left_context_feature): LSTM(64, 128, num_layers=2, batch_first=True, bidirectional=True)\n",
       "  (bilstm_oov_context_feature): LSTM(20, 128, num_layers=2, batch_first=True, bidirectional=True)\n",
       "  (bilstm_right_context_feature): LSTM(64, 128, num_layers=2, batch_first=True, bidirectional=True)\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (1): Tanh()\n",
       "  )\n",
       "  (oov_embedding): Linear(in_features=192, out_features=64, bias=True)\n",
       "  (output): Sequential(\n",
       "    (0): Linear(in_features=64, out_features=3611, bias=True)\n",
       "    (1): LogSoftmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Comick(init_wb_with_kaiming_normal=True).to(device)\n",
    "model.output[0].requires_grad_ = False # disable gradient for projection layer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.005)\n",
    "criterion = nn.NLLLoss().to(device)\n",
    "metric = F1Score().to(device)\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.5)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d463d75-dd43-4b45-9eec-8f4aca21b018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000219"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([param.numel() for param in model.parameters() if param.requires_grad_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "494a567d-acbc-46c2-adc8-b9a512366c17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b39ba3-b103-44da-ae1e-34fd12ad2d2f",
   "metadata": {},
   "source": [
    "# Training and Looping Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c51a3a6-a4af-425f-aa1f-34ffe9ff8248",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_step(dataloader, model, optimizer, criterion, metric, scheduler=None, path_name=None):\n",
    "    batch_losses = []\n",
    "    batch_metric_scores = []\n",
    "    \n",
    "    for batch, (input_left_context, input_oov_context, input_right_context, actual_label) in enumerate(tqdm(dataloader), 1):\n",
    "        # Forward Propagation\n",
    "        probs = model(\n",
    "            left_context_embedding(input_left_context).to(device),\n",
    "            oov_context_embedding(input_oov_context).to(device),\n",
    "            right_context_embedding(input_right_context).to(device),\n",
    "            actual_label.to(device)\n",
    "        )\n",
    "                \n",
    "        loss = criterion(probs, actual_label.to(device))\n",
    "        metric_score = metric(probs.argmax(dim=1), actual_label.to(device))\n",
    "        metric_score = metric.compute()\n",
    "        \n",
    "        if scheduler is not None:\n",
    "            scheduler.step(loss)\n",
    "        \n",
    "        batch_losses.append(loss.item())\n",
    "        batch_metric_scores.append(metric_score)\n",
    "        \n",
    "        if batch % 50 == 0 or batch == len(dataloader):\n",
    "            print(f\"Batch-{batch}: {str(criterion).split('(')[0]}={loss.item()} | {str(metric).split('(')[0]}={metric_score}\")\n",
    "            with open(f\"../../logs/comick/{context_size}_contexts/{path_name}/training_history.txt\", \"a\") as f:\n",
    "                f.write(f\"Batch-{batch}: {str(criterion).split('(')[0]}={loss.item()} | {str(metric).split('(')[0]}={metric_score}\\n\")\n",
    "\n",
    "        # Backward Propagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    return batch_losses, batch_metric_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e139244-b036-4d45-beca-1de5bd7b5e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH-1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dad1a02dbca8483e95d947c8164629f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50: NLLLoss=5.999701976776123 | F1Score=0.29249998927116394\n",
      "Batch-100: NLLLoss=4.314286231994629 | F1Score=0.3499999940395355\n",
      "Batch-150: NLLLoss=3.8958511352539062 | F1Score=0.3947916626930237\n",
      "Batch-200: NLLLoss=4.58422327041626 | F1Score=0.4221875071525574\n",
      "Batch-250: NLLLoss=2.85867977142334 | F1Score=0.44574999809265137\n",
      "Batch-300: NLLLoss=3.548815965652466 | F1Score=0.4659374952316284\n",
      "Batch-350: NLLLoss=2.1451644897460938 | F1Score=0.4858928620815277\n",
      "Batch-400: NLLLoss=3.3895866870880127 | F1Score=0.5015624761581421\n",
      "Batch-450: NLLLoss=2.8416078090667725 | F1Score=0.5164583325386047\n",
      "Batch-500: NLLLoss=2.389314651489258 | F1Score=0.5310624837875366\n",
      "Batch-518: NLLLoss=2.8952016830444336 | F1Score=0.535321831703186\n",
      "\n",
      "Mean NLLLoss: 3.667748212814331 | Mean F1Score: 0.4297913908958435\n",
      "===========================================================================\n",
      "\n",
      "Early stopping, patience = 0/3❗\n",
      "Training duration : 4.058 minutes.\n",
      "Training date     : 2022-09-20 11:20:22.318441\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def looping_step(dataloader, model, optimizer, criterion, metric, n_epoch=15, patience=3, monitor=\"loss\"):\n",
    "    start_time = time()\n",
    "    \n",
    "    epoch_losses = []\n",
    "    epoch_metric_scores = []\n",
    "    patience_counter = 0\n",
    "    \n",
    "    now = datetime.now()\n",
    "    path_name = now.strftime(\"%m-%d-%Y_%H-%M-%S\")\n",
    "    os.makedirs(f\"../../logs/comick/{context_size}_contexts/{path_name}\")\n",
    "\n",
    "    for epoch in range(1, n_epoch + 1):\n",
    "        print(f\"EPOCH-{epoch}\")\n",
    "        with open(f\"../../logs/comick/{context_size}_contexts/{path_name}/training_history.txt\", \"a\") as f:\n",
    "            f.write(f\"EPOCH-{epoch}\\n\")\n",
    "        \n",
    "        batch_losses, batch_metric_scores = training_step(dataloader, model, optimizer, criterion, metric, path_name=path_name)\n",
    "        epoch_loss = torch.mean(torch.FloatTensor(batch_losses))\n",
    "\n",
    "        epoch_loss = torch.mean(torch.FloatTensor(batch_losses))\n",
    "        epoch_losses.append(epoch_loss.item())\n",
    "\n",
    "        epoch_metric_score = torch.mean(torch.FloatTensor(batch_metric_scores))\n",
    "        epoch_metric_scores.append(epoch_metric_score.item())\n",
    "        \n",
    "        with open(f\"../../logs/comick/{context_size}_contexts/{path_name}/training_history.txt\", \"a\") as f:\n",
    "            if monitor == \"loss\":\n",
    "                if epoch == 1:\n",
    "                    print(f\"\\nMean {str(criterion).split('(')[0]}: {epoch_loss} | Mean {str(metric).split('(')[0]}: {epoch_metric_score}\")\n",
    "                    \n",
    "                    f.write(f\"\\nMean {str(criterion).split('(')[0]}: {epoch_loss} | Mean {str(metric).split('(')[0]}: {epoch_metric_score}\\n\")\n",
    "                elif epoch_losses[-1] < epoch_losses[-2]:\n",
    "                    print(\"\\nYeah 🎉😄! Model improved.\")\n",
    "                    print(f\"Mean {str(criterion).split('(')[0]}: {epoch_loss} | Mean {str(metric).split('(')[0]}: {epoch_metric_score}\")\n",
    "                    \n",
    "                    f.write(\"\\nYeah 🎉😄! Model improved.\\n\")\n",
    "                    f.write(f\"Mean {str(criterion).split('(')[0]}: {epoch_loss} | Mean {str(metric).split('(')[0]}: {epoch_metric_score}\\n\")\n",
    "                else:\n",
    "                    patience_counter += 1\n",
    "                    \n",
    "                    print(\"\\nHuft 😥! Model not improved.\")\n",
    "                    print(f\"Mean {str(criterion).split('(')[0]}: {epoch_loss} | Mean {str(metric).split('(')[0]}: {epoch_metric_score}\")\n",
    "                    print(f\"Patience = {patience_counter}/{patience}❗\")\n",
    "                    \n",
    "                    f.write(\"\\nHuft 😥! Model not improved.\\n\")\n",
    "                    f.write(f\"Mean {str(criterion).split('(')[0]}: {epoch_loss} | Mean {str(metric).split('(')[0]}: {epoch_metric_score}\\n\")                    \n",
    "                    f.write(f\"Patience = {patience_counter}/{patience}❗\")\n",
    "            else:\n",
    "                if epoch == 1:\n",
    "                    print(f\"\\nMean {str(criterion).split('(')[0]}: {epoch_loss} | Mean {str(metric).split('(')[0]}: {epoch_metric_score}\")\n",
    "                    \n",
    "                    f.write(f\"\\nMean {str(criterion).split('(')[0]}: {epoch_loss} | Mean {str(metric).split('(')[0]}: {epoch_metric_score}\\n\")\n",
    "                elif epoch_metric_scores[-1] > epoch_metric_scores[-2]:\n",
    "                    print(\"\\nYeah 🎉😄! Model improved.\")\n",
    "                    print(f\"Mean {str(criterion).split('(')[0]}: {epoch_loss} | Mean Mean {str(metric).split('(')[0]}: {epoch_metric_score}\")\n",
    "                    \n",
    "                    f.write(\"\\nYeah 🎉😄! Model improved.\\n\")\n",
    "                    f.write(f\"Mean {str(criterion).split('(')[0]}: {epoch_loss} | Mean {str(metric).split('(')[0]}: {epoch_metric_score}\\n\")\n",
    "                else:\n",
    "                    patience_counter += 1\n",
    "                    \n",
    "                    print(\"\\nHuft 😥! Model not improved.\")\n",
    "                    print(f\"Mean {str(criterion).split('(')[0]}: {epoch_loss} | Mean {str(metric).split('(')[0]}: {epoch_metric_score}\\n\")\n",
    "                    print(f\"Patience = {patience_counter}/{patience}❗\\n\")\n",
    "                    \n",
    "                    f.write(\"\\nHuft 😥! Model not improved.\\n\")\n",
    "                    f.write(f\"Mean {str(criterion).split('(')[0]}: {epoch_loss} | Mean {str(metric).split('(')[0]}: {epoch_metric_score}\\n\")\n",
    "                    f.write(f\"Patience = {patience_counter}/{patience}❗\")\n",
    "                    \n",
    "            print(\"=\" * 75, end=\"\\n\\n\")\n",
    "            f.write(f\"{'=' * 75}\\n\\n\")\n",
    "            \n",
    "            if patience_counter > patience:\n",
    "                print(f\"Early stopping, patience = {patience_counter}/{patience}❗\")\n",
    "                break\n",
    "        \n",
    "        metric.reset()\n",
    "    \n",
    "    finish_time = time()\n",
    "    \n",
    "    # Training plot \n",
    "    fig, (ax_loss, ax_metric_score) = plt.subplots(nrows=1, ncols=2, figsize=(15, 5))\n",
    "\n",
    "    fig.suptitle(\"Training with context size = 79\")\n",
    "\n",
    "    ax_loss.set_title(\"Loss\")\n",
    "    ax_loss.set_xlabel(\"Epoch\")\n",
    "    ax_loss.set_ylabel(\"Score\")\n",
    "    ax_loss.plot(epoch_losses, \"green\")\n",
    "    ax_loss.grid()\n",
    "\n",
    "    ax_metric_score.set_title(\"F1 Score\")\n",
    "    ax_metric_score.set_xlabel(\"Epoch\")\n",
    "    ax_metric_score.set_ylabel(\"Score\")\n",
    "    ax_metric_score.plot(epoch_metric_scores, \"orange\")\n",
    "    ax_metric_score.grid()\n",
    "\n",
    "    plt.savefig(f\"../../logs/comick/{context_size}_contexts/{path_name}/training_plot.jpg\", dpi=200)                        \n",
    "    \n",
    "    print(f\"Training duration : {((finish_time - start_time) / 60):.3f} minutes.\")\n",
    "    print(f\"Training date     : {now}\")\n",
    "    \n",
    "    with open(f\"../../logs/comick/{context_size}_contexts/{path_name}/training_history.txt\", \"a\") as f:\n",
    "        f.write(f\"\\nTraining duration : {((finish_time - start_time) / 60):.3f} minutes.\\n\")\n",
    "        f.write(f\"Training date     : {now}\\n\")\n",
    "    \n",
    "    # Save epoch losses, epoch metric scores, model, state dict, and oov embedding dict\n",
    "    filename_epoch_losses = open(f\"../../logs/comick/{context_size}_contexts/{path_name}/epoch_losses.pkl\", \"ab\")\n",
    "    filename_epoch_metric_scores = open(f\"../../logs/comick/{context_size}_contexts/{path_name}/epoch_metric_scores.pkl\", \"ab\")\n",
    "    filename_model = f\"../../logs/comick/{context_size}_contexts/{path_name}/model.pth\"\n",
    "    filename_model_params = f\"../../logs/comick/{context_size}_contexts/{path_name}/model_params.pth\"\n",
    "    filename_oov_embedding_dict = open(f\"../../logs/comick/{context_size}_contexts/{path_name}/oov_embedding_dict.pkl\", \"ab\")\n",
    "    \n",
    "    pickle.dump(epoch_losses, filename_epoch_losses)\n",
    "    pickle.dump(epoch_metric_scores, filename_epoch_metric_scores)\n",
    "    torch.save(model, filename_model)\n",
    "    torch.save(model.state_dict(), filename_model_params)\n",
    "    pickle.dump({token : embedding for token, embedding in zip(list(labels_to_idx.keys()), model.embedding)}, filename_oov_embedding_dict)\n",
    "    \n",
    "    return epoch_losses, epoch_metric_scores\n",
    "\n",
    "epoch_losses, epoch_metric_scores = looping_step(dataloader, model, optimizer, criterion, metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92debcb3-d6ea-4299-a3e9-37be5b63d2b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.5499138 , -1.9751033 , -1.7879875 , ...,  1.1527858 ,\n",
       "         0.03963082,  0.44367683],\n",
       "       [ 1.6951178 ,  1.9306301 , -0.2435205 , ...,  2.785703  ,\n",
       "         0.4273495 ,  0.3968112 ],\n",
       "       [ 0.19984624,  0.51437753,  0.20232268, ..., -0.9993238 ,\n",
       "         0.2875412 ,  0.22083245],\n",
       "       ...,\n",
       "       [-0.14819346, -0.32812598, -0.15799104, ...,  0.54260445,\n",
       "         0.98711205, -2.1968477 ],\n",
       "       [-0.05783287, -1.4442116 , -1.5402805 , ..., -0.1933623 ,\n",
       "         0.52753735, -0.06522676],\n",
       "       [-0.02293971, -0.3746931 , -1.6810402 , ..., -0.64100564,\n",
       "         0.5874735 , -1.5297515 ]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0338a288-6f5f-41d5-8626-1cc1a20fbf73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
