{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13fc63c4-da08-43a8-9972-2615d377d1fa",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "313363b9-24d1-4b87-87cd-a0b7dd5fc128",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pytz\n",
    "import torch\n",
    "import timeit\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime\n",
    "from itertools import chain\n",
    "from time import time\n",
    "from torch import nn, optim\n",
    "from torchmetrics import F1Score\n",
    "from torch.optim import lr_scheduler\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from polyglot.mapping import Embedding, CaseExpander, DigitExpander"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b49405-006a-4a45-ae79-0e22f6a7172e",
   "metadata": {},
   "source": [
    "# Hyperparameters Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68709d29-24a1-45bf-b549-804952fd1db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hyperparams:\n",
    "     def __init__(\n",
    "        self,\n",
    "        context_size=79,\n",
    "        input_size_left_context=64,\n",
    "        input_size_oov_context=20,\n",
    "        input_size_right_context=64,\n",
    "        batch_size=32,\n",
    "        num_hidden_layer=1,\n",
    "        hidden_size=128,\n",
    "        output_size=3611,\n",
    "        shuffle=True,\n",
    "        lr=0.001,\n",
    "        batch_first=True,\n",
    "        bidirectional=True,\n",
    "        init_wb_with_kaiming_normal=True,\n",
    "        n_epoch=20,\n",
    "        patience=3,\n",
    "        device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    ):\n",
    "        self.context_size = context_size\n",
    "        self.input_size_left_context = input_size_left_context\n",
    "        self.input_size_oov_context = input_size_oov_context\n",
    "        self.input_size_right_context = input_size_right_context\n",
    "        self.batch_size = batch_size\n",
    "        self.num_hidden_layer = num_hidden_layer\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.shuffle = shuffle\n",
    "        self.lr = lr\n",
    "        self.batch_first = batch_first\n",
    "        self.bidirectional = bidirectional\n",
    "        self.init_wb_with_kaiming_normal = init_wb_with_kaiming_normal\n",
    "        self.n_epoch = n_epoch\n",
    "        self.patience = patience\n",
    "        self.device = device\n",
    "        \n",
    "hyperparams = Hyperparams()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f750b1-d4a7-4a2a-9fe1-369a61f28a2b",
   "metadata": {},
   "source": [
    "# Prepare Feature Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f241f20b-fb34-4db2-b887-1687f137b141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left context shape: (16562, 71)\n",
      "OOV context shape: (16562, 28)\n",
      "Right context shape: (16562, 79)\n",
      "Actual lable shape: (16562,)\n"
     ]
    }
   ],
   "source": [
    "def convert_doc_to_idxs(docs, dict_vocabs):\n",
    "    doc_to_idx = []\n",
    "    \n",
    "    for doc in docs:\n",
    "        doc_to_idx.append([dict_vocabs[token] for token in doc])\n",
    "        \n",
    "    return np.array(doc_to_idx)\n",
    "\n",
    "# Left context\n",
    "left_context = open(f\"../../datasets/features/{hyperparams.context_size}_context/left_context_with_pad.pkl\", \"rb\")\n",
    "left_context = pickle.load(left_context)\n",
    "left_context_to_idx = open(f\"../../datasets/features/{hyperparams.context_size}_context/token2idx_left_context.pkl\", \"rb\")\n",
    "left_context_to_idx = pickle.load(left_context_to_idx)\n",
    "doc_left_context_to_idx = convert_doc_to_idxs(left_context, left_context_to_idx)\n",
    "\n",
    "# OOV context\n",
    "oov_context = open(f\"../../datasets/features/{hyperparams.context_size}_context/oov_context_with_pad.pkl\", \"rb\")\n",
    "oov_context = pickle.load(oov_context)\n",
    "oov_context_to_idx = open(f\"../../datasets/features/{hyperparams.context_size}_context/token2idx_oov_context.pkl\", \"rb\")\n",
    "oov_context_to_idx = pickle.load(oov_context_to_idx)\n",
    "doc_oov_context_to_idx = convert_doc_to_idxs(oov_context, oov_context_to_idx)\n",
    "\n",
    "# Right context\n",
    "right_context = open(f\"../../datasets/features/{hyperparams.context_size}_context/right_context_with_pad.pkl\", \"rb\")\n",
    "right_context = pickle.load(right_context)\n",
    "right_context_to_idx = open(f\"../../datasets/features/{hyperparams.context_size}_context/token2idx_right_context.pkl\", \"rb\")\n",
    "right_context_to_idx = pickle.load(right_context_to_idx)\n",
    "doc_right_context_to_idx = convert_doc_to_idxs(right_context, right_context_to_idx)\n",
    "\n",
    "# Actual labels\n",
    "labels_context = open(f\"../../datasets/features/{hyperparams.context_size}_context/lables.pkl\", \"rb\")\n",
    "labels_context = pickle.load(labels_context)\n",
    "labels_to_idx = open(f\"../../datasets/features/{hyperparams.context_size}_context/lable_vocabs.pkl\", \"rb\")\n",
    "labels_to_idx = pickle.load(labels_to_idx)\n",
    "doc_labels_to_idx = convert_doc_to_idxs(labels_context, labels_to_idx).flatten()\n",
    "\n",
    "print(f\"Left context shape: {doc_left_context_to_idx.shape}\")\n",
    "print(f\"OOV context shape: {doc_oov_context_to_idx.shape}\")\n",
    "print(f\"Right context shape: {doc_right_context_to_idx.shape}\")\n",
    "print(f\"Actual lable shape: {doc_labels_to_idx.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe386c1f-3e1d-4589-b18e-42e4bc4055ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 2968, 10710,  1320,  1320,  1320,  1320,  1320,  1320,  1320,  1320,\n",
       "          1320,  1320,  1320,  1320,  1320,  1320,  1320,  1320,  1320,  1320,\n",
       "          1320,  1320,  1320,  1320,  1320,  1320,  1320,  1320,  1320,  1320,\n",
       "          1320,  1320,  1320,  1320,  1320,  1320,  1320,  1320,  1320,  1320,\n",
       "          1320,  1320,  1320,  1320,  1320,  1320,  1320,  1320,  1320,  1320,\n",
       "          1320,  1320,  1320,  1320,  1320,  1320,  1320,  1320,  1320,  1320,\n",
       "          1320,  1320,  1320,  1320,  1320,  1320,  1320,  1320,  1320,  1320,\n",
       "          1320]),\n",
       " tensor([19, 31, 19, 32, 29, 19, 32, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "         17, 17, 17, 17, 17, 17, 17, 17, 17, 17]),\n",
       " tensor([1929, 1929, 1929, 1929, 1929, 1929, 1929, 1929, 1929, 1929, 1929, 1929,\n",
       "         1929, 1929, 1929, 1929, 1929, 1929, 1929, 1929, 1929, 1929, 1929, 1929,\n",
       "         1929, 1929, 1929, 1929, 1929, 1929, 1929, 1929, 1929, 1929, 1929, 1929,\n",
       "         1929, 1929, 1929, 1929, 1929, 1929, 1929, 1929, 1929, 1929, 1929, 1929,\n",
       "         1929, 1929, 1929, 1929, 1929, 1929, 1929, 1929, 1929, 1929, 1929, 1929,\n",
       "         1929, 1929, 1929, 1929, 1929, 1929, 1929, 1929, 1929, 1929, 1929, 1929,\n",
       "         1929, 1929, 1929, 1929, 1929, 1929, 1929]),\n",
       " tensor(171))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to Tensor\n",
    "left_contexts = torch.LongTensor(doc_left_context_to_idx)\n",
    "oov_contexts = torch.LongTensor(doc_oov_context_to_idx)\n",
    "right_contexts = torch.LongTensor(doc_right_context_to_idx)\n",
    "actual_labels = torch.LongTensor(doc_labels_to_idx)\n",
    "dataset = TensorDataset(left_contexts, oov_contexts, right_contexts, actual_labels)\n",
    "\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8806cc8-c1d1-450a-833d-f25375c52949",
   "metadata": {},
   "source": [
    "# Char and Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86595b81-a95e-4469-acad-49b9ed2c9662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word Embedding\n",
    "word_embeddings = Embedding.load(\"../../word_embeddings/polyglot/idn_embeddings.tar.bz2\")\n",
    "word_embeddings.apply_expansion(DigitExpander)\n",
    "word_embeddings.apply_expansion(CaseExpander)\n",
    "\n",
    "left_vocabs = open(f\"../../datasets/features/{hyperparams.context_size}_context/left_context_vocabs.pkl\", \"rb\")\n",
    "left_vocabs = pickle.load(left_vocabs)\n",
    "\n",
    "right_vocabs = open(f\"../../datasets/features/{hyperparams.context_size}_context/right_context_vocabs.pkl\", \"rb\")\n",
    "right_vocabs = pickle.load(right_vocabs)\n",
    "\n",
    "left_word_embedding_dict = {left_context_to_idx[vocab] : word_embeddings[vocab] for vocab in left_vocabs}\n",
    "right_word_embedding_dict = {right_context_to_idx[vocab] : word_embeddings[vocab] for vocab in right_vocabs}\n",
    "\n",
    "# Char Embedding\n",
    "char_embedding_dict = open(\"../../word_embeddings/chars_embedding/char_embeddings.pkl\", \"rb\")\n",
    "char_embedding_dict = pickle.load(char_embedding_dict)\n",
    "\n",
    "# Context embedding\n",
    "left_context_embedding = nn.Embedding.from_pretrained(torch.FloatTensor(np.array(list(left_word_embedding_dict.values()))), padding_idx=left_vocabs.index(\"<PAD>\"), freeze=True)\n",
    "oov_context_embedding = nn.Embedding.from_pretrained(torch.FloatTensor(np.array(list(char_embedding_dict.values()))), padding_idx=list(char_embedding_dict.keys()).index(\"PAD\"), freeze=True)\n",
    "right_context_embedding = nn.Embedding.from_pretrained(torch.FloatTensor(np.array(list(right_word_embedding_dict.values()))), padding_idx=right_vocabs.index(\"<PAD>\"), freeze=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593ddcfe-1525-41ae-bf02-c9ebf3d957aa",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "998fb38d-da64-4b4c-9371-75e06ebfc8f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[    9,  3719,  1839,  ...,  1320,  1320,  1320],\n",
       "         [10547, 10582,  5134,  ...,  1320,  1320,  1320],\n",
       "         [ 7656, 10790,  6176,  ...,  1320,  1320,  1320],\n",
       "         ...,\n",
       "         [ 1320,  1320,  1320,  ...,  1320,  1320,  1320],\n",
       "         [    9,  6996,  1320,  ...,  1320,  1320,  1320],\n",
       "         [ 1320,  1320,  1320,  ...,  1320,  1320,  1320]]),\n",
       " tensor([[39, 32, 27, 37, 23, 21, 39, 36, 27, 32, 22, 33, 19, 17, 17, 17, 17, 17,\n",
       "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "         [ 3, 32, 43, 19, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "         [ 3, 32, 43, 19, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "         [26, 27, 38, 39, 32, 25,  3, 26, 27, 38, 39, 32, 25, 19, 32, 17, 17, 17,\n",
       "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "         [38, 20, 29,  4, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "         [39, 32, 37, 39, 36,  3, 39, 32, 37, 39, 36, 17, 17, 17, 17, 17, 17, 17,\n",
       "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "         [29, 33, 37, 38, 19, 31, 19, 32, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "         [31, 19, 32, 19, 28, 23, 31, 23, 32, 18, 36, 27, 37, 27, 29, 33, 17, 17,\n",
       "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "         [ 3, 32, 43, 19, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "         [33, 36, 19, 32, 25,  3, 33, 36, 19, 32, 25, 17, 17, 17, 17, 17, 17, 17,\n",
       "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "         [38, 26, 19, 43, 27, 20, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "         [ 3, 32, 43, 19, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "         [19, 27, 36, 18, 31, 27, 32, 39, 31, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "         [37, 26, 19, 26, 20, 23, 32, 22, 23, 36, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "         [31, 33, 22, 19, 30, 18, 29, 23, 36, 28, 19, 17, 17, 17, 17, 17, 17, 17,\n",
       "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "         [19, 32, 19, 29, 18, 34, 23, 36, 39, 37, 19, 26, 19, 19, 32, 17, 17, 17,\n",
       "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "         [31, 23, 32, 21, 19, 36, 27, 18, 38, 19, 26, 39, 17, 17, 17, 17, 17, 17,\n",
       "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "         [22, 27, 38, 23, 32, 25, 33, 29, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "         [29, 39, 36, 19, 32, 25, 18, 30, 23, 20, 27, 26, 17, 17, 17, 17, 17, 17,\n",
       "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "         [37, 23, 34, 23, 36, 38, 27, 18, 28, 39, 25, 19, 17, 17, 17, 17, 17, 17,\n",
       "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "         [ 3, 32, 43, 19, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "         [ 3, 32, 43, 19, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "         [ 3, 32, 43, 19, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "         [22,  4, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "         [ 3, 32, 43, 19, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "         [22, 23, 34, 29, 23, 39, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "         [ 3, 32, 43, 19, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "         [30, 19, 20, 19, 18, 20, 23, 36, 37, 27, 26, 17, 17, 17, 17, 17, 17, 17,\n",
       "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "         [30, 19, 29, 27,  3, 30, 19, 29, 27, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "         [29, 23, 18, 22, 23, 34, 19, 32, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "         [22, 19, 36, 31, 27, 32, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17],\n",
       "         [43, 19, 20, 39, 32, 19, 29, 19, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "          17, 17, 17, 17, 17, 17, 17, 17, 17, 17]]),\n",
       " tensor([[ 1966,    11,  1929,  ...,  1929,  1929,  1929],\n",
       "         [ 8902,  1929,  1929,  ...,  1929,  1929,  1929],\n",
       "         [10507,  8118,  9421,  ...,  1929,  1929,  1929],\n",
       "         ...,\n",
       "         [   11,  1929,  1929,  ...,  1929,  1929,  1929],\n",
       "         [   11,  1929,  1929,  ...,  1929,  1929,  1929],\n",
       "         [   11,  1929,  1929,  ...,  1929,  1929,  1929]]),\n",
       " tensor([3468,    8,    8, 1247, 3284, 3473, 1723, 1905,    8, 2330, 3355,    8,\n",
       "           88, 3036, 2157,  190, 2031,  882, 1756, 3010,    8,    8,    8,  711,\n",
       "            8,  774,    8, 1768, 1781, 1561,  743, 3566])]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=hyperparams.batch_size, shuffle=hyperparams.shuffle)\n",
    "next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5be550-2f41-41b4-9df4-ac67744041c5",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed852446-c649-4727-b9ff-64375cf7e966",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Comick(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size_left_context=hyperparams.input_size_left_context,\n",
    "        input_size_oov_context=hyperparams.input_size_oov_context,\n",
    "        input_size_right_context=hyperparams.input_size_right_context,\n",
    "        hidden_size=hyperparams.hidden_size,\n",
    "        num_layers=hyperparams.num_hidden_layer,\n",
    "        output_size=hyperparams.output_size,\n",
    "        batch_first=hyperparams.batch_first,\n",
    "        bidirectional=hyperparams.bidirectional,\n",
    "        init_wb_with_kaiming_normal=hyperparams.init_wb_with_kaiming_normal\n",
    "    ):\n",
    "        super(Comick, self).__init__()\n",
    "        \n",
    "        self.input_size_left_context = input_size_left_context\n",
    "        self.input_size_oov_context = input_size_oov_context\n",
    "        self.input_size_right_context = input_size_right_context\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.output_size = output_size\n",
    "        self.batch_first = batch_first\n",
    "        self.bidirectional = bidirectional\n",
    "        \n",
    "        self.bilstm_left_context_feature = nn.LSTM(\n",
    "            input_size = self.input_size_left_context,\n",
    "            hidden_size = self.hidden_size,\n",
    "            num_layers = self.num_layers,\n",
    "            batch_first = self.batch_first,\n",
    "            bidirectional = self.bidirectional\n",
    "        )\n",
    "        \n",
    "        self.bilstm_oov_context_feature = nn.LSTM(\n",
    "            input_size = self.input_size_oov_context,\n",
    "            hidden_size = self.hidden_size,\n",
    "            num_layers = self.num_layers,\n",
    "            batch_first = self.batch_first,\n",
    "            bidirectional = self.bidirectional\n",
    "        )\n",
    "        \n",
    "        self.bilstm_right_context_feature = nn.LSTM(\n",
    "            input_size = self.input_size_right_context,\n",
    "            hidden_size = self.hidden_size,\n",
    "            num_layers = self.num_layers,\n",
    "            batch_first = self.batch_first,\n",
    "            bidirectional = self.bidirectional\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(2 * self.hidden_size, 64),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "        self.oov_embedding = nn.Linear(in_features=3 * 64, out_features=64)\n",
    "        \n",
    "        self.embedding = np.empty((output_size, 64), dtype=np.float32)\n",
    "        \n",
    "        self.output = nn.Sequential(\n",
    "            nn.Linear(64, self.output_size),\n",
    "            nn.LogSoftmax(dim=1)\n",
    "        )\n",
    "                \n",
    "        if init_wb_with_kaiming_normal:\n",
    "            self.init_wb()\n",
    "            \n",
    "    def init_wb(self):\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, (nn.Linear, nn.LSTM)):\n",
    "                for name, param in module.named_parameters():\n",
    "                    if \"weight\" in name:\n",
    "                        nn.init.kaiming_normal_(param)\n",
    "                    else:\n",
    "                        nn.init.kaiming_normal_(param.reshape(1, -1))\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_left_context,\n",
    "        input_oov_context,\n",
    "        input_right_context,\n",
    "        idxs_target,\n",
    "        hidden_left_context=None,\n",
    "        hidden_oov_context=None,\n",
    "        hidden_right_context=None,\n",
    "    ):\n",
    "        # BiLSTM left, oov, and right context\n",
    "        output_left_context, (hidden_left_context, memory_left_context) = self.bilstm_left_context_feature(input_left_context, hidden_left_context)\n",
    "        output_oov_context, (hidden_oov_context, memory_oov_context) = self.bilstm_oov_context_feature(input_oov_context, hidden_oov_context)\n",
    "        output_right_context, (hidden_right_context, memory_right_context) = self.bilstm_right_context_feature(input_right_context, hidden_right_context)\n",
    "                \n",
    "        # Concate hidden (forward and backward hidden BiLSTM)\n",
    "        hidden_left_bidirectional = torch.cat((hidden_left_context[0], hidden_left_context[-1]), dim=1)\n",
    "        hidden_oov_bidirectional = torch.cat((hidden_oov_context[0], hidden_oov_context[-1]), dim=1)\n",
    "        hidden_right_bidirectional = torch.cat((hidden_right_context[0], hidden_right_context[-1]), dim=1)\n",
    "        \n",
    "        # Fully connected\n",
    "        output_left_fc = self.fc(hidden_left_bidirectional)\n",
    "        output_oov_fc = self.fc(hidden_oov_bidirectional)\n",
    "        output_right_fc = self.fc(hidden_right_bidirectional)\n",
    "        \n",
    "        # Concate output left, oov, and right context feature\n",
    "        output = torch.cat((output_left_fc, output_oov_fc, output_right_fc), dim=1)\n",
    "        \n",
    "        # OOV embedding\n",
    "        output = self.oov_embedding(output)\n",
    "                \n",
    "        # save OOV embedding\n",
    "        self.embedding[idxs_target.tolist()] = output.cpu().detach().numpy()\n",
    "        \n",
    "        # Projection OOV embedding\n",
    "        output = self.output(output)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992eb40b-9062-47f1-9703-65e80d6cb07d",
   "metadata": {},
   "source": [
    "# Model, Optimizer, Criterion, Metric, and Learning Rate Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b08d05fc-0bb5-426e-aa7b-eb930ba9f06b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Comick(\n",
       "  (bilstm_left_context_feature): LSTM(64, 128, batch_first=True, bidirectional=True)\n",
       "  (bilstm_oov_context_feature): LSTM(20, 128, batch_first=True, bidirectional=True)\n",
       "  (bilstm_right_context_feature): LSTM(64, 128, batch_first=True, bidirectional=True)\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (1): Tanh()\n",
       "  )\n",
       "  (oov_embedding): Linear(in_features=192, out_features=64, bias=True)\n",
       "  (output): Sequential(\n",
       "    (0): Linear(in_features=64, out_features=3611, bias=True)\n",
       "    (1): LogSoftmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Comick().to(hyperparams.device)\n",
    "model.output[0].requires_grad_ = False # disable gradient for projection layer\n",
    "optimizer = optim.Adam(model.parameters(), lr=hyperparams.lr)\n",
    "criterion = nn.NLLLoss(ignore_index=list(char_embedding_dict.keys()).index(\"PAD\")).to(hyperparams.device)\n",
    "metric = F1Score(ignore_index=list(char_embedding_dict.keys()).index(\"PAD\")).to(hyperparams.device)\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.5)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d463d75-dd43-4b45-9eec-8f4aca21b018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "814,427\n"
     ]
    }
   ],
   "source": [
    "print(f\"{sum([param.numel() for param in model.parameters() if param.requires_grad_]):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "494a567d-acbc-46c2-adc8-b9a512366c17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b39ba3-b103-44da-ae1e-34fd12ad2d2f",
   "metadata": {},
   "source": [
    "# Training Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c51a3a6-a4af-425f-aa1f-34ffe9ff8248",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_step(dataloader, model, optimizer, criterion, metric, scheduler=None, path_name=None):\n",
    "    model.train()\n",
    "    \n",
    "    batch_losses = []\n",
    "    batch_metric_scores = []\n",
    "    \n",
    "    for batch, (input_left_context, input_oov_context, input_right_context, actual_label) in enumerate(tqdm(dataloader), 1):\n",
    "        # Forward Propagation\n",
    "        probs = model(\n",
    "            left_context_embedding(input_left_context).to(hyperparams.device),\n",
    "            oov_context_embedding(input_oov_context).to(hyperparams.device),\n",
    "            right_context_embedding(input_right_context).to(hyperparams.device),\n",
    "            actual_label.to(hyperparams.device)\n",
    "        )\n",
    "                \n",
    "        loss = criterion(probs, actual_label.to(hyperparams.device))\n",
    "        metric_score = metric(probs.argmax(dim=1), actual_label.to(hyperparams.device))\n",
    "        metric_score = metric.compute()\n",
    "        \n",
    "        if scheduler is not None:\n",
    "            scheduler.step(loss)\n",
    "        \n",
    "        batch_losses.append(loss.item())\n",
    "        batch_metric_scores.append(metric_score)\n",
    "        \n",
    "        if batch % 50 == 0 or batch == len(dataloader):\n",
    "            print(f\"Batch-{batch}: {str(criterion).split('(')[0]}={(loss.item()):.4f} | {str(metric).split('(')[0]}={(metric_score):.4f}\")\n",
    "            with open(f\"../../logs/comick/{hyperparams.context_size}_contexts/{path_name}/training_history.txt\", \"a\") as f:\n",
    "                f.write(f\"Batch-{batch}: {str(criterion).split('(')[0]}={(loss.item()):.4f} | {str(metric).split('(')[0]}={(metric_score):.4f}\\n\")\n",
    "\n",
    "        # Backward Propagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    return batch_losses, batch_metric_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3043a1-39cb-4b38-8024-54f909a565a9",
   "metadata": {},
   "source": [
    "# Looping Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e139244-b036-4d45-beca-1de5bd7b5e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH-1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5e8fddd63ab463eb808834d79fe3cac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50: NLLLoss=6.4237 | F1Score=0.2801\n",
      "Batch-100: NLLLoss=5.7180 | F1Score=0.3000\n",
      "Batch-150: NLLLoss=5.0416 | F1Score=0.3221\n",
      "Batch-200: NLLLoss=5.3826 | F1Score=0.3503\n",
      "Batch-250: NLLLoss=3.9032 | F1Score=0.3686\n",
      "Batch-300: NLLLoss=3.6627 | F1Score=0.3876\n",
      "Batch-350: NLLLoss=4.3465 | F1Score=0.4011\n",
      "Batch-400: NLLLoss=2.4487 | F1Score=0.4146\n",
      "Batch-450: NLLLoss=3.1837 | F1Score=0.4259\n",
      "Batch-500: NLLLoss=3.5804 | F1Score=0.4402\n",
      "Batch-518: NLLLoss=4.2556 | F1Score=0.4441\n",
      "\n",
      "Mean NLLLoss: 4.4573 | Mean F1Score: 0.3603\n",
      "==================================================\n",
      "\n",
      "EPOCH-2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bfd881a979d4ef6b3b5f2b1a5823c8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50: NLLLoss=2.9393 | F1Score=0.5894\n",
      "Batch-100: NLLLoss=2.6245 | F1Score=0.5997\n",
      "Batch-150: NLLLoss=2.0036 | F1Score=0.6100\n",
      "Batch-200: NLLLoss=2.3760 | F1Score=0.6135\n",
      "Batch-250: NLLLoss=3.1795 | F1Score=0.6187\n",
      "Batch-300: NLLLoss=3.2608 | F1Score=0.6236\n",
      "Batch-350: NLLLoss=2.3802 | F1Score=0.6262\n",
      "Batch-400: NLLLoss=2.6555 | F1Score=0.6292\n",
      "Batch-450: NLLLoss=2.6609 | F1Score=0.6357\n",
      "Batch-500: NLLLoss=1.8123 | F1Score=0.6407\n",
      "Batch-518: NLLLoss=3.5292 | F1Score=0.6424\n",
      "\n",
      "Yeah 🎉😄! Model improved.\n",
      "Mean NLLLoss: 2.6724 | Mean F1Score: 0.6170\n",
      "==================================================\n",
      "\n",
      "EPOCH-3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43210861bfa34f64ad3c7c2e82df469a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50: NLLLoss=1.3980 | F1Score=0.7106\n",
      "Batch-100: NLLLoss=2.1890 | F1Score=0.7184\n",
      "Batch-150: NLLLoss=2.0994 | F1Score=0.7281\n",
      "Batch-200: NLLLoss=1.7472 | F1Score=0.7250\n",
      "Batch-250: NLLLoss=2.1877 | F1Score=0.7289\n",
      "Batch-300: NLLLoss=1.7407 | F1Score=0.7315\n",
      "Batch-350: NLLLoss=2.2693 | F1Score=0.7357\n",
      "Batch-400: NLLLoss=0.9978 | F1Score=0.7369\n",
      "Batch-450: NLLLoss=1.5233 | F1Score=0.7424\n",
      "Batch-500: NLLLoss=1.6878 | F1Score=0.7468\n",
      "Batch-518: NLLLoss=1.0592 | F1Score=0.7465\n",
      "\n",
      "Yeah 🎉😄! Model improved.\n",
      "Mean NLLLoss: 1.7778 | Mean F1Score: 0.7302\n",
      "==================================================\n",
      "\n",
      "EPOCH-4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb10f9bd9f3d4b8ea634726d9cf790ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50: NLLLoss=1.2174 | F1Score=0.8163\n",
      "Batch-100: NLLLoss=1.1005 | F1Score=0.8194\n",
      "Batch-150: NLLLoss=1.0872 | F1Score=0.8142\n",
      "Batch-200: NLLLoss=1.9744 | F1Score=0.8094\n",
      "Batch-250: NLLLoss=1.7209 | F1Score=0.8124\n",
      "Batch-300: NLLLoss=0.7978 | F1Score=0.8123\n",
      "Batch-350: NLLLoss=1.7382 | F1Score=0.8125\n",
      "Batch-400: NLLLoss=1.4811 | F1Score=0.8122\n",
      "Batch-450: NLLLoss=1.7036 | F1Score=0.8128\n",
      "Batch-500: NLLLoss=1.6679 | F1Score=0.8150\n",
      "Batch-518: NLLLoss=0.7858 | F1Score=0.8155\n",
      "\n",
      "Yeah 🎉😄! Model improved.\n",
      "Mean NLLLoss: 1.1665 | Mean F1Score: 0.8141\n",
      "==================================================\n",
      "\n",
      "EPOCH-5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11e2ff4f071244d78afcd5efb57908c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50: NLLLoss=0.7030 | F1Score=0.8919\n",
      "Batch-100: NLLLoss=0.9888 | F1Score=0.8826\n",
      "Batch-150: NLLLoss=0.8599 | F1Score=0.8816\n",
      "Batch-200: NLLLoss=0.6009 | F1Score=0.8802\n",
      "Batch-250: NLLLoss=0.4554 | F1Score=0.8784\n",
      "Batch-300: NLLLoss=0.5178 | F1Score=0.8764\n",
      "Batch-350: NLLLoss=0.4879 | F1Score=0.8753\n",
      "Batch-400: NLLLoss=0.6194 | F1Score=0.8744\n",
      "Batch-450: NLLLoss=1.0866 | F1Score=0.8723\n",
      "Batch-500: NLLLoss=0.7891 | F1Score=0.8704\n",
      "Batch-518: NLLLoss=0.6812 | F1Score=0.8691\n",
      "\n",
      "Yeah 🎉😄! Model improved.\n",
      "Mean NLLLoss: 0.7094 | Mean F1Score: 0.8796\n",
      "==================================================\n",
      "\n",
      "EPOCH-6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afccf94d84c74d6e9a71ea1e76b64219",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50: NLLLoss=0.1991 | F1Score=0.9515\n",
      "Batch-100: NLLLoss=0.4706 | F1Score=0.9461\n",
      "Batch-150: NLLLoss=0.1474 | F1Score=0.9468\n",
      "Batch-200: NLLLoss=0.4013 | F1Score=0.9449\n",
      "Batch-250: NLLLoss=0.5278 | F1Score=0.9442\n",
      "Batch-300: NLLLoss=0.2125 | F1Score=0.9416\n",
      "Batch-350: NLLLoss=0.5702 | F1Score=0.9387\n",
      "Batch-400: NLLLoss=0.1883 | F1Score=0.9378\n",
      "Batch-450: NLLLoss=0.1977 | F1Score=0.9367\n",
      "Batch-500: NLLLoss=0.2879 | F1Score=0.9365\n",
      "Batch-518: NLLLoss=0.0790 | F1Score=0.9365\n",
      "\n",
      "Yeah 🎉😄! Model improved.\n",
      "Mean NLLLoss: 0.3474 | Mean F1Score: 0.9432\n",
      "==================================================\n",
      "\n",
      "EPOCH-7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31574c0480334ce0a9a7a8cff104069b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50: NLLLoss=0.0445 | F1Score=0.9906\n",
      "Batch-100: NLLLoss=0.1166 | F1Score=0.9909\n",
      "Batch-150: NLLLoss=0.0753 | F1Score=0.9890\n",
      "Batch-200: NLLLoss=0.2659 | F1Score=0.9877\n",
      "Batch-250: NLLLoss=0.1094 | F1Score=0.9876\n",
      "Batch-300: NLLLoss=0.1254 | F1Score=0.9872\n",
      "Batch-350: NLLLoss=0.0207 | F1Score=0.9877\n",
      "Batch-400: NLLLoss=0.0734 | F1Score=0.9871\n",
      "Batch-450: NLLLoss=0.1181 | F1Score=0.9867\n",
      "Batch-500: NLLLoss=0.2159 | F1Score=0.9866\n",
      "Batch-518: NLLLoss=0.1631 | F1Score=0.9862\n",
      "\n",
      "Yeah 🎉😄! Model improved.\n",
      "Mean NLLLoss: 0.1177 | Mean F1Score: 0.9885\n",
      "==================================================\n",
      "\n",
      "EPOCH-8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "364c585e6cbf4b96bc532a018bb30dac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50: NLLLoss=0.0184 | F1Score=0.9981\n",
      "Batch-100: NLLLoss=0.0296 | F1Score=0.9984\n",
      "Batch-150: NLLLoss=0.0422 | F1Score=0.9981\n",
      "Batch-200: NLLLoss=0.0346 | F1Score=0.9984\n",
      "Batch-250: NLLLoss=0.0134 | F1Score=0.9983\n",
      "Batch-300: NLLLoss=0.0106 | F1Score=0.9982\n",
      "Batch-350: NLLLoss=0.0414 | F1Score=0.9983\n",
      "Batch-400: NLLLoss=0.0360 | F1Score=0.9982\n",
      "Batch-450: NLLLoss=0.1088 | F1Score=0.9980\n",
      "Batch-500: NLLLoss=0.0436 | F1Score=0.9979\n",
      "Batch-518: NLLLoss=0.0379 | F1Score=0.9977\n",
      "\n",
      "Yeah 🎉😄! Model improved.\n",
      "Mean NLLLoss: 0.0331 | Mean F1Score: 0.9982\n",
      "==================================================\n",
      "\n",
      "EPOCH-9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f47f6a4fb0442549682f491f01fdd69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50: NLLLoss=0.0112 | F1Score=0.9994\n",
      "Batch-100: NLLLoss=0.0125 | F1Score=0.9994\n",
      "Batch-150: NLLLoss=0.0281 | F1Score=0.9985\n",
      "Batch-200: NLLLoss=0.0125 | F1Score=0.9989\n",
      "Batch-250: NLLLoss=0.0034 | F1Score=0.9989\n",
      "Batch-300: NLLLoss=0.0147 | F1Score=0.9987\n",
      "Batch-350: NLLLoss=0.0081 | F1Score=0.9987\n",
      "Batch-400: NLLLoss=0.0353 | F1Score=0.9988\n",
      "Batch-450: NLLLoss=0.0093 | F1Score=0.9990\n",
      "Batch-500: NLLLoss=0.0093 | F1Score=0.9989\n",
      "Batch-518: NLLLoss=0.0060 | F1Score=0.9990\n",
      "\n",
      "Yeah 🎉😄! Model improved.\n",
      "Mean NLLLoss: 0.0156 | Mean F1Score: 0.9990\n",
      "==================================================\n",
      "\n",
      "EPOCH-10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d730540c2c574bb68da5db52c281a6cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50: NLLLoss=0.0059 | F1Score=0.9994\n",
      "Batch-100: NLLLoss=0.0023 | F1Score=0.9997\n",
      "Batch-150: NLLLoss=0.0091 | F1Score=0.9994\n",
      "Batch-200: NLLLoss=0.0059 | F1Score=0.9995\n",
      "Batch-250: NLLLoss=0.0080 | F1Score=0.9994\n",
      "Batch-300: NLLLoss=0.0039 | F1Score=0.9994\n",
      "Batch-350: NLLLoss=0.0037 | F1Score=0.9993\n",
      "Batch-400: NLLLoss=0.0042 | F1Score=0.9993\n",
      "Batch-450: NLLLoss=0.0036 | F1Score=0.9994\n",
      "Batch-500: NLLLoss=0.0052 | F1Score=0.9994\n",
      "Batch-518: NLLLoss=0.0016 | F1Score=0.9993\n",
      "\n",
      "Yeah 🎉😄! Model improved.\n",
      "Mean NLLLoss: 0.0074 | Mean F1Score: 0.9995\n",
      "==================================================\n",
      "\n",
      "EPOCH-11\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35f5768f50c14b28b08c56f54d75caa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50: NLLLoss=0.0050 | F1Score=1.0000\n",
      "Batch-100: NLLLoss=0.0036 | F1Score=0.9998\n",
      "Batch-150: NLLLoss=0.0036 | F1Score=0.9999\n",
      "Batch-200: NLLLoss=0.0038 | F1Score=0.9999\n",
      "Batch-250: NLLLoss=0.0032 | F1Score=0.9999\n",
      "Batch-300: NLLLoss=0.0041 | F1Score=0.9999\n",
      "Batch-350: NLLLoss=0.0066 | F1Score=0.9999\n",
      "Batch-400: NLLLoss=0.0046 | F1Score=0.9997\n",
      "Batch-450: NLLLoss=0.0063 | F1Score=0.9996\n",
      "Batch-500: NLLLoss=0.0039 | F1Score=0.9996\n",
      "Batch-518: NLLLoss=0.0060 | F1Score=0.9996\n",
      "\n",
      "Yeah 🎉😄! Model improved.\n",
      "Mean NLLLoss: 0.0067 | Mean F1Score: 0.9998\n",
      "==================================================\n",
      "\n",
      "EPOCH-12\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a55b91e86cb34f4b914d2404f443e1b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50: NLLLoss=0.0026 | F1Score=1.0000\n",
      "Batch-100: NLLLoss=0.0022 | F1Score=1.0000\n",
      "Batch-150: NLLLoss=0.0050 | F1Score=0.9996\n",
      "Batch-200: NLLLoss=0.0026 | F1Score=0.9995\n",
      "Batch-250: NLLLoss=0.0041 | F1Score=0.9994\n",
      "Batch-300: NLLLoss=0.0042 | F1Score=0.9994\n",
      "Batch-350: NLLLoss=0.0250 | F1Score=0.9993\n",
      "Batch-400: NLLLoss=0.0033 | F1Score=0.9994\n",
      "Batch-450: NLLLoss=0.0121 | F1Score=0.9992\n",
      "Batch-500: NLLLoss=0.2727 | F1Score=0.9944\n",
      "Batch-518: NLLLoss=0.3511 | F1Score=0.9908\n",
      "\n",
      "Huft 😥! Model not improved.\n",
      "Mean NLLLoss: 0.0445 | Mean F1Score: 0.9991\n",
      "Patience = 1/3❗\n",
      "==================================================\n",
      "\n",
      "EPOCH-13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6e5ba6866d14facb69997bf7e4b11d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50: NLLLoss=0.1318 | F1Score=0.9081\n",
      "Batch-100: NLLLoss=0.3195 | F1Score=0.9151\n",
      "Batch-150: NLLLoss=0.1430 | F1Score=0.9191\n",
      "Batch-200: NLLLoss=0.1272 | F1Score=0.9285\n",
      "Batch-250: NLLLoss=0.3360 | F1Score=0.9327\n",
      "Batch-300: NLLLoss=0.2216 | F1Score=0.9382\n",
      "Batch-350: NLLLoss=0.1960 | F1Score=0.9425\n",
      "Batch-400: NLLLoss=0.1558 | F1Score=0.9458\n",
      "Batch-450: NLLLoss=0.0708 | F1Score=0.9487\n",
      "Batch-500: NLLLoss=0.1797 | F1Score=0.9513\n",
      "Batch-518: NLLLoss=0.1059 | F1Score=0.9524\n",
      "\n",
      "Huft 😥! Model not improved.\n",
      "Mean NLLLoss: 0.1987 | Mean F1Score: 0.9305\n",
      "Patience = 2/3❗\n",
      "==================================================\n",
      "\n",
      "EPOCH-14\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "213a22a022d341f8b11f3eaf1beef7a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50: NLLLoss=0.0245 | F1Score=0.9975\n",
      "Batch-100: NLLLoss=0.0100 | F1Score=0.9969\n",
      "Batch-150: NLLLoss=0.0117 | F1Score=0.9972\n",
      "Batch-200: NLLLoss=0.0129 | F1Score=0.9973\n",
      "Batch-250: NLLLoss=0.0079 | F1Score=0.9976\n",
      "Batch-300: NLLLoss=0.0046 | F1Score=0.9978\n",
      "Batch-350: NLLLoss=0.0070 | F1Score=0.9979\n",
      "Batch-400: NLLLoss=0.0094 | F1Score=0.9977\n",
      "Batch-450: NLLLoss=0.0044 | F1Score=0.9979\n",
      "Batch-500: NLLLoss=0.0078 | F1Score=0.9981\n",
      "Batch-518: NLLLoss=0.0047 | F1Score=0.9981\n",
      "\n",
      "Yeah 🎉😄! Model improved.\n",
      "Mean NLLLoss: 0.0135 | Mean F1Score: 0.9974\n",
      "==================================================\n",
      "\n",
      "EPOCH-15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ffc348f8e044b7f884ada55bb9c0f87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50: NLLLoss=0.0024 | F1Score=0.9994\n",
      "Batch-100: NLLLoss=0.0016 | F1Score=0.9997\n",
      "Batch-150: NLLLoss=0.0024 | F1Score=0.9998\n",
      "Batch-200: NLLLoss=0.0016 | F1Score=0.9998\n",
      "Batch-250: NLLLoss=0.0038 | F1Score=0.9998\n",
      "Batch-300: NLLLoss=0.0011 | F1Score=0.9997\n",
      "Batch-350: NLLLoss=0.0016 | F1Score=0.9997\n",
      "Batch-400: NLLLoss=0.0047 | F1Score=0.9997\n",
      "Batch-450: NLLLoss=0.0020 | F1Score=0.9997\n",
      "Batch-500: NLLLoss=0.0009 | F1Score=0.9997\n",
      "Batch-518: NLLLoss=0.0004 | F1Score=0.9998\n",
      "\n",
      "Yeah 🎉😄! Model improved.\n",
      "Mean NLLLoss: 0.0025 | Mean F1Score: 0.9997\n",
      "==================================================\n",
      "\n",
      "EPOCH-16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0a166f63e804bc9990c5d4172f3b37c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50: NLLLoss=0.0011 | F1Score=1.0000\n",
      "Batch-100: NLLLoss=0.0012 | F1Score=0.9998\n",
      "Batch-150: NLLLoss=0.0015 | F1Score=0.9999\n",
      "Batch-200: NLLLoss=0.0010 | F1Score=0.9998\n",
      "Batch-250: NLLLoss=0.0022 | F1Score=0.9998\n",
      "Batch-300: NLLLoss=0.0013 | F1Score=0.9998\n",
      "Batch-350: NLLLoss=0.0020 | F1Score=0.9998\n",
      "Batch-400: NLLLoss=0.0013 | F1Score=0.9998\n",
      "Batch-450: NLLLoss=0.0013 | F1Score=0.9997\n",
      "Batch-500: NLLLoss=0.0005 | F1Score=0.9997\n",
      "Batch-518: NLLLoss=0.0006 | F1Score=0.9997\n",
      "\n",
      "Yeah 🎉😄! Model improved.\n",
      "Mean NLLLoss: 0.0016 | Mean F1Score: 0.9998\n",
      "==================================================\n",
      "\n",
      "EPOCH-17\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23d1eb9ae09b4e67bec8429859103905",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50: NLLLoss=0.0010 | F1Score=1.0000\n",
      "Batch-100: NLLLoss=0.0004 | F1Score=1.0000\n",
      "Batch-150: NLLLoss=0.0012 | F1Score=1.0000\n",
      "Batch-200: NLLLoss=0.0006 | F1Score=0.9998\n",
      "Batch-250: NLLLoss=0.0006 | F1Score=0.9999\n",
      "Batch-300: NLLLoss=0.0009 | F1Score=0.9999\n",
      "Batch-350: NLLLoss=0.0016 | F1Score=0.9998\n",
      "Batch-400: NLLLoss=0.0005 | F1Score=0.9998\n",
      "Batch-450: NLLLoss=0.0012 | F1Score=0.9999\n",
      "Batch-500: NLLLoss=0.0009 | F1Score=0.9999\n",
      "Batch-518: NLLLoss=0.0005 | F1Score=0.9999\n",
      "\n",
      "Yeah 🎉😄! Model improved.\n",
      "Mean NLLLoss: 0.0010 | Mean F1Score: 0.9999\n",
      "==================================================\n",
      "\n",
      "EPOCH-18\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4a1c3e26506430d9624763b6f0c3340",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50: NLLLoss=0.0004 | F1Score=1.0000\n",
      "Batch-100: NLLLoss=0.0008 | F1Score=1.0000\n",
      "Batch-150: NLLLoss=0.0012 | F1Score=0.9999\n",
      "Batch-200: NLLLoss=0.0004 | F1Score=0.9999\n",
      "Batch-250: NLLLoss=0.0005 | F1Score=0.9999\n",
      "Batch-300: NLLLoss=0.0010 | F1Score=0.9999\n",
      "Batch-350: NLLLoss=0.0007 | F1Score=0.9999\n",
      "Batch-400: NLLLoss=0.0007 | F1Score=0.9999\n",
      "Batch-450: NLLLoss=0.0010 | F1Score=0.9999\n",
      "Batch-500: NLLLoss=0.0007 | F1Score=0.9999\n",
      "Batch-518: NLLLoss=0.0005 | F1Score=0.9999\n",
      "\n",
      "Yeah 🎉😄! Model improved.\n",
      "Mean NLLLoss: 0.0008 | Mean F1Score: 0.9999\n",
      "==================================================\n",
      "\n",
      "EPOCH-19\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b47e5fc40c7421f9be4337e5c60474a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50: NLLLoss=0.0005 | F1Score=1.0000\n",
      "Batch-100: NLLLoss=0.0010 | F1Score=0.9998\n",
      "Batch-150: NLLLoss=0.0007 | F1Score=0.9999\n",
      "Batch-200: NLLLoss=0.0004 | F1Score=0.9999\n",
      "Batch-250: NLLLoss=0.0004 | F1Score=0.9998\n",
      "Batch-300: NLLLoss=0.0009 | F1Score=0.9997\n",
      "Batch-350: NLLLoss=0.0014 | F1Score=0.9997\n",
      "Batch-400: NLLLoss=0.0010 | F1Score=0.9997\n",
      "Batch-450: NLLLoss=0.0003 | F1Score=0.9998\n",
      "Batch-500: NLLLoss=0.0006 | F1Score=0.9997\n",
      "Batch-518: NLLLoss=0.0004 | F1Score=0.9998\n",
      "\n",
      "Huft 😥! Model not improved.\n",
      "Mean NLLLoss: 0.0014 | Mean F1Score: 0.9998\n",
      "Patience = 3/3❗\n",
      "==================================================\n",
      "\n",
      "Early stopping, patience = 3/3❗\n",
      "\n",
      "TRAINING SUMMARY\n",
      "Best NLLLoss : 0.0008\n",
      "Best F1Score    : 0.9999\n",
      "Training duration                   : 3.535 minutes.\n",
      "Training date                       : 2022-09-29 12:20:11.610210+08:00\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def looping_step(dataloader, model, optimizer, criterion, metric, n_epoch=hyperparams.n_epoch, patience=hyperparams.patience, monitor=\"loss\"):    \n",
    "    start_time = time()\n",
    "    \n",
    "    epoch_losses = []\n",
    "    epoch_metric_scores = []\n",
    "    patience_counter = 0\n",
    "    \n",
    "    now = datetime.now(pytz.timezone(\"Asia/Ujung_Pandang\"))\n",
    "    path_name = now.strftime(\"%m-%d-%Y_%H-%M-%S\")\n",
    "    os.makedirs(f\"../../logs/comick/{hyperparams.context_size}_contexts/{path_name}\")\n",
    "    \n",
    "    # Hyperparameters\n",
    "    with open(f\"../../logs/comick/{hyperparams.context_size}_contexts/{path_name}/training_history.txt\", \"a\") as f:\n",
    "        f.write(f\"HYPERPARAMETERS\\n\")\n",
    "        f.write(f\"{'-' * 50}\\n\")\n",
    "        for name, value in vars(hyperparams).items():\n",
    "            f.write(f\"{name}: {value}\\n\")\n",
    "        \n",
    "        f.write(\"\\n\")\n",
    "        f.write(\"TRAINING PROGRESS\\n\")\n",
    "        f.write(f\"{'-' * 50}\\n\")\n",
    "    \n",
    "    # Training Progress\n",
    "    for epoch in range(1, n_epoch + 1):\n",
    "        print(f\"EPOCH-{epoch}\")\n",
    "        with open(f\"../../logs/comick/{hyperparams.context_size}_contexts/{path_name}/training_history.txt\", \"a\") as f:\n",
    "            f.write(f\"EPOCH-{epoch}\\n\")\n",
    "        \n",
    "        batch_losses, batch_metric_scores = training_step(dataloader, model, optimizer, criterion, metric, path_name=path_name)\n",
    "        epoch_loss = torch.mean(torch.FloatTensor(batch_losses))\n",
    "\n",
    "        epoch_loss = torch.mean(torch.FloatTensor(batch_losses))\n",
    "        epoch_losses.append(epoch_loss.item())\n",
    "\n",
    "        epoch_metric_score = torch.mean(torch.FloatTensor(batch_metric_scores))\n",
    "        epoch_metric_scores.append(epoch_metric_score.item())\n",
    "        \n",
    "        with open(f\"../../logs/comick/{hyperparams.context_size}_contexts/{path_name}/training_history.txt\", \"a\") as f:\n",
    "            if monitor == \"loss\":\n",
    "                if epoch == 1:\n",
    "                    best_state_dict = model.state_dict()\n",
    "                    best_loss = (epoch_loss)\n",
    "                    best_metric = (epoch_metric_score)\n",
    "                    \n",
    "                    print(f\"\\nMean {str(criterion).split('(')[0]}: {(epoch_loss):.4f} | Mean {str(metric).split('(')[0]}: {(epoch_metric_score):.4f}\")\n",
    "                    \n",
    "                    f.write(f\"\\nMean {str(criterion).split('(')[0]}: {(epoch_loss):.4f} | Mean {str(metric).split('(')[0]}: {(epoch_metric_score):.4f}\\n\")\n",
    "                elif epoch_losses[-1] < epoch_losses[-2]:\n",
    "                    best_state_dict = model.state_dict()\n",
    "                    best_loss = (epoch_loss)\n",
    "                    best_metric = (epoch_metric_score)\n",
    "                    \n",
    "                    print(\"\\nYeah 🎉😄! Model improved.\")\n",
    "                    print(f\"Mean {str(criterion).split('(')[0]}: {(epoch_loss):.4f} | Mean {str(metric).split('(')[0]}: {(epoch_metric_score):.4f}\")\n",
    "                    \n",
    "                    f.write(\"\\nYeah 🎉😄! Model improved.\\n\")\n",
    "                    f.write(f\"Mean {str(criterion).split('(')[0]}: {(epoch_loss):.4f} | Mean {str(metric).split('(')[0]}: {(epoch_metric_score):.4f}\\n\")\n",
    "                else:\n",
    "                    patience_counter += 1\n",
    "                    \n",
    "                    print(\"\\nHuft 😥! Model not improved.\")\n",
    "                    print(f\"Mean {str(criterion).split('(')[0]}: {(epoch_loss):.4f} | Mean {str(metric).split('(')[0]}: {(epoch_metric_score):.4f}\")\n",
    "                    print(f\"Patience = {patience_counter}/{patience}❗\")\n",
    "                    \n",
    "                    f.write(\"\\nHuft 😥! Model not improved.\\n\")\n",
    "                    f.write(f\"Mean {str(criterion).split('(')[0]}: {(epoch_loss):.4f} | Mean {str(metric).split('(')[0]}: {(epoch_metric_score):.4f}\\n\")                    \n",
    "                    f.write(f\"Patience = {patience_counter}/{patience}❗\\n\")\n",
    "            else:\n",
    "                if epoch == 1:\n",
    "                    best_state_dict = model.state_dict()\n",
    "                    best_loss = (epoch_loss)\n",
    "                    best_metric = (epoch_metric_score)\n",
    "                    \n",
    "                    print(f\"\\nMean {str(criterion).split('(')[0]}: {(epoch_loss):.4f} | Mean {str(metric).split('(')[0]}: {(epoch_metric_score):.4f}\")\n",
    "                    \n",
    "                    f.write(f\"\\nMean {str(criterion).split('(')[0]}: {(epoch_loss):.4f} | Mean {str(metric).split('(')[0]}: {(epoch_metric_score):.4f}\\n\")\n",
    "                elif epoch_metric_scores[-1] > epoch_metric_scores[-2]:\n",
    "                    best_state_dict = model.state_dict()\n",
    "                    best_loss = (epoch_loss)\n",
    "                    best_metric = (epoch_metric_score)\n",
    "                    \n",
    "                    print(\"\\nYeah 🎉😄! Model improved.\")\n",
    "                    print(f\"Mean {str(criterion).split('(')[0]}: {(epoch_loss):.4f} | Mean Mean {str(metric).split('(')[0]}: {(epoch_metric_score):.4f}\")\n",
    "                    \n",
    "                    f.write(\"\\nYeah 🎉😄! Model improved.\\n\")\n",
    "                    f.write(f\"Mean {str(criterion).split('(')[0]}: {(epoch_loss):.4f} | Mean {str(metric).split('(')[0]}: {(epoch_metric_score):.4f}\\n\")\n",
    "                else:\n",
    "                    patience_counter += 1\n",
    "                    \n",
    "                    print(\"\\nHuft 😥! Model not improved.\")\n",
    "                    print(f\"Mean {str(criterion).split('(')[0]}: {(epoch_loss):.4f} | Mean {str(metric).split('(')[0]}: {(epoch_metric_score):.4f}\\n\")\n",
    "                    print(f\"Patience = {patience_counter}/{patience}❗\\n\")\n",
    "                    \n",
    "                    f.write(\"\\nHuft 😥! Model not improved.\\n\")\n",
    "                    f.write(f\"Mean {str(criterion).split('(')[0]}: {(epoch_loss):.4f} | Mean {str(metric).split('(')[0]}: {(epoch_metric_score):.4f}\\n\")\n",
    "                    f.write(f\"Patience = {patience_counter}/{patience}❗\\n\")\n",
    "                    \n",
    "            print(\"=\" * 50, end=\"\\n\\n\")\n",
    "            f.write(f\"{'=' * 50}\\n\\n\")\n",
    "            \n",
    "            if patience_counter == patience:\n",
    "                print(f\"Early stopping, patience = {patience_counter}/{patience}❗\\n\")\n",
    "                f.write(f\"Early stopping, patience = {patience_counter}/{patience}❗\\n\")\n",
    "                break\n",
    "        \n",
    "        metric.reset()\n",
    "    \n",
    "    finish_time = time()\n",
    "    \n",
    "    # Training plot \n",
    "    fig, (ax_loss, ax_metric_score) = plt.subplots(nrows=1, ncols=2, figsize=(15, 5))\n",
    "\n",
    "    fig.suptitle(f\"Training with context size = {hyperparams.context_size}\")\n",
    "\n",
    "    ax_loss.set_title(\"Loss\")\n",
    "    ax_loss.set_xlabel(\"Epoch\")\n",
    "    ax_loss.set_ylabel(\"Score\")\n",
    "    ax_loss.plot(epoch_losses, \"green\")\n",
    "    ax_loss.grid()\n",
    "\n",
    "    ax_metric_score.set_title(\"F1 Score\")\n",
    "    ax_metric_score.set_xlabel(\"Epoch\")\n",
    "    ax_metric_score.set_ylabel(\"Score\")\n",
    "    ax_metric_score.plot(epoch_metric_scores, \"orange\")\n",
    "    ax_metric_score.grid()\n",
    "\n",
    "    plt.savefig(f\"../../logs/comick/{hyperparams.context_size}_contexts/{path_name}/training_plot.jpg\", dpi=200)                        \n",
    "    \n",
    "    print(\"TRAINING SUMMARY\")\n",
    "    print(f\"Best {str(criterion).split('(')[0]} : {best_loss:.4f}\")\n",
    "    print(f\"Best {str(metric).split('(')[0]}    : {best_metric:.4f}\")\n",
    "    print(f\"Training duration                   : {((finish_time - start_time) / 60):.3f} minutes.\")\n",
    "    print(f\"Training date                       : {now}\")\n",
    "    \n",
    "    with open(f\"../../logs/comick/{hyperparams.context_size}_contexts/{path_name}/training_history.txt\", \"a\") as f:\n",
    "        f.write(\"\\nTRAINING SUMMARY\\n\")\n",
    "        f.write(f\"{'-' * 50}\\n\")\n",
    "        f.write(f\"Best {str(criterion).split('(')[0]}\\t\\t\\t: {best_loss:.4f}\\n\")\n",
    "        f.write(f\"Best {str(metric).split('(')[0]}\\t\\t\\t: {best_metric:.4f}\\n\")\n",
    "        f.write(f\"Training duration\\t\\t: {((finish_time - start_time) / 60):.3f} minutes.\\n\")\n",
    "        f.write(f\"Training date\\t\\t\\t: {now}\\n\")\n",
    "    \n",
    "    # Save epoch losses, epoch metric scores, model, state dict, and oov embedding dict\n",
    "    filename_epoch_losses = open(f\"../../logs/comick/{hyperparams.context_size}_contexts/{path_name}/epoch_losses.pkl\", \"ab\")\n",
    "    filename_epoch_metric_scores = open(f\"../../logs/comick/{hyperparams.context_size}_contexts/{path_name}/epoch_metric_scores.pkl\", \"ab\")\n",
    "    filename_model_params = f\"../../logs/comick/{hyperparams.context_size}_contexts/{path_name}/model_params.pth\"\n",
    "    filename_oov_embedding_dict = open(f\"../../logs/comick/{hyperparams.context_size}_contexts/{path_name}/oov_embedding_dict.pkl\", \"ab\")\n",
    "    \n",
    "    pickle.dump(epoch_losses, filename_epoch_losses)\n",
    "    pickle.dump(epoch_metric_scores, filename_epoch_metric_scores)\n",
    "    torch.save(best_state_dict, filename_model_params)\n",
    "    pickle.dump({token : embedding for token, embedding in zip(list(labels_to_idx.keys()), model.embedding)}, filename_oov_embedding_dict)\n",
    "    \n",
    "    return epoch_losses, epoch_metric_scores\n",
    "\n",
    "epoch_losses, epoch_metric_scores = looping_step(dataloader, model, optimizer, criterion, metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfef50c-e71c-4288-a9f3-6fd8831033b0",
   "metadata": {},
   "source": [
    "# END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92debcb3-d6ea-4299-a3e9-37be5b63d2b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.90868366, -4.1549144 ,  5.2108417 , ..., -6.640148  ,\n",
       "         0.60780436, -1.0263817 ],\n",
       "       [ 4.900607  , -2.7702937 , -4.8761005 , ..., -4.378692  ,\n",
       "        -0.6962776 ,  3.3533762 ],\n",
       "       [ 0.80582476,  2.5302584 ,  0.959975  , ..., -3.8521132 ,\n",
       "        -1.7387218 , -6.0607824 ],\n",
       "       ...,\n",
       "       [-4.0838666 ,  1.9469248 ,  4.289667  , ...,  0.17587516,\n",
       "        -1.5028721 , -7.856037  ],\n",
       "       [ 0.5916616 , -5.990313  , -3.012122  , ..., -5.856158  ,\n",
       "         2.6461236 ,  7.9622774 ],\n",
       "       [ 2.7643962 ,  1.0465059 , -5.4865603 , ...,  1.6393834 ,\n",
       "         1.6459161 , -1.0754699 ]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27ce78c3-ac2c-4a84-a8e8-4d8e85d26563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('bilstm_left_context_feature.weight_ih_l0',\n",
       "              tensor([[ 0.2297,  0.0470,  0.2737,  ...,  0.3074,  0.0970,  0.3210],\n",
       "                      [-0.1701,  0.0885,  0.1251,  ...,  0.1653,  0.1912, -0.1623],\n",
       "                      [ 0.3383, -0.2234, -0.0911,  ...,  0.0424,  0.1507, -0.1490],\n",
       "                      ...,\n",
       "                      [ 0.1673, -0.1510,  0.0022,  ..., -0.1756,  0.2138, -0.1844],\n",
       "                      [ 0.1912, -0.1971,  0.0659,  ..., -0.2890,  0.2707, -0.0536],\n",
       "                      [ 0.3225, -0.1347,  0.1028,  ...,  0.1219, -0.0260, -0.3223]],\n",
       "                     device='cuda:0')),\n",
       "             ('bilstm_left_context_feature.weight_hh_l0',\n",
       "              tensor([[ 0.0675, -0.1158, -0.0803,  ..., -0.1703,  0.2989,  0.1415],\n",
       "                      [ 0.0610,  0.0051,  0.0758,  ..., -0.2306, -0.2986, -0.1703],\n",
       "                      [-0.1006, -0.0351, -0.0202,  ..., -0.1860,  0.0466,  0.0068],\n",
       "                      ...,\n",
       "                      [-0.0656, -0.0911, -0.2207,  ...,  0.0483,  0.1722, -0.1537],\n",
       "                      [-0.1136, -0.2022,  0.1676,  ..., -0.0659, -0.0380, -0.2563],\n",
       "                      [-0.0247,  0.1711,  0.1161,  ..., -0.0749,  0.0477, -0.1230]],\n",
       "                     device='cuda:0')),\n",
       "             ('bilstm_left_context_feature.bias_ih_l0',\n",
       "              tensor([-1.6389e-01, -1.3172e-01, -2.9145e-01, -2.0304e-01, -2.0156e-01,\n",
       "                      -1.7772e-01, -1.5120e-01, -1.4777e-01, -1.0719e-01, -1.8681e-01,\n",
       "                      -2.1969e-02, -1.6081e-01, -5.3615e-02, -2.7793e-01, -5.7447e-02,\n",
       "                      -1.4560e-01, -1.5083e-01, -1.3985e-01, -2.0409e-01, -2.1274e-01,\n",
       "                       9.0340e-02, -2.0156e-01, -6.0210e-02, -1.6090e-01, -1.4225e-01,\n",
       "                      -1.5178e-01, -1.3428e-01, -1.8196e-01, -1.8144e-01, -1.7982e-01,\n",
       "                      -2.6628e-02,  4.5542e-02, -2.7588e-01, -1.0248e-01, -2.6050e-01,\n",
       "                      -9.4651e-02, -8.3896e-02, -7.3581e-02, -1.4514e-01,  3.8996e-04,\n",
       "                      -3.6536e-02, -9.7424e-02, -1.2097e-01, -1.7351e-01, -7.4263e-02,\n",
       "                      -5.5579e-02, -7.9269e-02, -6.7659e-02, -1.2831e-01, -1.7184e-01,\n",
       "                      -6.4619e-02, -1.0288e-01, -1.9366e-01, -9.9500e-02, -1.6413e-01,\n",
       "                      -8.4665e-02, -1.8174e-01, -1.2262e-01, -1.2368e-01, -5.3612e-02,\n",
       "                      -5.2688e-02, -1.0366e-01, -1.0596e-01, -1.7749e-01, -8.0582e-02,\n",
       "                      -4.1514e-02, -1.3282e-01, -2.9312e-02, -2.1856e-01,  2.4425e-02,\n",
       "                      -1.4410e-01, -9.7468e-02, -1.1387e-01, -3.8817e-03, -1.6639e-01,\n",
       "                      -4.2608e-02, -4.0394e-02, -5.5307e-02, -8.8012e-02, -5.3834e-02,\n",
       "                      -1.0014e-01, -1.3828e-01, -1.5280e-01, -1.1499e-01, -8.3705e-02,\n",
       "                      -1.2083e-01, -2.0931e-01, -1.0993e-01, -1.1656e-01, -1.9132e-01,\n",
       "                      -2.2624e-01, -1.3617e-01, -2.1027e-01,  7.6085e-03, -5.5047e-02,\n",
       "                      -2.2292e-01, -1.3684e-01, -1.9644e-01, -1.9663e-01, -2.0886e-01,\n",
       "                      -9.4264e-02, -4.4603e-02, -1.6359e-01, -2.0315e-01, -9.0441e-02,\n",
       "                      -1.9788e-01, -1.4709e-01, -9.8557e-02, -1.1833e-01, -1.7328e-01,\n",
       "                      -1.2345e-01, -4.9416e-02, -1.2428e-01,  9.6107e-02, -4.5418e-02,\n",
       "                      -1.4461e-01, -1.6446e-01, -2.8304e-02, -1.5197e-01, -2.4227e-01,\n",
       "                      -1.6294e-01, -2.4065e-01, -1.8831e-01, -2.0397e-01, -2.0785e-01,\n",
       "                       4.6233e-02, -1.1980e-01, -1.8138e-01, -1.2658e-01, -1.8065e-02,\n",
       "                      -8.2135e-02, -1.4634e-01, -2.1435e-01, -1.3008e-01, -1.0010e-01,\n",
       "                      -1.2995e-01, -7.4321e-02,  3.4704e-03, -2.3649e-02, -1.3042e-01,\n",
       "                      -1.2769e-01, -1.7046e-01, -1.6078e-01, -2.0329e-01, -1.4942e-01,\n",
       "                      -1.7381e-02, -4.4094e-02,  1.2918e-04, -1.5634e-01, -1.6151e-01,\n",
       "                      -9.6904e-02, -1.1807e-01, -1.9761e-01, -1.3337e-01, -8.5284e-02,\n",
       "                      -5.9014e-02, -9.7092e-02, -2.5545e-01, -1.2104e-02, -8.1393e-02,\n",
       "                      -2.4979e-01, -1.4744e-01, -2.4029e-01, -9.8761e-02, -4.9158e-02,\n",
       "                      -2.6235e-01, -4.9792e-02, -1.3296e-01, -2.8901e-02, -7.8614e-02,\n",
       "                      -6.7634e-02, -3.7732e-02, -1.1917e-01, -1.2523e-01, -1.6635e-01,\n",
       "                      -1.5290e-01, -8.4279e-02, -1.1952e-01, -8.2224e-03, -8.3382e-02,\n",
       "                      -3.0174e-01, -1.0735e-01, -6.9091e-02, -4.8157e-03, -1.1375e-01,\n",
       "                      -6.3443e-02, -1.8567e-01, -1.1237e-01, -4.6289e-02, -1.3222e-01,\n",
       "                      -9.7926e-02, -1.1254e-01, -8.7570e-02, -2.1038e-01, -1.8452e-01,\n",
       "                      -1.3569e-01, -2.3862e-01,  2.8853e-02, -1.3600e-01, -9.2458e-02,\n",
       "                      -4.0936e-02, -8.3265e-02, -1.1413e-01, -4.8310e-02, -2.2806e-02,\n",
       "                      -1.9888e-01, -7.6631e-02,  7.7300e-02, -2.6499e-02, -8.0595e-02,\n",
       "                      -3.1071e-03,  8.1032e-02, -1.0080e-01, -1.3396e-01, -1.1499e-01,\n",
       "                      -7.1365e-02, -1.4092e-01, -1.6570e-01, -1.9166e-01, -1.0398e-01,\n",
       "                      -9.2209e-02, -1.4930e-01, -4.3505e-02, -5.1835e-02, -4.7421e-02,\n",
       "                      -1.7792e-01, -1.2229e-01, -1.3076e-01, -1.1854e-01, -1.5845e-01,\n",
       "                      -8.1090e-02, -1.4664e-01, -1.0931e-01, -7.1898e-02, -8.2785e-02,\n",
       "                      -1.1355e-01, -1.0803e-01,  9.6580e-03, -1.5315e-01, -4.3846e-02,\n",
       "                      -9.8795e-02, -1.6142e-01,  7.6126e-02, -4.3383e-02, -2.6241e-02,\n",
       "                       4.0689e-02, -2.0953e-01, -1.5515e-01, -9.9867e-02, -2.7832e-01,\n",
       "                      -1.4253e-01,  6.9734e-03, -3.8299e-02, -6.2669e-02, -5.3534e-02,\n",
       "                      -1.4790e-01,  2.1715e-03, -6.0950e-02,  3.6183e-02,  2.1477e-02,\n",
       "                      -5.1672e-02, -8.9167e-03,  3.1890e-02, -1.0365e-02, -5.1850e-02,\n",
       "                       2.7032e-02, -2.5061e-02,  1.4198e-01,  3.5111e-02, -2.9541e-02,\n",
       "                       1.1114e-01, -3.0126e-02,  7.0942e-02, -3.9271e-02,  5.1120e-03,\n",
       "                       1.5929e-02,  3.4946e-02, -7.7291e-02, -9.8483e-02,  4.2709e-02,\n",
       "                       9.2733e-02, -6.8607e-02,  3.2461e-03, -4.1734e-02, -5.6359e-02,\n",
       "                       7.6660e-02,  4.7381e-03, -3.6434e-02, -8.1227e-02, -4.6189e-02,\n",
       "                      -7.5504e-03,  8.7564e-02, -8.5932e-02,  5.4957e-02,  1.5887e-02,\n",
       "                       4.2080e-03, -4.2775e-02, -9.6600e-02, -3.3460e-02,  1.0433e-02,\n",
       "                       4.3625e-02, -2.6575e-02, -1.5242e-01, -8.4417e-02, -1.1365e-01,\n",
       "                       3.0219e-02, -3.2497e-02,  2.9955e-02,  2.0939e-02, -8.3568e-02,\n",
       "                      -4.1792e-02,  6.4668e-02, -1.0017e-02, -6.5358e-02,  5.3350e-02,\n",
       "                       5.4180e-03,  6.5548e-02,  6.0594e-02, -3.6101e-02, -4.1523e-02,\n",
       "                      -7.8232e-03,  4.0924e-02, -9.7687e-03, -7.2255e-03, -2.5891e-02,\n",
       "                      -3.0645e-03,  1.0710e-01, -3.0442e-02, -7.1806e-02,  2.1853e-02,\n",
       "                      -4.3466e-02, -3.6867e-02,  8.5514e-02, -8.6644e-02,  2.0381e-02,\n",
       "                      -4.4974e-03,  2.6920e-02, -2.8334e-02,  2.5852e-02,  1.7547e-02,\n",
       "                       4.2619e-03, -2.8694e-02,  4.3028e-02, -7.1462e-02, -2.8125e-02,\n",
       "                      -5.4482e-02, -2.2510e-02, -8.6896e-02, -9.9889e-02, -4.1791e-02,\n",
       "                      -5.1602e-02, -7.1266e-02,  2.7438e-02,  7.9435e-03, -8.1556e-02,\n",
       "                       1.5521e-02,  1.7840e-02, -1.9091e-02, -2.1640e-01, -2.2798e-03,\n",
       "                      -9.8140e-02,  6.6190e-02, -7.6502e-02, -5.7561e-02, -4.8907e-02,\n",
       "                       3.0268e-02, -7.4457e-02, -9.6560e-02, -3.8669e-02,  5.1381e-02,\n",
       "                      -8.5443e-02,  2.4956e-02, -4.2873e-02, -2.1249e-03,  3.6167e-02,\n",
       "                       5.9374e-02,  2.1630e-02,  6.1333e-02,  6.5401e-02, -3.3032e-02,\n",
       "                      -4.4268e-02, -4.9703e-02,  6.4059e-02, -1.2356e-01, -1.9484e-01,\n",
       "                      -1.7056e-01, -1.1312e-01, -9.5690e-02, -1.6547e-01, -2.4115e-01,\n",
       "                      -2.2461e-01, -1.0271e-01, -1.6302e-01, -9.8325e-02, -4.4212e-03,\n",
       "                      -8.1840e-02, -1.5330e-01, -2.1269e-01, -1.5058e-01, -4.9729e-02,\n",
       "                      -2.5380e-01, -1.0837e-01, -1.4197e-01, -1.2391e-01, -9.5112e-02,\n",
       "                      -8.5691e-02, -9.2128e-02, -2.1069e-01, -7.6944e-02, -1.0746e-01,\n",
       "                      -2.0404e-01, -1.2818e-01,  1.9335e-02, -1.8463e-01, -1.3621e-01,\n",
       "                      -1.4079e-01, -2.4482e-01, -1.3614e-01, -1.6155e-01, -1.8104e-01,\n",
       "                      -1.5445e-01, -2.6851e-01, -2.9027e-01, -1.2778e-01, -7.1387e-02,\n",
       "                      -1.1376e-01, -1.0317e-01, -1.3896e-01, -1.8007e-01,  1.0209e-02,\n",
       "                      -2.2698e-01, -4.9181e-02, -1.5841e-01, -1.9811e-02, -9.1845e-02,\n",
       "                      -1.1571e-01, -1.9134e-01, -1.6933e-01, -6.4415e-02, -1.0049e-01,\n",
       "                      -1.3198e-01, -1.5305e-01, -6.6712e-02, -2.3263e-01, -8.0249e-02,\n",
       "                      -9.4455e-02, -1.6372e-01, -2.2371e-01, -8.9156e-02, -1.3462e-01,\n",
       "                      -9.8425e-02, -6.8845e-02, -2.7488e-01, -1.1238e-01, -7.5414e-02,\n",
       "                      -1.8956e-01, -5.7797e-02, -4.6308e-02, -1.3397e-01, -1.1636e-01,\n",
       "                      -1.0753e-02, -2.3128e-01, -2.1969e-01, -5.5683e-02, -1.9994e-02,\n",
       "                      -7.4835e-02, -1.5748e-01, -5.2192e-02, -1.4926e-01, -1.7617e-01,\n",
       "                      -2.2185e-01, -1.7945e-01, -7.9030e-02, -2.0741e-01, -1.2487e-01,\n",
       "                      -1.0917e-01, -1.0192e-01, -1.7636e-01, -1.5567e-01, -2.2065e-01,\n",
       "                      -7.3138e-02, -1.5060e-01, -5.8925e-02, -1.3216e-01, -8.8217e-02,\n",
       "                      -1.3051e-01, -1.6214e-01, -1.3691e-01, -1.7022e-01, -1.6044e-01,\n",
       "                      -1.9346e-01, -6.3752e-02, -1.3764e-01, -3.8663e-02, -2.4026e-02,\n",
       "                      -1.0355e-01, -1.1259e-01,  1.9051e-02, -7.7172e-02,  7.2176e-02,\n",
       "                      -2.2840e-02,  5.1889e-02, -1.8020e-01, -1.8926e-01, -1.1884e-01,\n",
       "                      -2.2147e-01, -9.6170e-02,  1.0336e-02, -1.2372e-01, -2.6625e-02,\n",
       "                      -1.5815e-01, -3.4931e-02], device='cuda:0')),\n",
       "             ('bilstm_left_context_feature.bias_hh_l0',\n",
       "              tensor([-0.2227, -0.0106, -0.0924, -0.0587, -0.1318, -0.1419, -0.1891, -0.1557,\n",
       "                      -0.0160, -0.1016, -0.0087, -0.1376, -0.0732, -0.2587, -0.1279, -0.0503,\n",
       "                      -0.2025, -0.1228, -0.1454, -0.1889, -0.1002, -0.1859, -0.2557, -0.2207,\n",
       "                      -0.1251, -0.0605, -0.1610, -0.0466, -0.1493, -0.1039, -0.0636, -0.0149,\n",
       "                      -0.1960, -0.2098, -0.1092,  0.0454, -0.2324, -0.1203, -0.0753, -0.1979,\n",
       "                      -0.0695, -0.0004, -0.1627, -0.0399, -0.0402, -0.0322, -0.1628,  0.0827,\n",
       "                      -0.1072, -0.1216, -0.0197,  0.0130, -0.1443, -0.1427, -0.1843,  0.0011,\n",
       "                      -0.1657, -0.1283, -0.0444, -0.2262, -0.0463, -0.0575, -0.0027, -0.1550,\n",
       "                      -0.1190, -0.0899, -0.0064, -0.0813, -0.2229, -0.0776, -0.0914, -0.0296,\n",
       "                      -0.1951, -0.0085, -0.1147, -0.0501, -0.1589, -0.1586, -0.2133, -0.0656,\n",
       "                      -0.2098, -0.1321,  0.0061, -0.2052, -0.1168, -0.1448, -0.0840, -0.2038,\n",
       "                      -0.0789, -0.1452, -0.1263, -0.1716, -0.2388, -0.1356, -0.1075, -0.2231,\n",
       "                      -0.0135, -0.1565, -0.0777, -0.2610, -0.0609, -0.1976, -0.1549, -0.2491,\n",
       "                      -0.2122, -0.2343, -0.1982, -0.1704, -0.0768, -0.1182, -0.1048, -0.0344,\n",
       "                      -0.1161,  0.0713, -0.1423, -0.1758, -0.2335, -0.0419, -0.1676, -0.2343,\n",
       "                      -0.1864, -0.2714, -0.1279, -0.0782, -0.0840, -0.1345, -0.0880, -0.0698,\n",
       "                      -0.1970, -0.1682, -0.0616, -0.0693, -0.1260, -0.1098, -0.0462, -0.0174,\n",
       "                      -0.0464, -0.0527, -0.2130, -0.0984, -0.0892, -0.1168, -0.0426, -0.1912,\n",
       "                      -0.0473, -0.1012, -0.2035, -0.0650, -0.1173, -0.2009, -0.2200, -0.0648,\n",
       "                      -0.1076, -0.1559, -0.0923, -0.0411, -0.0576, -0.0902, -0.1636, -0.0481,\n",
       "                      -0.1615, -0.0430, -0.1457, -0.1126, -0.1438, -0.1216, -0.0435, -0.1000,\n",
       "                      -0.1065, -0.0838, -0.0532, -0.1500, -0.0289, -0.1103, -0.1710, -0.1586,\n",
       "                      -0.0244, -0.1256, -0.0420,  0.0031, -0.1325, -0.1325, -0.0872, -0.0124,\n",
       "                      -0.1531,  0.0331, -0.1534, -0.0491, -0.1101, -0.0043, -0.2252, -0.1183,\n",
       "                      -0.1040, -0.1822, -0.1064, -0.1216, -0.1546, -0.0155, -0.1787, -0.2215,\n",
       "                      -0.0499,  0.0072, -0.1091, -0.0727, -0.0153, -0.0660, -0.1848, -0.1360,\n",
       "                      -0.1775, -0.1844, -0.0821, -0.0037, -0.0753, -0.0175, -0.0982, -0.1591,\n",
       "                      -0.0949, -0.1406, -0.0656, -0.0035, -0.1636, -0.0631, -0.1615, -0.1556,\n",
       "                       0.0431, -0.1536, -0.0874, -0.1612, -0.1346, -0.1700, -0.1743, -0.1940,\n",
       "                      -0.1508, -0.0763, -0.0634, -0.0723, -0.0420, -0.1281, -0.1044, -0.1379,\n",
       "                      -0.1360,  0.0253, -0.1456, -0.0045, -0.1200, -0.1719, -0.1759, -0.0548,\n",
       "                      -0.1414, -0.1948, -0.0864, -0.1257, -0.1600, -0.0855, -0.2287, -0.1325,\n",
       "                      -0.0066,  0.0349,  0.0664,  0.0947,  0.0233, -0.0015, -0.0351,  0.0069,\n",
       "                       0.0388, -0.1354,  0.1915, -0.0276, -0.0077, -0.0258, -0.0346,  0.0256,\n",
       "                      -0.0016,  0.0027,  0.0389,  0.0469,  0.1215, -0.0500,  0.0500,  0.0476,\n",
       "                       0.0293,  0.0004, -0.0732, -0.0407,  0.0638,  0.0679,  0.0377, -0.0012,\n",
       "                      -0.0259, -0.0632,  0.0037, -0.0279,  0.0647,  0.0274, -0.0135,  0.0232,\n",
       "                       0.0063, -0.0920,  0.0383, -0.0469,  0.0329,  0.0208,  0.0434, -0.0624,\n",
       "                       0.0529, -0.0766, -0.1783,  0.0250,  0.0854,  0.0721, -0.0065, -0.0853,\n",
       "                       0.0475,  0.0208, -0.0567, -0.1050, -0.0616,  0.0140,  0.0245, -0.1328,\n",
       "                       0.0466, -0.0473,  0.0674, -0.0210,  0.0470, -0.0796, -0.0590, -0.0807,\n",
       "                      -0.0212, -0.0046, -0.0006, -0.0521, -0.1575, -0.0544, -0.0115, -0.1346,\n",
       "                       0.0446,  0.0531,  0.0330,  0.0271, -0.0577, -0.0430, -0.0823, -0.0618,\n",
       "                      -0.0166, -0.0306,  0.0663, -0.0117,  0.0268, -0.0543, -0.0408, -0.0264,\n",
       "                       0.0498, -0.0059,  0.0502,  0.0286, -0.0110, -0.0797, -0.0173,  0.1444,\n",
       "                       0.0690, -0.0627,  0.0280,  0.1594, -0.0529, -0.0491,  0.0444,  0.0549,\n",
       "                      -0.0067,  0.0077, -0.1063, -0.0326, -0.0481, -0.0213, -0.0289, -0.0175,\n",
       "                      -0.0877,  0.0408,  0.0343,  0.0336, -0.0496,  0.1024,  0.0289,  0.0285,\n",
       "                      -0.0599, -0.1345, -0.0625, -0.2408, -0.1148, -0.2492, -0.1800, -0.1081,\n",
       "                      -0.1819, -0.0749,  0.0456, -0.1353, -0.1202, -0.2247, -0.1670, -0.0517,\n",
       "                      -0.1134, -0.1919, -0.0382, -0.1800, -0.0868, -0.1227, -0.1864, -0.0267,\n",
       "                      -0.0298, -0.0738, -0.0772, -0.0799, -0.1104, -0.0971,  0.0017, -0.1350,\n",
       "                      -0.2272, -0.0509, -0.0541, -0.0828, -0.1313, -0.0321, -0.1025, -0.0022,\n",
       "                      -0.1342, -0.0851, -0.1021, -0.0152, -0.1969, -0.1288, -0.1111, -0.2101,\n",
       "                      -0.0948, -0.1146,  0.0024, -0.1111, -0.1223, -0.1748, -0.2108, -0.1171,\n",
       "                      -0.1739, -0.1586, -0.0257, -0.0492, -0.0395, -0.1354, -0.0365, -0.1387,\n",
       "                      -0.1329, -0.1350, -0.1519, -0.0915, -0.3161, -0.0754, -0.0713, -0.2156,\n",
       "                      -0.0059, -0.0971, -0.1435, -0.1579, -0.1086, -0.0756, -0.2639, -0.0651,\n",
       "                      -0.1195, -0.1387, -0.0549, -0.0300, -0.1621, -0.0847, -0.2576, -0.2006,\n",
       "                       0.0158, -0.1946, -0.1757, -0.2338, -0.1470,  0.0093, -0.1405, -0.1887,\n",
       "                      -0.2208, -0.2073,  0.0112, -0.2168, -0.1132, -0.1673, -0.1188, -0.2087,\n",
       "                      -0.1474, -0.1347, -0.2019, -0.2764, -0.0513, -0.1063, -0.2139, -0.1013,\n",
       "                      -0.1303, -0.0807, -0.1588, -0.1198, -0.0337, -0.1739, -0.0993, -0.2052,\n",
       "                      -0.1920, -0.0159, -0.2032,  0.0450, -0.2422, -0.0888, -0.1012, -0.1751],\n",
       "                     device='cuda:0')),\n",
       "             ('bilstm_left_context_feature.weight_ih_l0_reverse',\n",
       "              tensor([[-0.0377, -0.0277,  0.1947,  ..., -0.1578, -0.0007, -0.3053],\n",
       "                      [ 0.0568, -0.1119,  0.2808,  ..., -0.1310, -0.0862, -0.0035],\n",
       "                      [-0.2660, -0.3650, -0.1514,  ..., -0.0909, -0.0816, -0.0222],\n",
       "                      ...,\n",
       "                      [ 0.1751, -0.1385,  0.1750,  ...,  0.0347, -0.2066, -0.2259],\n",
       "                      [-0.1579,  0.0901, -0.3382,  ..., -0.0792, -0.1593, -0.3894],\n",
       "                      [ 0.5046, -0.0345, -0.1339,  ..., -0.2740, -0.0419, -0.4692]],\n",
       "                     device='cuda:0')),\n",
       "             ('bilstm_left_context_feature.weight_hh_l0_reverse',\n",
       "              tensor([[-0.0384,  0.0162, -0.2931,  ..., -0.0124,  0.2032, -0.0780],\n",
       "                      [ 0.0305, -0.2224,  0.1491,  ...,  0.0017, -0.1804,  0.1217],\n",
       "                      [-0.0633,  0.2362, -0.3080,  ..., -0.0412, -0.1026,  0.1922],\n",
       "                      ...,\n",
       "                      [ 0.0363, -0.2938,  0.0347,  ..., -0.0919, -0.1408, -0.0191],\n",
       "                      [ 0.0673, -0.0507, -0.0250,  ...,  0.0080,  0.1721,  0.0119],\n",
       "                      [ 0.1040, -0.3542,  0.0229,  ..., -0.1915, -0.0985, -0.0698]],\n",
       "                     device='cuda:0')),\n",
       "             ('bilstm_left_context_feature.bias_ih_l0_reverse',\n",
       "              tensor([-2.4929e-02,  9.1668e-03,  1.9544e-01,  6.0306e-02,  4.3515e-02,\n",
       "                       3.4276e-02, -4.3380e-02, -3.5140e-03,  4.7075e-02,  1.2403e-01,\n",
       "                       2.7069e-01,  1.7867e-02,  6.9161e-03, -8.3366e-02,  5.7270e-02,\n",
       "                      -1.4293e-01, -1.0842e-01,  1.0810e-01,  3.7119e-02, -9.0227e-03,\n",
       "                       1.2565e-01, -1.7867e-02,  2.2830e-02,  1.4077e-01,  1.6301e-01,\n",
       "                       5.7463e-02,  1.9139e-01, -6.9241e-02,  9.4373e-02,  7.3654e-02,\n",
       "                       2.8471e-02,  2.4635e-01,  5.8601e-02,  1.0418e-01,  7.6424e-02,\n",
       "                       1.5102e-01,  1.6630e-01,  2.8156e-03,  9.0340e-02,  8.8952e-02,\n",
       "                       3.7306e-02, -2.9452e-02,  1.4877e-02,  5.2771e-02,  1.4234e-02,\n",
       "                       9.4922e-02, -2.0291e-02, -3.9548e-03,  1.1980e-01,  1.0318e-01,\n",
       "                       1.0779e-01,  1.7094e-01,  1.4708e-01,  5.4181e-02, -1.0959e-02,\n",
       "                       1.1130e-02,  1.2191e-01,  6.6950e-02, -1.0773e-01,  1.4584e-02,\n",
       "                       9.0618e-02,  4.3790e-02, -1.3924e-02, -7.7028e-02,  2.7475e-02,\n",
       "                       6.0683e-02,  3.0048e-02,  3.2576e-02,  1.8146e-01, -1.1701e-01,\n",
       "                       3.1131e-02,  2.0343e-02, -6.1893e-02, -4.5612e-02,  1.2035e-01,\n",
       "                       5.0180e-02,  1.4255e-01, -2.6586e-02,  7.0533e-02,  1.0049e-02,\n",
       "                      -4.0782e-02,  1.5131e-01,  1.1403e-01,  5.8479e-02, -1.6637e-01,\n",
       "                       1.9001e-01, -4.2781e-03,  1.3518e-02,  2.2501e-01,  5.6208e-02,\n",
       "                       1.2470e-01,  4.0731e-02,  1.7524e-01,  9.1786e-02,  1.1691e-01,\n",
       "                       9.0928e-04,  1.8226e-01,  8.2396e-02,  1.3233e-01,  6.4580e-02,\n",
       "                       9.1261e-04,  2.3252e-02,  1.1419e-01, -2.5142e-02,  1.0097e-01,\n",
       "                       1.3848e-01,  1.1813e-01,  1.8940e-01, -1.0278e-02,  5.4642e-03,\n",
       "                       9.0674e-02,  1.2992e-01, -4.1592e-02,  1.4945e-01,  4.3790e-02,\n",
       "                       1.8840e-01,  9.0703e-02,  1.6341e-01, -6.8628e-02,  6.5126e-02,\n",
       "                       1.0193e-01, -5.6137e-02, -3.5952e-02,  1.1114e-01,  5.8337e-02,\n",
       "                       1.4639e-01,  1.4199e-01, -5.9944e-02, -6.7225e-02, -1.2061e-01,\n",
       "                       8.7436e-03,  5.0307e-02, -1.2063e-01, -9.8522e-02,  4.4865e-03,\n",
       "                       1.6361e-02, -1.2307e-01, -7.8835e-02, -3.9709e-02, -1.4250e-01,\n",
       "                      -2.1129e-01, -1.1459e-01, -8.6963e-02,  2.4980e-02,  3.4544e-02,\n",
       "                       9.4972e-03, -1.8679e-01, -5.0944e-02,  6.7376e-02, -5.5411e-02,\n",
       "                      -1.0473e-02, -1.6035e-02, -8.0446e-02,  5.4446e-03, -6.4357e-02,\n",
       "                      -6.5949e-02,  1.4553e-02, -1.6030e-01,  1.0238e-01, -1.2696e-01,\n",
       "                      -1.1950e-01,  3.6069e-02, -7.4587e-02, -1.1048e-01, -1.3147e-03,\n",
       "                      -1.1420e-03,  1.8361e-03, -3.5202e-02, -7.4584e-02, -4.2781e-02,\n",
       "                       7.3778e-02, -6.0917e-02, -2.0926e-01, -2.3826e-01,  6.3596e-02,\n",
       "                      -9.1457e-02, -1.5538e-01, -5.2903e-02,  4.9969e-02,  4.1096e-02,\n",
       "                       4.4041e-03, -1.9147e-01, -4.9081e-02,  1.2427e-01, -1.4344e-01,\n",
       "                      -3.4932e-02, -7.4406e-02, -1.8715e-02, -8.3777e-02, -4.3485e-02,\n",
       "                       4.6578e-02, -1.3080e-01, -9.9683e-02, -1.1913e-01, -1.3171e-01,\n",
       "                      -1.0109e-01, -3.3234e-02, -1.0917e-01,  6.3019e-03, -5.0846e-03,\n",
       "                       2.6614e-02, -1.4665e-01,  1.3583e-01, -5.9370e-02, -4.4239e-02,\n",
       "                      -1.1993e-01,  1.7364e-02,  1.0825e-01, -1.5766e-01, -1.9895e-01,\n",
       "                       4.9414e-02, -2.2784e-02, -4.0334e-02,  4.4553e-02, -8.0459e-02,\n",
       "                      -5.4332e-02, -1.1834e-01, -4.3494e-02, -2.0063e-02, -1.9734e-01,\n",
       "                      -3.2492e-02, -2.2036e-01, -4.0806e-03, -5.9071e-02,  2.0471e-02,\n",
       "                      -1.2148e-02, -9.7990e-02, -2.1030e-01,  1.1304e-02, -1.2090e-01,\n",
       "                      -2.0572e-02, -5.1648e-02, -8.7065e-02, -1.1748e-01, -1.0918e-01,\n",
       "                       3.8564e-02, -2.7601e-02,  2.8549e-02,  1.2024e-01,  1.3741e-01,\n",
       "                      -1.1241e-01,  8.5237e-02,  2.3241e-02, -6.7337e-02,  9.5515e-02,\n",
       "                      -6.7189e-02, -8.9585e-02,  1.9840e-01,  7.2358e-03, -6.2916e-02,\n",
       "                      -1.7509e-01,  5.6943e-02, -5.4445e-02, -8.6624e-02,  5.3746e-02,\n",
       "                      -5.5007e-02,  9.7008e-02, -3.2417e-02,  3.0081e-02,  3.6720e-03,\n",
       "                       7.4280e-02, -1.3461e-01,  2.8433e-02,  8.5814e-02,  4.7733e-03,\n",
       "                      -4.6975e-02, -2.4702e-02, -2.4593e-02,  5.2755e-02, -6.4036e-02,\n",
       "                       1.8675e-02, -5.2773e-02,  7.0080e-02,  2.7761e-02,  1.1916e-01,\n",
       "                       1.2138e-02, -3.7420e-02,  1.0634e-02, -8.0234e-03, -6.9438e-02,\n",
       "                      -4.2333e-02,  1.5591e-01,  3.5665e-02,  1.2526e-01, -5.6060e-02,\n",
       "                      -5.7761e-02,  4.2894e-03, -4.5787e-02,  5.2106e-02,  3.7169e-02,\n",
       "                       2.6295e-02,  4.1377e-02, -9.2443e-02, -4.4729e-02, -1.8782e-01,\n",
       "                      -2.2694e-02, -5.2452e-02,  1.4074e-02,  1.4699e-01,  6.9484e-02,\n",
       "                       4.0404e-02,  1.8818e-02, -1.0451e-01, -3.8353e-02,  2.3506e-02,\n",
       "                      -2.7069e-02,  1.1013e-03,  5.9123e-02, -4.5791e-02, -3.6774e-02,\n",
       "                       9.6870e-02, -1.0325e-01, -1.6991e-01, -6.6820e-02, -6.7794e-02,\n",
       "                      -4.3727e-02, -1.2705e-01,  8.6691e-02,  4.3608e-02, -7.7519e-02,\n",
       "                       2.0638e-02,  2.1171e-02,  1.7831e-02, -8.1564e-02, -1.7291e-02,\n",
       "                       1.2742e-01, -1.7246e-02,  8.2544e-02,  3.3869e-02, -9.1700e-02,\n",
       "                       1.9233e-02, -4.9988e-03, -1.3726e-02, -3.1197e-02, -3.4901e-02,\n",
       "                       2.7950e-02, -9.4451e-02, -8.1125e-04, -4.2451e-02,  1.8479e-02,\n",
       "                      -9.9045e-02,  2.7209e-02, -2.4794e-02, -1.0959e-01,  1.6146e-01,\n",
       "                       5.5344e-02,  1.2343e-01, -9.1044e-02,  2.8792e-02,  1.5761e-02,\n",
       "                      -6.2912e-02,  3.6234e-03,  2.7821e-02, -1.1908e-02, -1.1401e-01,\n",
       "                       8.6849e-02,  3.7735e-02, -7.9955e-02, -5.6038e-02,  2.6145e-04,\n",
       "                       3.1325e-03,  2.8568e-02,  1.6338e-01, -9.1636e-03,  2.1227e-02,\n",
       "                      -9.0674e-02,  1.0230e-02,  8.2175e-02, -8.6290e-02, -3.8653e-02,\n",
       "                       7.1542e-02,  4.5266e-02, -1.7066e-02, -3.0585e-02, -7.5590e-02,\n",
       "                       3.4238e-02, -1.1425e-02, -2.9220e-02,  3.2860e-02,  1.3325e-02,\n",
       "                      -1.1800e-01,  4.4396e-02, -2.5030e-02,  3.2124e-02, -1.9029e-01,\n",
       "                       4.7296e-02,  1.8627e-01,  2.4597e-01,  8.5897e-02,  7.7251e-02,\n",
       "                       3.8344e-02, -7.0845e-02,  1.8628e-01,  1.3120e-01,  2.6959e-01,\n",
       "                       1.1829e-01,  1.8284e-01, -4.2889e-02,  1.4918e-02,  4.3312e-02,\n",
       "                       4.0683e-02,  1.5943e-01,  2.4021e-01, -4.9513e-03,  7.9275e-02,\n",
       "                      -3.8769e-02, -7.4696e-03, -1.0757e-02,  9.2530e-02,  9.9580e-02,\n",
       "                       1.4421e-01,  1.7719e-01,  1.2846e-01,  9.8371e-02,  1.2870e-01,\n",
       "                       1.3786e-01,  1.2358e-01, -8.9739e-02,  5.8711e-02,  5.6843e-02,\n",
       "                       7.0703e-02, -1.6044e-02,  1.1236e-01,  1.2147e-01,  1.7798e-01,\n",
       "                       1.8404e-02, -7.7325e-02,  1.6663e-01,  6.5250e-02,  9.1428e-02,\n",
       "                       2.9548e-02,  7.0074e-02,  9.1623e-02,  4.8945e-02,  1.3155e-01,\n",
       "                       1.7559e-01, -2.6759e-02,  2.6441e-02, -1.8017e-02, -8.2057e-03,\n",
       "                       1.9369e-01, -9.7037e-03, -5.5509e-02,  6.8529e-02,  1.6620e-01,\n",
       "                       6.9344e-02, -2.8969e-02, -2.7035e-02,  1.4790e-02,  1.2241e-01,\n",
       "                       8.1779e-02, -1.5021e-02,  1.3961e-01, -6.4927e-02,  1.2264e-01,\n",
       "                      -8.7785e-02,  1.1917e-01,  8.3217e-03,  2.2974e-01, -6.9967e-03,\n",
       "                       7.6513e-02, -1.1298e-02,  8.9714e-02,  1.1872e-02, -4.1667e-02,\n",
       "                       2.7271e-02,  2.0010e-01,  1.4328e-01, -1.5741e-01,  1.4275e-01,\n",
       "                       8.5324e-02,  8.9866e-02,  6.2921e-02,  2.5381e-01, -6.1668e-02,\n",
       "                      -1.0542e-01,  2.7484e-01,  1.6940e-03,  2.4927e-01,  1.1348e-01,\n",
       "                       6.8736e-02,  1.7071e-01,  1.1672e-01, -1.7314e-02,  1.3215e-01,\n",
       "                       2.4056e-02, -2.1295e-02, -1.5450e-01,  2.9473e-02,  1.7203e-01,\n",
       "                      -4.1316e-02,  8.3842e-02,  1.6325e-01, -5.1745e-02,  1.5190e-01,\n",
       "                       6.7028e-02, -6.9895e-02, -1.1423e-02,  1.9207e-01,  1.0581e-01,\n",
       "                       5.4855e-02,  1.0251e-01, -4.3747e-02,  1.3416e-01,  1.6845e-01,\n",
       "                       4.3142e-02, -5.6051e-02,  1.8548e-02,  5.2401e-02,  3.6538e-03,\n",
       "                       1.9058e-01,  9.8960e-02], device='cuda:0')),\n",
       "             ('bilstm_left_context_feature.bias_hh_l0_reverse',\n",
       "              tensor([ 3.3778e-02,  1.2478e-01,  1.6691e-01,  1.6374e-02,  5.2240e-02,\n",
       "                       3.9403e-02, -1.3617e-01,  1.1163e-01,  1.1544e-01,  9.9043e-02,\n",
       "                       2.4728e-01,  6.1448e-02,  1.9382e-01, -1.5188e-02,  3.1446e-02,\n",
       "                      -2.0187e-02, -1.2547e-01,  1.4830e-01,  1.3924e-01,  3.9693e-02,\n",
       "                       9.6546e-02, -5.8452e-02,  2.7946e-02,  8.2495e-02,  1.4155e-01,\n",
       "                       4.1242e-02,  1.7541e-01,  1.0765e-01, -2.5763e-02,  2.2606e-02,\n",
       "                       1.1698e-02,  2.2698e-01,  1.2625e-01, -6.6153e-02,  1.6388e-02,\n",
       "                       1.5168e-01,  1.7509e-01,  1.3526e-01,  1.3792e-01,  3.5909e-02,\n",
       "                       1.5262e-01,  1.2015e-01,  6.4742e-02, -2.8259e-02,  4.9947e-02,\n",
       "                       8.4092e-02,  1.2693e-01,  1.6790e-01,  3.5030e-02, -4.8230e-02,\n",
       "                       2.5641e-02,  1.7630e-01, -1.7128e-02,  4.2856e-02,  7.8283e-02,\n",
       "                       1.3636e-01,  2.3368e-01, -8.2651e-02, -4.4070e-02,  6.3294e-03,\n",
       "                       2.1855e-01,  2.2593e-02,  3.4957e-02, -1.9110e-02, -2.9550e-03,\n",
       "                       3.1846e-02,  8.0480e-02,  9.7169e-02,  9.3943e-02, -4.7314e-02,\n",
       "                       8.1056e-03, -6.8357e-02, -5.4240e-03,  2.4674e-02,  2.9580e-02,\n",
       "                      -2.4623e-02,  6.5927e-02, -2.9276e-02, -2.7376e-02, -2.6408e-02,\n",
       "                      -2.1663e-02, -1.4976e-02,  3.1129e-02,  4.1440e-02, -2.0246e-01,\n",
       "                       8.4361e-02,  2.5073e-02, -7.5604e-02,  1.5371e-01,  6.7384e-02,\n",
       "                      -2.7456e-02, -1.1768e-01,  2.1248e-01,  1.7014e-01,  1.0807e-01,\n",
       "                       8.6152e-02,  2.6718e-02,  8.1598e-02,  1.3921e-01, -1.3833e-01,\n",
       "                       7.7986e-02,  6.2211e-02,  8.4014e-02,  3.1202e-02,  1.0411e-01,\n",
       "                       1.4519e-02,  1.4006e-02,  7.7884e-02, -4.3256e-02,  1.0881e-02,\n",
       "                       1.7824e-01,  5.4320e-02, -1.6969e-02,  3.0266e-02,  1.5645e-01,\n",
       "                       2.2588e-01, -1.8847e-02,  5.3496e-02, -9.2351e-02,  6.0814e-02,\n",
       "                       9.6066e-02,  1.0796e-02,  4.6273e-02, -4.1645e-02, -6.4738e-02,\n",
       "                       1.3458e-01,  1.7014e-01, -1.1225e-01,  3.2250e-02, -1.1127e-01,\n",
       "                       1.6542e-01, -8.6806e-02,  4.7576e-02, -1.4499e-01, -1.1200e-01,\n",
       "                      -6.5366e-02,  9.8272e-02, -8.3533e-03, -5.4275e-02, -1.0633e-01,\n",
       "                      -1.4752e-01, -1.5109e-01, -6.3050e-02,  1.4587e-02, -1.2078e-01,\n",
       "                       3.6775e-02, -2.9617e-02,  6.0776e-02,  4.9922e-02, -2.8331e-02,\n",
       "                      -3.0383e-02, -1.9922e-02, -8.6305e-02,  7.9066e-03, -4.3353e-02,\n",
       "                      -7.1301e-02, -1.7637e-02,  1.9807e-02,  4.2768e-02, -2.0907e-02,\n",
       "                      -1.6768e-01,  2.3107e-03, -7.6866e-02, -5.2683e-02,  8.4276e-03,\n",
       "                       2.8618e-02, -7.1756e-02, -6.6750e-02, -6.1647e-02, -1.7368e-01,\n",
       "                      -1.3304e-01, -1.3672e-02, -5.7925e-02, -1.2177e-01,  6.2268e-02,\n",
       "                       1.6595e-03, -1.9996e-01, -1.5354e-01,  4.7378e-02, -8.4313e-02,\n",
       "                       1.6119e-02, -8.4253e-02,  7.2002e-02,  3.4781e-02,  3.8122e-02,\n",
       "                      -2.0219e-02, -3.3133e-02, -1.1865e-01, -5.5531e-02, -2.3359e-02,\n",
       "                       7.4466e-02, -3.5500e-02, -4.1378e-02, -6.5355e-03, -8.7223e-02,\n",
       "                      -7.4054e-02,  1.1981e-02, -4.4298e-02,  1.2171e-01, -5.4130e-02,\n",
       "                      -1.1497e-01,  1.6921e-02, -1.7196e-01, -7.1141e-02, -1.4896e-01,\n",
       "                      -2.6252e-01, -3.9677e-03, -7.6426e-02, -8.8663e-02, -1.9663e-03,\n",
       "                      -8.4316e-02, -1.0971e-01,  1.1783e-01, -5.2438e-02, -9.1740e-02,\n",
       "                      -7.8962e-02,  1.4522e-02, -2.1902e-02, -7.5509e-02, -1.2558e-01,\n",
       "                       1.8318e-02,  3.0485e-02,  5.4473e-02,  1.4072e-02, -1.3473e-01,\n",
       "                       1.1358e-02,  4.6622e-03, -3.3661e-02, -3.8608e-02, -4.9205e-03,\n",
       "                      -1.1059e-01, -1.4226e-01, -1.9553e-01, -1.5901e-01, -9.4595e-02,\n",
       "                       4.8220e-02,  1.5666e-02,  1.0386e-01,  7.7490e-03,  5.5945e-02,\n",
       "                      -1.9873e-02,  7.4103e-02, -3.0391e-02,  7.1413e-02,  6.2236e-02,\n",
       "                      -8.6438e-02, -5.3631e-02,  1.6691e-02, -8.6266e-03,  1.0830e-01,\n",
       "                       1.0831e-01,  5.5168e-02, -2.1514e-01, -1.0925e-01, -2.4304e-02,\n",
       "                      -9.1537e-02,  3.6317e-02, -9.2243e-02,  3.2543e-02,  1.0475e-01,\n",
       "                      -3.0089e-04, -1.1086e-01, -7.7212e-02,  2.0004e-03,  1.3175e-01,\n",
       "                      -1.5701e-02,  2.6088e-02, -7.7113e-02, -4.2347e-02, -3.3654e-02,\n",
       "                      -2.2056e-02, -4.7773e-02,  2.6244e-02,  3.8496e-02,  5.8716e-02,\n",
       "                      -5.1944e-02, -1.2400e-02,  6.5740e-03, -5.7936e-02,  1.5763e-03,\n",
       "                       2.8300e-02,  5.4657e-02, -7.0906e-02,  1.1337e-01,  2.6461e-03,\n",
       "                      -9.3684e-03, -5.5033e-02, -9.5585e-02,  1.0961e-02,  1.7022e-02,\n",
       "                      -7.4753e-02, -4.1038e-03, -8.5886e-02, -2.3140e-02,  6.9239e-02,\n",
       "                      -1.1754e-01, -9.0097e-02,  1.2447e-01, -5.0872e-02,  2.2576e-02,\n",
       "                      -4.9149e-02, -2.8367e-02, -3.2450e-02, -9.1416e-04, -2.1077e-02,\n",
       "                      -7.6548e-02, -5.0051e-02,  1.6317e-02,  2.0543e-02, -4.5344e-02,\n",
       "                       9.4010e-02,  1.1899e-02, -4.6216e-02,  1.1792e-03,  2.4350e-02,\n",
       "                       5.7799e-02,  2.3421e-02, -1.0922e-01, -4.8145e-02,  5.4981e-02,\n",
       "                      -5.3197e-02,  3.8577e-02, -5.2248e-02,  4.8094e-02,  7.9553e-02,\n",
       "                      -1.3669e-01, -3.1243e-02, -5.6176e-02,  6.4499e-02,  5.5132e-02,\n",
       "                       6.4813e-02,  4.2581e-02, -1.3142e-02, -1.3611e-02, -2.4022e-04,\n",
       "                      -2.0059e-02,  1.0209e-01, -6.6474e-02,  8.7166e-03, -4.5042e-02,\n",
       "                      -2.6124e-02,  1.0131e-01, -7.5317e-02, -7.4114e-02, -2.8430e-02,\n",
       "                       1.9954e-02,  2.4014e-02,  4.6936e-02, -4.3827e-02, -9.3011e-03,\n",
       "                       6.6111e-02,  7.2941e-02,  3.2836e-02, -4.8664e-02,  1.0723e-01,\n",
       "                      -4.2907e-02,  8.6051e-02, -1.5824e-02, -1.6246e-02,  6.6185e-03,\n",
       "                      -6.9894e-02, -2.6199e-02,  1.0672e-01, -5.0528e-02, -2.1241e-01,\n",
       "                      -5.7277e-02, -3.7920e-02, -2.8220e-02, -1.6880e-02, -2.5023e-02,\n",
       "                       1.3624e-02,  7.3473e-02, -6.6329e-02, -7.3884e-02,  4.7746e-02,\n",
       "                      -8.1217e-02,  6.1111e-02,  1.6643e-02, -1.1326e-02,  6.4208e-02,\n",
       "                       4.1023e-02,  5.0386e-02,  1.4126e-01,  4.9847e-02, -6.6423e-02,\n",
       "                       6.7040e-02,  1.1548e-01,  3.0368e-02,  1.4711e-01,  1.0750e-01,\n",
       "                       1.2427e-01,  1.3671e-01,  1.2302e-01,  2.1041e-01,  1.8642e-01,\n",
       "                       1.5615e-01,  1.6088e-01, -2.8817e-02, -6.8872e-02, -6.1900e-02,\n",
       "                       1.0508e-01,  9.0097e-02,  1.0195e-01,  1.9617e-02,  1.0335e-01,\n",
       "                       3.0639e-02,  1.2681e-01,  1.7724e-02,  2.3912e-01,  1.3302e-01,\n",
       "                       1.9717e-01,  1.5017e-01,  3.6897e-02,  2.0203e-01,  1.5854e-01,\n",
       "                       2.3642e-01,  1.7911e-01,  1.1514e-01, -2.8796e-02,  2.2686e-01,\n",
       "                       1.4129e-01,  2.4022e-02,  2.4171e-02,  1.1184e-01,  1.3908e-01,\n",
       "                      -1.6557e-02, -6.0728e-02,  4.4646e-02,  8.4294e-02,  1.4309e-01,\n",
       "                      -1.3353e-02,  7.3439e-02,  1.2016e-01,  4.6734e-02, -4.5122e-02,\n",
       "                       2.4709e-01, -7.2659e-02, -3.7428e-02,  3.5750e-02, -1.7631e-01,\n",
       "                       2.6798e-01, -8.5331e-03, -8.4452e-02,  2.4047e-02,  1.7007e-01,\n",
       "                       4.3936e-02,  1.1187e-02,  8.2762e-02,  4.1475e-02,  1.9728e-01,\n",
       "                       1.2279e-01,  1.3243e-01,  1.1459e-01, -1.1319e-01,  3.0080e-02,\n",
       "                       5.8859e-02,  3.4367e-02, -2.6910e-02,  9.1021e-02, -8.2834e-02,\n",
       "                       1.7754e-01,  6.1257e-02,  2.2741e-01,  9.4415e-02,  2.0620e-02,\n",
       "                       1.5692e-02,  5.5635e-02,  1.0144e-01, -1.8189e-01,  1.9671e-01,\n",
       "                       7.4068e-02,  9.5332e-02,  5.5354e-02,  1.0581e-01,  7.8449e-02,\n",
       "                      -3.6833e-02,  2.5820e-01,  9.6929e-02,  1.3226e-01,  1.3868e-01,\n",
       "                       1.5910e-01,  9.3835e-02, -4.0805e-02, -2.3014e-02,  2.8186e-02,\n",
       "                       8.1113e-02,  1.0878e-01,  5.1808e-02,  9.0855e-02,  6.2983e-02,\n",
       "                       7.7801e-02,  1.2182e-01,  1.1902e-01,  2.2915e-02,  4.3273e-02,\n",
       "                      -2.1874e-02,  3.6761e-02,  4.0205e-02,  1.4227e-01,  1.9053e-01,\n",
       "                       1.4286e-01,  6.1455e-02, -8.7898e-02,  9.6805e-02,  4.3287e-02,\n",
       "                       1.0100e-01,  1.4448e-01,  6.6065e-02,  2.4702e-01,  1.6613e-02,\n",
       "                       2.6946e-01,  3.4263e-02], device='cuda:0')),\n",
       "             ('bilstm_oov_context_feature.weight_ih_l0',\n",
       "              tensor([[ 0.7975,  0.2363,  0.1472,  ...,  0.0691, -0.0650, -0.0189],\n",
       "                      [ 0.1220,  0.1524,  0.3090,  ..., -0.1347, -0.2795, -0.1916],\n",
       "                      [-0.4939,  0.6303, -0.0388,  ...,  0.4229, -0.5148,  0.1277],\n",
       "                      ...,\n",
       "                      [-0.0201,  0.2648, -0.1575,  ..., -0.6171, -0.0241,  0.5079],\n",
       "                      [-0.1119,  0.0841, -0.4069,  ..., -0.0061, -0.2346, -0.4521],\n",
       "                      [-0.3669,  0.2600, -0.0362,  ..., -0.0603,  0.1008,  0.1273]],\n",
       "                     device='cuda:0')),\n",
       "             ('bilstm_oov_context_feature.weight_hh_l0',\n",
       "              tensor([[ 0.0092,  0.0626,  0.2563,  ..., -0.0623,  0.0248,  0.0508],\n",
       "                      [-0.3116, -0.0551, -0.0390,  ..., -0.1277,  0.1220,  0.2014],\n",
       "                      [ 0.0676, -0.0253,  0.0005,  ..., -0.1910,  0.1066, -0.3704],\n",
       "                      ...,\n",
       "                      [-0.0348,  0.1504,  0.1152,  ..., -0.0598,  0.1404, -0.1089],\n",
       "                      [ 0.1223, -0.0028,  0.2078,  ..., -0.0665,  0.0269, -0.0452],\n",
       "                      [ 0.3955, -0.0177, -0.1143,  ...,  0.0901, -0.3748,  0.0852]],\n",
       "                     device='cuda:0')),\n",
       "             ('bilstm_oov_context_feature.bias_ih_l0',\n",
       "              tensor([ 1.5833e-01, -1.5473e-01, -4.3592e-02,  4.0761e-02, -8.7220e-02,\n",
       "                       1.4345e-02, -5.9181e-03, -6.1510e-02, -3.9464e-02,  1.7056e-02,\n",
       "                      -2.4201e-02, -1.0843e-01, -1.9921e-03, -3.1533e-02, -1.7044e-01,\n",
       "                       2.7814e-02, -6.9351e-02, -2.0557e-01, -4.6152e-02, -2.2796e-01,\n",
       "                      -1.0250e-01, -3.3355e-02, -1.5631e-01, -1.2706e-03, -1.5567e-02,\n",
       "                      -3.0006e-02, -1.1440e-01, -6.9012e-02, -1.9174e-01, -1.5065e-01,\n",
       "                      -1.1438e-01,  4.1393e-02, -9.7239e-02,  2.8735e-02,  1.0380e-01,\n",
       "                       9.7670e-02, -1.6564e-01, -8.9664e-03, -1.0636e-02, -2.0841e-01,\n",
       "                      -1.1461e-01, -8.1131e-02, -2.8345e-01, -1.0316e-02,  6.3398e-04,\n",
       "                      -1.3746e-01,  4.4347e-02, -1.2258e-01, -7.8283e-02, -1.2254e-01,\n",
       "                       1.9857e-02, -6.9267e-02, -9.4387e-02, -1.9649e-01,  4.5249e-02,\n",
       "                      -2.2024e-01, -1.5449e-01, -1.6370e-01, -1.6022e-01, -1.7727e-01,\n",
       "                      -2.2423e-02, -2.9262e-02, -7.0975e-02, -1.4694e-01, -3.2300e-02,\n",
       "                      -1.4328e-01, -1.2140e-01,  1.2859e-02,  4.4365e-02, -1.8473e-01,\n",
       "                      -8.9543e-02, -8.7639e-02,  9.3478e-02, -5.2137e-02,  2.0544e-01,\n",
       "                      -9.7794e-03, -4.8341e-02, -6.3175e-02, -1.6928e-01, -3.4992e-02,\n",
       "                      -1.2249e-01, -1.4158e-01, -1.4825e-01, -1.1144e-01, -2.3477e-02,\n",
       "                      -4.3857e-02, -6.5554e-02, -1.8327e-01, -2.0543e-01, -1.0841e-01,\n",
       "                       3.6454e-02,  7.9283e-02, -1.1538e-01,  3.8410e-03, -2.5694e-02,\n",
       "                      -1.6565e-01, -1.0471e-01, -1.5760e-01, -3.9194e-02, -1.3662e-01,\n",
       "                      -2.5001e-02, -4.3145e-02, -4.3884e-02, -8.0410e-02, -6.3185e-03,\n",
       "                      -1.3558e-01, -6.4875e-02, -1.8529e-01, -1.3687e-01, -4.3054e-02,\n",
       "                      -1.3062e-01, -1.6227e-01, -1.7963e-01, -3.7455e-03,  7.6969e-02,\n",
       "                      -9.3938e-02, -2.0149e-01, -5.4540e-02, -3.3135e-03, -4.2248e-02,\n",
       "                      -9.9208e-02,  2.8905e-02,  4.8160e-03,  5.2852e-03, -4.6066e-02,\n",
       "                       2.2751e-02, -3.6366e-02, -6.9993e-02, -2.4996e-03, -1.8660e-01,\n",
       "                      -2.6191e-02, -5.1198e-02, -5.0351e-02, -2.8947e-02,  3.5917e-02,\n",
       "                      -7.5588e-02, -1.6278e-01, -2.3447e-02, -3.8921e-02, -7.5841e-02,\n",
       "                       1.5591e-01,  2.3863e-02,  1.9933e-02, -7.5361e-03,  1.2248e-02,\n",
       "                      -1.5357e-01, -8.5896e-02, -5.8563e-03, -3.5405e-02,  8.0239e-02,\n",
       "                      -1.2073e-01,  1.8245e-02, -7.2186e-02, -5.6632e-02,  5.8502e-02,\n",
       "                      -6.5214e-02,  1.3411e-01, -9.0482e-04, -2.1587e-02,  1.4364e-01,\n",
       "                      -4.7084e-02, -1.9554e-02, -3.9304e-02,  8.6047e-02, -1.7890e-01,\n",
       "                       7.0611e-02,  6.8976e-02, -1.5611e-01, -1.3625e-02,  8.1777e-03,\n",
       "                      -3.0216e-02,  1.1593e-01,  6.3892e-03, -1.6324e-02, -2.4347e-01,\n",
       "                      -9.5605e-02, -2.0221e-02,  1.7790e-02, -7.4858e-02, -6.0339e-02,\n",
       "                       1.0546e-01, -2.4413e-03,  8.1363e-02, -1.3523e-01, -1.0699e-01,\n",
       "                      -1.3646e-01,  1.3170e-01, -8.4824e-03,  8.8515e-02, -4.6621e-02,\n",
       "                      -1.6828e-02,  3.9896e-02,  1.2323e-02, -1.6236e-01,  5.5886e-02,\n",
       "                      -1.2404e-02,  3.4109e-02, -9.7261e-02,  1.7179e-02, -1.2118e-01,\n",
       "                      -4.2353e-02, -3.3070e-02,  1.6910e-02, -1.7690e-01, -6.5796e-02,\n",
       "                       4.5286e-04, -1.2334e-01,  1.1086e-01, -2.3340e-03, -4.1131e-02,\n",
       "                      -3.3702e-02, -2.6543e-01, -1.8952e-02,  1.3464e-01,  7.7987e-02,\n",
       "                       6.8277e-02, -1.2597e-01, -1.0891e-02,  3.0157e-02, -6.2831e-02,\n",
       "                      -2.1488e-01,  6.1647e-02, -2.2493e-01, -8.0039e-02,  1.0924e-01,\n",
       "                      -3.0999e-02, -7.4549e-02, -1.0209e-01, -5.0577e-02, -1.4173e-01,\n",
       "                       4.8846e-02,  6.3276e-02,  2.2643e-02, -9.0804e-02, -2.5134e-02,\n",
       "                      -1.6443e-02, -7.4945e-02,  5.0018e-02, -5.8157e-02, -1.6526e-02,\n",
       "                       7.8463e-02,  5.0311e-02,  1.0437e-01,  3.4492e-02, -1.2143e-01,\n",
       "                       2.6949e-02, -8.1678e-03,  2.5329e-03,  5.1382e-02, -2.0509e-01,\n",
       "                      -1.0827e-01, -4.2508e-02, -2.0890e-01,  2.8758e-02, -1.5491e-01,\n",
       "                       1.7866e-01,  6.7676e-02,  3.7276e-02,  3.4016e-02,  8.5636e-02,\n",
       "                      -1.4128e-03,  3.3823e-02, -3.9230e-02,  1.9170e-03,  3.0978e-03,\n",
       "                       1.0880e-01,  6.4034e-02, -4.5910e-02,  2.6853e-02, -3.0040e-02,\n",
       "                      -5.2851e-02,  9.6210e-02,  2.2367e-02,  1.1945e-02, -2.1154e-02,\n",
       "                      -2.2798e-03, -8.5806e-02,  4.6895e-03,  4.8523e-03,  4.9889e-02,\n",
       "                       7.5467e-02,  8.3528e-02, -2.1078e-02, -2.3857e-02, -1.1048e-01,\n",
       "                       2.0631e-02,  1.2251e-03, -4.4041e-02, -1.6618e-02, -3.0630e-03,\n",
       "                       3.7270e-02,  5.5788e-02,  2.3366e-02,  2.6474e-03, -1.8094e-02,\n",
       "                      -1.8773e-03,  3.9742e-02,  1.9811e-02, -3.0422e-02,  7.4302e-02,\n",
       "                       6.3269e-03,  3.8380e-02, -7.7229e-03, -9.1921e-02,  3.0729e-02,\n",
       "                      -1.4844e-01, -1.3065e-01, -1.8955e-02, -7.6518e-02, -3.4790e-02,\n",
       "                       6.0612e-02,  1.3558e-01,  8.1846e-02, -4.0088e-02,  6.2800e-02,\n",
       "                       5.2477e-02, -4.8828e-02,  5.6370e-03,  1.8709e-01,  5.7979e-02,\n",
       "                       4.5588e-02, -7.9991e-02,  9.0577e-02, -2.1441e-02, -3.2817e-02,\n",
       "                      -2.3856e-02,  3.2523e-02,  2.3204e-02, -6.3010e-02, -8.8210e-02,\n",
       "                       2.9191e-03, -4.0912e-02, -8.5787e-02,  6.2144e-02,  3.2698e-02,\n",
       "                      -4.7154e-02, -2.2921e-02,  2.9407e-02, -2.7498e-02, -1.1336e-01,\n",
       "                       5.0731e-02, -3.1364e-02,  3.4334e-02, -6.6818e-02,  1.0518e-01,\n",
       "                      -1.6143e-02, -2.3954e-02, -6.7215e-02,  3.7765e-03, -2.4601e-02,\n",
       "                      -1.4254e-01,  1.5588e-01, -1.5449e-01, -9.6672e-02,  8.5601e-02,\n",
       "                      -1.7519e-01, -4.5126e-02,  6.5910e-03,  1.5734e-02, -3.3062e-02,\n",
       "                       5.6082e-02, -6.9378e-02,  2.9307e-02,  4.1200e-02, -1.2916e-01,\n",
       "                      -6.4202e-02,  6.9077e-02,  1.9770e-01, -1.6616e-02,  7.9315e-02,\n",
       "                       3.0736e-03, -1.0385e-02,  1.4562e-03,  3.8557e-02,  3.3803e-04,\n",
       "                      -3.1975e-02,  3.3451e-02, -1.6124e-02, -7.7337e-02, -1.9943e-02,\n",
       "                       3.9224e-02, -1.1490e-01, -1.8061e-02, -1.7990e-02,  5.1898e-02,\n",
       "                      -8.4258e-02, -2.1779e-02,  6.5512e-02, -1.0729e-01,  5.5440e-02,\n",
       "                      -8.5761e-02, -1.9465e-01, -1.2103e-01,  2.3324e-02, -9.1736e-02,\n",
       "                      -1.3345e-01, -1.0433e-01, -1.5066e-01, -7.8891e-02,  5.5462e-02,\n",
       "                       7.6500e-02, -2.2287e-01, -6.3827e-02, -1.5670e-02, -2.5419e-02,\n",
       "                       1.7795e-02, -1.3977e-01, -4.6397e-02, -6.7803e-02,  4.1602e-02,\n",
       "                      -1.7556e-01, -9.9333e-02,  1.3200e-01, -8.3059e-02, -2.6882e-02,\n",
       "                      -7.4662e-02, -1.2239e-02, -7.0647e-02,  2.5799e-02,  3.7448e-02,\n",
       "                      -2.4707e-01, -1.1643e-02, -1.3710e-01, -1.1093e-01, -1.1836e-01,\n",
       "                      -6.4559e-03, -1.3837e-01, -5.9179e-02, -1.1290e-01, -6.9092e-02,\n",
       "                      -4.4291e-02, -1.1199e-01, -1.2697e-01, -1.4675e-01, -1.3813e-01,\n",
       "                      -1.2135e-01,  6.1500e-02, -6.0895e-02,  5.1750e-02,  1.3365e-01,\n",
       "                       4.3958e-02, -1.0763e-01,  3.6146e-02, -1.1643e-01, -1.3856e-02,\n",
       "                      -7.5044e-02, -6.9887e-02, -1.3516e-01, -2.4362e-02, -1.2217e-01,\n",
       "                       1.1962e-02, -1.1924e-01, -1.7476e-01, -9.8943e-02,  1.5077e-04,\n",
       "                      -8.1826e-02, -9.7942e-02, -1.1061e-01,  4.5568e-02,  1.8034e-02,\n",
       "                      -9.6230e-02, -4.3144e-02, -1.4975e-01,  3.8956e-02, -1.2409e-01,\n",
       "                      -1.1550e-01, -6.3232e-02, -6.5861e-02,  3.9832e-02, -1.7193e-02,\n",
       "                      -2.8783e-02, -1.3317e-01, -1.0641e-01, -9.5858e-02,  2.0611e-02,\n",
       "                       8.9539e-02, -4.8831e-02, -1.1239e-01, -1.8242e-01,  2.1863e-02,\n",
       "                      -6.2275e-02,  4.6587e-02, -3.3354e-02, -1.8462e-01, -3.8989e-02,\n",
       "                       2.2969e-03,  1.9295e-02, -2.2900e-02, -5.9140e-02, -1.4600e-01,\n",
       "                      -4.0251e-02, -1.2167e-02, -1.2051e-01, -2.5957e-01, -1.3457e-01,\n",
       "                      -9.1792e-02, -1.5801e-02,  2.0456e-02, -1.5363e-02,  9.3473e-02,\n",
       "                      -2.4692e-01, -7.7064e-02,  3.9912e-02, -6.6188e-02, -4.3935e-02,\n",
       "                      -1.0425e-01, -1.7011e-01, -8.1742e-05, -1.7691e-01, -1.2589e-01,\n",
       "                      -1.4829e-01,  1.3640e-01], device='cuda:0')),\n",
       "             ('bilstm_oov_context_feature.bias_hh_l0',\n",
       "              tensor([ 3.9392e-02, -1.7940e-01, -8.2508e-02,  4.0822e-02, -7.8942e-02,\n",
       "                      -3.8524e-02, -8.9670e-02, -4.0336e-02, -8.9674e-02, -1.4168e-01,\n",
       "                      -8.2186e-02,  9.3118e-03, -3.8980e-02, -7.9442e-02, -1.1821e-01,\n",
       "                      -2.3358e-03, -9.8159e-02, -2.4029e-01, -2.6060e-02, -1.0877e-01,\n",
       "                      -6.9080e-02, -6.9491e-02, -8.2786e-02, -2.3587e-02, -8.3488e-02,\n",
       "                      -3.9399e-02, -3.2100e-02, -8.8046e-02, -1.4372e-01, -1.0695e-01,\n",
       "                      -6.2905e-02, -1.3776e-01, -1.4051e-01,  3.6053e-02, -8.8450e-03,\n",
       "                      -3.1925e-02, -1.2254e-01, -1.2543e-01, -1.2007e-01, -1.7575e-01,\n",
       "                      -1.5250e-01, -1.5277e-01, -2.8578e-01,  6.1465e-02,  6.2161e-02,\n",
       "                       2.5862e-02, -2.0179e-02, -2.2330e-01, -5.2308e-03, -1.9641e-01,\n",
       "                      -7.9038e-02, -7.7482e-02, -4.2977e-02, -1.8798e-01,  1.7790e-02,\n",
       "                      -1.4986e-01, -1.8498e-01, -6.1739e-02, -8.9046e-02, -1.0807e-01,\n",
       "                      -6.0943e-02,  1.3508e-03,  5.1668e-02, -1.7436e-01, -4.8286e-02,\n",
       "                      -1.5234e-01, -5.8090e-03, -1.0694e-01, -1.0528e-01, -1.0539e-01,\n",
       "                      -4.5826e-02, -4.6968e-02, -8.7029e-02, -2.6743e-03,  8.9658e-02,\n",
       "                      -6.2132e-02, -1.1322e-01,  2.9268e-02, -1.1004e-01, -2.8299e-02,\n",
       "                      -1.3829e-01, -2.1624e-01, -1.0441e-01, -2.9734e-01, -8.6647e-02,\n",
       "                       2.9398e-02, -3.0486e-02, -3.7565e-02, -1.7070e-01, -8.7516e-02,\n",
       "                       4.1627e-02,  8.6015e-02, -5.2176e-02, -5.6792e-02, -1.1231e-01,\n",
       "                       3.1633e-02, -1.1359e-01, -1.8389e-01,  1.7357e-02, -2.4792e-01,\n",
       "                      -1.3217e-01, -2.0543e-01, -8.9520e-02, -1.2433e-01, -1.1934e-01,\n",
       "                      -7.3023e-02,  3.6481e-02, -1.2474e-01, -9.7369e-02, -1.8072e-01,\n",
       "                      -1.9057e-01, -2.0221e-01, -2.8274e-02, -8.2850e-02,  1.3185e-01,\n",
       "                      -1.3328e-01, -1.9673e-01, -3.2620e-02,  7.9387e-03, -3.7363e-02,\n",
       "                       1.4159e-02, -2.6028e-02, -1.8772e-01,  1.5173e-03, -9.1798e-03,\n",
       "                      -1.8507e-01, -4.1662e-02,  2.9582e-02,  6.4039e-02,  1.7081e-02,\n",
       "                       7.6721e-02,  1.1892e-02, -8.7443e-02, -8.7901e-02, -6.5136e-02,\n",
       "                      -3.3481e-02, -1.0606e-01, -3.4199e-02, -4.6129e-02, -9.4072e-03,\n",
       "                       4.6044e-02, -1.0165e-01, -1.2932e-01,  1.6126e-01, -4.6460e-03,\n",
       "                      -1.2135e-01,  7.5780e-03,  4.0706e-02, -2.6252e-02,  1.2654e-01,\n",
       "                      -8.7813e-02, -8.7595e-02, -9.6853e-02, -6.4608e-02, -2.4202e-02,\n",
       "                      -7.6639e-02,  7.6816e-02, -5.1406e-02, -8.3177e-02,  3.5791e-02,\n",
       "                      -1.8009e-02,  4.4661e-02,  4.3604e-02, -2.4617e-03, -5.3654e-02,\n",
       "                       7.1385e-02, -1.2229e-01, -1.9217e-01, -1.1124e-01,  1.2648e-02,\n",
       "                      -9.2042e-02,  2.5639e-02,  3.3495e-02,  1.8019e-02, -2.6982e-02,\n",
       "                      -1.7676e-01, -2.8606e-02, -2.3893e-02, -3.7364e-02,  2.3712e-02,\n",
       "                      -6.6232e-02,  3.7965e-02, -1.6604e-02,  2.4264e-02, -2.9116e-02,\n",
       "                      -1.0308e-01, -3.2294e-02, -5.6642e-02,  1.0998e-01, -1.9080e-02,\n",
       "                      -9.9986e-03, -4.4170e-02, -1.0142e-01, -1.6711e-01, -8.6417e-02,\n",
       "                      -6.1888e-02,  1.3805e-02, -7.0261e-02,  2.4792e-02, -1.8457e-01,\n",
       "                       7.2786e-02, -5.1809e-03, -3.2861e-02, -4.9550e-02, -6.3037e-02,\n",
       "                      -1.0388e-02,  4.1451e-02,  6.7541e-02,  6.1830e-02, -1.3513e-01,\n",
       "                      -7.1577e-02, -1.1519e-01,  1.1803e-01,  6.1700e-02, -8.2848e-02,\n",
       "                       1.0781e-01, -7.1519e-03,  6.2550e-02,  1.4324e-01,  4.5068e-02,\n",
       "                      -1.3181e-02, -2.4529e-02, -1.7418e-01, -3.1895e-02,  2.0137e-02,\n",
       "                      -6.1832e-02,  6.0292e-02, -1.6811e-01, -2.0970e-02, -2.8186e-01,\n",
       "                      -6.9038e-02,  5.7947e-02, -3.1158e-02,  1.7362e-02, -3.0532e-03,\n",
       "                      -9.2503e-02, -7.3703e-02,  8.0694e-02, -2.6651e-02, -9.5363e-02,\n",
       "                      -8.9385e-03,  4.2663e-02,  4.1135e-02, -3.1256e-02, -1.5342e-01,\n",
       "                      -1.3160e-01, -5.1519e-02,  9.4978e-02,  9.2914e-02, -1.0243e-01,\n",
       "                      -8.4398e-02,  1.2212e-02, -1.5808e-01, -4.8445e-02, -6.2434e-02,\n",
       "                       7.9101e-02, -7.2139e-02,  9.3107e-04,  2.8494e-02,  7.7552e-04,\n",
       "                       1.7721e-02,  2.9721e-02, -8.9499e-02,  5.6344e-02, -3.4684e-02,\n",
       "                      -5.8474e-02,  1.3035e-01,  2.1725e-02,  6.0353e-02, -1.7673e-02,\n",
       "                      -1.9764e-03,  3.8347e-02, -2.0793e-02,  4.1568e-02,  6.4422e-02,\n",
       "                       1.6674e-02,  4.3566e-02, -4.8575e-02, -2.1032e-03, -2.7085e-02,\n",
       "                       6.2275e-02,  3.6424e-03,  8.3190e-02,  9.3440e-02,  5.0265e-02,\n",
       "                       2.6630e-02,  1.5321e-01,  1.5647e-02, -1.0428e-01, -2.1837e-02,\n",
       "                      -4.3965e-02,  9.2484e-02,  1.3154e-01, -1.0435e-01,  5.0780e-03,\n",
       "                      -1.3623e-03,  1.3163e-02, -6.3277e-02,  2.9858e-02, -2.5694e-02,\n",
       "                      -6.4285e-02, -4.1772e-02, -5.1447e-02, -7.9938e-02, -3.8675e-02,\n",
       "                      -5.1047e-02,  2.0075e-02, -1.2259e-01, -2.3622e-02, -7.7982e-03,\n",
       "                      -9.5230e-02, -7.8650e-02,  8.7008e-03,  1.0719e-01, -6.2513e-02,\n",
       "                       1.0047e-01,  5.9001e-02,  5.8579e-02,  4.7837e-02,  3.6604e-02,\n",
       "                       1.8044e-02, -6.3994e-02,  4.0819e-02,  1.0743e-01,  6.9613e-02,\n",
       "                       8.4291e-03, -2.1266e-02,  6.4138e-02, -1.0113e-01, -8.0685e-02,\n",
       "                      -9.5317e-03, -4.0988e-02,  4.4462e-02,  1.1804e-02, -3.0430e-02,\n",
       "                      -1.0337e-01,  4.8295e-02,  4.6434e-02,  8.8401e-02, -6.7380e-02,\n",
       "                       6.7807e-02, -5.1854e-02,  3.4420e-02,  1.9460e-02,  2.4182e-02,\n",
       "                      -3.1741e-02,  8.7783e-02,  1.3703e-01, -1.1111e-02, -1.2457e-01,\n",
       "                      -1.3813e-01, -5.5163e-02, -1.8523e-01, -9.6120e-02,  6.7505e-02,\n",
       "                       1.1336e-03, -3.8614e-02, -3.6103e-02, -3.8827e-02, -2.3431e-02,\n",
       "                      -2.0146e-02, -8.5169e-02,  4.1405e-02,  2.3444e-02, -9.1236e-02,\n",
       "                       2.3884e-02,  1.0177e-01, -8.1312e-02, -6.1826e-02, -5.8041e-02,\n",
       "                      -5.7349e-03,  1.0963e-02, -3.4166e-02,  1.2213e-01,  3.7404e-02,\n",
       "                       4.3990e-02, -5.3736e-02,  4.8546e-02,  1.5827e-01,  5.0915e-02,\n",
       "                      -5.2375e-02, -5.2805e-02,  6.0826e-02, -3.6989e-02,  1.8008e-03,\n",
       "                      -6.6203e-02, -8.2265e-02, -1.2614e-01, -4.9276e-02, -1.6118e-01,\n",
       "                      -9.7438e-02, -2.0867e-01,  2.1525e-03, -8.7180e-02, -1.1747e-01,\n",
       "                      -8.5174e-02,  1.3806e-02, -1.5280e-01, -1.6957e-02, -1.5587e-02,\n",
       "                      -7.0917e-03, -2.9699e-01,  1.0529e-02,  2.2909e-02, -9.0792e-02,\n",
       "                      -7.6962e-02, -6.9118e-02, -1.2524e-02, -2.6243e-02, -3.5774e-03,\n",
       "                       3.8122e-02, -2.0396e-01,  9.7282e-02,  7.9552e-02, -1.9731e-01,\n",
       "                       8.0282e-02, -3.9273e-02, -7.6481e-02, -8.8635e-04,  6.9072e-02,\n",
       "                      -7.3860e-02, -9.0363e-02, -8.8293e-02, -1.4945e-01, -1.6292e-01,\n",
       "                      -1.1512e-01, -8.3434e-02, -4.8334e-02, -3.4805e-02,  1.7917e-02,\n",
       "                      -2.1356e-01, -6.1727e-03, -2.1249e-01, -1.7974e-01, -6.1857e-02,\n",
       "                      -6.5052e-02,  1.5213e-01, -1.5836e-01, -9.1973e-02, -1.3304e-01,\n",
       "                      -1.4619e-02, -1.4675e-01,  5.7294e-03,  9.3396e-03, -2.8144e-02,\n",
       "                      -9.7582e-02, -1.6209e-01, -1.5868e-01, -7.1917e-02, -1.0941e-01,\n",
       "                       8.4959e-02, -2.2183e-01, -1.4031e-01, -8.6975e-03, -8.7153e-02,\n",
       "                      -1.0838e-04, -2.5661e-03, -1.2579e-01, -3.9995e-02, -1.6401e-01,\n",
       "                      -2.0175e-02, -6.8754e-02, -1.0537e-02, -4.3946e-02, -9.6977e-02,\n",
       "                      -1.4855e-01, -5.7534e-02, -1.4543e-01,  6.2641e-02, -9.1615e-02,\n",
       "                       5.3399e-02,  5.3222e-02, -8.7593e-02, -8.4787e-02, -1.1355e-01,\n",
       "                       1.6915e-01, -1.0009e-01, -1.3731e-01, -1.8633e-01, -1.8385e-02,\n",
       "                      -7.0314e-02, -1.1476e-01, -8.8245e-02, -1.3912e-01,  2.4085e-02,\n",
       "                      -1.6900e-01,  2.8346e-02, -1.3856e-01, -7.6736e-02, -1.1627e-01,\n",
       "                      -9.3018e-02, -1.9629e-01, -5.3528e-02, -1.7747e-01, -1.5687e-01,\n",
       "                      -1.0014e-01,  6.4680e-02,  4.0177e-02,  8.1889e-02, -6.8359e-02,\n",
       "                      -2.1842e-01, -1.0083e-01, -1.6079e-01, -1.4830e-02,  2.1292e-03,\n",
       "                      -1.9712e-01, -1.2934e-01, -1.1023e-01, -7.6197e-02, -3.2691e-02,\n",
       "                      -1.4038e-01,  2.2907e-01], device='cuda:0')),\n",
       "             ('bilstm_oov_context_feature.weight_ih_l0_reverse',\n",
       "              tensor([[-0.4716, -0.4244, -0.1086,  ...,  0.0839,  0.3737, -0.0065],\n",
       "                      [-0.3356, -0.0167, -0.3302,  ..., -0.2351,  0.4060,  0.2282],\n",
       "                      [ 0.0118, -0.0908, -0.0691,  ..., -0.1722, -0.2552, -0.2071],\n",
       "                      ...,\n",
       "                      [ 0.0324,  0.2888,  0.0396,  ..., -0.5589, -0.3357, -0.5248],\n",
       "                      [-0.3207,  1.0058, -0.1274,  ...,  0.0968, -0.4181,  0.0897],\n",
       "                      [-0.1753,  0.0942, -0.0198,  ..., -0.1891, -0.2587,  0.8272]],\n",
       "                     device='cuda:0')),\n",
       "             ('bilstm_oov_context_feature.weight_hh_l0_reverse',\n",
       "              tensor([[ 0.0049, -0.0466,  0.1068,  ..., -0.3040, -0.0595,  0.2401],\n",
       "                      [-0.1765,  0.1980,  0.0382,  ...,  0.2159,  0.0603, -0.2388],\n",
       "                      [-0.2440,  0.1554,  0.0304,  ...,  0.1232, -0.1317, -0.1747],\n",
       "                      ...,\n",
       "                      [-0.2107, -0.0553,  0.2536,  ..., -0.2160, -0.0275, -0.0653],\n",
       "                      [ 0.1810,  0.1610, -0.1386,  ...,  0.1541, -0.1776,  0.2742],\n",
       "                      [-0.2121, -0.0629,  0.1315,  ..., -0.0261,  0.0264, -0.0905]],\n",
       "                     device='cuda:0')),\n",
       "             ('bilstm_oov_context_feature.bias_ih_l0_reverse',\n",
       "              tensor([ 3.2087e-01,  9.6537e-02,  1.8487e-01,  2.3351e-01, -4.7738e-03,\n",
       "                       2.4036e-01,  1.2987e-01,  6.6343e-02,  6.4779e-02,  1.4843e-01,\n",
       "                       4.5188e-02,  7.7065e-02,  2.2366e-01,  1.3404e-01,  3.1896e-01,\n",
       "                       7.1464e-02,  2.2155e-01, -9.1246e-02,  1.6489e-01, -4.3043e-03,\n",
       "                       1.3846e-01, -7.2587e-02,  3.0887e-01,  8.7580e-02,  3.0552e-02,\n",
       "                       6.9653e-02,  2.7922e-01,  1.5882e-01,  1.2685e-01,  2.9285e-01,\n",
       "                       9.5920e-02,  2.3696e-01,  8.8544e-02,  3.2141e-01,  1.6020e-01,\n",
       "                       1.1389e-01,  1.9495e-01,  1.7958e-01,  2.4881e-01,  1.0867e-01,\n",
       "                       2.0868e-01,  9.6231e-02,  1.2718e-01,  1.2770e-01,  6.7613e-02,\n",
       "                       1.9759e-01,  2.0440e-01,  1.0574e-01,  1.7733e-01,  1.8406e-03,\n",
       "                       3.9301e-02,  1.4393e-01,  1.0814e-01, -5.1424e-02,  1.8421e-01,\n",
       "                       2.0173e-01, -8.0533e-02,  4.9762e-02,  8.1347e-02,  1.7492e-01,\n",
       "                       2.1763e-01,  2.0312e-01,  1.6861e-01,  3.1429e-02,  1.0439e-01,\n",
       "                       2.0428e-01,  8.9686e-02,  2.8419e-01,  2.2507e-02,  6.7080e-03,\n",
       "                       1.7140e-01,  1.3435e-01,  1.4681e-01,  4.5309e-02, -4.4316e-02,\n",
       "                       2.0099e-01,  9.4487e-02,  1.3830e-01,  7.4749e-02,  3.9714e-01,\n",
       "                       2.4057e-01, -1.4661e-02,  2.3042e-01,  1.4275e-01,  1.6964e-01,\n",
       "                       1.7182e-01,  1.9152e-01,  1.1635e-01,  2.0390e-01,  1.2733e-01,\n",
       "                      -5.8532e-02,  1.3057e-01,  1.0846e-01,  1.7807e-01,  1.2709e-01,\n",
       "                       1.5727e-01,  1.5565e-01, -4.5254e-02,  9.8122e-02,  6.3184e-02,\n",
       "                       2.9552e-01,  2.1137e-01,  1.9050e-02,  1.8366e-01, -5.1218e-02,\n",
       "                      -4.9712e-02, -4.1809e-02,  3.2202e-01,  1.5743e-01,  1.8656e-02,\n",
       "                       2.1429e-01,  7.8228e-02,  2.7305e-02,  3.0094e-01,  1.8615e-01,\n",
       "                       2.1124e-01,  8.4094e-02,  2.3927e-03, -4.1568e-02,  1.3119e-01,\n",
       "                       2.2962e-01,  1.9003e-02,  2.2881e-01,  1.3703e-01,  1.8411e-01,\n",
       "                       1.7254e-01,  1.1197e-01,  1.4084e-01,  1.3061e-01,  7.4389e-02,\n",
       "                      -7.1092e-02, -1.0289e-01,  6.9278e-02, -2.3428e-02,  3.1490e-02,\n",
       "                      -2.5106e-02,  6.7867e-02,  1.8826e-02, -2.6428e-02, -8.2822e-02,\n",
       "                       1.5905e-01,  2.7751e-02,  1.4146e-02,  8.4220e-03, -4.9444e-02,\n",
       "                      -3.1883e-02, -4.6502e-03,  1.4160e-01,  2.2898e-01, -5.9734e-02,\n",
       "                       8.1229e-02,  7.6847e-02,  4.6795e-02,  1.0383e-02, -1.7340e-01,\n",
       "                       6.4547e-02, -5.0104e-02,  6.9694e-02, -4.9384e-02,  9.0381e-02,\n",
       "                      -9.7016e-02, -9.4383e-03,  4.5515e-02,  9.7461e-02,  4.1103e-02,\n",
       "                       9.5594e-02,  6.3231e-02, -3.5941e-02,  4.5996e-02,  8.2468e-02,\n",
       "                      -1.0516e-01,  7.7420e-02,  2.7724e-03, -7.0617e-02, -3.0587e-03,\n",
       "                       8.6647e-02, -8.4886e-02, -4.9873e-03,  1.0536e-01,  1.5587e-01,\n",
       "                      -7.6530e-02, -4.8585e-02,  1.5466e-02, -7.3232e-02,  6.4609e-02,\n",
       "                       7.3444e-02,  4.0222e-03,  1.1024e-01,  1.3669e-01,  1.3363e-01,\n",
       "                      -5.2568e-02, -8.5802e-02,  8.4160e-02, -3.7781e-02,  6.2855e-02,\n",
       "                       6.0886e-02, -3.0536e-03,  3.7079e-02,  6.1952e-02, -8.5592e-03,\n",
       "                       9.7888e-02,  1.1513e-01,  3.4230e-02,  1.6087e-02,  3.1742e-02,\n",
       "                       1.5104e-01,  1.6698e-02, -1.3625e-02,  5.7419e-02,  1.0525e-01,\n",
       "                       3.5788e-02,  1.2475e-01,  7.5978e-02,  6.6801e-02,  2.5134e-02,\n",
       "                       1.5629e-02,  3.5776e-02, -1.2081e-02, -1.9472e-02, -1.8170e-02,\n",
       "                       4.4351e-02,  3.7182e-02,  2.8928e-02,  9.8334e-03,  6.5894e-02,\n",
       "                      -1.3324e-01,  7.3419e-02, -3.1681e-03,  6.9997e-02,  9.6766e-02,\n",
       "                      -3.6072e-04,  3.6918e-02, -2.9644e-02,  5.6246e-02,  1.1923e-01,\n",
       "                       1.3205e-01,  1.2362e-02,  8.7806e-04,  1.7485e-01,  6.0716e-02,\n",
       "                       4.3397e-02,  3.2014e-03,  3.4326e-02,  1.4299e-01,  6.4744e-02,\n",
       "                      -1.8795e-02,  5.8550e-02,  7.5185e-02, -7.2256e-02,  7.4969e-02,\n",
       "                       9.4953e-02,  7.5094e-02,  5.8008e-02,  7.6703e-02,  2.1366e-02,\n",
       "                       3.2032e-02, -7.7395e-02, -1.3215e-01,  1.8392e-03, -1.6712e-02,\n",
       "                      -5.6666e-03,  7.0055e-03, -8.8754e-02,  1.6643e-02, -1.1082e-01,\n",
       "                      -1.3632e-03,  7.1005e-02, -3.3607e-03, -1.5030e-01,  3.9750e-03,\n",
       "                       1.1303e-01, -1.2184e-02,  5.2642e-02,  5.0021e-02, -2.5167e-02,\n",
       "                      -6.9227e-02, -5.2596e-02, -3.2471e-02, -6.1137e-02,  7.6857e-02,\n",
       "                       6.9658e-02,  2.4043e-02, -6.8908e-02, -1.4517e-01, -4.8581e-02,\n",
       "                      -6.6561e-02,  5.7190e-02,  6.6544e-03,  9.6783e-02, -5.7736e-02,\n",
       "                      -3.6754e-02,  2.1585e-02,  4.6125e-02, -5.8294e-02,  1.7876e-04,\n",
       "                      -1.6523e-02,  7.7748e-02,  6.7922e-02, -2.8613e-02,  1.1606e-01,\n",
       "                       8.7871e-02, -2.7818e-02, -1.4204e-01,  9.5487e-02,  1.2152e-01,\n",
       "                      -1.3953e-01, -3.3546e-03, -1.2421e-01,  7.3529e-03,  2.3198e-02,\n",
       "                      -6.7796e-03, -2.1450e-02,  1.6433e-02, -3.1046e-02,  2.8690e-02,\n",
       "                      -1.7629e-01,  5.7722e-02, -8.6553e-02,  8.1200e-02, -3.4892e-02,\n",
       "                      -7.7370e-03, -1.2925e-01,  2.2857e-02, -2.4145e-02, -2.7000e-02,\n",
       "                       5.3939e-04, -3.1018e-03, -1.7851e-01,  5.1955e-02,  1.8571e-02,\n",
       "                      -3.0210e-02, -6.8818e-02,  1.2695e-01,  8.2434e-02, -1.0304e-01,\n",
       "                       3.6636e-02, -5.9064e-02, -3.7585e-02,  2.1774e-01, -7.5946e-02,\n",
       "                      -1.1055e-01,  2.9780e-02,  3.0373e-02,  9.6866e-03,  2.0419e-02,\n",
       "                      -1.1898e-01, -6.3419e-02, -3.2068e-02, -1.1581e-01,  1.8654e-02,\n",
       "                      -4.6141e-02, -1.0341e-01, -2.0297e-02,  2.0027e-02,  4.6734e-02,\n",
       "                      -4.7732e-02, -2.7205e-03, -4.0227e-02,  1.0022e-01,  7.1571e-02,\n",
       "                       1.8412e-02, -7.2178e-02,  6.0947e-02,  3.5299e-02,  1.1857e-02,\n",
       "                       8.9085e-02,  1.5030e-01, -1.4633e-01,  8.7827e-02,  5.0623e-02,\n",
       "                       1.0351e-01,  5.7910e-02,  2.0143e-02,  2.6739e-02, -1.5759e-01,\n",
       "                       3.8569e-02,  5.9638e-02, -7.7553e-02, -1.7189e-02, -6.1326e-02,\n",
       "                       6.6337e-02, -7.6114e-02,  2.7951e-03,  8.1612e-02, -2.9185e-02,\n",
       "                       2.3773e-01,  7.2120e-02,  2.8679e-01,  2.6101e-01,  1.4372e-01,\n",
       "                       1.8354e-01,  5.8412e-02,  4.0801e-02,  1.6127e-01,  1.4811e-01,\n",
       "                       2.1499e-01,  2.8731e-01, -3.8082e-02,  1.9504e-01, -4.1378e-02,\n",
       "                       2.3253e-01,  1.6445e-01,  1.4849e-01,  7.2162e-02,  2.0104e-01,\n",
       "                      -2.2951e-02,  3.6025e-01, -3.8686e-02,  1.2869e-01,  4.5703e-02,\n",
       "                       9.2273e-02,  3.7189e-01, -2.5862e-02, -4.3236e-02,  2.7629e-02,\n",
       "                       1.2986e-01,  3.1846e-01,  2.9700e-01,  2.2853e-01,  5.6865e-02,\n",
       "                       1.8163e-01,  2.4322e-01,  1.3684e-01, -1.4704e-02,  1.2255e-01,\n",
       "                       7.3849e-02,  2.7318e-01, -9.6768e-02,  1.4322e-01,  6.0748e-02,\n",
       "                       2.1699e-01,  2.5710e-01,  1.4940e-01,  9.9048e-02,  1.0604e-01,\n",
       "                       3.1427e-02,  1.1552e-01,  1.1106e-02,  2.2294e-01,  1.9128e-01,\n",
       "                       1.2592e-01,  8.9793e-02,  9.3256e-02,  2.4493e-01,  2.7027e-01,\n",
       "                       4.1249e-02,  4.2014e-01,  6.8395e-02,  1.7311e-01,  4.2714e-02,\n",
       "                       3.0595e-01,  2.2854e-01,  2.6594e-01,  5.5779e-03, -7.3843e-02,\n",
       "                       2.3736e-01,  2.9794e-01,  1.8511e-01,  8.1754e-02,  9.9015e-02,\n",
       "                      -2.3543e-02,  8.6978e-02, -5.7645e-02,  1.3597e-01,  2.4174e-01,\n",
       "                       8.5777e-02,  1.2512e-01,  1.8869e-01,  2.1709e-01,  1.5303e-01,\n",
       "                       1.7433e-01,  1.7335e-01,  2.0502e-01,  6.1908e-02,  1.5677e-01,\n",
       "                       7.1301e-02, -1.2571e-02,  2.1049e-01,  2.0449e-01, -2.5064e-02,\n",
       "                       3.2487e-01,  2.2536e-02,  1.0413e-01,  1.2488e-01,  3.1265e-01,\n",
       "                      -8.9181e-02,  3.1477e-01,  4.8182e-02,  4.4628e-02,  2.1326e-01,\n",
       "                       1.6645e-01, -1.1192e-02,  2.2626e-01,  7.5774e-02, -5.6070e-02,\n",
       "                       1.7529e-01,  2.4827e-01,  6.3360e-02,  5.6734e-02,  2.2433e-01,\n",
       "                       1.4165e-01,  1.9072e-02,  1.5071e-01,  2.7785e-01,  2.8004e-01,\n",
       "                      -1.3979e-02,  2.2209e-01, -4.6390e-02,  1.5242e-01,  8.0755e-02,\n",
       "                       2.2208e-02,  2.5256e-02], device='cuda:0')),\n",
       "             ('bilstm_oov_context_feature.bias_hh_l0_reverse',\n",
       "              tensor([ 8.2708e-02,  2.0184e-01,  1.8377e-02,  1.3006e-01,  1.8122e-01,\n",
       "                       2.0499e-01,  4.0385e-02,  2.1331e-01,  8.3722e-02,  4.3900e-02,\n",
       "                       1.3177e-01,  1.4331e-01,  9.4325e-02,  1.6045e-01,  3.7583e-01,\n",
       "                       8.8840e-02,  3.4369e-01, -8.0079e-02,  1.9215e-01, -8.5514e-02,\n",
       "                       2.8006e-01, -1.0010e-01,  3.2319e-01,  1.5975e-01,  9.1817e-02,\n",
       "                       2.2876e-02,  2.2602e-01,  1.4470e-01,  1.1706e-01,  7.5007e-02,\n",
       "                       1.5372e-01,  1.7777e-01,  7.0991e-02,  1.9106e-01,  1.8926e-01,\n",
       "                       2.5700e-01,  1.2778e-01,  2.9015e-01,  9.1433e-02,  1.5195e-01,\n",
       "                       2.1258e-01,  2.6884e-02,  8.2636e-02,  4.2323e-02, -1.2651e-01,\n",
       "                       3.1451e-01,  1.0519e-01, -7.9834e-02,  9.9403e-02,  7.1150e-02,\n",
       "                       8.9014e-02,  6.4277e-02,  1.4374e-01,  9.1614e-06,  1.7657e-01,\n",
       "                       1.2796e-01, -1.3074e-01,  1.4399e-01,  4.4147e-02,  1.1599e-01,\n",
       "                       2.5373e-01,  2.2589e-01,  9.2029e-02, -3.7771e-03,  5.5697e-02,\n",
       "                       6.7926e-02,  2.3019e-01,  2.6855e-01,  1.0026e-01,  1.8694e-02,\n",
       "                       8.1253e-02,  1.6904e-01,  2.1546e-01, -6.8275e-03,  4.8065e-02,\n",
       "                       1.5235e-01,  5.8663e-02,  1.4021e-01, -1.6206e-04,  3.8852e-01,\n",
       "                       1.7388e-01,  5.4886e-02,  1.6387e-01,  3.5239e-02,  1.4148e-01,\n",
       "                       1.8401e-01,  2.9854e-01,  3.2719e-01,  1.2593e-01,  2.1606e-01,\n",
       "                       4.4042e-02,  4.6187e-02,  1.6571e-01,  3.4055e-01,  2.5405e-01,\n",
       "                       2.1466e-01,  1.5403e-01, -6.3886e-02,  1.2957e-01,  6.4094e-03,\n",
       "                       2.8230e-01,  1.3040e-01, -2.3139e-02,  2.6198e-01,  3.6031e-02,\n",
       "                       1.0757e-01,  7.0558e-02,  2.3049e-01,  2.3649e-01,  6.7859e-02,\n",
       "                       1.5992e-01,  6.8683e-02,  3.2284e-02,  1.9180e-01,  1.1883e-01,\n",
       "                       3.7674e-01,  6.7033e-02, -5.1089e-02,  1.7975e-01,  3.7090e-02,\n",
       "                       1.1749e-01,  5.4834e-03,  1.7874e-01, -2.5063e-02,  2.8591e-01,\n",
       "                       2.4349e-01,  1.6826e-01,  1.1138e-01,  1.6120e-01,  1.1173e-01,\n",
       "                      -1.5544e-02,  4.9215e-02,  1.1142e-01,  2.8188e-02,  9.1270e-03,\n",
       "                       6.4072e-02,  4.2976e-02, -4.6813e-02,  4.5498e-02, -6.7668e-02,\n",
       "                       1.1916e-01, -2.8054e-02,  2.2953e-03,  9.3207e-02, -8.5134e-02,\n",
       "                       9.7208e-03,  6.0937e-02, -7.2967e-02,  4.4071e-02,  2.8682e-02,\n",
       "                       1.2265e-01,  7.4583e-03,  4.7993e-02,  8.8818e-02, -4.4848e-03,\n",
       "                       2.6952e-02, -6.9343e-03, -1.6443e-02,  1.2992e-01,  1.3856e-01,\n",
       "                       1.6467e-02, -3.6196e-02, -1.6714e-03,  3.3843e-02, -3.1794e-02,\n",
       "                      -1.5896e-02,  7.8486e-02, -1.3691e-02,  1.2784e-01, -8.6036e-04,\n",
       "                      -4.2130e-02,  1.8799e-02, -2.1780e-02,  1.1570e-01, -7.8794e-02,\n",
       "                       4.9161e-02,  1.4807e-01,  9.7965e-02,  1.1409e-01,  5.6993e-02,\n",
       "                      -1.6908e-01,  2.0594e-02,  4.3115e-02, -9.5926e-02,  2.0166e-01,\n",
       "                       4.3056e-02,  5.1772e-02,  2.2339e-01, -2.5019e-03,  1.2097e-01,\n",
       "                       2.4937e-02, -1.2154e-01,  2.1095e-03, -8.3133e-02,  1.4232e-01,\n",
       "                       6.2924e-02,  4.9178e-02, -2.1767e-02,  1.0285e-01,  7.4315e-02,\n",
       "                       1.0571e-01,  4.5921e-02, -2.4653e-02, -8.0410e-03,  5.8589e-02,\n",
       "                       5.1066e-02, -6.5750e-02, -1.7482e-02,  1.0600e-01,  2.1248e-01,\n",
       "                       6.3267e-02, -1.5850e-02,  6.7905e-02,  3.6650e-02,  4.2631e-02,\n",
       "                       2.0617e-01,  4.0878e-02, -2.1219e-03,  1.6845e-02,  3.2348e-02,\n",
       "                       1.2298e-01,  7.0619e-02, -6.1330e-02,  1.5614e-02,  1.8815e-01,\n",
       "                       7.4798e-02,  3.3903e-02, -3.6317e-02,  7.9083e-02,  1.1004e-01,\n",
       "                       3.2140e-02,  1.8306e-01, -1.1273e-02,  4.5046e-02,  4.9460e-02,\n",
       "                       8.5359e-02, -2.1584e-02, -7.4163e-02,  1.4170e-01,  1.2992e-01,\n",
       "                       2.7068e-02, -2.1813e-03, -6.8704e-02,  1.5140e-01,  1.0468e-01,\n",
       "                       9.7077e-02,  3.0162e-02, -1.3783e-03, -7.5457e-02, -6.1705e-02,\n",
       "                      -1.5117e-02, -6.5844e-02, -8.0133e-03,  2.1108e-01, -1.8704e-02,\n",
       "                       6.4942e-02, -1.4748e-01, -1.2616e-01,  4.5413e-02,  1.4359e-01,\n",
       "                       1.4877e-02,  5.9351e-02, -8.7287e-02,  9.9904e-02, -2.2093e-01,\n",
       "                       5.6955e-02,  6.3803e-02, -3.8128e-02, -1.6559e-02,  1.5308e-01,\n",
       "                       3.1950e-02, -1.1190e-02, -7.9842e-02,  9.4786e-02, -3.5140e-02,\n",
       "                       5.1529e-02, -1.0181e-01,  1.0822e-02,  2.2866e-02, -6.1479e-02,\n",
       "                      -2.5324e-02,  3.4892e-02, -1.4595e-02, -4.1624e-02,  4.6276e-03,\n",
       "                      -5.7178e-02,  3.1541e-03,  4.3394e-02, -1.4348e-01,  1.2246e-02,\n",
       "                      -7.6766e-02,  2.5593e-03,  2.0798e-03, -1.6185e-02,  1.2280e-01,\n",
       "                       7.3092e-02,  1.6508e-02, -1.0286e-01,  2.4242e-03,  5.7934e-02,\n",
       "                      -4.4634e-02, -8.1443e-02, -1.1680e-02, -1.8627e-02,  1.5488e-02,\n",
       "                      -1.6924e-02,  2.6204e-02, -1.3616e-01,  6.4107e-02, -2.6421e-02,\n",
       "                       5.8657e-02,  3.4813e-02,  2.3266e-02, -1.2832e-01,  4.5617e-02,\n",
       "                       1.1903e-01,  4.0314e-03, -4.7373e-02, -9.2610e-02,  9.0652e-03,\n",
       "                      -1.1421e-01,  7.8321e-02, -2.4047e-02, -8.1048e-03,  2.5453e-02,\n",
       "                      -2.4227e-03, -9.4562e-03, -1.0717e-01, -1.2944e-02,  1.2735e-01,\n",
       "                      -9.6352e-02, -7.8963e-02,  2.9385e-02,  3.6172e-02, -4.3839e-02,\n",
       "                       4.7350e-02, -5.3416e-04,  1.1127e-01,  1.0892e-02, -8.7784e-03,\n",
       "                      -9.1346e-02, -8.5910e-03,  1.1685e-01,  2.3063e-03,  7.1837e-02,\n",
       "                      -1.2468e-01, -9.5272e-02,  8.2457e-02, -1.0104e-01,  9.1547e-02,\n",
       "                      -3.4811e-02, -9.9204e-02,  8.8241e-02,  1.5415e-02,  1.8893e-02,\n",
       "                      -4.6488e-02, -1.8570e-01, -3.0845e-02, -3.1998e-02,  2.2824e-02,\n",
       "                      -1.1259e-01,  3.8433e-02,  4.3382e-02,  9.8602e-02,  5.0133e-02,\n",
       "                      -7.0424e-02,  5.5861e-02,  7.2619e-02, -1.5091e-02,  6.5824e-02,\n",
       "                      -3.8750e-02,  8.4487e-02,  3.9534e-02, -5.9528e-02, -7.8799e-03,\n",
       "                      -1.7781e-01,  6.5675e-02,  5.5859e-02,  7.4258e-02,  1.3666e-01,\n",
       "                       1.5587e-01,  9.3539e-02,  7.5557e-03, -9.1064e-02, -6.8486e-02,\n",
       "                       1.8462e-01,  1.5658e-01,  2.8892e-01,  3.0197e-01,  1.5061e-01,\n",
       "                       1.4836e-01,  9.3847e-02,  6.8301e-02,  9.5876e-02,  1.3047e-02,\n",
       "                       4.2549e-02,  2.6704e-01,  3.7726e-02,  4.2373e-01,  5.0883e-02,\n",
       "                       4.3134e-01,  1.0514e-01,  1.6597e-01,  1.1466e-01, -5.7185e-02,\n",
       "                       6.6646e-02,  3.8159e-01,  6.9289e-02,  2.1357e-02, -7.0102e-03,\n",
       "                       1.2049e-02,  3.9570e-01, -2.7944e-02,  3.3164e-02, -4.3214e-02,\n",
       "                       2.3548e-01,  2.8632e-01,  2.2499e-01,  1.3912e-01,  4.0769e-03,\n",
       "                       1.5032e-01,  2.6899e-01,  1.3106e-01, -1.6409e-01,  3.9270e-02,\n",
       "                       1.0028e-01,  1.2326e-01,  5.3386e-04,  9.7277e-03,  1.4066e-01,\n",
       "                       2.6804e-01,  1.7980e-01,  2.2202e-01,  1.5551e-01,  1.3993e-01,\n",
       "                       1.8882e-02,  1.1945e-01,  2.1855e-01,  3.6701e-01,  1.4965e-01,\n",
       "                      -4.0531e-03,  2.4785e-01,  1.6211e-02,  2.7567e-01,  2.0832e-01,\n",
       "                       1.2902e-01,  2.5697e-01,  5.7050e-03,  2.4888e-01,  1.3991e-01,\n",
       "                       1.3639e-01,  2.8535e-01,  1.1731e-01,  9.1694e-02,  4.7323e-02,\n",
       "                       1.9228e-01,  1.9203e-01,  1.8098e-01,  4.8180e-02,  6.8536e-02,\n",
       "                       6.7274e-03,  2.5858e-02,  6.3705e-02,  2.8354e-01,  2.3379e-01,\n",
       "                       9.6094e-02,  2.4739e-01,  7.4805e-02,  2.2633e-01,  2.1011e-01,\n",
       "                       2.2352e-01,  1.6924e-01, -4.7288e-02,  9.4068e-02,  2.7743e-01,\n",
       "                       1.0068e-01,  1.0095e-01,  1.6772e-01,  1.1056e-01,  3.5076e-02,\n",
       "                       2.7265e-01, -5.2355e-02,  1.4018e-01, -7.7074e-03,  3.0700e-01,\n",
       "                       3.0039e-02,  6.5465e-02,  6.6847e-03,  1.9916e-01,  1.8479e-01,\n",
       "                       1.1928e-01,  7.3765e-02,  3.0081e-01, -4.0313e-03,  6.6029e-02,\n",
       "                       1.3654e-01,  1.7849e-01,  1.6484e-01,  2.6276e-01,  1.5628e-01,\n",
       "                       1.4465e-01,  8.2939e-02,  1.8618e-01,  2.1579e-01,  2.3520e-01,\n",
       "                       7.3828e-02,  5.8802e-02,  7.0157e-02,  1.2881e-01,  1.2292e-01,\n",
       "                       5.6744e-02,  6.3265e-02], device='cuda:0')),\n",
       "             ('bilstm_right_context_feature.weight_ih_l0',\n",
       "              tensor([[ 0.0505,  0.3196, -0.0465,  ...,  0.0112,  0.2082,  0.3072],\n",
       "                      [-0.1887, -0.0796,  0.4570,  ..., -0.1586,  0.0470,  0.0805],\n",
       "                      [-0.0453, -0.1047,  0.1162,  ..., -0.0053,  0.2129, -0.1108],\n",
       "                      ...,\n",
       "                      [ 0.0999, -0.3968, -0.0720,  ...,  0.0184,  0.0222, -0.3067],\n",
       "                      [ 0.0616, -0.0943,  0.0296,  ..., -0.2580, -0.1061, -0.2210],\n",
       "                      [ 0.1471,  0.3146, -0.2825,  ..., -0.1515, -0.2101,  0.1346]],\n",
       "                     device='cuda:0')),\n",
       "             ('bilstm_right_context_feature.weight_hh_l0',\n",
       "              tensor([[-1.5415e-01,  1.3552e-01, -1.8675e-01,  ..., -2.2421e-01,\n",
       "                       -1.2724e-01, -4.2533e-02],\n",
       "                      [-6.7092e-02,  1.8602e-01, -1.2023e-01,  ..., -4.7869e-02,\n",
       "                        7.5112e-02, -2.3800e-01],\n",
       "                      [ 7.2330e-03,  1.6016e-01, -1.8632e-02,  ..., -7.3651e-02,\n",
       "                       -6.4054e-03, -4.7643e-02],\n",
       "                      ...,\n",
       "                      [-1.1130e-01,  6.9129e-02, -1.5155e-01,  ...,  1.8472e-01,\n",
       "                       -4.0930e-02,  9.4815e-02],\n",
       "                      [ 3.1115e-02, -1.3877e-02, -7.9922e-02,  ..., -9.2232e-03,\n",
       "                       -7.9138e-02, -1.0300e-01],\n",
       "                      [-1.7327e-01,  1.5785e-02, -2.4797e-02,  ..., -3.0867e-02,\n",
       "                       -4.2910e-02,  5.4430e-05]], device='cuda:0')),\n",
       "             ('bilstm_right_context_feature.bias_ih_l0',\n",
       "              tensor([-4.4562e-02, -1.1657e-01, -6.8646e-02, -1.4861e-01, -1.0321e-01,\n",
       "                      -7.0181e-02, -1.7984e-01, -1.5023e-01, -1.8460e-01, -4.1939e-02,\n",
       "                      -2.0110e-01, -1.0588e-01, -1.8166e-01,  4.5108e-03, -1.0996e-01,\n",
       "                      -3.7735e-02, -1.3966e-01, -1.2834e-01, -2.0117e-01, -1.6538e-01,\n",
       "                      -2.2367e-01, -7.8486e-02, -2.0548e-01, -1.5941e-01, -1.1582e-01,\n",
       "                      -1.2194e-01, -7.8579e-02, -1.2957e-01, -8.7579e-02, -1.4076e-01,\n",
       "                      -2.2927e-01, -2.8606e-01, -3.5245e-02, -1.7279e-01, -1.1991e-01,\n",
       "                      -1.7309e-01, -7.7165e-02, -1.3228e-01, -2.0785e-01, -1.2514e-01,\n",
       "                      -7.6988e-02, -5.8787e-02, -1.6535e-01, -1.6345e-01, -5.4888e-02,\n",
       "                      -1.0818e-01, -5.6622e-02, -1.7746e-01, -1.5465e-01, -1.1098e-01,\n",
       "                      -1.0990e-01, -1.9467e-01, -1.1957e-01, -2.6836e-01, -1.2815e-01,\n",
       "                       1.1061e-02, -1.5281e-01, -1.9588e-01, -2.1747e-01, -1.2283e-01,\n",
       "                      -1.2545e-01, -2.0514e-01, -1.8052e-01, -9.4229e-02, -1.2707e-01,\n",
       "                      -8.0533e-02, -9.3568e-03,  1.2724e-03, -2.6985e-01, -1.2365e-01,\n",
       "                      -2.6156e-01, -3.8131e-02, -8.9442e-02, -2.4094e-01, -3.0504e-02,\n",
       "                      -9.8265e-02, -6.8165e-02, -1.5553e-01, -2.3217e-02, -1.1507e-01,\n",
       "                      -1.2989e-01, -3.4598e-02, -9.0603e-02, -1.4837e-01, -1.2791e-01,\n",
       "                      -1.1388e-01, -9.5719e-02, -4.6463e-02, -7.5731e-02, -1.4051e-01,\n",
       "                      -8.8985e-02, -5.0756e-02, -1.6330e-01, -1.5441e-02, -1.6235e-01,\n",
       "                      -5.7002e-02, -2.9058e-02,  1.3318e-02, -5.7648e-02, -6.9029e-02,\n",
       "                      -1.7219e-01, -4.1090e-02, -1.8508e-01, -1.8936e-01, -1.0297e-01,\n",
       "                      -1.1898e-01, -1.1436e-01, -1.4723e-01, -1.5925e-01, -9.4887e-02,\n",
       "                      -1.1402e-01,  3.4959e-02, -1.4067e-01, -1.5892e-01, -6.9009e-02,\n",
       "                      -6.0064e-02,  1.1237e-04, -4.7537e-02, -2.1994e-01, -2.7569e-01,\n",
       "                      -1.3022e-01, -1.5169e-01, -2.9852e-01, -1.9909e-01, -2.0488e-01,\n",
       "                      -1.9045e-02, -1.6202e-01, -1.8591e-01, -1.3555e-01, -1.7026e-01,\n",
       "                      -1.0482e-01, -1.4793e-01, -6.3725e-02, -1.9726e-01, -2.0895e-02,\n",
       "                      -5.2453e-02, -1.4027e-01, -8.8220e-02, -2.3401e-01, -1.4613e-01,\n",
       "                      -2.1426e-01, -1.1527e-01, -1.7354e-02, -4.7027e-02, -4.9021e-02,\n",
       "                      -1.3291e-01, -9.0677e-02, -1.8170e-01, -1.6365e-01, -1.1123e-01,\n",
       "                      -8.0368e-02, -8.3505e-02, -1.3516e-01, -6.8212e-03, -9.5590e-02,\n",
       "                      -8.0911e-02, -3.3660e-02, -2.0105e-01, -1.8727e-01,  4.3561e-02,\n",
       "                      -5.5374e-02, -1.8934e-01, -1.8755e-01, -6.1473e-02, -1.5479e-01,\n",
       "                      -9.2413e-02,  2.7474e-02, -1.1880e-01, -2.8699e-02, -1.2502e-01,\n",
       "                      -1.0576e-01, -6.4789e-02, -1.0951e-01, -9.6562e-02, -7.5745e-02,\n",
       "                      -9.4993e-02, -1.7473e-01, -6.5009e-02, -1.2195e-01, -8.3460e-02,\n",
       "                      -3.8095e-02, -6.6259e-02, -1.0862e-01, -8.7663e-02, -1.6131e-01,\n",
       "                      -1.5072e-01,  3.8436e-02, -1.0875e-01, -3.6258e-02, -1.9158e-01,\n",
       "                      -8.0972e-02, -6.7325e-02, -1.2795e-01, -1.7014e-01, -9.7439e-02,\n",
       "                      -6.3248e-02, -1.3576e-01, -1.5648e-01, -1.0840e-01, -1.1100e-01,\n",
       "                      -1.1029e-01, -3.4590e-02, -2.3113e-02, -7.3430e-02, -1.7043e-01,\n",
       "                      -1.8728e-01, -1.0645e-01, -3.6877e-02, -8.4795e-02, -8.9129e-02,\n",
       "                      -3.0465e-02, -6.7336e-03, -9.5706e-02, -1.3940e-01, -9.4727e-02,\n",
       "                      -1.9637e-01, -4.9486e-02, -1.3853e-01, -1.2467e-02,  7.5390e-02,\n",
       "                      -2.0047e-01, -9.1094e-02,  2.3781e-02, -2.5887e-02,  4.5557e-02,\n",
       "                      -5.2299e-02, -7.5098e-02, -1.2020e-01, -6.2549e-03, -1.0133e-01,\n",
       "                       1.5357e-02, -1.1620e-01, -9.2881e-02, -7.4672e-02, -1.2302e-01,\n",
       "                      -8.2839e-02, -5.6755e-02, -3.8679e-02, -1.5962e-01, -3.9033e-02,\n",
       "                      -1.3700e-02, -1.5531e-01, -9.8127e-02, -2.1090e-02, -4.2743e-02,\n",
       "                      -1.4096e-01, -5.0187e-02, -1.3193e-01, -9.6713e-02, -6.0832e-02,\n",
       "                      -1.6976e-01, -1.4649e-01, -1.1832e-01, -2.9928e-03, -2.2737e-01,\n",
       "                      -1.2712e-01, -4.3106e-02, -1.2106e-02, -6.2454e-02,  9.9000e-02,\n",
       "                      -3.2283e-02,  2.7538e-03,  5.8961e-02,  1.0983e-02,  6.0220e-02,\n",
       "                       6.9906e-02,  1.4290e-02, -1.4509e-02,  1.2072e-02,  3.7023e-02,\n",
       "                      -5.2380e-02,  1.0568e-01,  6.5264e-02,  6.6793e-03, -8.4254e-02,\n",
       "                      -5.0859e-02,  8.3678e-03, -3.2830e-02, -9.0658e-02, -4.0282e-02,\n",
       "                      -8.0160e-02, -2.2490e-03,  6.2425e-02,  5.2960e-02, -3.1215e-02,\n",
       "                      -1.9507e-02, -7.9823e-02, -2.0533e-02, -1.1903e-02,  3.5536e-02,\n",
       "                      -7.5681e-04,  1.0166e-01, -7.8524e-02,  2.2150e-02,  1.2652e-05,\n",
       "                      -6.6383e-02, -4.3173e-02, -4.7482e-02,  3.3727e-02,  1.3836e-02,\n",
       "                      -2.9016e-02, -1.7111e-02, -8.7204e-02, -2.9694e-02, -1.7169e-02,\n",
       "                       1.7641e-03,  3.2743e-02, -7.5171e-02, -8.3153e-02,  5.6073e-02,\n",
       "                      -4.9155e-02,  9.1032e-02, -2.3144e-02, -1.0863e-02,  1.2449e-01,\n",
       "                       3.5471e-02,  5.6803e-02, -1.3301e-02,  1.7027e-03,  6.6440e-02,\n",
       "                      -1.2506e-01,  5.4782e-02,  3.0973e-02,  9.8756e-02, -4.6556e-03,\n",
       "                       1.3003e-01,  5.1300e-03,  8.1227e-02,  5.3025e-02,  4.1832e-02,\n",
       "                       1.3355e-02,  5.9464e-02, -4.7626e-02, -2.0825e-02, -6.4878e-03,\n",
       "                       6.3595e-02,  4.4022e-02, -8.5291e-03,  6.3335e-02,  1.4701e-01,\n",
       "                       1.0887e-02,  8.2101e-02,  7.6531e-03, -1.0190e-01, -2.2434e-02,\n",
       "                      -2.0932e-02,  1.0090e-01, -1.9184e-02, -8.1364e-02, -5.9671e-02,\n",
       "                      -5.6337e-02, -8.8135e-02, -2.2492e-02, -1.1906e-01,  4.7375e-02,\n",
       "                       1.4305e-02,  6.1608e-02, -5.8265e-02, -2.5616e-02, -4.9483e-02,\n",
       "                       9.3515e-03,  2.0799e-01, -1.1405e-02,  1.0826e-02, -2.2734e-02,\n",
       "                      -2.1903e-02, -3.7450e-02,  2.0769e-02, -4.1405e-02, -1.6694e-02,\n",
       "                       4.9739e-02, -3.9350e-02, -1.0809e-01,  9.1247e-02,  7.4373e-02,\n",
       "                       9.4134e-02,  3.9397e-03,  5.3425e-02,  7.0275e-03,  3.6065e-02,\n",
       "                       6.8195e-02,  5.9727e-02,  4.6698e-02,  6.3927e-02, -1.4482e-01,\n",
       "                      -3.0768e-01, -1.6020e-02, -1.2861e-01, -1.4702e-02, -3.3684e-02,\n",
       "                      -1.3419e-01,  1.4705e-02, -1.1102e-01, -1.2431e-01, -5.8015e-02,\n",
       "                      -3.6534e-02, -2.1630e-01, -5.8815e-02, -2.6963e-01, -1.7735e-01,\n",
       "                      -1.0555e-01, -1.0319e-01, -1.9012e-01, -1.7082e-01, -1.9422e-01,\n",
       "                      -7.6686e-02, -5.2166e-02, -1.6166e-01, -1.5684e-01, -1.2198e-01,\n",
       "                      -9.9871e-02, -6.8492e-02, -1.6030e-01, -2.9789e-01, -4.7098e-02,\n",
       "                      -5.4573e-02, -1.0899e-01, -1.9933e-01, -4.2447e-02, -1.1517e-01,\n",
       "                      -1.2935e-01, -1.4353e-01, -7.3744e-02,  2.3248e-04, -1.7612e-01,\n",
       "                      -1.5448e-01, -2.0934e-01, -7.9838e-03, -4.5654e-03, -7.9445e-02,\n",
       "                      -2.5942e-02, -3.6691e-02, -1.2319e-01, -2.1343e-01, -1.0708e-01,\n",
       "                      -2.3508e-01, -1.6964e-01, -1.5111e-01, -1.7605e-01, -2.8015e-01,\n",
       "                      -2.0883e-01,  1.0183e-02, -8.4521e-02, -5.9954e-02, -2.3704e-01,\n",
       "                      -2.1862e-01, -1.7854e-01, -2.0660e-01, -1.5102e-01, -2.8302e-02,\n",
       "                       3.1128e-02, -8.3259e-02, -1.1689e-01, -4.9310e-02, -2.0918e-01,\n",
       "                      -1.5238e-01, -1.7578e-01, -1.2578e-01, -1.5155e-01, -1.5845e-01,\n",
       "                      -1.9039e-01, -1.1972e-01, -3.0802e-02, -4.1729e-02, -8.4997e-02,\n",
       "                      -1.9204e-01, -2.2288e-01, -1.5503e-01, -2.1191e-01, -1.5849e-01,\n",
       "                      -9.0740e-02, -1.6065e-01, -1.9409e-01, -1.9030e-01, -1.9489e-01,\n",
       "                      -2.5579e-02, -1.5790e-01, -7.3595e-02, -3.4529e-02, -7.2990e-03,\n",
       "                      -1.2624e-01, -2.8962e-02, -9.7765e-02, -6.8728e-02,  1.2044e-03,\n",
       "                      -1.6811e-01, -1.4432e-01, -1.2650e-01, -9.7203e-02, -5.7701e-02,\n",
       "                      -7.0549e-02, -5.3157e-02, -1.8376e-01, -9.9991e-02, -4.2855e-02,\n",
       "                      -1.4019e-01, -1.7772e-01, -1.1174e-01, -1.4843e-01,  5.4461e-02,\n",
       "                      -6.8247e-02, -1.8690e-01, -2.1068e-01, -2.4002e-01, -1.7320e-01,\n",
       "                      -2.8382e-01, -1.4889e-01, -6.4098e-02, -3.3012e-01, -3.2594e-02,\n",
       "                      -7.3330e-02, -1.1271e-01], device='cuda:0')),\n",
       "             ('bilstm_right_context_feature.bias_hh_l0',\n",
       "              tensor([-0.1809, -0.0671, -0.1027, -0.1738, -0.1122,  0.0047, -0.0789, -0.0570,\n",
       "                      -0.1292,  0.0023, -0.0544, -0.1511, -0.1496, -0.1589, -0.1123, -0.0424,\n",
       "                      -0.1424, -0.0399, -0.2276, -0.0309, -0.1235, -0.0732, -0.0895, -0.2497,\n",
       "                      -0.0293, -0.0643, -0.1123, -0.0863, -0.0769, -0.0028, -0.1588, -0.2147,\n",
       "                      -0.1779, -0.0991, -0.0210, -0.1366, -0.1298, -0.1291, -0.1246, -0.0497,\n",
       "                      -0.0809, -0.0357, -0.2414, -0.1857, -0.0943, -0.0839, -0.1443, -0.2120,\n",
       "                      -0.1386, -0.0473, -0.1422, -0.1539, -0.1101, -0.1595, -0.0733, -0.1895,\n",
       "                      -0.1488, -0.1007, -0.2001, -0.1211, -0.1900, -0.2193, -0.0913, -0.1709,\n",
       "                      -0.1407, -0.2057, -0.0296, -0.0408, -0.0943,  0.0249, -0.2032, -0.0853,\n",
       "                      -0.1981, -0.1699, -0.1562, -0.0054, -0.1362, -0.2529, -0.1719, -0.1028,\n",
       "                      -0.1543, -0.2815, -0.2150, -0.0501, -0.2542, -0.0524, -0.1230, -0.1800,\n",
       "                      -0.1664, -0.2884, -0.0266, -0.0261, -0.2015, -0.1285, -0.0210, -0.1684,\n",
       "                      -0.0923, -0.1886, -0.1208, -0.0881, -0.0478, -0.1049, -0.1059, -0.1544,\n",
       "                      -0.1953, -0.2441, -0.0796, -0.2674, -0.0573, -0.2312, -0.1693,  0.0148,\n",
       "                      -0.1833, -0.1240, -0.1165, -0.0667, -0.0649, -0.0695, -0.1344, -0.1070,\n",
       "                      -0.0980, -0.2321, -0.2084, -0.2395, -0.1918,  0.0487, -0.2252, -0.1022,\n",
       "                      -0.0759, -0.0008, -0.0395, -0.1741, -0.0203,  0.0304, -0.0940, -0.0956,\n",
       "                      -0.1681, -0.1764, -0.1298, -0.1850, -0.1212, -0.0570, -0.1798, -0.0126,\n",
       "                      -0.0630, -0.0588, -0.0921,  0.0523, -0.0941, -0.1470, -0.0274, -0.1090,\n",
       "                      -0.0093,  0.0250,  0.0012, -0.0840, -0.1790, -0.0659, -0.1679, -0.0776,\n",
       "                      -0.0705, -0.1332,  0.0219, -0.1090, -0.0500, -0.0934, -0.1032, -0.0373,\n",
       "                       0.0019,  0.0059, -0.2078, -0.1196, -0.1307, -0.0102, -0.0571, -0.1049,\n",
       "                      -0.1932, -0.1369, -0.1601, -0.0188, -0.0874, -0.0997, -0.1206, -0.0052,\n",
       "                      -0.1361, -0.0569, -0.2061, -0.0545, -0.1434, -0.1810, -0.0332, -0.0395,\n",
       "                      -0.1304, -0.0420,  0.0044, -0.0758,  0.0246, -0.1742, -0.0894, -0.0917,\n",
       "                      -0.2075, -0.2153, -0.1568, -0.0334, -0.1003, -0.2078, -0.0439, -0.0568,\n",
       "                      -0.0442, -0.1255, -0.1774, -0.0116, -0.0525, -0.2168, -0.1129, -0.0628,\n",
       "                      -0.1425, -0.0823, -0.0520, -0.1335, -0.0270,  0.0310, -0.0913, -0.1075,\n",
       "                      -0.0770, -0.0652, -0.0937, -0.1517, -0.0798, -0.1133, -0.0796, -0.1404,\n",
       "                      -0.0982, -0.2139, -0.0146, -0.0214, -0.0492, -0.0295, -0.1602, -0.1169,\n",
       "                      -0.1466, -0.0575, -0.1507, -0.1378, -0.0403, -0.1479, -0.1963, -0.1316,\n",
       "                       0.0038, -0.1040, -0.1223, -0.1261, -0.1766, -0.0543, -0.0621, -0.0945,\n",
       "                      -0.0796, -0.0476,  0.0366, -0.0071, -0.1854, -0.0375, -0.1254,  0.0254,\n",
       "                      -0.0428, -0.0106, -0.0467, -0.0351,  0.0110, -0.1321,  0.0414, -0.0357,\n",
       "                      -0.0336, -0.0356,  0.0353, -0.1190,  0.0272, -0.0469, -0.0301,  0.0532,\n",
       "                       0.0518,  0.0129, -0.0616, -0.0172, -0.0125,  0.0137, -0.0667, -0.0524,\n",
       "                       0.0649,  0.0073,  0.0497, -0.0160, -0.0352, -0.0174, -0.0713, -0.1417,\n",
       "                      -0.0471,  0.1298,  0.0015, -0.0167, -0.0084, -0.0765,  0.0236, -0.0353,\n",
       "                       0.0133, -0.0930, -0.0885, -0.0452,  0.0128,  0.0061,  0.0751, -0.0975,\n",
       "                      -0.0261, -0.0253, -0.0763, -0.0150, -0.1618, -0.0301, -0.1511, -0.0651,\n",
       "                      -0.0125, -0.0499, -0.1280,  0.0322, -0.0506,  0.0827,  0.0301, -0.0209,\n",
       "                      -0.0739,  0.0413,  0.0091, -0.0392,  0.0520,  0.1069, -0.0953,  0.0524,\n",
       "                      -0.0476,  0.0107, -0.0632, -0.0393, -0.0282, -0.0134, -0.0086,  0.0296,\n",
       "                      -0.0453, -0.0655,  0.0143, -0.0510, -0.1085,  0.0991,  0.0097,  0.0155,\n",
       "                       0.0379,  0.0796, -0.0190,  0.0385, -0.0026,  0.0076, -0.0045,  0.0068,\n",
       "                      -0.0601, -0.0757,  0.0011,  0.0356,  0.0152,  0.0194,  0.0080,  0.1004,\n",
       "                      -0.0263, -0.0748,  0.0223, -0.0212,  0.0120, -0.0663,  0.0309,  0.0203,\n",
       "                       0.0062, -0.0746,  0.0230,  0.0263,  0.0462,  0.0887,  0.0996,  0.0533,\n",
       "                      -0.0798, -0.2209, -0.0045, -0.0739,  0.0185, -0.0232, -0.1717, -0.0819,\n",
       "                      -0.1006,  0.0905, -0.1358, -0.1094, -0.1317, -0.0421, -0.0800, -0.1626,\n",
       "                      -0.0806, -0.1495, -0.1052, -0.1481, -0.1647, -0.1614, -0.0653, -0.1765,\n",
       "                      -0.2183, -0.0506, -0.1217, -0.1983, -0.0928, -0.0744, -0.1051, -0.1860,\n",
       "                      -0.1532, -0.1165, -0.0701, -0.1065, -0.1287, -0.1753, -0.0854, -0.1170,\n",
       "                      -0.1885, -0.1544, -0.2967, -0.0930,  0.0613, -0.0860, -0.1140, -0.2018,\n",
       "                      -0.1967, -0.0629, -0.3014, -0.1684, -0.1970, -0.1819, -0.1830, -0.2123,\n",
       "                      -0.0665, -0.0617, -0.1402, -0.0425, -0.1320, -0.1752,  0.0131, -0.0512,\n",
       "                      -0.1162, -0.0329, -0.0656, -0.0287, -0.1299, -0.1177, -0.1665, -0.1765,\n",
       "                      -0.1905, -0.0370, -0.0574, -0.1803, -0.1486, -0.2552, -0.0586, -0.0891,\n",
       "                      -0.1197, -0.1422, -0.1352, -0.0540, -0.1510, -0.2885, -0.1146,  0.0334,\n",
       "                      -0.1977, -0.1363, -0.0990, -0.0505, -0.1660, -0.2019, -0.1255, -0.0894,\n",
       "                      -0.1970, -0.1169, -0.1188, -0.1288, -0.0796, -0.0764, -0.0423, -0.1467,\n",
       "                      -0.1579, -0.1387, -0.1057, -0.1814, -0.3170, -0.1207, -0.0345, -0.2117,\n",
       "                      -0.1116, -0.1399, -0.0834,  0.0412, -0.0647, -0.1855, -0.1434, -0.1463,\n",
       "                      -0.1158, -0.1209, -0.2048, -0.1814, -0.2917, -0.0457, -0.1826, -0.0335],\n",
       "                     device='cuda:0')),\n",
       "             ('bilstm_right_context_feature.weight_ih_l0_reverse',\n",
       "              tensor([[ 2.1923e-01, -5.2243e-02, -1.2354e-01,  ..., -2.4477e-01,\n",
       "                       -2.6153e-01, -7.4223e-02],\n",
       "                      [-1.1897e-01, -2.2570e-01, -2.5407e-01,  ..., -2.8438e-01,\n",
       "                        3.7096e-01, -1.2522e-01],\n",
       "                      [ 1.1686e-01,  1.5055e-01,  9.0743e-02,  ...,  1.0017e-01,\n",
       "                       -2.5186e-02, -4.3936e-01],\n",
       "                      ...,\n",
       "                      [ 1.2661e-01, -3.0730e-05, -5.7500e-03,  ...,  8.1971e-02,\n",
       "                        6.9667e-01,  2.0700e-01],\n",
       "                      [-4.2101e-01, -1.0577e-01,  4.6715e-01,  ..., -1.5214e-01,\n",
       "                        2.2720e-02, -4.8335e-02],\n",
       "                      [ 1.7420e-01,  1.0642e-01,  1.9723e-01,  ..., -2.2087e-01,\n",
       "                       -2.0733e-01, -4.0464e-01]], device='cuda:0')),\n",
       "             ('bilstm_right_context_feature.weight_hh_l0_reverse',\n",
       "              tensor([[ 0.0564, -0.0920,  0.0425,  ...,  0.0777, -0.2196, -0.0489],\n",
       "                      [ 0.2146,  0.1099, -0.0687,  ..., -0.0212,  0.2169,  0.1290],\n",
       "                      [ 0.2370,  0.1128,  0.0780,  ...,  0.2064,  0.0765, -0.2310],\n",
       "                      ...,\n",
       "                      [ 0.1952,  0.1755, -0.1922,  ..., -0.0830, -0.0821, -0.0769],\n",
       "                      [ 0.1368, -0.2086,  0.2203,  ...,  0.1709, -0.1056,  0.1558],\n",
       "                      [ 0.0828, -0.0204, -0.1245,  ...,  0.0146,  0.2934,  0.0908]],\n",
       "                     device='cuda:0')),\n",
       "             ('bilstm_right_context_feature.bias_ih_l0_reverse',\n",
       "              tensor([ 7.4286e-02, -1.0753e-01,  5.1309e-02,  1.2720e-02, -2.6329e-02,\n",
       "                       4.3144e-02,  1.9567e-01,  5.7216e-02, -1.5965e-02,  7.0273e-02,\n",
       "                       1.5158e-01,  1.1701e-02,  1.3382e-02,  1.2811e-01,  7.9483e-02,\n",
       "                      -8.8439e-02,  1.0403e-01,  7.8209e-02, -5.3991e-04, -1.2912e-04,\n",
       "                      -7.3668e-02,  3.0323e-01,  1.3063e-01,  1.7434e-02, -1.9593e-02,\n",
       "                      -1.0988e-01,  3.3793e-02,  4.4425e-02, -2.0402e-02,  9.3566e-02,\n",
       "                       1.7056e-01,  2.5195e-02,  2.4984e-01, -1.3186e-02, -3.0292e-03,\n",
       "                       6.8740e-02, -2.2769e-02,  3.9083e-02,  1.3826e-01, -3.5187e-03,\n",
       "                       1.8918e-01,  6.4945e-02, -8.6978e-02,  9.7140e-02,  2.0173e-01,\n",
       "                       3.1502e-02, -2.1666e-02,  6.7699e-02,  3.6339e-02,  1.0817e-01,\n",
       "                      -7.7336e-02, -8.4663e-02, -1.1090e-02,  4.0966e-02, -8.2550e-02,\n",
       "                      -3.6504e-03,  1.7662e-01,  1.0432e-02,  6.6738e-02, -7.2939e-03,\n",
       "                       4.3758e-02,  1.8615e-02, -9.0075e-02,  3.0078e-02, -5.2601e-02,\n",
       "                      -7.3532e-02,  1.8869e-01,  9.0044e-03,  7.5482e-02,  1.4685e-02,\n",
       "                       1.4620e-01,  9.4647e-02,  7.9712e-02,  1.1040e-01,  9.5243e-02,\n",
       "                      -3.0573e-02,  9.9051e-02,  1.2286e-01, -2.7370e-02,  1.3144e-01,\n",
       "                       2.9272e-01,  2.1470e-02,  5.7300e-02,  6.9176e-02,  4.1768e-02,\n",
       "                      -8.0178e-02,  2.2400e-01,  1.6768e-01,  6.4370e-02, -7.4109e-02,\n",
       "                      -1.4070e-01,  6.2499e-02, -5.7207e-02, -7.8816e-02,  1.0088e-01,\n",
       "                       9.1220e-02,  8.0428e-02,  9.0749e-02,  6.3050e-02,  9.4162e-02,\n",
       "                       2.1927e-01,  1.2639e-01,  1.1209e-02,  1.0165e-01,  7.9255e-02,\n",
       "                       4.9982e-02,  1.6338e-01,  4.9191e-02, -9.6521e-02,  1.4762e-01,\n",
       "                      -1.8634e-02,  8.5950e-02,  3.1728e-01,  1.0216e-01,  1.4702e-01,\n",
       "                       6.6238e-02, -6.8731e-02,  6.3815e-02,  1.1309e-01, -4.6412e-02,\n",
       "                      -5.6701e-03,  2.0223e-02,  6.0059e-02,  2.6794e-01, -8.8193e-03,\n",
       "                       1.8155e-04, -6.6058e-02,  8.5218e-02, -5.1729e-02, -8.2512e-03,\n",
       "                      -1.1835e-02,  1.1618e-01, -1.3221e-01,  9.0961e-03, -5.8483e-02,\n",
       "                       2.1759e-01, -1.5486e-01, -2.1995e-02,  1.6080e-02, -5.3404e-02,\n",
       "                      -9.8418e-02, -2.1211e-02, -1.6302e-01, -1.1589e-01, -8.0428e-02,\n",
       "                      -3.9457e-02,  4.9752e-02, -2.6024e-01, -1.4679e-01, -6.8343e-02,\n",
       "                       7.4988e-02, -9.7908e-02, -8.1424e-02, -6.2544e-02, -1.4409e-01,\n",
       "                      -1.1678e-01, -1.2450e-01, -2.1987e-02,  3.8793e-02,  5.7996e-02,\n",
       "                      -1.4925e-01,  1.4031e-02, -1.2947e-01, -3.1800e-02, -1.9202e-02,\n",
       "                      -4.9820e-02, -2.1502e-02, -1.2822e-01, -1.4121e-01, -7.1863e-02,\n",
       "                       1.9748e-02, -5.1194e-02, -8.7427e-03,  3.1375e-02, -1.9314e-02,\n",
       "                      -1.0206e-01,  5.3313e-02,  2.8051e-02, -1.5421e-01, -9.1353e-02,\n",
       "                      -1.5357e-01, -1.0182e-01, -5.3783e-02,  5.7969e-02,  1.0045e-01,\n",
       "                      -7.3792e-02, -6.2360e-03, -5.6790e-02, -5.2328e-03, -8.0121e-02,\n",
       "                       6.3229e-02, -1.0016e-01, -4.8561e-02, -7.3541e-02, -5.4540e-02,\n",
       "                      -7.0805e-02, -4.8988e-02, -6.6934e-02,  2.6607e-03,  1.4558e-02,\n",
       "                      -5.7626e-02, -3.3122e-02, -1.0896e-01, -1.1832e-01, -8.6286e-02,\n",
       "                       2.1713e-02, -1.0969e-02,  3.4724e-02, -1.2157e-01, -7.8911e-02,\n",
       "                      -7.6776e-02,  2.8277e-02, -3.4430e-02, -3.3944e-02, -2.3021e-01,\n",
       "                      -6.2547e-03,  1.3136e-02,  3.7202e-02,  2.1318e-02,  1.4426e-02,\n",
       "                      -7.6540e-02, -4.0142e-02, -1.0828e-01, -1.2173e-01, -1.8666e-01,\n",
       "                      -1.1109e-01, -9.3827e-02,  1.6378e-03, -1.2495e-01,  3.7802e-03,\n",
       "                       1.1403e-01,  1.7960e-02, -1.0120e-01,  4.5756e-02,  4.6638e-02,\n",
       "                      -8.0774e-02, -6.3433e-02,  9.0690e-02, -7.9211e-02, -4.2993e-02,\n",
       "                      -2.0155e-01, -1.9667e-01, -1.8192e-01,  5.7216e-02, -6.3876e-02,\n",
       "                      -2.7331e-02,  5.6385e-02,  1.0405e-01, -9.3720e-02, -8.5671e-02,\n",
       "                      -6.5772e-02, -5.0885e-02,  6.0815e-02, -5.1630e-02, -3.4006e-02,\n",
       "                      -8.4837e-02, -6.5938e-02,  1.0581e-02, -6.7555e-02,  9.3831e-03,\n",
       "                      -8.3716e-02, -2.7333e-03,  9.2615e-03, -4.7643e-02, -2.0850e-02,\n",
       "                      -2.9334e-02, -4.3128e-02, -5.2966e-03,  5.4269e-02,  1.9391e-01,\n",
       "                       1.0740e-01,  3.8529e-02,  2.4847e-02,  1.9179e-02,  7.3419e-02,\n",
       "                      -3.7858e-02, -3.6152e-02, -3.6354e-03, -1.8572e-02, -4.0160e-02,\n",
       "                      -9.0549e-02,  4.5399e-02,  2.1863e-02, -2.2142e-02, -2.3409e-02,\n",
       "                      -3.5814e-02,  2.4279e-02,  3.4290e-02,  1.3179e-01, -4.7478e-02,\n",
       "                      -8.9971e-02,  1.3161e-03,  1.1094e-01, -4.4635e-02, -2.4694e-02,\n",
       "                      -5.8546e-02, -3.4813e-02,  2.0475e-02,  1.1032e-01,  1.2955e-01,\n",
       "                      -8.5476e-02,  4.5884e-02,  5.6120e-02, -1.0476e-01,  1.4565e-03,\n",
       "                       8.6026e-02, -3.3910e-02,  1.7447e-02, -3.6669e-02,  1.0975e-01,\n",
       "                      -8.1119e-03,  7.3185e-02, -6.4924e-02,  7.8089e-03, -2.5784e-02,\n",
       "                       6.3361e-02, -7.0278e-02,  1.7118e-01,  3.7664e-02, -7.0559e-02,\n",
       "                       1.1629e-01, -1.4288e-01, -1.5909e-01, -1.1073e-01, -1.7897e-02,\n",
       "                       9.9995e-03, -2.8774e-02, -7.9303e-02,  1.1206e-01, -1.1950e-03,\n",
       "                      -5.7740e-02, -7.2471e-02, -2.3080e-02,  6.3995e-02, -3.8086e-02,\n",
       "                       9.6338e-03, -1.1765e-01, -8.2133e-02,  8.3835e-02, -1.4176e-01,\n",
       "                      -7.7590e-03, -5.7318e-02, -2.0155e-03, -4.8419e-03, -4.3603e-02,\n",
       "                       1.4683e-02,  4.0114e-02, -1.3409e-01, -1.3390e-01,  1.4520e-02,\n",
       "                      -8.4649e-03,  1.9826e-02,  3.1791e-02, -1.2186e-01, -7.8666e-02,\n",
       "                       1.0187e-01,  4.0312e-02,  5.9419e-02, -1.7426e-02, -9.7456e-03,\n",
       "                       8.1049e-02, -1.5188e-02,  4.6106e-02,  2.6875e-02, -1.0430e-01,\n",
       "                      -1.1162e-01,  1.0681e-01,  6.3861e-02, -7.5160e-02,  5.1148e-02,\n",
       "                       1.5308e-02, -3.9996e-02, -1.7291e-02, -2.2233e-02,  1.4310e-01,\n",
       "                       6.9543e-02, -9.5791e-02, -1.0079e-02,  1.1872e-02, -1.5946e-02,\n",
       "                       7.3689e-02,  4.4660e-02,  7.8727e-02, -3.4108e-02,  7.6464e-02,\n",
       "                       2.8865e-03,  1.9872e-02,  4.7139e-02,  6.1184e-02, -3.0838e-02,\n",
       "                       6.8027e-02,  3.8133e-02,  1.1733e-01,  2.5253e-02,  1.5686e-01,\n",
       "                       4.8716e-02,  8.2311e-02,  1.7363e-02,  6.5657e-02, -7.3969e-02,\n",
       "                       1.7833e-02,  7.1979e-02,  6.6208e-03, -2.1003e-04, -1.0013e-01,\n",
       "                       3.0774e-01,  7.7827e-02,  2.4732e-02, -1.0447e-01,  9.6154e-02,\n",
       "                      -1.0504e-01,  5.9232e-03,  2.8524e-03, -1.5386e-02, -6.0192e-02,\n",
       "                       1.1499e-01,  1.4299e-01,  1.7022e-01, -1.1454e-01,  2.8615e-01,\n",
       "                      -6.0930e-02,  3.3976e-02,  8.5672e-03,  1.7228e-02,  1.0045e-01,\n",
       "                      -1.7735e-01, -3.8250e-02,  8.0304e-02,  2.2776e-01,  3.8581e-02,\n",
       "                       4.4048e-02,  1.0815e-01,  1.0301e-01,  8.7058e-02, -5.6418e-02,\n",
       "                      -8.7623e-03,  4.4914e-02,  2.4294e-03,  1.3280e-01,  7.1714e-02,\n",
       "                       6.7338e-02,  6.3514e-02, -1.3609e-01, -4.3928e-02,  8.0421e-02,\n",
       "                       1.5181e-01, -2.2463e-02,  5.1903e-02,  1.1922e-01,  1.0676e-01,\n",
       "                       2.1184e-01, -5.5361e-02, -7.0556e-02,  1.0024e-01,  1.2445e-01,\n",
       "                       7.0011e-02,  1.5601e-01,  1.1767e-01,  2.0879e-01,  7.8522e-02,\n",
       "                       1.3399e-01,  1.9686e-01,  5.5083e-02,  7.3401e-02,  1.7861e-01,\n",
       "                       1.6088e-01,  5.4050e-02,  3.0511e-02, -5.6245e-02, -1.0995e-01,\n",
       "                       2.0823e-01,  2.2257e-01,  1.4132e-01, -4.3650e-02,  1.3082e-02,\n",
       "                       1.0717e-01,  1.4151e-01, -3.7089e-02,  1.0706e-01,  8.3543e-02,\n",
       "                       7.1722e-02,  1.5693e-01,  5.8605e-02, -9.5299e-02,  1.9367e-01,\n",
       "                       9.0258e-02,  1.1565e-03,  2.6993e-02, -1.2649e-03,  2.8430e-01,\n",
       "                       2.4383e-01,  8.3794e-02,  1.0294e-01, -2.1353e-02,  1.0734e-01,\n",
       "                       9.5015e-02,  3.7218e-01,  1.7263e-01,  4.9374e-02,  1.3299e-01,\n",
       "                       9.8884e-02, -4.9351e-02,  1.6547e-01, -1.5192e-02,  7.5301e-02,\n",
       "                      -1.0366e-02,  5.0618e-02,  3.3246e-01,  9.0063e-02,  9.8691e-02,\n",
       "                       1.9705e-01,  1.1392e-01], device='cuda:0')),\n",
       "             ('bilstm_right_context_feature.bias_hh_l0_reverse',\n",
       "              tensor([ 6.6908e-02,  7.0194e-02,  1.1422e-01,  2.9946e-02, -4.4971e-02,\n",
       "                       4.2434e-02,  1.1382e-01,  4.1272e-02, -3.1941e-02,  6.3085e-02,\n",
       "                       1.4667e-02,  9.1504e-02,  2.4814e-02,  4.7252e-02,  7.1029e-02,\n",
       "                      -9.7269e-03, -1.1374e-01,  1.3287e-01,  5.8172e-02,  7.9070e-02,\n",
       "                      -1.2070e-01,  2.3134e-01,  1.4238e-01,  1.3655e-01,  1.5490e-01,\n",
       "                       7.0800e-02, -1.1015e-01,  1.5118e-01, -1.2755e-02, -2.6550e-02,\n",
       "                      -5.5252e-02, -5.2991e-03,  2.1738e-01, -5.4557e-02,  1.1352e-02,\n",
       "                       1.2479e-01, -5.3964e-02,  7.0312e-02,  3.0660e-02, -1.3515e-01,\n",
       "                       1.3803e-01,  1.0521e-03,  5.3691e-02,  5.5948e-02,  8.9283e-02,\n",
       "                       2.3807e-01,  1.4227e-01,  5.4524e-02, -1.9610e-02,  1.4827e-01,\n",
       "                       1.0734e-01,  1.3788e-02,  1.0303e-01,  7.8280e-02, -4.3367e-02,\n",
       "                       1.0625e-01,  2.8473e-01, -2.2612e-02,  1.7921e-02, -4.6698e-02,\n",
       "                      -1.5587e-03,  1.4381e-01, -3.5598e-02, -1.1992e-02,  5.9890e-03,\n",
       "                       8.9915e-02,  1.2471e-01, -1.0269e-02,  1.5017e-02,  3.0763e-02,\n",
       "                       4.8092e-02,  1.4320e-01,  1.5711e-01,  8.4940e-03,  9.1647e-02,\n",
       "                       2.1628e-01, -8.9027e-02,  1.4750e-01,  7.5499e-02,  4.4484e-03,\n",
       "                       1.1052e-01,  1.5659e-02,  1.0642e-01, -3.0855e-02,  1.0257e-01,\n",
       "                      -1.8134e-01,  7.7485e-02,  1.7702e-01,  7.1450e-02, -7.5620e-02,\n",
       "                       1.0122e-01,  1.1825e-01, -1.6135e-01, -5.1998e-03,  3.0543e-02,\n",
       "                       5.5128e-02,  1.3045e-01,  6.3230e-02,  4.7581e-02,  9.3412e-02,\n",
       "                       7.1888e-02,  1.7949e-01,  5.9992e-02, -8.7830e-03,  1.3339e-01,\n",
       "                       1.1650e-01,  2.2476e-01, -4.8644e-03, -2.2275e-02,  5.3021e-02,\n",
       "                       7.7500e-02,  1.9301e-01,  2.0944e-01, -1.0714e-02,  5.7053e-02,\n",
       "                       1.1947e-01,  6.9874e-02,  8.1981e-02,  5.3111e-02, -1.4589e-02,\n",
       "                       2.1339e-02, -4.9705e-03, -7.7814e-03,  2.7777e-01, -1.1036e-02,\n",
       "                       7.5953e-02,  1.1020e-02,  1.3722e-01, -5.9476e-02, -1.2896e-01,\n",
       "                       5.6329e-03,  1.2650e-01,  2.9004e-02,  1.0638e-01, -1.0359e-01,\n",
       "                       1.8228e-01, -4.6688e-02,  4.5413e-02, -8.4736e-03, -9.7785e-04,\n",
       "                      -5.7542e-02, -1.6162e-02, -1.9915e-01, -1.7750e-01,  6.5070e-02,\n",
       "                      -6.4569e-02,  5.0706e-03, -1.5530e-01, -7.6550e-02, -9.8545e-02,\n",
       "                      -8.3238e-02, -2.3745e-01, -1.0191e-02, -6.7372e-06, -8.9491e-02,\n",
       "                       1.6207e-02, -2.8082e-02, -2.5185e-03, -1.1355e-01, -1.0080e-01,\n",
       "                      -3.2752e-02, -5.7439e-02,  3.5287e-03, -6.7435e-02, -9.0327e-03,\n",
       "                       1.0270e-01, -1.2475e-01, -6.2219e-02, -1.4938e-01, -5.8866e-02,\n",
       "                      -1.6286e-02,  7.3465e-02,  3.6939e-03, -2.0906e-02,  2.2125e-02,\n",
       "                      -1.8801e-02,  5.4701e-02, -5.3422e-02, -1.3540e-01, -2.4935e-03,\n",
       "                      -1.3477e-01, -1.2797e-01,  9.1120e-02,  8.5623e-02,  7.0595e-02,\n",
       "                       6.6122e-02,  8.5126e-02, -1.5781e-01,  5.6128e-02, -1.4282e-01,\n",
       "                       7.9705e-02, -6.9886e-02, -1.4956e-01, -1.0166e-01, -6.3388e-02,\n",
       "                      -6.0115e-02, -7.3360e-03, -4.5815e-02, -1.3574e-01, -1.1887e-02,\n",
       "                      -4.2115e-02, -2.6710e-02, -1.7065e-01, -1.1776e-01, -9.1089e-02,\n",
       "                       1.1702e-02,  5.1330e-02, -5.8626e-02, -7.0432e-02, -4.8499e-04,\n",
       "                      -3.2538e-02,  7.4070e-02,  1.8349e-02, -1.2270e-01, -1.7891e-01,\n",
       "                       1.2088e-01,  3.6690e-02,  1.2371e-01,  1.2743e-02,  4.3287e-02,\n",
       "                      -6.0927e-02,  2.9413e-02,  3.1075e-02, -6.9923e-02, -1.0783e-01,\n",
       "                      -3.7169e-02, -1.1605e-01,  2.9073e-02, -6.5923e-02,  7.4994e-03,\n",
       "                       1.2158e-01, -8.6069e-03,  5.9281e-02, -2.5720e-02, -6.1833e-02,\n",
       "                      -7.3424e-02, -6.2790e-02,  1.1635e-01, -6.7021e-02, -1.2551e-01,\n",
       "                      -3.6319e-02, -1.7707e-01, -1.5834e-01, -7.6390e-02, -6.4210e-02,\n",
       "                       5.2754e-02,  2.6549e-02, -1.2039e-01, -1.7768e-01,  1.9759e-02,\n",
       "                      -3.5408e-03, -3.4809e-02,  5.4511e-03, -6.1063e-03, -3.1319e-02,\n",
       "                      -1.8497e-01,  6.0841e-02,  3.7390e-02, -1.0166e-02,  2.3369e-02,\n",
       "                      -6.5763e-02,  5.5916e-02,  6.0529e-02, -6.7460e-02, -2.5390e-03,\n",
       "                      -9.9412e-04,  7.4851e-02,  4.6652e-02, -5.2666e-04, -4.6047e-02,\n",
       "                       6.0559e-02, -1.2444e-02,  4.2500e-02, -6.4210e-02,  3.8847e-02,\n",
       "                      -1.2804e-02,  1.3766e-03, -5.6144e-02, -1.1596e-01,  1.1413e-01,\n",
       "                      -5.6101e-02,  2.2448e-02,  7.8587e-02, -2.6089e-02,  3.2832e-04,\n",
       "                      -6.0572e-02,  6.9638e-02,  1.0880e-01, -2.0585e-02, -5.7881e-02,\n",
       "                       1.1026e-02,  5.7040e-02,  7.8640e-03,  1.1233e-03, -2.8959e-02,\n",
       "                       8.7380e-02,  6.6601e-02,  3.2568e-02, -3.4886e-02, -8.8519e-02,\n",
       "                      -3.0344e-02,  9.0082e-03,  7.0160e-03, -1.1386e-02, -8.2302e-02,\n",
       "                      -9.6055e-03, -2.2158e-02,  7.3598e-02, -7.9622e-02,  1.5878e-02,\n",
       "                       8.6526e-03, -5.0426e-02,  4.5136e-02,  4.2523e-02,  6.0599e-02,\n",
       "                      -1.5226e-01,  9.0623e-02, -4.9213e-02,  6.6775e-02,  8.2881e-04,\n",
       "                       1.1695e-02,  3.1074e-02, -1.3101e-01, -1.1163e-02, -5.6778e-02,\n",
       "                       1.5004e-01, -1.0257e-01, -6.1726e-03, -4.5168e-02, -1.0268e-01,\n",
       "                       1.1112e-01,  4.8958e-02,  3.2805e-02,  1.1807e-01,  5.2321e-02,\n",
       "                       6.6627e-02, -1.3734e-01, -5.2484e-02, -1.1050e-01,  1.0737e-01,\n",
       "                      -4.8830e-02,  3.6024e-03,  8.7198e-02,  6.3389e-02, -1.4165e-01,\n",
       "                       4.0751e-02, -8.9063e-02,  6.4993e-02,  8.9029e-02,  2.5162e-02,\n",
       "                      -2.4175e-03,  1.0151e-02, -4.8552e-02, -4.4724e-02, -1.6181e-01,\n",
       "                      -3.5394e-02,  3.4300e-02, -1.6983e-02, -1.2180e-01,  7.5295e-02,\n",
       "                       1.0060e-01,  3.0489e-02, -1.8556e-02,  1.2116e-01, -7.1435e-02,\n",
       "                      -4.7897e-02,  9.1998e-03, -5.3134e-02, -6.3546e-02, -3.3796e-03,\n",
       "                      -1.1761e-01, -1.0530e-01,  3.1264e-02,  9.8161e-02,  1.0760e-01,\n",
       "                      -5.7016e-02,  2.7219e-06, -9.1550e-02, -5.8144e-02, -9.3341e-02,\n",
       "                       4.6098e-02,  5.9033e-02, -1.8180e-02, -8.6672e-02,  1.4233e-02,\n",
       "                       5.5141e-02,  1.2760e-01,  1.2654e-01, -4.0367e-02, -1.0048e-01,\n",
       "                       1.9073e-01,  3.7911e-03,  1.1305e-01,  1.6099e-01,  1.0899e-01,\n",
       "                       1.5718e-01,  7.8595e-02,  1.1020e-01,  1.1238e-01,  1.8270e-02,\n",
       "                      -5.0613e-02,  1.0405e-01, -3.2768e-02, -4.8867e-02,  6.9022e-02,\n",
       "                       2.9952e-01,  1.4067e-01, -2.5059e-02,  9.1990e-02,  1.6869e-01,\n",
       "                      -1.1877e-01,  8.3100e-02,  8.8578e-02,  8.6413e-02, -3.9472e-02,\n",
       "                       1.7110e-03,  1.7588e-01,  1.1450e-01, -1.5316e-01,  5.5146e-02,\n",
       "                       3.2773e-02,  8.1596e-02,  7.0813e-04, -5.0645e-02, -4.0249e-03,\n",
       "                       3.3272e-02, -8.3152e-02,  1.3743e-01,  3.2355e-01,  9.2163e-02,\n",
       "                       1.9587e-02,  1.3693e-01,  8.9770e-02,  1.5275e-02,  2.1461e-02,\n",
       "                       2.8714e-02,  3.2273e-03,  1.3340e-01,  9.0726e-02,  1.1459e-01,\n",
       "                       1.0858e-01,  7.0966e-02, -3.9691e-02,  5.4113e-02,  2.7518e-02,\n",
       "                       8.5306e-02,  9.4685e-02,  9.0872e-02,  1.8435e-01, -9.4811e-02,\n",
       "                       1.0296e-01,  2.7171e-02, -5.3136e-02,  4.7186e-03,  1.4222e-02,\n",
       "                       7.8656e-02,  2.1601e-01, -1.5810e-03,  2.2824e-01,  6.6656e-02,\n",
       "                       1.6463e-01,  1.8567e-01,  1.7906e-01,  1.4879e-01,  1.7176e-01,\n",
       "                       1.8515e-01,  4.3125e-02,  6.1641e-02, -2.6033e-02, -2.3132e-02,\n",
       "                       2.3696e-01,  1.7293e-01,  6.9624e-02,  4.1945e-02,  6.1191e-02,\n",
       "                       1.4973e-01,  7.2054e-03, -1.5241e-04,  7.1581e-02,  4.9442e-02,\n",
       "                       5.2793e-02,  1.4030e-01, -5.6097e-02,  1.7348e-02,  7.9064e-02,\n",
       "                       1.5654e-01, -3.8334e-02,  1.5325e-01,  7.1095e-02,  1.5386e-02,\n",
       "                       7.7960e-02,  1.0341e-01,  4.5124e-02, -5.6055e-02, -3.9075e-02,\n",
       "                       7.5827e-02,  2.9804e-01,  1.5715e-01,  1.1462e-01,  2.4532e-01,\n",
       "                       8.6951e-02, -1.0074e-01,  2.0155e-01,  1.6632e-01, -9.3101e-04,\n",
       "                       8.1269e-02,  8.2190e-02,  2.8725e-01, -7.9718e-03,  7.9910e-02,\n",
       "                      -4.9106e-02,  1.3715e-01], device='cuda:0')),\n",
       "             ('fc.0.weight',\n",
       "              tensor([[-0.0767, -0.0235, -0.0427,  ..., -0.3476, -0.2654,  0.0403],\n",
       "                      [-0.0817, -0.0202, -0.1389,  ..., -0.1628,  0.0353,  0.2220],\n",
       "                      [ 0.1019,  0.0184, -0.1060,  ..., -0.0314,  0.1445, -0.1073],\n",
       "                      ...,\n",
       "                      [ 0.0347,  0.2076,  0.1853,  ..., -0.1767,  0.0581,  0.2010],\n",
       "                      [-0.0598, -0.0961, -0.0961,  ...,  0.0246,  0.3111,  0.0621],\n",
       "                      [-0.0778, -0.0519, -0.0525,  ...,  0.4447, -0.0609, -0.0603]],\n",
       "                     device='cuda:0')),\n",
       "             ('fc.0.bias',\n",
       "              tensor([-1.0411e-01, -4.1677e-02,  1.6307e-01,  4.0729e-01, -6.4258e-03,\n",
       "                      -5.0801e-02, -2.8522e-01, -6.8077e-02,  1.5365e-01,  1.0208e-01,\n",
       "                       1.4005e-01,  2.4892e-01,  1.6424e-01, -2.6011e-02, -1.1765e-01,\n",
       "                       2.3666e-02, -9.6056e-02,  2.1552e-01,  6.6218e-02, -1.3286e-01,\n",
       "                       9.7213e-02,  7.4428e-02,  3.7217e-02, -8.0448e-02, -1.1140e-01,\n",
       "                      -9.3078e-02,  1.0936e-01, -2.4048e-01,  1.6461e-01,  8.8804e-02,\n",
       "                       1.0530e-01,  1.1237e-01,  7.3620e-02, -3.3240e-02,  9.6039e-02,\n",
       "                       1.5424e-01, -8.3831e-02, -2.9457e-03,  1.0337e-01, -1.6227e-01,\n",
       "                      -1.8991e-01,  4.8433e-02, -2.0501e-01, -1.5005e-02, -1.4423e-01,\n",
       "                      -1.1777e-01,  1.4364e-02, -3.9132e-02,  9.0089e-02, -1.1306e-01,\n",
       "                       7.8553e-02, -2.6908e-02,  1.6308e-01, -8.2359e-02, -1.3549e-01,\n",
       "                       2.8926e-02, -1.1255e-01, -2.4468e-01,  1.5815e-01,  7.0019e-02,\n",
       "                      -1.1460e-01, -2.2009e-04,  1.9477e-01, -8.1963e-02], device='cuda:0')),\n",
       "             ('oov_embedding.weight',\n",
       "              tensor([[ 0.1209,  0.0983,  0.0471,  ..., -0.0650, -0.1060,  0.0240],\n",
       "                      [ 0.0902, -0.1605,  0.0911,  ..., -0.2231,  0.1364, -0.2054],\n",
       "                      [ 0.0655,  0.0360,  0.3236,  ...,  0.0006, -0.0521, -0.1147],\n",
       "                      ...,\n",
       "                      [-0.1978,  0.2654, -0.1191,  ..., -0.0898, -0.2721, -0.0670],\n",
       "                      [-0.0973,  0.1421,  0.1105,  ...,  0.0802,  0.2282,  0.2222],\n",
       "                      [-0.1864, -0.0062, -0.2562,  ..., -0.0248,  0.0379,  0.2528]],\n",
       "                     device='cuda:0')),\n",
       "             ('oov_embedding.bias',\n",
       "              tensor([ 0.2969, -0.0618, -0.1995,  0.0093, -0.0381,  0.1018, -0.1662,  0.0156,\n",
       "                       0.1173,  0.3262,  0.0940,  0.1635, -0.2214,  0.2481,  0.0860, -0.2674,\n",
       "                      -0.2756, -0.0597,  0.0818, -0.0427, -0.0537, -0.2007, -0.0754,  0.0116,\n",
       "                       0.1205,  0.1093,  0.0883, -0.0452,  0.0639, -0.1604,  0.2398, -0.0549,\n",
       "                      -0.0735, -0.0072, -0.0134, -0.1715, -0.0425, -0.2357,  0.0388, -0.0853,\n",
       "                       0.2444,  0.2073, -0.1610, -0.0238,  0.0402,  0.1398, -0.0706, -0.2099,\n",
       "                       0.1711,  0.3082, -0.1312,  0.0953,  0.1673, -0.0248,  0.1381, -0.0263,\n",
       "                      -0.1341,  0.2400,  0.0230, -0.2097, -0.0396, -0.2974, -0.0976,  0.3030],\n",
       "                     device='cuda:0')),\n",
       "             ('output.0.weight',\n",
       "              tensor([[ 0.1611,  0.0935, -0.0411,  ...,  0.1871,  0.0782, -0.1101],\n",
       "                      [ 0.2739,  0.3058, -0.1127,  ..., -0.3513, -0.1181,  0.2185],\n",
       "                      [ 0.0957,  0.1273, -0.0155,  ..., -0.1173, -0.0167, -0.1632],\n",
       "                      ...,\n",
       "                      [-0.0045,  0.2161,  0.2307,  ...,  0.1190,  0.4106, -0.3701],\n",
       "                      [-0.0524, -0.2545, -0.3785,  ...,  0.0857,  0.1971,  0.2570],\n",
       "                      [ 0.1238, -0.1518, -0.0975,  ..., -0.0950,  0.1469, -0.1459]],\n",
       "                     device='cuda:0')),\n",
       "             ('output.0.bias',\n",
       "              tensor([-0.5729, -0.1015, -0.0308,  ..., -0.2322, -0.1179, -0.1154],\n",
       "                     device='cuda:0'))])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93761e8b-86c3-4ed8-adb6-1ce13517cfcf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
