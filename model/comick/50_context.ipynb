{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13fc63c4-da08-43a8-9972-2615d377d1fa",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "313363b9-24d1-4b87-87cd-a0b7dd5fc128",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pytz\n",
    "import torch\n",
    "import timeit\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from itertools import chain\n",
    "from time import time\n",
    "from torch import nn, optim\n",
    "from torchmetrics import F1Score\n",
    "from torch.optim import lr_scheduler\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from polyglot.mapping import Embedding, CaseExpander, DigitExpander"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b49405-006a-4a45-ae79-0e22f6a7172e",
   "metadata": {},
   "source": [
    "# Hyperparameters Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68709d29-24a1-45bf-b549-804952fd1db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hyperparams:\n",
    "     def __init__(\n",
    "        self,\n",
    "        context_size=50,\n",
    "        input_size_left_context=64,\n",
    "        input_size_oov_context=20,\n",
    "        input_size_right_context=64,\n",
    "        batch_size=32,\n",
    "        num_hidden_layer=1,\n",
    "        hidden_size=128,\n",
    "        output_size=3611,\n",
    "        shuffle=True,\n",
    "        lr=0.001,\n",
    "        batch_first=True,\n",
    "        bidirectional=True,\n",
    "        init_wb_with_kaiming_normal=True,\n",
    "        n_epoch=20,\n",
    "        patience=20,\n",
    "        device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    ):\n",
    "        self.context_size = context_size\n",
    "        self.input_size_left_context = input_size_left_context\n",
    "        self.input_size_oov_context = input_size_oov_context\n",
    "        self.input_size_right_context = input_size_right_context\n",
    "        self.batch_size = batch_size\n",
    "        self.num_hidden_layer = num_hidden_layer\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.shuffle = shuffle\n",
    "        self.lr = lr\n",
    "        self.batch_first = batch_first\n",
    "        self.bidirectional = bidirectional\n",
    "        self.init_wb_with_kaiming_normal = init_wb_with_kaiming_normal\n",
    "        self.n_epoch = n_epoch\n",
    "        self.patience = patience\n",
    "        self.device = device\n",
    "        \n",
    "hyperparams = Hyperparams()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f750b1-d4a7-4a2a-9fe1-369a61f28a2b",
   "metadata": {},
   "source": [
    "# Prepare Feature Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f241f20b-fb34-4db2-b887-1687f137b141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left context shape: (16562, 50)\n",
      "OOV context shape: (16562, 28)\n",
      "Right context shape: (16562, 50)\n",
      "Actual lable shape: (16562,)\n"
     ]
    }
   ],
   "source": [
    "def convert_doc_to_idxs(docs, dict_vocabs):\n",
    "    doc_to_idx = []\n",
    "    \n",
    "    for doc in docs:\n",
    "        doc_to_idx.append([dict_vocabs[token] for token in doc])\n",
    "        \n",
    "    return np.array(doc_to_idx)\n",
    "\n",
    "# Left context\n",
    "left_context = open(f\"../../datasets/features/{hyperparams.context_size}_context/left_context_with_pad.pkl\", \"rb\")\n",
    "left_context = pickle.load(left_context)\n",
    "left_context_to_idx = open(f\"../../datasets/features/{hyperparams.context_size}_context/token2idx_left_context.pkl\", \"rb\")\n",
    "left_context_to_idx = pickle.load(left_context_to_idx)\n",
    "doc_left_context_to_idx = convert_doc_to_idxs(left_context, left_context_to_idx)\n",
    "\n",
    "# OOV context\n",
    "oov_context = open(f\"../../datasets/features/{hyperparams.context_size}_context/oov_context_with_pad.pkl\", \"rb\")\n",
    "oov_context = pickle.load(oov_context)\n",
    "oov_context_to_idx = open(f\"../../datasets/features/{hyperparams.context_size}_context/token2idx_oov_context.pkl\", \"rb\")\n",
    "oov_context_to_idx = pickle.load(oov_context_to_idx)\n",
    "doc_oov_context_to_idx = convert_doc_to_idxs(oov_context, oov_context_to_idx)\n",
    "\n",
    "# Right context\n",
    "right_context = open(f\"../../datasets/features/{hyperparams.context_size}_context/right_context_with_pad.pkl\", \"rb\")\n",
    "right_context = pickle.load(right_context)\n",
    "right_context_to_idx = open(f\"../../datasets/features/{hyperparams.context_size}_context/token2idx_right_context.pkl\", \"rb\")\n",
    "right_context_to_idx = pickle.load(right_context_to_idx)\n",
    "doc_right_context_to_idx = convert_doc_to_idxs(right_context, right_context_to_idx)\n",
    "\n",
    "# Actual labels\n",
    "labels_context = open(f\"../../datasets/features/{hyperparams.context_size}_context/lables.pkl\", \"rb\")\n",
    "labels_context = pickle.load(labels_context)\n",
    "labels_to_idx = open(f\"../../datasets/features/{hyperparams.context_size}_context/lable_vocabs.pkl\", \"rb\")\n",
    "labels_to_idx = pickle.load(labels_to_idx)\n",
    "doc_labels_to_idx = convert_doc_to_idxs(labels_context, labels_to_idx).flatten()\n",
    "\n",
    "print(f\"Left context shape: {doc_left_context_to_idx.shape}\")\n",
    "print(f\"OOV context shape: {doc_oov_context_to_idx.shape}\")\n",
    "print(f\"Right context shape: {doc_right_context_to_idx.shape}\")\n",
    "print(f\"Actual lable shape: {doc_labels_to_idx.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe386c1f-3e1d-4589-b18e-42e4bc4055ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to Tensor\n",
    "left_contexts = torch.LongTensor(doc_left_context_to_idx)\n",
    "oov_contexts = torch.LongTensor(doc_oov_context_to_idx)\n",
    "right_contexts = torch.LongTensor(doc_right_context_to_idx)\n",
    "actual_labels = torch.LongTensor(doc_labels_to_idx)\n",
    "dataset = TensorDataset(left_contexts, oov_contexts, right_contexts, actual_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8806cc8-c1d1-450a-833d-f25375c52949",
   "metadata": {},
   "source": [
    "# Char and Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86595b81-a95e-4469-acad-49b9ed2c9662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word Embedding\n",
    "word_embeddings = Embedding.load(\"../../word_embeddings/polyglot/idn_embeddings.tar.bz2\")\n",
    "word_embeddings.apply_expansion(DigitExpander)\n",
    "word_embeddings.apply_expansion(CaseExpander)\n",
    "\n",
    "left_vocabs = open(f\"../../datasets/features/{hyperparams.context_size}_context/left_context_vocabs.pkl\", \"rb\")\n",
    "left_vocabs = pickle.load(left_vocabs)\n",
    "\n",
    "right_vocabs = open(f\"../../datasets/features/{hyperparams.context_size}_context/right_context_vocabs.pkl\", \"rb\")\n",
    "right_vocabs = pickle.load(right_vocabs)\n",
    "\n",
    "left_word_embedding_dict = {left_context_to_idx[vocab] : word_embeddings[vocab] for vocab in left_vocabs}\n",
    "right_word_embedding_dict = {right_context_to_idx[vocab] : word_embeddings[vocab] for vocab in right_vocabs}\n",
    "\n",
    "# Char Embedding\n",
    "char_embedding_dict = open(\"../../word_embeddings/chars_embedding/char_embeddings.pkl\", \"rb\")\n",
    "char_embedding_dict = pickle.load(char_embedding_dict)\n",
    "\n",
    "# Context embedding\n",
    "left_context_embedding = nn.Embedding.from_pretrained(torch.FloatTensor(np.array(list(left_word_embedding_dict.values()))), padding_idx=left_vocabs.index(\"<PAD>\"), freeze=True)\n",
    "oov_context_embedding = nn.Embedding.from_pretrained(torch.FloatTensor(np.array(list(char_embedding_dict.values()))), padding_idx=list(char_embedding_dict.keys()).index(\"PAD\"), freeze=True)\n",
    "right_context_embedding = nn.Embedding.from_pretrained(torch.FloatTensor(np.array(list(right_word_embedding_dict.values()))), padding_idx=right_vocabs.index(\"<PAD>\"), freeze=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593ddcfe-1525-41ae-bf02-c9ebf3d957aa",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "998fb38d-da64-4b4c-9371-75e06ebfc8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=hyperparams.batch_size, shuffle=hyperparams.shuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5be550-2f41-41b4-9df4-ac67744041c5",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed852446-c649-4727-b9ff-64375cf7e966",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Comick(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size_left_context=hyperparams.input_size_left_context,\n",
    "        input_size_oov_context=hyperparams.input_size_oov_context,\n",
    "        input_size_right_context=hyperparams.input_size_right_context,\n",
    "        hidden_size=hyperparams.hidden_size,\n",
    "        num_layers=hyperparams.num_hidden_layer,\n",
    "        output_size=hyperparams.output_size,\n",
    "        batch_first=hyperparams.batch_first,\n",
    "        bidirectional=hyperparams.bidirectional,\n",
    "        init_wb_with_kaiming_normal=hyperparams.init_wb_with_kaiming_normal\n",
    "    ):\n",
    "        super(Comick, self).__init__()\n",
    "        \n",
    "        self.input_size_left_context = input_size_left_context\n",
    "        self.input_size_oov_context = input_size_oov_context\n",
    "        self.input_size_right_context = input_size_right_context\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.output_size = output_size\n",
    "        self.batch_first = batch_first\n",
    "        self.bidirectional = bidirectional\n",
    "        \n",
    "        self.bilstm_left_context_feature = nn.LSTM(\n",
    "            input_size = self.input_size_left_context,\n",
    "            hidden_size = self.hidden_size,\n",
    "            num_layers = self.num_layers,\n",
    "            batch_first = self.batch_first,\n",
    "            bidirectional = self.bidirectional\n",
    "        )\n",
    "        \n",
    "        self.bilstm_oov_context_feature = nn.LSTM(\n",
    "            input_size = self.input_size_oov_context,\n",
    "            hidden_size = self.hidden_size,\n",
    "            num_layers = self.num_layers,\n",
    "            batch_first = self.batch_first,\n",
    "            bidirectional = self.bidirectional\n",
    "        )\n",
    "        \n",
    "        self.bilstm_right_context_feature = nn.LSTM(\n",
    "            input_size = self.input_size_right_context,\n",
    "            hidden_size = self.hidden_size,\n",
    "            num_layers = self.num_layers,\n",
    "            batch_first = self.batch_first,\n",
    "            bidirectional = self.bidirectional\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(2 * self.hidden_size, 64),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "        self.oov_embedding = nn.Linear(in_features=3 * 64, out_features=64)\n",
    "        \n",
    "        self.embedding = np.empty((output_size, 64), dtype=np.float32)\n",
    "        \n",
    "        self.prob = nn.Sequential(\n",
    "            nn.Linear(64, self.output_size),\n",
    "            nn.LogSoftmax(dim=1)\n",
    "        )\n",
    "                \n",
    "        if init_wb_with_kaiming_normal:\n",
    "            self.init_wb()\n",
    "            \n",
    "    def init_wb(self):\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, (nn.Linear, nn.LSTM)):\n",
    "                for name, param in module.named_parameters():\n",
    "                    if \"weight\" in name:\n",
    "                        nn.init.kaiming_normal_(param)\n",
    "                    else:\n",
    "                        nn.init.kaiming_normal_(param.reshape(1, -1))\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_left_context,\n",
    "        input_oov_context,\n",
    "        input_right_context,\n",
    "        idxs_target,\n",
    "        hidden_left_context=None,\n",
    "        hidden_oov_context=None,\n",
    "        hidden_right_context=None,\n",
    "    ):\n",
    "        # BiLSTM left, oov, and right context\n",
    "        output_left_context, (hidden_left_context, memory_left_context) = self.bilstm_left_context_feature(input_left_context, hidden_left_context)\n",
    "        output_oov_context, (hidden_oov_context, memory_oov_context) = self.bilstm_oov_context_feature(input_oov_context, hidden_oov_context)\n",
    "        output_right_context, (hidden_right_context, memory_right_context) = self.bilstm_right_context_feature(input_right_context, hidden_right_context)\n",
    "                \n",
    "        # Concate hidden (forward and backward hidden BiLSTM)\n",
    "        hidden_left_bidirectional = torch.cat((hidden_left_context[0], hidden_left_context[-1]), dim=1)\n",
    "        hidden_oov_bidirectional = torch.cat((hidden_oov_context[0], hidden_oov_context[-1]), dim=1)\n",
    "        hidden_right_bidirectional = torch.cat((hidden_right_context[0], hidden_right_context[-1]), dim=1)\n",
    "        \n",
    "        # Fully connected\n",
    "        output_left_fc = self.fc(hidden_left_bidirectional)\n",
    "        output_oov_fc = self.fc(hidden_oov_bidirectional)\n",
    "        output_right_fc = self.fc(hidden_right_bidirectional)\n",
    "        \n",
    "        # Concate output left, oov, and right context feature\n",
    "        output = torch.cat((output_left_fc, output_oov_fc, output_right_fc), dim=1)\n",
    "        \n",
    "        # OOV embedding\n",
    "        output = self.oov_embedding(output)\n",
    "                \n",
    "        # save OOV embedding\n",
    "        self.embedding[idxs_target.tolist()] = output.cpu().detach().numpy()\n",
    "        \n",
    "        # Projection OOV embedding\n",
    "        prob = self.prob(output)\n",
    "        \n",
    "        return prob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992eb40b-9062-47f1-9703-65e80d6cb07d",
   "metadata": {},
   "source": [
    "# Model, Optimizer, Criterion, Metric, and Learning Rate Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b08d05fc-0bb5-426e-aa7b-eb930ba9f06b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Comick(\n",
       "  (bilstm_left_context_feature): LSTM(64, 128, batch_first=True, bidirectional=True)\n",
       "  (bilstm_oov_context_feature): LSTM(20, 128, batch_first=True, bidirectional=True)\n",
       "  (bilstm_right_context_feature): LSTM(64, 128, batch_first=True, bidirectional=True)\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (1): Tanh()\n",
       "  )\n",
       "  (oov_embedding): Linear(in_features=192, out_features=64, bias=True)\n",
       "  (prob): Sequential(\n",
       "    (0): Linear(in_features=64, out_features=3611, bias=True)\n",
       "    (1): LogSoftmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Comick().to(hyperparams.device)\n",
    "model.prob[0].requires_grad_ = False # disable gradient for projection layer\n",
    "optimizer = optim.Adam(model.parameters(), lr=hyperparams.lr)\n",
    "criterion = nn.NLLLoss(ignore_index=list(char_embedding_dict.keys()).index(\"PAD\")).to(hyperparams.device)\n",
    "metric = F1Score(ignore_index=list(char_embedding_dict.keys()).index(\"PAD\")).to(hyperparams.device)\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.5)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d463d75-dd43-4b45-9eec-8f4aca21b018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "814,427\n"
     ]
    }
   ],
   "source": [
    "print(f\"{sum([param.numel() for param in model.parameters() if param.requires_grad_]):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "494a567d-acbc-46c2-adc8-b9a512366c17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b39ba3-b103-44da-ae1e-34fd12ad2d2f",
   "metadata": {},
   "source": [
    "# Training Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c51a3a6-a4af-425f-aa1f-34ffe9ff8248",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_step(dataloader, model, optimizer, criterion, metric, scheduler=None, path_name=None):\n",
    "    model.train()\n",
    "    \n",
    "    batch_losses = []\n",
    "    batch_metric_scores = []\n",
    "    \n",
    "    for batch, (input_left_context, input_oov_context, input_right_context, actual_label) in enumerate(tqdm(dataloader), 1):\n",
    "        # Forward Propagation\n",
    "        prob = model(\n",
    "            left_context_embedding(input_left_context).to(hyperparams.device),\n",
    "            oov_context_embedding(input_oov_context).to(hyperparams.device),\n",
    "            right_context_embedding(input_right_context).to(hyperparams.device),\n",
    "            actual_label.to(hyperparams.device)\n",
    "        )\n",
    "                \n",
    "        loss = criterion(prob, actual_label.to(hyperparams.device))\n",
    "        metric_score = metric(prob.argmax(dim=1), actual_label.to(hyperparams.device))\n",
    "        metric_score = metric.compute()\n",
    "        \n",
    "        if scheduler is not None:\n",
    "            scheduler.step(loss)\n",
    "        \n",
    "        batch_losses.append(loss.item())\n",
    "        batch_metric_scores.append(metric_score)\n",
    "        \n",
    "        if batch % 50 == 0 or batch == len(dataloader):\n",
    "            batch_name = \"Batch-\" + str(batch)\n",
    "            print(f\"{batch_name.ljust(9)}: {str(criterion).split('(')[0]}={(loss.item()):.4f} | {str(metric).split('(')[0]}={(metric_score):.4f}\")\n",
    "            with open(f\"../../logs/comick/{hyperparams.context_size}_contexts/{path_name}/training_history.txt\", \"a\") as f:\n",
    "                f.write(f\"{batch_name.ljust(9)}: {str(criterion).split('(')[0]}={(loss.item()):.4f} | {str(metric).split('(')[0]}={(metric_score):.4f}\\n\")\n",
    "\n",
    "        # Backward Propagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    return batch_losses, batch_metric_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3043a1-39cb-4b38-8024-54f909a565a9",
   "metadata": {},
   "source": [
    "# Looping Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e139244-b036-4d45-beca-1de5bd7b5e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH-1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1583f0617c874a729fe112257ba786f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=6.5632 | F1Score=0.2600\n",
      "Batch-100: NLLLoss=5.8305 | F1Score=0.2844\n",
      "Batch-150: NLLLoss=5.6856 | F1Score=0.3152\n",
      "Batch-200: NLLLoss=4.4876 | F1Score=0.3372\n",
      "Batch-250: NLLLoss=4.7733 | F1Score=0.3583\n",
      "Batch-300: NLLLoss=4.1760 | F1Score=0.3760\n",
      "Batch-350: NLLLoss=3.9035 | F1Score=0.3937\n",
      "Batch-400: NLLLoss=4.5684 | F1Score=0.4103\n",
      "Batch-450: NLLLoss=4.6977 | F1Score=0.4216\n",
      "Batch-500: NLLLoss=4.6912 | F1Score=0.4336\n",
      "Batch-518: NLLLoss=2.8926 | F1Score=0.4380\n",
      "\n",
      "Mean NLLLoss: 4.5257 | Mean F1Score: 0.3513\n",
      "==================================================\n",
      "\n",
      "EPOCH-2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e93ccd656e94f19bc00fdedc2d41d02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=3.4172 | F1Score=0.5719\n",
      "Batch-100: NLLLoss=3.2717 | F1Score=0.5875\n",
      "Batch-150: NLLLoss=2.3579 | F1Score=0.5975\n",
      "Batch-200: NLLLoss=2.0955 | F1Score=0.6011\n",
      "Batch-250: NLLLoss=2.8075 | F1Score=0.6056\n",
      "Batch-300: NLLLoss=2.1715 | F1Score=0.6105\n",
      "Batch-350: NLLLoss=2.3028 | F1Score=0.6154\n",
      "Batch-400: NLLLoss=4.5892 | F1Score=0.6239\n",
      "Batch-450: NLLLoss=2.2895 | F1Score=0.6277\n",
      "Batch-500: NLLLoss=2.5085 | F1Score=0.6312\n",
      "Batch-518: NLLLoss=1.1882 | F1Score=0.6329\n",
      "\n",
      "Yeah ðŸŽ‰ðŸ˜„! Model improved.\n",
      "Mean NLLLoss: 2.7315 | Mean F1Score: 0.6063\n",
      "==================================================\n",
      "\n",
      "EPOCH-3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "597fa323d3c94a92865a453520fde411",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=1.1180 | F1Score=0.7306\n",
      "Batch-100: NLLLoss=2.1126 | F1Score=0.7303\n",
      "Batch-150: NLLLoss=3.2960 | F1Score=0.7285\n",
      "Batch-200: NLLLoss=2.5372 | F1Score=0.7262\n",
      "Batch-250: NLLLoss=1.8328 | F1Score=0.7254\n",
      "Batch-300: NLLLoss=1.7280 | F1Score=0.7268\n",
      "Batch-350: NLLLoss=1.3128 | F1Score=0.7308\n",
      "Batch-400: NLLLoss=1.4087 | F1Score=0.7329\n",
      "Batch-450: NLLLoss=1.4332 | F1Score=0.7357\n",
      "Batch-500: NLLLoss=1.1911 | F1Score=0.7377\n",
      "Batch-518: NLLLoss=2.3658 | F1Score=0.7387\n",
      "\n",
      "Yeah ðŸŽ‰ðŸ˜„! Model improved.\n",
      "Mean NLLLoss: 1.8262 | Mean F1Score: 0.7301\n",
      "==================================================\n",
      "\n",
      "EPOCH-4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68e72f5aca1e483b80569331de14f1c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=1.1336 | F1Score=0.8106\n",
      "Batch-100: NLLLoss=1.2077 | F1Score=0.8084\n",
      "Batch-150: NLLLoss=2.0100 | F1Score=0.8048\n",
      "Batch-200: NLLLoss=1.2233 | F1Score=0.8089\n",
      "Batch-250: NLLLoss=1.1826 | F1Score=0.8081\n",
      "Batch-300: NLLLoss=0.7627 | F1Score=0.8082\n",
      "Batch-350: NLLLoss=1.8835 | F1Score=0.8096\n",
      "Batch-400: NLLLoss=0.6471 | F1Score=0.8085\n",
      "Batch-450: NLLLoss=0.5120 | F1Score=0.8106\n",
      "Batch-500: NLLLoss=0.7302 | F1Score=0.8109\n",
      "Batch-518: NLLLoss=1.4781 | F1Score=0.8111\n",
      "\n",
      "Yeah ðŸŽ‰ðŸ˜„! Model improved.\n",
      "Mean NLLLoss: 1.1917 | Mean F1Score: 0.8107\n",
      "==================================================\n",
      "\n",
      "EPOCH-5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cce6d63f13cb4a89aa315c8548058b5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=0.9266 | F1Score=0.8878\n",
      "Batch-100: NLLLoss=0.4381 | F1Score=0.8820\n",
      "Batch-150: NLLLoss=0.6383 | F1Score=0.8807\n",
      "Batch-200: NLLLoss=0.7479 | F1Score=0.8782\n",
      "Batch-250: NLLLoss=0.8338 | F1Score=0.8767\n",
      "Batch-300: NLLLoss=0.6124 | F1Score=0.8728\n",
      "Batch-350: NLLLoss=0.5509 | F1Score=0.8706\n",
      "Batch-400: NLLLoss=0.6215 | F1Score=0.8707\n",
      "Batch-450: NLLLoss=0.6165 | F1Score=0.8696\n",
      "Batch-500: NLLLoss=0.7818 | F1Score=0.8705\n",
      "Batch-518: NLLLoss=0.6325 | F1Score=0.8701\n",
      "\n",
      "Yeah ðŸŽ‰ðŸ˜„! Model improved.\n",
      "Mean NLLLoss: 0.7180 | Mean F1Score: 0.8771\n",
      "==================================================\n",
      "\n",
      "EPOCH-6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e763413dd3c434b8bb62933cc272425",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=0.3735 | F1Score=0.9550\n",
      "Batch-100: NLLLoss=0.2457 | F1Score=0.9488\n",
      "Batch-150: NLLLoss=0.0966 | F1Score=0.9485\n",
      "Batch-200: NLLLoss=0.0723 | F1Score=0.9458\n",
      "Batch-250: NLLLoss=0.4512 | F1Score=0.9420\n",
      "Batch-300: NLLLoss=0.2427 | F1Score=0.9406\n",
      "Batch-350: NLLLoss=0.3492 | F1Score=0.9377\n",
      "Batch-400: NLLLoss=0.2434 | F1Score=0.9361\n",
      "Batch-450: NLLLoss=0.3429 | F1Score=0.9343\n",
      "Batch-500: NLLLoss=0.1980 | F1Score=0.9325\n",
      "Batch-518: NLLLoss=0.8256 | F1Score=0.9327\n",
      "\n",
      "Yeah ðŸŽ‰ðŸ˜„! Model improved.\n",
      "Mean NLLLoss: 0.3590 | Mean F1Score: 0.9428\n",
      "==================================================\n",
      "\n",
      "EPOCH-7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f660d774ec8463eb509a6c844bfda66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=0.1629 | F1Score=0.9887\n",
      "Batch-100: NLLLoss=0.1647 | F1Score=0.9872\n",
      "Batch-150: NLLLoss=0.2828 | F1Score=0.9881\n",
      "Batch-200: NLLLoss=0.0836 | F1Score=0.9883\n",
      "Batch-250: NLLLoss=0.1434 | F1Score=0.9874\n",
      "Batch-300: NLLLoss=0.2337 | F1Score=0.9874\n",
      "Batch-350: NLLLoss=0.0362 | F1Score=0.9868\n",
      "Batch-400: NLLLoss=0.2115 | F1Score=0.9863\n",
      "Batch-450: NLLLoss=0.1510 | F1Score=0.9856\n",
      "Batch-500: NLLLoss=0.3884 | F1Score=0.9847\n",
      "Batch-518: NLLLoss=0.1167 | F1Score=0.9845\n",
      "\n",
      "Yeah ðŸŽ‰ðŸ˜„! Model improved.\n",
      "Mean NLLLoss: 0.1280 | Mean F1Score: 0.9873\n",
      "==================================================\n",
      "\n",
      "EPOCH-8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edf0a1d7620946b2a9949b535bb847d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=0.0336 | F1Score=0.9981\n",
      "Batch-100: NLLLoss=0.0299 | F1Score=0.9978\n",
      "Batch-150: NLLLoss=0.0193 | F1Score=0.9983\n",
      "Batch-200: NLLLoss=0.0373 | F1Score=0.9981\n",
      "Batch-250: NLLLoss=0.0095 | F1Score=0.9981\n",
      "Batch-300: NLLLoss=0.0133 | F1Score=0.9980\n",
      "Batch-350: NLLLoss=0.0693 | F1Score=0.9979\n",
      "Batch-400: NLLLoss=0.0425 | F1Score=0.9976\n",
      "Batch-450: NLLLoss=0.0510 | F1Score=0.9974\n",
      "Batch-500: NLLLoss=0.0150 | F1Score=0.9975\n",
      "Batch-518: NLLLoss=0.0761 | F1Score=0.9973\n",
      "\n",
      "Yeah ðŸŽ‰ðŸ˜„! Model improved.\n",
      "Mean NLLLoss: 0.0414 | Mean F1Score: 0.9980\n",
      "==================================================\n",
      "\n",
      "EPOCH-9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42806089bdd5474290c32e32719abf8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=0.0090 | F1Score=0.9994\n",
      "Batch-100: NLLLoss=0.0127 | F1Score=0.9994\n",
      "Batch-150: NLLLoss=0.0109 | F1Score=0.9992\n",
      "Batch-200: NLLLoss=0.0045 | F1Score=0.9994\n",
      "Batch-250: NLLLoss=0.0092 | F1Score=0.9991\n",
      "Batch-300: NLLLoss=0.0048 | F1Score=0.9992\n",
      "Batch-350: NLLLoss=0.0088 | F1Score=0.9992\n",
      "Batch-400: NLLLoss=0.0071 | F1Score=0.9989\n",
      "Batch-450: NLLLoss=0.0072 | F1Score=0.9989\n",
      "Batch-500: NLLLoss=0.0042 | F1Score=0.9989\n",
      "Batch-518: NLLLoss=0.0064 | F1Score=0.9989\n",
      "\n",
      "Yeah ðŸŽ‰ðŸ˜„! Model improved.\n",
      "Mean NLLLoss: 0.0145 | Mean F1Score: 0.9992\n",
      "==================================================\n",
      "\n",
      "EPOCH-10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7484b2b470c4fe6a937b930a3782909",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=0.0073 | F1Score=0.9994\n",
      "Batch-100: NLLLoss=0.0164 | F1Score=0.9989\n",
      "Batch-150: NLLLoss=0.0055 | F1Score=0.9993\n",
      "Batch-200: NLLLoss=0.0061 | F1Score=0.9993\n",
      "Batch-250: NLLLoss=0.0072 | F1Score=0.9993\n",
      "Batch-300: NLLLoss=0.0071 | F1Score=0.9992\n",
      "Batch-350: NLLLoss=0.0058 | F1Score=0.9991\n",
      "Batch-400: NLLLoss=0.0032 | F1Score=0.9992\n",
      "Batch-450: NLLLoss=0.0055 | F1Score=0.9992\n",
      "Batch-500: NLLLoss=0.0052 | F1Score=0.9992\n",
      "Batch-518: NLLLoss=0.0051 | F1Score=0.9993\n",
      "\n",
      "Yeah ðŸŽ‰ðŸ˜„! Model improved.\n",
      "Mean NLLLoss: 0.0090 | Mean F1Score: 0.9993\n",
      "==================================================\n",
      "\n",
      "EPOCH-11\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44b665cefacc49c6bd7b651fec3c39d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=0.0030 | F1Score=1.0000\n",
      "Batch-100: NLLLoss=0.0023 | F1Score=1.0000\n",
      "Batch-150: NLLLoss=0.0012 | F1Score=0.9998\n",
      "Batch-200: NLLLoss=0.0037 | F1Score=0.9997\n",
      "Batch-250: NLLLoss=0.0041 | F1Score=0.9994\n",
      "Batch-300: NLLLoss=0.0025 | F1Score=0.9994\n",
      "Batch-350: NLLLoss=0.0026 | F1Score=0.9995\n",
      "Batch-400: NLLLoss=0.1715 | F1Score=0.9995\n",
      "Batch-450: NLLLoss=0.0067 | F1Score=0.9995\n",
      "Batch-500: NLLLoss=0.0094 | F1Score=0.9994\n",
      "Batch-518: NLLLoss=0.0695 | F1Score=0.9990\n",
      "\n",
      "Yeah ðŸŽ‰ðŸ˜„! Model improved.\n",
      "Mean NLLLoss: 0.0074 | Mean F1Score: 0.9996\n",
      "==================================================\n",
      "\n",
      "EPOCH-12\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b7fb81db1534a9cb7022730ddb32cc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=0.1741 | F1Score=0.9819\n",
      "Batch-100: NLLLoss=0.4885 | F1Score=0.9553\n",
      "Batch-150: NLLLoss=0.3469 | F1Score=0.9454\n",
      "Batch-200: NLLLoss=0.1567 | F1Score=0.9450\n",
      "Batch-250: NLLLoss=0.1743 | F1Score=0.9469\n",
      "Batch-300: NLLLoss=0.1748 | F1Score=0.9486\n",
      "Batch-350: NLLLoss=0.0802 | F1Score=0.9493\n",
      "Batch-400: NLLLoss=0.0342 | F1Score=0.9514\n",
      "Batch-450: NLLLoss=0.1111 | F1Score=0.9548\n",
      "Batch-500: NLLLoss=0.0317 | F1Score=0.9571\n",
      "Batch-518: NLLLoss=0.1816 | F1Score=0.9579\n",
      "\n",
      "Huft ðŸ˜¥! Model not improved.\n",
      "Mean NLLLoss: 0.1858 | Mean F1Score: 0.9551\n",
      "Patience = 1/20â—\n",
      "==================================================\n",
      "\n",
      "EPOCH-13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14ab739abd2f4b51b0818d80598c80ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=0.0259 | F1Score=0.9981\n",
      "Batch-100: NLLLoss=0.0076 | F1Score=0.9984\n",
      "Batch-150: NLLLoss=0.0516 | F1Score=0.9977\n",
      "Batch-200: NLLLoss=0.0047 | F1Score=0.9978\n",
      "Batch-250: NLLLoss=0.0100 | F1Score=0.9980\n",
      "Batch-300: NLLLoss=0.0054 | F1Score=0.9980\n",
      "Batch-350: NLLLoss=0.0941 | F1Score=0.9980\n",
      "Batch-400: NLLLoss=0.0729 | F1Score=0.9981\n",
      "Batch-450: NLLLoss=0.0072 | F1Score=0.9983\n",
      "Batch-500: NLLLoss=0.0150 | F1Score=0.9984\n",
      "Batch-518: NLLLoss=0.0119 | F1Score=0.9984\n",
      "\n",
      "Yeah ðŸŽ‰ðŸ˜„! Model improved.\n",
      "Mean NLLLoss: 0.0169 | Mean F1Score: 0.9982\n",
      "==================================================\n",
      "\n",
      "EPOCH-14\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0362649152674e5aaccd912827020289",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=0.0028 | F1Score=1.0000\n",
      "Batch-100: NLLLoss=0.0034 | F1Score=0.9994\n",
      "Batch-150: NLLLoss=0.0024 | F1Score=0.9996\n",
      "Batch-200: NLLLoss=0.0023 | F1Score=0.9995\n",
      "Batch-250: NLLLoss=0.0015 | F1Score=0.9996\n",
      "Batch-300: NLLLoss=0.0013 | F1Score=0.9996\n",
      "Batch-350: NLLLoss=0.0033 | F1Score=0.9996\n",
      "Batch-400: NLLLoss=0.0021 | F1Score=0.9995\n",
      "Batch-450: NLLLoss=0.0019 | F1Score=0.9995\n",
      "Batch-500: NLLLoss=0.0011 | F1Score=0.9995\n",
      "Batch-518: NLLLoss=0.0018 | F1Score=0.9995\n",
      "\n",
      "Yeah ðŸŽ‰ðŸ˜„! Model improved.\n",
      "Mean NLLLoss: 0.0035 | Mean F1Score: 0.9996\n",
      "==================================================\n",
      "\n",
      "EPOCH-15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2cae23341ec425ba8fd8180bbc99489",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=0.0012 | F1Score=0.9997\n",
      "Batch-100: NLLLoss=0.0037 | F1Score=0.9998\n",
      "Batch-150: NLLLoss=0.0022 | F1Score=0.9999\n",
      "Batch-200: NLLLoss=0.0009 | F1Score=0.9999\n",
      "Batch-250: NLLLoss=0.0013 | F1Score=0.9999\n",
      "Batch-300: NLLLoss=0.0010 | F1Score=0.9999\n",
      "Batch-350: NLLLoss=0.0009 | F1Score=0.9999\n",
      "Batch-400: NLLLoss=0.0009 | F1Score=0.9999\n",
      "Batch-450: NLLLoss=0.0016 | F1Score=0.9999\n",
      "Batch-500: NLLLoss=0.0016 | F1Score=0.9998\n",
      "Batch-518: NLLLoss=0.0017 | F1Score=0.9998\n",
      "\n",
      "Yeah ðŸŽ‰ðŸ˜„! Model improved.\n",
      "Mean NLLLoss: 0.0022 | Mean F1Score: 0.9999\n",
      "==================================================\n",
      "\n",
      "EPOCH-16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ceacf1c35b804a6a92946597fa68b94c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=0.0012 | F1Score=1.0000\n",
      "Batch-100: NLLLoss=0.0010 | F1Score=1.0000\n",
      "Batch-150: NLLLoss=0.0008 | F1Score=1.0000\n",
      "Batch-200: NLLLoss=0.0016 | F1Score=1.0000\n",
      "Batch-250: NLLLoss=0.0012 | F1Score=1.0000\n",
      "Batch-300: NLLLoss=0.0015 | F1Score=1.0000\n",
      "Batch-350: NLLLoss=0.0012 | F1Score=1.0000\n",
      "Batch-400: NLLLoss=0.0008 | F1Score=1.0000\n",
      "Batch-450: NLLLoss=0.0011 | F1Score=0.9999\n",
      "Batch-500: NLLLoss=0.0010 | F1Score=0.9999\n",
      "Batch-518: NLLLoss=0.0007 | F1Score=0.9998\n",
      "\n",
      "Yeah ðŸŽ‰ðŸ˜„! Model improved.\n",
      "Mean NLLLoss: 0.0012 | Mean F1Score: 1.0000\n",
      "==================================================\n",
      "\n",
      "EPOCH-17\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c43b37faee44e8ba6e4f089a960df23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=0.0019 | F1Score=0.9994\n",
      "Batch-100: NLLLoss=0.0012 | F1Score=0.9992\n",
      "Batch-150: NLLLoss=0.0008 | F1Score=0.9989\n",
      "Batch-200: NLLLoss=0.0008 | F1Score=0.9990\n",
      "Batch-250: NLLLoss=0.0020 | F1Score=0.9992\n",
      "Batch-300: NLLLoss=0.0011 | F1Score=0.9993\n",
      "Batch-350: NLLLoss=0.0006 | F1Score=0.9994\n",
      "Batch-400: NLLLoss=0.0006 | F1Score=0.9995\n",
      "Batch-450: NLLLoss=0.0011 | F1Score=0.9995\n",
      "Batch-500: NLLLoss=0.0009 | F1Score=0.9996\n",
      "Batch-518: NLLLoss=0.0012 | F1Score=0.9996\n",
      "\n",
      "Huft ðŸ˜¥! Model not improved.\n",
      "Mean NLLLoss: 0.0031 | Mean F1Score: 0.9993\n",
      "Patience = 2/20â—\n",
      "==================================================\n",
      "\n",
      "EPOCH-18\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c08b90dfa824ab6a00db08bb3b2d642",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=0.0009 | F1Score=1.0000\n",
      "Batch-100: NLLLoss=0.0006 | F1Score=1.0000\n",
      "Batch-150: NLLLoss=0.0020 | F1Score=0.9998\n",
      "Batch-200: NLLLoss=0.0011 | F1Score=0.9995\n",
      "Batch-250: NLLLoss=0.0011 | F1Score=0.9995\n",
      "Batch-300: NLLLoss=0.0020 | F1Score=0.9994\n",
      "Batch-350: NLLLoss=0.0555 | F1Score=0.9989\n",
      "Batch-400: NLLLoss=0.0164 | F1Score=0.9972\n",
      "Batch-450: NLLLoss=0.0599 | F1Score=0.9914\n",
      "Batch-500: NLLLoss=0.2917 | F1Score=0.9860\n",
      "Batch-518: NLLLoss=0.3983 | F1Score=0.9847\n",
      "\n",
      "Huft ðŸ˜¥! Model not improved.\n",
      "Mean NLLLoss: 0.0624 | Mean F1Score: 0.9974\n",
      "Patience = 3/20â—\n",
      "==================================================\n",
      "\n",
      "EPOCH-19\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11eb3f43b8af474db4206d9e72973b5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=0.1618 | F1Score=0.9647\n",
      "Batch-100: NLLLoss=0.0366 | F1Score=0.9664\n",
      "Batch-150: NLLLoss=0.3069 | F1Score=0.9691\n",
      "Batch-200: NLLLoss=0.0360 | F1Score=0.9710\n",
      "Batch-250: NLLLoss=0.0435 | F1Score=0.9724\n",
      "Batch-300: NLLLoss=0.1595 | F1Score=0.9736\n",
      "Batch-350: NLLLoss=0.0570 | F1Score=0.9763\n",
      "Batch-400: NLLLoss=0.0545 | F1Score=0.9774\n",
      "Batch-450: NLLLoss=0.0137 | F1Score=0.9785\n",
      "Batch-500: NLLLoss=0.2048 | F1Score=0.9793\n",
      "Batch-518: NLLLoss=0.0500 | F1Score=0.9793\n",
      "\n",
      "Huft ðŸ˜¥! Model not improved.\n",
      "Mean NLLLoss: 0.0849 | Mean F1Score: 0.9725\n",
      "Patience = 4/20â—\n",
      "==================================================\n",
      "\n",
      "EPOCH-20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bc0e9a1990143ecb6efce34c1809695",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=0.0728 | F1Score=0.9969\n",
      "Batch-100: NLLLoss=0.0052 | F1Score=0.9981\n",
      "Batch-150: NLLLoss=0.0013 | F1Score=0.9979\n",
      "Batch-200: NLLLoss=0.0028 | F1Score=0.9980\n",
      "Batch-250: NLLLoss=0.0020 | F1Score=0.9984\n",
      "Batch-300: NLLLoss=0.0119 | F1Score=0.9985\n",
      "Batch-350: NLLLoss=0.0012 | F1Score=0.9986\n",
      "Batch-400: NLLLoss=0.0008 | F1Score=0.9987\n",
      "Batch-450: NLLLoss=0.0039 | F1Score=0.9988\n",
      "Batch-500: NLLLoss=0.0011 | F1Score=0.9988\n",
      "Batch-518: NLLLoss=0.0005 | F1Score=0.9988\n",
      "\n",
      "Yeah ðŸŽ‰ðŸ˜„! Model improved.\n",
      "Mean NLLLoss: 0.0078 | Mean F1Score: 0.9982\n",
      "==================================================\n",
      "\n",
      "TRAINING SUMMARY\n",
      "Best NLLLoss      : 0.0078\n",
      "Best F1Score      : 0.9982\n",
      "Training duration : 26.315 minutes.\n",
      "Training date     : 2022-10-11 15:24:28.056143+08:00\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA24AAAFhCAYAAAAImPmbAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAABThUlEQVR4nO3dd3xV9f3H8dcnC8LeARkyBBWEREUUsRpFW7V11Pqrq6K1La2tq9W2Vq1Vq7baodXaKlZbcFtbrbVYqSMO3CNMRYbIkE0Aw8r6/P44J3gNCQSSe889ue8nj/u4Z91z3jkJfPnke873mLsjIiIiIiIi6Ssr6gAiIiIiIiKyYyrcRERERERE0pwKNxERERERkTSnwk1ERERERCTNqXATERERERFJcyrcRERERERE0pwKNxGRGDGzp83snObeNhnM7Cwzm7KD9cVmtiSVmdLVzs6ViIiICjcRkSQzs/KEV42ZbU6YP2tX9uXux7n7xObeNhnc/QF3/2LtvJm5me0VVZ76mNm5ZvZK1Puqe66iZGbXmFllnZ/bgQnri8zsHTPbFL4XRRhXRCRjqHATEUkyd29X+wIWASckLHugdjszy4kupcjnPJL4c+vuCwDMLA/4F3A/0BmYCPwrXC4iIkmkwk1EJCK1lwqa2U/NbDnwVzPrbGZPmdkqMysLp/skfKbEzL4dTp9rZq+Y2W/DbT8ys+N2c9sBZvaSmX1qZs+a2R1mdn8DuV80s6+F02PCnrQvh/Njzaw08Zjh9Evhx6eFPTinJezvUjNbaWbLzOybOzhfXczsr2b2Sfg1PJGw7jtmNs/M1prZk2a2R8I6N7PvmdlcM1sXfm1mZvsCdwKjw0zrwu1bhedpkZmtMLM7zSw/XDfZzH6XsO+HzezehvZVz9dwrpktCM/zR7U9rnXO1U/q9HZVmtnfwnUdzeye8FwtNbPrzSy7oXOWBMVADnCru29199sAA45KYQYRkYykwk1EJFo9gS7AnsB4gn+X/xrO9wM2A3/cwecPBuYA3YCbgXvMzHZj2weBN4GuwDXA2Ts45osE/4EHOAJYAByeMP9i3Q+4e+36wrAH55FwvifQEegNfAu4w8w6N3Dc+4A2wDCgB3ALgJkdBfwK+DrQC/gYeLjOZ78CHASMCLf7kru/D3wPeC3M1Cnc9tfAEKAI2CvMdnW47jzgbDM7Kiy6RgEX72Bf25hZW+A24Dh3bw8cCpTWc65uTuih3RdYBdSer78BVWGu/YEvAt+u72SZ2ZlhodrQq199nwudEBbBs8zs/ITlw4Dp7u4Jy6aHy0VEJIlUuImIRKsG+EXYe7HZ3de4+z/cfZO7fwrcQFAMNeRjd7/b3asJLlvrBRTsyrbhf+APAq529wp3fwV4cgfHfDEh0+EERVPtfL2F2w5UAte5e6W7TwbKgb3rbmRmvYDjgO+5e1m4fe1xzgLudfd33X0r8DOCnq/+Cbv4tbuvc/dFwAsERdl2wkJ2PPBDd18bfg9uBE4HcPflwPkE5+8PwLhwm8aqAfYzs3x3X+busxraMOzlewL4g7s/bWYFwPHAJe6+0d1XEhSvp9f3eXd/0N077eC1qIFDP0pQMHYHvgNcbWZnhOvaAevrbL8eaN+or15ERHabCjcRkWitcvcttTNm1sbM7jKzj81sA/AS0GkHl8Mtr51w903hZLtd3HYPYG3CMoDFO8j8GjAkLCSKgElAXzPrRtAD9dIOPlvXGnevSpjf1ED+vmHGsnrW7UHQywaAu5cDawh6ymotT5hu6BgQFCttgHdqe6aA/4bLa/0byAbmhEVuo7j7RuA0gp65ZWb2HzPbZwcfuSc8xk3h/J5AbvjZ2mx3EfQ+Nht3n+3un7h7tbu/SlCgnhquLgc61PlIB2BXilcREdkNKtxERKLldeYvJehxOtjdO/DZJYgNXf7YHJYBXcysTcKyvg1tHBZ47wAXAzPdvQJ4FfgRMN/dVych4+IwY6d61n1CUNQA2y5J7AosbcR+657/1QSXpw5L6JnqGF62WOsG4H2gV0JPVH372v5g7s+4+zEEvZ0fAHfXt52ZXU5wuea3EhYvBrYC3RKydXD3ei9TtOARA+U7eO3oUsnPxeazn79ZwIg6l+OOCJeLiEgSqXATEUkv7QkKh3Vm1gX4RbIP6O4fA28D15hZnpmNBk7YycdeBC7gs8siS+rM12cFMHAH63eUcRnwNPAnCwZwyTWz2qL2IeCbFgxT34rg0sY33H1hI3a9Auhj4aiI7l5DUEzdYmY9AMyst5l9KZw+HPgmMA44B7jdzHrXt6+6zKzAzE4KC8utBL1XNfVsdxxwEfBVd99c5xxMAX5nZh3MLMvMBplZvZfSho8YaLeDV72XSoYZO4cDuIwKs/wrXF0CVAMXhYO4XBAuf76+fYmISPNR4SYikl5uBfIJen5eJ7hMLxXOAkYTXGJ4PcFgGFt3sP2LBEXmSw3M1+caYGJ4md/XdyPj2QT3xH0ArAQuAXD3Z4GfA/8g6D0cRAP3fdXjeYLeouVmVttT+FNgHvB6eLnqs8DeZtaB4LLQC9x9qbu/THA541/DHqj69pUoi6BX8hNgLcH9gOfXs91pBJdmvp/QO3ZnuG4ckAfMBsqAxwh675rT6QRf/6cEX+9Ntc8DDHtXTw5zrCMYrOXkcLmIiCSRfX5gKBERETCzR4AP3D3pPX4iIiKyc+pxExERzOyg8LK7LDM7FjiJYERDERERSQM5UQcQEZG00BP4J8GgHkuA8939vWgjiYiISC1dKikiIiIiIpLmdKmkiIiIiIhImlPhJiIiIiIikuZUuImIiIiIiKQ5FW4iIiIiIiJpToWbiIiIiIhImlPhJiIiIiIikuZUuImIiIiIiKQ5FW4izczMFprZ0VHnEBERSaawvdtsZuUJrz3CdRPMbI6Z1ZjZuTvZTx8z+4eZrTaz9WY2c2efEclEKtxEREREZHed4O7tEl6fhMunAd8H3m3EPu4DFgN7Al2Bs4EVzRnSzHKac38iUVDhJpICZtbKzG41s0/C161m1ipc183MnjKzdWa21sxeNrOscN1PzWypmX0a/uZybLRfiYiIyM65+x3u/hywpRGbHwT8zd03unuVu7/n7k/XrjSzw8zs1bCdXFzbG2dmHc1skpmtMrOPzeyqhPbzXDObama3mNka4JqwLf6tmS0ysxVmdqeZ5SfhyxdJChVuIqlxJXAIUAQUAqOAq8J1lwJLgO5AAXAF4Ga2N3ABcJC7twe+BCxMaWoREZHkex24w8xON7N+iSvMbE/gaeB2gnayCCgNV98OdAQGAkcA44BvJnz8YGABQdt6A/BrYEi4j72A3sDVSfh6RJJChZtIapwFXOfuK919FXAtwaUgAJVAL2BPd69095fd3YFqoBUw1Mxy3X2hu8+PJL2IiEj9ngh7wtaZ2RO7uY//A14Gfg58ZGalZnZQuO5M4Fl3fyhsI9e4e6mZZQOnAz9z90/dfSHwOz5rWwE+cffb3b2KoOdvPPBDd1/r7p8CN4b7EIkFFW4iqbEH8HHC/MfhMoDfAPOAKWa2wMwuB3D3ecAlwDXASjN7uPambxERkTRxsrt3Cl8n784O3L3M3S9392EEvWOlBAWhAX2B+n5p2Q3IZfu2tXfC/OKE6e5AG+Cd2kIT+G+4XCQWVLiJpMYnBDdd1+oXLiP8TeGl7j4QOBH4Ue29bO7+oLsfFn7WgZtSG1tERCR13H018FuCX252ISi+BtWz6WqCK1bqtq1LE3dXZ/vNwLCEQrOju7drzvwiyaTCTSQ5cs2sde0LeAi4ysy6m1k3gmvq7wcws6+Y2V7hbxbXE1wiWWNme5vZUeEgJlsIGpyaaL4cERGRxjOzvLD9Mz5rE+v9f6eZ3WRm+5lZjpm1B84H5rn7GuAB4Ggz+3q4vquZFbl7NfAocIOZtQ/vhfsRYdtal7vXAHcDt5hZj/C4vc3sS839tYskiwo3keSYTFBo1b5aA28D04EZBMMjXx9uOxh4FigHXgP+5O4vENzf9muC3xIuB3oAP0vdlyAiIrLbphC0f4cCE8LpwxvYtg3wOLCOYDCRPQmuQMHdFwHHEwzktZbgMsrC8HMXAhvDz7wCPAjcu4NMPyW4NeF1M9tA0PbuvRtfm0gkLBgDQURERERERNKVetxERERERETSnAo3ERERERGRNKfCTUREREREJM2pcBMREREREUlzKtxERERERETSXE7UARJ169bN+/fv36R9bNy4kbZt2zZPoBSJY2aIZ+44ZoZ45o5jZohn7jhmfuedd1a7e/eoc8RFpraPEM/cccwM8cwdx8wQz9xxzAzxzN1QG5lWhVv//v15++23m7SPkpISiouLmydQisQxM8QzdxwzQzxzxzEzxDN3HDOb2cdRZ4iTTG0fIZ6545gZ4pk7jpkhnrnjmBnimbuhNlKXSoqIiIiIiKQ5FW4iIiIiIiJpToWbiIiIiIhImlPhJiIiIiIikuZUuImIiIiIiKQ5FW4iIiIiIiJpToWbiIiIiIhImlPhJiIi0kzM7F4zW2lmMxtYb2Z2m5nNM7PpZnZAqjOKiEg8qXATERFpPn8Djt3B+uOAweFrPPDnFGQSEZEWICfqAM3F3Xl01qMsW7eMYoqjjiMiIhnI3V8ys/472OQkYJK7O/C6mXUys17uviw1CUV2kTvUVEJNRfDyqmAZtS92bd69dsfgNcGrdpqahGU1wbbbLf/8svYVc8GPALMUnIxm5A7VW6B6K9RsDd6rtwTTtfNetePz8blzGK5PPFefO1+w7fux7Z3Pfz8S3z1hm3BZr41zYP4CsBywbMgK3+ub39E6y4GcfMhuAzltIKtV/L5/EWkxhZuZcflzlzMgdwCXcEnUcUREROrTG1icML8kXLZd4WZm4wl65SgoKKCkpKRJBy4vL2/yPqIQx9xpkdmd/OpP6FAxiw4V75Nbsw6jiiyvxLyKLCqD6YRlo2q2svXharK8CqOSrHC7dHYgsOTJZ5nX4ftg0V5IZl7BoA0TaFc5NzynldvOc5ZXkEVFsMwrKaYKHok07i7bG+CN5t+vk0W1taLGWie8t6bGWlFdZ/qz92Dbda0K2Zi71w73n4q/j+bV9Nz0X7pveZHpXX4VFKlJ0GIKN4DCgkLeXfRu1DFERESazN0nABMARo4c6cXFxU3aX0lJCU3dRxTimDuSzFUbYc1bsPq14LXmddi6KliX0x7a9IasvPDVCrI7JMwHr2Ury+jVu992y8lu9dm0ZQMW9pDUvti1+drelW37ygqLrtr3usvss3X2+W2WvHYrfTb+gz4F7WHU3UHPThQq1sNLJ8PGEuh+WNCblN0qPNeJ760huxULFy2j/6C966xv/dl0VquEXqqEc1LfOapv/eeWJZxz6r7T8LrP9YIZr732KqMPOTjoCaypAq8OewWrPz+/03VVQe9i1Uao3oRVbSKnelMwX7UJqjeF77Xzq7Zfl9hr2O/rMOI66LB3vd+apP59dIclT8C0K2DDB9D1EIoPGQr5vZJyuBZVuBX1LOLJOU+ysWIjbfPaRh1HRESkrqVA34T5PuEykcZzh/IFnxVpq1+DddOD/xxD8B/Y3l+GbodCt9HQYV/I2nkPwJySEnqNKk5u9mY2r0M1fQYWwYxfQMU6GPNQUACl0uZl8MJxsH4WjL4fBpy1048sXFdC/2HFyc/WjLZmd4e2/aKO8dllphVlMPfPMOcWWPwYDBgH+/0C2vVPTY6VL8F7Pw1+SdJhH/jC49DnpKRe9tmiCrfCgkIcZ+bKmRzc5+Co44iIiNT1JHCBmT0MHAys1/1tslNVm7bvTduyMliX0w66HgxDfxYUad0OgVZdos2bSmYw/GrI6wTvXAwlX4HDH4fc9qk5/oYP4YUvBb2bRzwFe3wpNcfNZGbBPXI5+VD4S9j7Qpj1a5j7J1j4AAwaD/tdmbReL9bNgNKfwSf/gfzeQU/vwHNT0tvbogq3op5FAExbMU2Fm4iIpJyZPQQUA93MbAnwCyAXwN3vBCYDxwPzgE3AN6NJKmmvahPMuAaWPwfrpn3Wm9Z+CPQ6LizSRkPHYY3qTWvx9r4IcjvBG+fB80dD8dPJL2DXvAUlxwfTY1+Argcl93hSv9Y94MDfw74/gpm/hHl3wYJ7YciFMPQnzXecjR/D9Kvho/sgtyMU/To4Rk6b5jvGTrSowq1/p/60zW5L6fLSqKOIiEgGcvczdrLegR+kKI7EVcU6ePErQe9aj2IYenlCb1rXqNOlr4HjIK8jvHIaPHs4HDkF2uyRnGN98gy88jVo1QOOfAY6DE7OcaTx2vSBUXfBvj8Jfunx/m9g3p3s2foUqDwAcjvs3n63rIZZN8LcOwCDfS8L/k5G0LPdop7jZmYMajdIhZuIiIjE0+YV8GwxrHkTxjwCY5+DwuuDe9ZUtO1cn5PgyKeD3pH/HRbcC9jcPro/KKzb7QVffFVFW7ppPwgOvQ+Onw4FYxnw6d/gyYHw/u+ganPj91O1EWbeAP8eBB/+Afp/A06YC/vfHNnlyC2qcAMY1G4Q01dMp2bbMytEREREYmDjx/DsF+DTucH9Uv1OjTpRPBUcCUc9B5Xrg+Jt3czm2/f7v4PXzoYeX4CjX4T8ns23b2lenfaDw//JO93+DJ0PhPcug3/vFQxoUl3R8OdqKmHunfDkXjD9quDn6fgZcMg90LZvw59LgZZXuLUdxMbKjcxfOz/qKCIiIiKNs/6DoMjYsgqO+h/0+mLUieKt2yg4+iXAgssmV7/etP15Dbx7WfCf/37/F9xDl9exWaJKcn2atw8c9QyMLYF2A+Ct78NT+8CCSVBT/dmG7rDo7/CfYfDW+dB+LzhmKhz+BHQcGlH6z2txhdte7YKH8E1bMS3iJCIiIiKNsPadoKetpjLoxel+aNSJWoZOw+CYVyCvSzBgyfJnd28/1RXw2jj44Hcw5AI49KHgeWsSLwVHwNEvQ/HkYBTS18+BycNh0T9g+fPwzMHwyteD5xUe8e+g8E+zv4strnAb0HYA2Zat+9xEREQk/a14EZ49EnLaBkVG5xFRJ2pZ2g2AY16GdgOh5Muw+J+79vnKcnjxhGCY+cIb4MDbNIpnnJnBHsfBsW/DYX8Plr1yKjw/FrYsh0P+BsdNg95fSerz2HZXixpVEiAvK499uu2jHjcRERFJb0ufglf+D9oOCC6PbNM76kQtU36voCez5MvB+T74nuC5WzuzZVXwmbJ34OC/wKBvJT2qpIhlBfeQ9vkqLHoEqsqDB3in+uHtu6jFFW4QPM/txY9fjDqGiIiISP0WPgivnQOdi4L7pVp3izpRy5bXOSiOX/oqvP7N4JEL+1zS8PblHwUP1t60GL7wBPQ5IUVBJaWysqH/mVGnaLQWd6kkQGFBIUs2LGHNpjVRRxERERH5vA//BK9+A7ofFgz3r6ItNXLaBvcu9f0avPvD4GHK7ttvV1YKUw6FrauD0SlVtEmaaJGFW1HPIkADlIiIiEgacQ+eC/X2D4J7aIon7/5DgWX3ZLeCMQ/DwPNg5i/hnYuDESNrrXgBnj0CsnKCew7TbHAKyWwtsnAr7FkIoAFKREREJD24w3s/Dp4L1f8b8IV/QE5+1KkyU1ZOcM/aPpfCh7cHl6zWVAZDwb9wLLTpA198LW2GgBep1SLvcevRtge92vVSj5uIiIhEr6Ya3vouzL8nGE7+wD8EgyNIdMxg/98E975NvwrWz4ay94IetsOfhFZdok4osp0WWbhB0OumHjcRERGJVPVWePUsWPwP2O/nMPzatBxmPCOZwX5XBsXb2z+A3icGl1GqJ1TSVIst3IoKinhuwXNUVFeQl50XdRwRERHJNFUb4aVTYPkUOOD3sM8Po04k9RnyfehzUvDYAPWEShprsT+dRT2LqKypZPaq2VFHERERkUxTUQbPHwMrng2eG6aiLb216a2iTdJei/0JrR2gZNpy3ecmIiIiqZNXvTYYmXDtO3DY32HQeVFHEpEWoMUWboO7DCY/J1/3uYmIiEjqbPqE/VdfCOUL4IinoO8pUScSkRaixd7jlp2VzfCC4RpZUkRERFKjphpePZO8mrVw9PPQfXTUiUSkBWmxPW4QDFBSurwUd486ioiIiLR0s38FK1/kw44Xq2gTkWbXogu3wp6FlG0pY/GGxVFHERERkZZs1VSYcQ3seSYr8r8UdRoRaYGSXriZWbaZvWdmTyX7WHUV9SwCNECJiIiIJFFFGUw9E9ruCaP+rOe0iUhSpKLH7WLg/RQcZzvDewzHMA1QIiIiIsnhDm98BzZ/Aoc+BLkdok4kIi1UUgs3M+sDfBn4SzKP05D2rdozqMsgDVAiIiIiyTH/L7D4H1B4A3QbFXUaEWnBkt3jdivwE6AmycdpUFHPIvW4iYiISPNbPxveuRh6Hg37XhZ1GhFp4ZL2OAAz+wqw0t3fMbPiHWw3HhgPUFBQQElJSZOOW15e/rl9dNjUgfll85n87GTa5LRp0r6TpW7muIhj7jhmhnjmjmNmiGfuOGYWib2qzTD1dMhpB6MngbXo8d5EJA0k8zluY4ATzex4oDXQwczud/dvJG7k7hOACQAjR4704uLiJh20pKSExH2Uf1jOvQvvpeOQjozpN6ZJ+06WupnjIo6545gZ4pk7jpkhnrnjmFkk9t77MaybAcWTIb9X1GlEJAMk7ddD7v4zd+/j7v2B04Hn6xZtqVBYUAig+9xERESkeSz5F8y9A/b5EexxXNRpRCRDtPh+/T4d+tAlv4vucxMREZGm27QEXj8POh8AhTdGnUZEMkgyL5Xcxt1LgJJUHKsuM9MAJSIiItJ0NdXw6llQsxXGPAzZraJOJCIZpMX3uEFwueSMlTOoqqmKOoqIiIjE1awbYeVLMPJP0GFw1GlEJMNkROFW1LOILVVbmLtmbtRRRESkhTOzY81sjpnNM7PL61m/p5k9Z2bTzawkfOappLtVU2HmNdD/LBhwdtRpRCQDZUThpgFKREQkFcwsG7gDOA4YCpxhZkPrbPZbYJK7jwCuA36V2pSyyyrKYOqZ0HYAHPQnMIs6kYhkoIwo3Pbtvi+5Wbm6z01ERJJtFDDP3Re4ewXwMHBSnW2GAs+H0y/Us17SiTu88R3Y/AmMeQhyO0SdSEQyVEoGJ4laXnYeQ7sPVY+biIgkW29gccL8EuDgOttMA04B/gB8FWhvZl3dfU3iRmY2HhgPUFBQ0OSHrMf1Qe1R5+618d/svf4fzO/wXRbP2EhjxlqLOvPuimPuOGaGeOaOY2aIb+76ZEThBsF9bs/MfybqGCIiIpcBfzSzc4GXgKVAdd2N3H0CMAFg5MiR3tSHrMf1Qe2R5l43C575E/Q8hkFH/olB1rgLlXSuUyeOmSGeueOYGeKbuz4ZcakkBPe5LS9fzoryFVFHERGRlmsp0Ddhvk+4bBt3/8TdT3H3/YErw2XrUpZQGqdqM0w9Pbg0cvQkaGTRJiKSLBnzr1BRzyJAA5SIiEhSvQUMNrMBZpYHnA48mbiBmXUz21YF/Ay4N8UZpTHeuwzWz4RDJkJ+z6jTiIhkTuFW2DMYWVIDlIiISLK4exVwAfAM8D7wqLvPMrPrzOzEcLNiYI6ZfQgUADdEElYatvgJmPsn2OdS2OPYqNOIiAAZdI9bl/wu9O3QVz1uIiKSVO4+GZhcZ9nVCdOPAY+lOpc00sbF8MZ50OVAKLwx6jQiIttkTI8bBJdLqsdNRERE6lVTDa99A2oq4dCHIDsv6kQiIttkVOFWWFDInNVz2Fy5OeooIiIikm5m3QArXwoest1hcNRpREQ+J6MKt6KeRVR7NbNWzYo6ioiIiKSTla/AzGuh/zdgwNlRpxER2U5GFW61A5RMW6773ERERCRUUQavngltB8BBd0SdRkSkXhkzOAnAwM4DaZfXTve5iYiISMAd3vwebF4Gx0wNntsmIpKGMqpwy7IsCgsKKV1RGnUUERERSQcL/gqLHoXCX0G3UVGnERFpUEZdKgnBACXTlk+jxmuijiIiIiJR2jAH3r4QCo6CoT+JOo2IyA5lXOFW1LOITys+ZeG6hVFHERERkahUb4WpZ0JOPoyeBJZx/yUSkZjJuH+lNECJiIiIMP0qKHsXDr4H2vSOOo2IyE5lXOG2X4/9yLIsDVAiIiKSqZZNgfd/C4PPhz4nRZ1GRKRRMq5wa5PbhiFdhzBthXrcREREMs6WlfDaOOg4FPb/bdRpREQaLeMKNwjuc1OPm4iISIZxh9fPg4p1cOhDkNMm6kQiIo2WmYVbQREfr/+YdVvWRR1FREREUuXDP8In/4H9fwOdR0SdRkRkl2Rk4aYBSkRERDJM2XR478ewx5dhyAVRpxER2WUZWbgV9SwC0OWSIiIimaBqE7x6BuR1hkP+CmZRJxIR2WU5UQeIQs92PenRtocGKBEREckE710G62fDkVOgdfeo04iI7JaM7HEDDVAiIiKSERY/AXP/DPteBr2OiTqNiMhuy9jCrbCgkFmrZlFZXRl1FBEREUmGTUvhjW9B5wNgxA1RpxERaZKMLdyKehZRUV3BB6s/iDqKiIiINLeaanjtbKjeAmMeguy8qBOJiDRJRhdugO5zExERaYne/w2seAFG3g4dhkSdRkSkyTK2cBvSdQitslvpPjcREZGWZvWbMP3n0O/rMPCbUacREWkWGVu45WTlMLxguHrcREREWpLKT+HVMyF/Dxh1p4b+F5EWI2MLNwgGKCldXoq7Rx1FREREmsPbF8DGj+DQB4LntomItBAZXbgV9Sxi9abVfPLpJ1FHERERkaZa+CB8NAmG/Rx6HBZ1GhGRZpXRhVthQSGgAUpERERir3wBvPk96D4G9rsq6jQiIs0uowu3EQUjADRAiYiISJzVVMHUs8Cygksks3KiTiQi0uwy+l+2jq07MrDzQPW4iYiIxNmMa2HN63DoQ9B2z6jTiIgkRUb3uMFnA5SIiIhIDK14EWbdAAPPhf6nR51GRCRpMr5wK+pZxNw1c9lYsTHqKCIiIrIrqrfAG+dBu0Fw4O1RpxERSaqML9wKCwpxnBkrZ0QdRUREWgAzO9bM5pjZPDO7vJ71/czsBTN7z8ymm9nxUeRsEd7/bTAoyag/Q267qNOIiCRVxhduRT2LAJi2XPe5iYhI05hZNnAHcBwwFDjDzIbW2ewq4FF33x84HfhTalO2EBsXwawboe+p0PPoqNOIiCRdxhdu/Tr2o1PrTrrPTUREmsMoYJ67L3D3CuBh4KQ62zjQIZzuCOhhorvj3UuD9wN+F20OEZEUyehRJQHMLBigZEVp1FFERCT+egOLE+aXAAfX2eYaYIqZXQi0BdRdtKuWPwuLH4MRv4S2/aJOIyKSEhlfuEFwn9s9791DdU012VnZUccREZGW7Qzgb+7+OzMbDdxnZvu5e03iRmY2HhgPUFBQQElJSZMOWl5e3uR9RKFubvMqRq76NlnZe/DWqlHUpOHX1FLOdRzEMTPEM3ccM0N8c9dHhRvBfW4bKzcyv2w+Q7oOiTqOiIjE11Kgb8J8n3BZom8BxwK4+2tm1hroBqxM3MjdJwATAEaOHOnFxcVNClZSUkJT9xGF7XK//3tY9jEc8W8O7/3FyHLtSIs51zEQx8wQz9xxzAzxzV2fjL/HDTRAiYiINJu3gMFmNsDM8ggGH3myzjaLgLEAZrYv0BpYldKUcbV5Gcy4BvY4Hnp/Jeo0IiIplbTCzcxam9mbZjbNzGaZ2bXJOlZTDe0+lJysHA1QIiIiTeLuVcAFwDPA+wSjR84ys+vM7MRws0uB75jZNOAh4Fx392gSx8x7P4WarXDArVEnERFJuWReKrkVOMrdy80sF3jFzJ5299eTeMzd0iqnFft225dpK9TjJiIiTePuk4HJdZZdnTA9GxiT6lyxt2oqLLwPhl0BHQZHnUZEJOWS1uPmgfJwNjd8pe1vFAt7FqrHTUREJB3VVMPbF0CbPkHhJiKSgZJ6j5uZZZtZKcEN1/9z9zeSebymKCooYumnS1m9aXXUUURERCTR/AlQVgr7/w5y2kadRkQkEkkdVdLdq4EiM+sEPB4OdzwzcZu0Ge64LHib+MxEDux8YJMy7Kq4DlMax9xxzAzxzB3HzBDP3HHMLNJYudXrYdqVUHAk9Pu/qOOIiEQmJY8DcPd1ZvYCwfDHM+usS4vhjodtHMZl0y+DAig+tGkZdlVchymNY+44ZoZ45o5jZohn7jhmFmmsAZ/+BSo3wIG3g1nUcUREIpPMUSW7hz1tmFk+cAzwQbKO11Td23and/veGqBEREQkXax9h16b/gNDLoJOw6JOIyISqWT2uPUCJppZNkGB+Ki7P5XE4zWZBigRERFJE14Db11AZVYn8ob/Iuo0IiKRS1rh5u7Tgf2Ttf9kKCooYsr8KWyt2kqrnFZRxxEREclcH02CNa8zv9NP2TevY9RpREQil9RRJeOmsGchVTVVzF41O+ooIiIimatiPZT+FLqNZkX+F6NOIyKSFlS4JSjqWQSg+9xERESiNOMa2LIKRv4RTP9VEREBFW6fM6jzINrkttF9biIiIlFZNxM+vB32Gg9dDog6jYhI2lDhliA7K5sRBSPU4yYiIhIFd3j7QsjtCIU3RJ1GRCStqHCro6igiNLlpbh71FFEREQyy6JHYWVJULS16hp1GhGRtKLCrY7CnoWs27KOResXRR1FREQkc1SWw3uXQef9YdB3ok4jIpJ2VLjVoQFKREREIjDrRti0BEbeDlnZUacREUk7KtzqGN5jOIZpgBIREZFU2fAhfPBbGDAOuo+JOo2ISFpS4VZH27y2DO46WD1uIiIiqeAO71wCWa2h6Kao04iIpC0VbvUYucdIXv74ZSqrK6OOIiIi0rItfQqWPQ3Dr4H8nlGnERFJWyrc6nHasNNYtWkVz8x/JuooIiIiLVf1FnjnYuiwL+x9YdRpRETSmgq3ehy313F0a9ONSdMmRR1FRESk5Zr9G9j4UTggSW7UaURE0poKt3rkZudy5n5n8uScJynbXBZ1HBERkZZn48cw+0bo93/Qc2zUaURE0p4KtwaMKxzH1uqtPDrr0aijiIiItDzvXgYY7P/bqJOIiMSCCrcGHNDrAIZ2H8qk6bpcUkREpFmVL4DFj8E+l0LbflGnERGJBRVuDTAzzik8h1cXv8q8tfOijiMiItJyzP8rYLDX+KiTiIjEhgq3HThr+FkYxn3T7os6ioiISMtQUw0f/Q16fQna9o06jYhIbKhw24HeHXpz9MCjmTR9EjVeE3UcERGR+Fv+P9i0BAZ9K+okIiKxosJtJ84pPIeF6xbyyqJXoo4iIiISf/PvgVZdofcJUScREYkVFW47cfI+J9Mur52e6SYiItJUW1bB0n9B/7Mhu1XUaUREYkWF2060zWvLqUNP5dFZj7K5cnPUcUREROJr4f1QU6nLJEVEdoMKt0YYN2Icn1Z8yhMfPBF1FBERkXhyDy6T7DoKOu0XdRoRkdhR4dYIR/Q/gn4d++mZbiIislNmdqyZzTGzeWZ2eT3rbzGz0vD1oZmtiyBm6q15C9bPUm+biMhuanThZmb5ZrZ3MsOkqyzL4uwRZzNl/hSWfbos6jgiIpIiu9r2mVk2cAdwHDAUOMPMhiZu4+4/dPcidy8Cbgf+2YyR09eCeyA7H/qdFnUSEZFYalThZmYnAKXAf8P5IjN7Mom50s7ZI86mxmt4cMaDUUcREZEU2M22bxQwz90XuHsF8DBw0g62PwN4qBnipreqjbDwIej3f5DXMeo0IiKx1Nget2sIGqN1AO5eCgxISqI0tXe3vTm498FMnDYRd486joiIJN817Hrb1xtYnDC/JFy2HTPbM9zf802LGQOLHoOqT3WZpIhIE+Q0crtKd19vZonLMq56OafwHL4/+ftMWzGNop5FUccREZHkSnbbdzrwmLtX17fSzMYD4wEKCgooKSlp0sHKy8ubvI/dVbT69+Rl9+HNWdUwe9cyRJl7d8UxM8QzdxwzQzxzxzEzxDd3fRpbuM0yszOBbDMbDFwEvJq8WOnptP1O4+L/XsykaZNUuImItHy70/YtBfomzPcJl9XndOAHDe3I3ScAEwBGjhzpxcXFjYxdv5KSEpq6j92y4UN4ajoU/oriYUfu8scjy90EccwM8cwdx8wQz9xxzAzxzV2fxl4qeSEwDNgKPAisBy5JUqa01SW/CyfsfQIPzHiAqpqqqOOIiEhy7U7b9xYw2MwGmFkeQXG23X1xZrYP0Bl4rTkDp6UFfwXLggHjok4iIhJrO+1xC0fI+o+7HwlcmfxI6W3ciHH88/1/8sy8Z/jykC9HHUdERJJgd9s+d68yswuAZ4Bs4F53n2Vm1wFvu3ttEXc68LC39Juma6rgo4nQ63hos0fUaUREYm2nhZu7V5tZjZl1dPf1qQiVzo4bfBzd2nRj0vRJKtxERFqoprR97j4ZmFxn2dV15q9pesoY+ORp2LwMRmpQEhGRpmrsPW7lwAwz+x+wsXahu1+UlFRpLC87jzP2O4MJ70xg3ZZ1dGrdKepIIiKSHGr7mmrBPdC6AHrrF50iIk3V2Hvc/gn8HHgJeCfhlZHGFY5ja/VW/j7r71FHERGR5FHb1xSbl8PSp4J727Jyo04jIhJ7jepxc/eJ4U3WQ8JFc9y9Mnmx0tuBvQ5k3277MnHaRL5z4HeijiMiIkmgtq+JProPvBoGnhd1EhGRFqFRPW5mVgzMBe4A/gR8aGaHJy9WejMzzik8h6mLpzJ/7fyo44iISBKo7WsC9+AyyW6HQsd9ok4jItIiNPZSyd8BX3T3I9z9cOBLwC3Ji5X+zhpxFoZx3/T7oo4iIiLJobZvd61+FTbMgUEalEREpLk0tnDLdfc5tTPu/iGQ0Res9+nQh7EDxzJp2iRqvCbqOCIi0vzU9u2u+fdATlvo9/Wok4iItBiNLdzeNrO/mFlx+LobeDuZweJg3IhxfLTuI6Yumhp1FBERaX5q+3ZH5aew6FHodxrktos6jYhIi9HYwu18YDZwUfiaHS7LaKfsewptc9syadqkqKOIiEjzU9u3OxY9ClUbdZmkiEgza+xz3HKAP7j77wHMLBtolbRUMdE2ry2nDj2VR2c/ym3H3UZ+bn7UkUREpPmo7dsd8++BDvtAt9FRJxERaVEa2+P2HJBYleQDzzZ/nPgZVziODVs38K85/4o6ioiINC+1fbtq/fuw+rWgt80s6jQiIi1KYwu31u5eXjsTTrdJTqR4Ke5fTN8OfXW5pIhIy6O2b1fNvwcsB/qfHXUSEZEWp7GF20YzO6B2xsxGApuTEylesiyLs0eczTPzn2F5+fKo44iISPNR27crairho0nQ+yuQXxB1GhGRFqexhdslwN/N7GUzexl4GLggaali5uzCs6nxGh6c8WDUUUREpPlcgtq+xlv6FGxdpUFJRESSZIeFm5kdZGY93f0tYB/gEaAS+C/wUQryxcI+3fZhVO9RTJw2MeooIiLSRGr7dtP8eyC/F/Q6NuokIiIt0s563O4CKsLp0cAVwB1AGTBhRx80s75m9oKZzTazWWZ2cZPTprFzCs9h+orpTFs+LeooIiLSNLvd9mWsTUth2dMw4FzIauyA1SIisit2Vrhlu/vacPo0YIK7/8Pdfw7stZPPVgGXuvtQ4BDgB2Y2tGlx09dpw04jNytXg5SIiMRfU9q+zPTRJPAaGHRe1ElERFqsnRZuZlb7q7OxwPMJ63b4KzV3X+bu74bTnwLvA713N2i669qmK18Z8hUemPEAVTVVUccREZHdt9ttX0Zyh/n3Qo/Dob3qWhGRZNlZ4fYQ8KKZ/YtgJK2XAcxsL2B9Yw9iZv2B/YE3di9mPIwrHMeKjSuYMn9K1FFERGT3NUvblzFWvgTl82CgBiUREUmmnfWa3WBmzwG9gCnu7uGqLODCxhzAzNoB/wAucfcN9awfD4wHKCgooKSkpPHp61FeXt7kfeyutjVt6ZDTgd/+77e0Wdr4R/1Embkp4pg7jpkhnrnjmBnimTuOmdNZc7R9GWX+PZDbAfqdGnUSEZEWbaeXfLj76/Us+7AxOzezXIKi7QF3/2cD+59AeLP3yJEjvbi4uDG7blBJSQlN3UdTjNsyjrvfvZuiQ4ro1LpToz4TdebdFcfcccwM8cwdx8wQz9xxzJzumtL2ZZSK9bD4MRgwDnL0bHIRkWRq7HPcdpmZGXAP8L67/z5Zx0k34wrHsbV6K4/NfizqKCIiIsn18cNQvVnPbhMRSYGkFW7AGOBs4CgzKw1fxyfxeGlh5B4j2afbPnqmm4iItHzz74GO+0GXkVEnERFp8ZJWuLn7K+5u7j7C3YvC1+RkHS9dmBnnFJ7DK4teYf7a+VHHERERSY51M2DtW0Fvm1nUaUREWrxk9rhlrLOGn4Vh3D/9/qijiIiIJMf8eyArF/p/I+okIiIZQYVbEvTt2JejBhzFpOmT+GwwMhERkRaieit8dB/0ORlad4s6jYhIRlDhliTjCsexoGwBUxdPjTqKiIhI81r6JFSs1bPbRERSSIVbkpyy7ym0zW3LpGmToo4iIiLSvObfA236Qs+jo04iIpIxVLglSbu8dnxt6Nd4ZNYjbNi63XPHRURE4mnjIlg2BQaeC1nZUacREckYKtyS6OKDL2bD1g38/rWMeYydiIi0dAv+BjgM/GbUSUREMooKtyQ6oNcBnDr0VH732u9YvWl11HFERCQFzOxYM5tjZvPM7PIGtvm6mc02s1lm9mCqM+42r4EFf4WCsdBuQNRpREQyigq3JPvlkb9kU+UmfvXyr6KOIiIiSWZm2cAdwHHAUOAMMxtaZ5vBwM+AMe4+DLgk1Tl327oZsHEhDNAjAEREUk2FW5Lt020fzik8hzveuoMlG5ZEHUdERJJrFDDP3Re4ewXwMHBSnW2+A9zh7mUA7r4yxRl3X1lp8N71kEhjiIhkIhVuKfCLI36B41z34nVRRxERkeTqDSxOmF8SLks0BBhiZlPN7HUzOzZl6ZqqrBSy86H94KiTiIhknJyoA2SCPTvtyfcO/B53vHUHPz70xwzuqgZPRCSD5QCDgWKgD/CSmQ1393WJG5nZeGA8QEFBASUlJU06aHl5eZP3Ubi6hOys/rz70stN2s+uaI7cqRbHzBDP3HHMDPHMHcfMEN/c9VHhliJXfOEK7nnvHq4uuZqHvvZQ1HFERCQ5lgJ9E+b7hMsSLQHecPdK4CMz+5CgkHsrcSN3nwBMABg5cqQXFxc3KVhJSQlN2oc7PLYQ9jyN4lFNy7Irmpw7AnHMDPHMHcfMEM/cccwM8c1dH10qmSIF7Qq45JBLeHjmw0xbPi3qOCIikhxvAYPNbICZ5QGnA0/W2eYJgt42zKwbwaWTC1KYcfdsWgSV66BzUdRJREQykgq3FLrs0Mvo3LozVz5/ZdRRREQkCdy9CrgAeAZ4H3jU3WeZ2XVmdmK42TPAGjObDbwA/Njd10STeBfUDkyiwk1EJBK6VDKFOrXuxE/H/JTLn7ucqYumMqbfmKgjiYhIM3P3ycDkOsuuTph24EfhKz7KSgGDTsOjTiIikpHU45ZiFx58IT3b9eSK568gaLtFRERioKwUOgyBnLZRJxERyUgq3FKsTW4bfn74z3np45eYMn9K1HFEREQap6wUOhVFnUJEJGOpcIvAtw/4NgM6DeCK56+gxmuijiMiIrJjFetg40Ld3yYiEiEVbhHIy87j2uJreXfZu/zz/X9GHUdERGTHysLRkFW4iYhERoVbRM4cfibDug/jquevotqro44jIiLSMI0oKSISORVuEcnOyub6o65nzpo5TFmhe91ERCSNrSuF1gWQ3zPqJCIiGUuFW4RO2vskRvUexcSFE9latTXqOCIiIvUrK1Vvm4hIxFS4RcjMuPGoG1mxdQV3vXNX1HFERES2V10B62dBp8Kok4iIZDQVbhEbO3As+3fan+tfup7yivKo44iIiHzehvehplI9biIiEVPhlga+PeDbrNq0ij+8/oeoo4iIiHyeBiYREUkLKtzSwNAOQzlp75P4zau/Ye3mtVHHERER+UxZKWTnQ/shUScREcloKtzSxPVHXc+GrRu4eerNUUcRERH5TFkpdBoOWdlRJxERyWgq3NLEfj3246wRZ3HbG7ex7NNlUccREREBd40oKSKSJlS4pZFrjriGyppKrn/p+qijiIiIwKZFULlOhZuISBpQ4ZZGBnUZxHcO+A4T3p3AgrIFUccREZFMVzswSaeiKFOIiAgq3NLOVYdfRW5WLteUXBN1FBERyXRlpYAF97iJiEikVLilmT3a78GFoy7k/un3M3PlzKjjiIhIJisrhfaDIbdd1ElERDKeCrc09JMxP6F9q/b8/IWfRx1FREQymQYmERFJGyrc0lDXNl358aE/5okPnuCNJW9EHUdERDJRxTrYuFCFm4hImlDhlqYuPvhiurfpzpXPXxl1FBERyUTrpgfvKtxERNKCCrc01b5Ve678wpU899FzPLfguajjiIhIpqkdUVKFm4hIWlDhlsa+O/K79O3QlyuevwJ3jzqOiIhkkrJSaN0DWveMOomIiKDCLa21zmnNNcXX8ObSN/nXnH9FHUdERDJJWWnw/DazqJOIiAgq3NLeuMJxDOk6hKuev4rqmuqo44iISCaoroD1s3SZpIhIGlHhluZysnK4/sjrmbVqFre+fmvUcUREJBNs+ABqKlS4iYikERVuMXDq0FM5ae+TuOL5K5i+YnrUcUREpKXTwCQiImlHhVsMmBl3n3A3nVt35qx/nsWWqi1RRxIRkZasrBSy86H9kKiTiIhISIVbTHRv252/nvRXZq6cyRXPXRF1HBERacnWlUKn4ZCVHXUSEREJqXCLkeMGH8cPDvoBt7x+C88ueDbqOCIi0hK5Bz1uukxSRCStqHCLmZuPuZl9u+3LOU+cw9rNa6OOIyIidZjZsWY2x8zmmdnl9aw/18xWmVlp+Pp2FDkbtGkxVJSpcBMRSTMq3GKmTW4b7j/lflZtXMV3n/quHswtIpJGzCwbuAM4DhgKnGFmQ+vZ9BF3Lwpff0lpyJ2pHZikU1GUKUREpI6kFW5mdq+ZrTSzmck6RqY6oNcB/PLIX/LY7Me4b/p9UccREZHPjALmufsCd68AHgZOijjTrikrBSy4x01ERNJGMnvc/gYcm8T9Z7TLDr2Mw/c8nAsmX8BHZR9FHUdERAK9gcUJ80vCZXV9zcymm9ljZtY3NdEaqawU2g+G3HZRJxERkQQ5ydqxu79kZv2Ttf9Ml52VzaSTJzHizhGc/fjZlJxbQk5W0r6dIiLSfP4NPOTuW83su8BE4Ki6G5nZeGA8QEFBASUlJU06aHl5eaP2cfCK1/k0d29mN/F4zaWxudNJHDNDPHPHMTPEM3ccM0N8c9dH/9OPsT077cmfjv8T33j8G9z0yk1cefiVUUcSEcl0S4HEHrQ+4bJt3H1NwuxfgJvr25G7TwAmAIwcOdKLi4ubFKykpISd7qNiHTy2jPz9LqTHsKYdr7k0KneaiWNmiGfuOGaGeOaOY2aIb+76RF64RfUbxXTSlMx7+B4c1f0oflHyC7qu68o+HfZp3nA7kGnnOkpxzB3HzBDP3HHM3IK9BQw2swEEBdvpwJmJG5hZL3dfFs6eCLyf2og7sG568K4RJUVE0k7khVskv1FMM03NXHRIEYV3FnLLolt4d/y7tM1r23zhdiATz3VU4pg7jpkhnrnjmLmlcvcqM7sAeAbIBu5191lmdh3wtrs/CVxkZicCVcBa4NzIAtdVO6KkCjcRkbSjxwG0AJ3zOzPx5InMXTOXy6ZcFnUcEZGM5u6T3X2Iuw9y9xvCZVeHRRvu/jN3H+buhe5+pLt/EG3iBGWl0LoHtO4ZdRIREakjmY8DeAh4DdjbzJaY2beSdSyBIwccyWWHXsad79zJUx8+FXUcERGJo7LS4PltZlEnERGROpJWuLn7Ge7ey91z3b2Pu9+TrGNJ4JdH/pLCgkLO+9d5rChfEXUcERGJk+oKWD9Ll0mKiKQpXSrZgrTKacUDpzzAhq0b+Pa/v427Rx1JRETiYsMHUFOhwk1EJE2pcGthhvUYxs3H3MxTHz7FXe/cFXUcERGJCw1MIiKS1lS4tUAXjLqALw76Ij965kfMWT0n6jgiIhIHZaWQnQ/th0SdRERE6qHCrQXKsiz+etJfyc/N56x/nkVldWXUkUREJN2tK4VOwyErO+okIiJSDxVuLdQe7ffg7hPu5p1l73Dti9dGHUdERNKZe9DjpsskRUTSlgq3FuyUfU/hvKLz+NUrv+KVRa9EHUdERNLVpsVQUabCTUQkjalwa+FuPfZW+nfqz9mPn82GrRuijiMiIumodmCSTkVRphARkR1Q4dbCtW/Vnvu/ej+L1i/ioqcvijqOiIiko7JSwIJ73EREJC2pcMsAo/uO5qovXMXEaRP5+6y/Rx1HRETSTVkptB8Mue2iTiIiIg1Q4ZYhrjr8Kkb1HsV3n/oui9cvjjqOiIikEw1MIiKS9lS4ZYjc7Fzu/+r9VNZUcvyDx7N289qoI4mISDqoWAcbP1LhJiKS5lS4ZZDBXQfzxGlP8OGaD/nyg19mY8XGqCOJiEjU1k0P3lW4iYikNRVuGWbswLE8/LWHeXPpm5zy6ClsrdoadSQREYlS7YiSKtxERNKaCrcM9NV9v8rdJ9zNlPlTOPvxs6muqY46koiIRKWsFFr3gNY9o04iIiI7kBN1AInGefufx7ot67h0yqV0at2Ju75yF2YWdSwREUm1smnB89vUBoiIpDUVbhnsR6N/xNrNa7nh5Rvokt+FXx/966gjiYhIKtVUwvqZsPclUScREZGdUOGW4X555C9Zs2kNN029iS75XfjJmJ9EHUlERFJlwwdQU6H720REYkCFW4YzM/54/B9Zt3UdP332p3Ru3ZnvHPidqGOJiEgqaGASEZHYUOEmZGdlM/Hkiazfsp7v/ed7dM7vzKlDT406loiIJFtZKWTnQ/shUScREZGd0KiSAkBedh6Pff0xRvcZzZn/OJP/zf9f1JFERCTZykqh03DIyo46iYiI7IQKN9mmTW4bnjrzKYZ2H8rJj5zMa4tfizqSiIgki3tQuOkySRGRWFDhJp/TqXUnnvnGM+zRfg++/OCXmblyZtSRREQkGTYtgYq1KtxERGJChZtsp6BdAf87+3/k5+bzxfu+yIKyBVFHEhGR5lY7MEmnoihTiIhII6lwk3r179SfKd+YwtbqrRxz3zEs+3RZ1JFERKQ5lZUCFtzjJiIiaU+FmzRoWI9hPH3W06woX8GX7v8SZZvLoo4kIiLNZV0ptB8Mue2iTiIiIo2gwk12aFTvUfzr9H8xZ80cvvzgl9lYsTHqSCIi0hw0MImISKyocJOdGjtwLA997SHeWPoGpzx6ChXVFVFHEhGRpqhYD+ULVLiJiMSICjdplFP2PYW7T7ibKfOncPbjZ1NdUx11JBGRtGRmx5rZHDObZ2aX72C7r5mZm9nIVOYDYN304L1TYcoPLSIiuycn6gASH+ftfx5lm8u47H+X0alVJ05vd3rUkURE0oqZZQN3AMcAS4C3zOxJd59dZ7v2wMXAG6lPyWcjSqrHTUQkNlS4yS659NBLWbt5LTe+ciNLey7l4MMOpk1um6hjiYiki1HAPHdfAGBmDwMnAbPrbPdL4Cbgx6mNFyorhVbdIb9XJIcXEZFdp0slZZddf9T1/OywnzF5+WT2v2t/3lr6VtSRRETSRW9gccL8knDZNmZ2ANDX3f+TymCfUzswiVlkEUREZNeox012mZlx49gb6b6hO7csvIXR94zmqsOv4sovXEludm7U8URE0paZZQG/B85txLbjgfEABQUFlJSUNOnY5eXllJSUYF7FF8pmsKTtKSxo4j5ToTZ3nMQxM8QzdxwzQzxzxzEzxDd3fVS4yW7bv/P+zDhuBhf99yKuffFaJs+dzH1fvY+9u+0ddTQRkagsBfomzPcJl9VqD+wHlFjQ29UTeNLMTnT3txN35O4TgAkAI0eO9OLi4iYFKykpobi4GNbNgGWV9Cs8kX79m7bPVNiWO0bimBnimTuOmSGeueOYGeKbuz66VFKapGPrjkw8eSKP/d9jLChbwP537c8f3/wj7h51NBGRKLwFDDazAWaWB5wOPFm70t3Xu3s3d+/v7v2B14Htirak0sAkIiKxpMJNmsXXhn6NGefP4MgBR3Lh0xdy7APHsnTD0p1/UESkBXH3KuAC4BngfeBRd59lZteZ2YnRpguVlUJ2a2g/JOokIiKyC1S4SbPp1b4XT53xFHd++U5eWfQKw/88nEdmPhJ1LBGRlHL3ye4+xN0HufsN4bKr3f3JerYtTmlvGwSFW8fhkKW7JURE4kSFmzQrM+O7I79L6XdL2bvb3pz+j9M58x9nUra5LOpoIiLi/tmIkiIiEisq3CQpBncdzMvffJnrj7yev8/+O8P/PJxnFzwbdSwRkcy2aQlUrFXhJiISQyrcJGlysnK48vAref1br9OhVQeOue8YLnr6IjZVboo6Wkb6YPUHvLr4VQ0cI5LJNDCJiEhsqXCTpDtwjwN5Z/w7XHzwxdz+5u0cOOFA3v4ktbd0ZLKP133MOU+cw9A7hjLm3jGMuXcMzy54VgWcSCYqKwUMOg2POomIiOwiFW6SEvm5+dx67K08e/azlFeUM/qe0Vz34nVU1VRFHa3FWr1pNT/87w8Z8schPDLzES479DLuOP4OFm9YzDH3HcMRfzuCkoUlUccUkVRaVwrt94Lc9lEnERGRXaTCTVJq7MCxzDh/BqcNO41flPyCw+49jGnLp6n3pxmVV5Tzyxd/ycA/DOS2N2/j7BFnM++iedx8zM18/6DvM+/CefzxuD8yv2w+R048kiMnHsnLH78cdWwRSQUNTCIiElsq3CTlOrXuxP2n3M8jpz7Ch2s+pOiuIvrd2o9znziXSdMmsWTDkqgjxlJFdQV3vHkHe922F1eXXM3RA49m5vkz+cuJf6FPhz7btmuV04ofjPoB8y+azx+O/QMfrP6Aw/92OMfcdwyvLn41wq9ARJIpu6YcyheocBMRiSk9xEUi8/VhX+eIPY/g8Q8e5/mPnuepD59i4rSJAAzpOoSj+h/F2IFjKe5fTLc23SJOm75qvIZHZj7CVS9cxYKyBRyx5xE8cfoTHNLnkB1+rnVOay46+CK+fcC3ufPtO7lp6k2MuXcMXxr0Ja4tvpaD+xycoq9ARFKhXeWCYKJTUaQ5RERk96hwk0gVtCvgeyO/x/dGfo8ar2HGihk8/9HzPPfRc9w/437ufOdOAIp6Fm0r5L7Q7wu0b6X7M9ydKfOn8LPnfsZ7y99jRMEIJp85mWP3OhYza/R+2uS24Uejf8R3D/wuf3rrT9z86s0ccs8hHD/4eK4tvpaRe4xM4lchu6O6ppr1W9dTtrmMsi1lvL32bVbMXEHZljLKNpexdvPaYHpLOL25jE2Vm9ivx34c1u8wxvQdw/699icvOy/qL0VSqF3lvGBCPW4iIrGkwk3SRpZlUdizkMKehfxw9A+prK7k7U/e3lbI3fHWHfz+9d+TbdmM6j2KsQPGctSAoxjddzStc1pHHT+l3lr6Fpc/dznPf/Q8/Tv1576v3seZw88ky3b/6ue2eW358Zgfc/5B5/PHN//Ib179DQfdfRAn7n0i1xxxDfv32r8ZvwJpSFVNFXPXzGXGyhlMXzGduWvnbiu+aguy9VvW49S5L3TGZ5Otc1rTJb8LnVt3pnN+Z/p17Ededh7vLnuXxz94fNs2o3qP4rC+hzGm3xhG9xlN5/zOKfxKJdXaVc2DVt0hv1fUUUREZDcktXAzs2OBPwDZwF/c/dfJPJ60LLnZuYzuO5rRfUdz5eFXsrlyM68ufnVbIXfjKzdy/cvX0zqnNWP6jmFM3zH0at+Lbm260b1Nd7q37U63Nt3omt+V7KzsqL+cZjFn9RyueuEqHpv9GN3bdOe2Y29j/IHjaZXTqtmO0S6vHZcfdjnfP+j73P7G7fz2td9ywIQD+Oo+X+Wa4msYUTCi2Y6V6VaUr2D6iunbirTpK6Yze9VstlZvBSDbshnQeQDd23SnoF0B+3Tb53MFWe30wg8WctToo4L5/M47/EXGsk+XMXXxVF5Z9ApTF0/lpqk3Uf1KNQDDug/b1iM3pt8YBnQasEu9t5Le2lXOg65FoO+piEgsJa1wM7Ns4A7gGGAJ8JaZPenus5N1TGnZ8nPzGTtwLGMHjuUGbmD9lvW89PFLPP/R8zy/8Hmue+m6ej9nGF3yu9CtTTfyKvPYa8VedG8TFHXd23bfbrprm67kZeeRbdlp85/WVVtXMf7f47n3vXvJz83nmiOu4Uejf5TUS0Y7tOrAlYdfyQWjLuDW12/lltdv4fEPHufUoady6ehL2aP9HrTJbUOb3Dbk5+SnzblKR5srNzN71eztirRVm1Zt26Znu56MKBjBhQMuZHjBcEYUjGCfbvs0qje5ZFkJw3oMa1SWXu17cerQUzl16KkAbKzYyJtL39xWzD008yHueueuYNt2vRjTb8y2X4wU9SwiNzt3N86ARK6mkraVC6HzyVEnERGR3ZTMHrdRwDx3XwBgZg8DJwEq3KRZdGzdkRP2PoET9j4BCEZVXLNpDas2rWL1ptWs2rhqu+m5S+cyd+1cXl38Kqs3rabaq3d4jJysnM+9crNyt1uWk5VDbnb9y7MsC8OCd7Ptps1s2zb1rc+yLKpqqnjygyepoYbvH/R9rjr8Knq07ZGKUwwE5/kXxb/gooMv4pbXb+HW12/lsdmPbbddbRFX+6rZUkPBRwXb5tvmtaVNTsJ0WPDVPR87et/ZtsBOlwE7XD9j9QzK3i/DcWq8BvfwvZ75Ha1btXHV5y53rPEaAPJz8tmvx36cMOQERhSMYHjBcIb3GE73tt1T8e3cTtu8thw54EiOHHAkENw/N2vVLKYumsori19h6qKp277fbXLbcHDvg/nBQT/ga0O/Fkle2U0b5pBFpe5vExGJsWQWbr2BxQnzSwANUydJk5edR6/2vejVvuH7N0pKSiguLgaC0RjXb1nPqk2rWLUxLPA2rWLNpjVU1lRSVVNFVU0VldWfTVfVVH1uXUPLKqsr2Vq1td7/4Lv75/6jX3e6vm0P7344d552JwM7D0zR2dxe5/zOXHfkdVx88MU899FzlFeUs6lyExsrNrKpctO218bKYH7x8sVkZ2VTtqWMpZ8u/dy2Gys3bitk0tKs5tnNoM6DGFEwgtOGnbatSBvUeVBaX7qbnZXNiIIRjCgYwfkHnQ/A0g1LP3d55drNayNOKbusrDR4V+EmIhJbkQ9OYmbjgfEABQUFlJSUNGl/5eXlTd5HqsUxM8Qz944ydwz/7MVeny3MIi2edlheXs6iaYtYxKKoowDQI/yzjQF54StUnl9Ou3bt6v28u1PlVWyt+ay4rV1e+6eh+Rpq6l23O8uA7Y61efNm2rZpi7F9b1/wpX42nUVCD2BiTx9Gm5w25Gfnf/ZFr4RPVn7CJ3zS2NPcaKn4u9iDHpySfwqnDDkFPiV2f/czXt+v8u7cP3JA+yFRJxERkd2UzMJtKdA3Yb5PuOxz3H0CMAFg5MiRXtsbsrsSe1TiIo6ZIZ6545gZ4pk7jpkhnrnjmFlSLKctG/KGQVbkv68VEZHdlMy+hLeAwWY2wMzygNOBJ5N4PBERERERkRYpab96c/cqM7sAeIbgcQD3unsz3TkiIiIiIiKSOZJ6zYS7TwYmJ/MYIiIiIiIiLV0aDLsgIiIiIiIiO6LCTUREREREJM2pcBMREREREUlzKtxERERERETSnAo3ERERERGRNKfCTUREREREJM2pcBMREREREUlz5u5RZ9jGzFYBHzdxN92A1c0QJ5XimBnimTuOmSGeueOYGeKZO46Z93T37lGHiIsMbh8hnrnjmBnimTuOmSGeueOYGeKZu942Mq0Kt+ZgZm+7+8ioc+yKOGaGeOaOY2aIZ+44ZoZ45o5jZkm9uP6cxDF3HDNDPHPHMTPEM3ccM0N8c9dHl0qKiIiIiIikORVuIiIiIiIiaa4lFm4Tog6wG+KYGeKZO46ZIZ6545gZ4pk7jpkl9eL6cxLH3HHMDPHMHcfMEM/cccwM8c29nRZ3j5uIiIiIiEhL0xJ73ERERERERFqU2BZuZnasmc0xs3lmdnk961uZ2SPh+jfMrH8EMRPz9DWzF8xstpnNMrOL69mm2MzWm1lp+Lo6iqx1mdlCM5sRZnq7nvVmZreF53q6mR0QRc6EPHsnnMNSM9tgZpfU2SYtzrWZ3WtmK81sZsKyLmb2PzObG753buCz54TbzDWzcyLO/Bsz+yD8/j9uZp0a+OwOf5aSqYHc15jZ0oSfg+Mb+OwO/71JceZHEvIuNLPSBj4b2bmWaMWtfQwzxbKNjFv7GGZSG5n6zGndRsaxfQyPnXltpLvH7gVkA/OBgUAeMA0YWmeb7wN3htOnA49EnLkXcEA43R74sJ7MxcBTUZ/ferIvBLrtYP3xwNOAAYcAb0Sduc7PynKC52Gk3bkGDgcOAGYmLLsZuDycvhy4qZ7PdQEWhO+dw+nOEWb+IpATTt9UX+bG/CxFkPsa4LJG/Azt8N+bVGaus/53wNXpdq71iu4Vx/YxzBHLNjLO7WPCz4vayORnTus2Mo7tY0O566xvcW1kXHvcRgHz3H2Bu1cADwMn1dnmJGBiOP0YMNbMLIUZP8fdl7n7u+H0p8D7QO+o8jSzk4BJHngd6GRmvaIOFRoLzHf3pj64Ninc/SVgbZ3FiT+7E4GT6/nol4D/uftady8D/gccm6ycierL7O5T3L0qnH0d6JOKLLuigXPdGI359yYpdpQ5/Pfs68BDqcgisRG79hFadBuZzu0jqI1sdnFsI+PYPkJmtpFxLdx6A4sT5pew/T/w27YJ/7KsB7qmJN1OhJel7A+8Uc/q0WY2zcyeNrNhqU3WIAemmNk7Zja+nvWN+X5E5XQa/kubjucaoMDdl4XTy4GCerZJ53N+HsFvmOuzs5+lKFwQXr5ybwOX3KTruf4CsMLd5zawPh3PtSRfrNtHiF0bGef2EdRGRiFObWRc20dooW1kXAu32DKzdsA/gEvcfUOd1e8SXK5QCNwOPJHieA05zN0PAI4DfmBmh0cdqDHMLA84Efh7PavT9Vx/jgf9+bEZ+tXMrgSqgAca2CTdfpb+DAwCioBlBJdVxMUZ7Pg3iel2rkV2KoZtZGz/nqmNTL2YtZFxbh+hhbaRcS3clgJ9E+b7hMvq3cbMcoCOwJqUpGuAmeUSNEgPuPs/66539w3uXh5OTwZyzaxbimNux92Xhu8rgccJusYTNeb7EYXjgHfdfUXdFel6rkMrai+lCd9X1rNN2p1zMzsX+ApwVtiYbqcRP0sp5e4r3L3a3WuAuxvIk47nOgc4BXikoW3S7VxLysSyfQyzxK6NjHH7CGojUypubWRc20do2W1kXAu3t4DBZjYg/I3R6cCTdbZ5EqgdRehU4PmG/qKkQnit7T3A++7++wa26Vl7n4GZjSL4/kRdbLY1s/a10wQ32M6ss9mTwDgLHAKsT7iMIUoN/rYlHc91gsSf3XOAf9WzzTPAF82sc3j5whfDZZEws2OBnwAnuvumBrZpzM9SStW51+Sr1J+nMf/epNrRwAfuvqS+lel4riVlYtc+QjzbyJi3j6A2MmXi2EbGuH2EltxGNnYUk3R7EYzU9CHBaDZXhsuuI/hLAdCaoPt/HvAmMDDivIcRdOdPB0rD1/HA94DvhdtcAMwiGJXndeDQNDjPA8M808Jstec6MbcBd4TfixnAyDTI3ZagkemYsCztzjVBo7kMqCS4NvxbBPeaPAfMBZ4FuoTbjgT+kvDZ88Kf73nANyPOPI/gOvfan+3aEev2ACbv6Gcp4tz3hT+z0wkam151c4fz2/17E1XmcPnfan+WE7ZNm3OtV7Sv+n5eSeP2McwUuzayob9npHn7GOZSG5nazGndRjaQOa3bx4Zyh8v/RgttIy38AkRERERERCRNxfVSSRERERERkYyhwk1ERERERCTNqXATERERERFJcyrcRERERERE0pwKNxERERERkTSnwk2kmZhZtZmVJrwub8Z99zezeDxjREREJIHaR5HmkRN1AJEWZLO7F0UdQkREJM2ofRRpBupxE0kyM1toZjeb2Qwze9PM9gqX9zez581supk9Z2b9wuUFZva4mU0LX4eGu8o2s7vNbJaZTTGz/Mi+KBERkSZS+yiya1S4iTSf/DqXgpyWsG69uw8H/gjcGi67HZjo7iOAB4DbwuW3AS+6eyFwADArXD4YuMPdhwHrgK8l9asRERFpHmofRZqBuXvUGURaBDMrd/d29SxfCBzl7gvMLBdY7u5dzWw10MvdK8Ply9y9m5mtAvq4+9aEffQH/ufug8P5nwK57n59Cr40ERGR3ab2UaR5qMdNJDW8geldsTVhuhrdoyoiIvGn9lGkkVS4iaTGaQnvr4XTrwKnh9NnAS+H088B5wOYWbaZdUxVSBERkRRT+yjSSPqNhEjzyTez0oT5/7p77ZDHnc1sOsFvBc8Il10I/NXMfgysAr4ZLr8YmGBm3yL4zeH5wLJkhxcREUkStY8izUD3uIkkWXgN/0h3Xx11FhERkXSh9lFk1+hSSRERERERkTSnHjcREREREZE0px43ERERERGRNKfCTUREREREJM2pcBMREREREUlzKtxERERERETSnAo3ERERERGRNKfCTUREREREJM39P5mn9Nbi9/X9AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def looping_step(dataloader, model, optimizer, criterion, metric, n_epoch=hyperparams.n_epoch, patience=hyperparams.patience, monitor=\"loss\"):    \n",
    "    start_time = time()\n",
    "    \n",
    "    epoch_losses = []\n",
    "    epoch_metric_scores = []\n",
    "    patience_counter = 0\n",
    "    \n",
    "    now = datetime.now(pytz.timezone(\"Asia/Ujung_Pandang\"))\n",
    "    path_name = now.strftime(\"%m-%d-%Y_%H-%M-%S\")\n",
    "    os.makedirs(f\"../../logs/comick/{hyperparams.context_size}_contexts/{path_name}\")\n",
    "    \n",
    "    # Hyperparameters\n",
    "    with open(f\"../../logs/comick/{hyperparams.context_size}_contexts/{path_name}/training_history.txt\", \"a\") as f:\n",
    "        f.write(f\"HYPERPARAMETERS\\n\")\n",
    "        f.write(f\"{'-' * 50}\\n\")\n",
    "        for name, value in vars(hyperparams).items():\n",
    "            f.write(f\"{name}: {value}\\n\")\n",
    "        \n",
    "        f.write(\"\\n\\nTRAINING PROGRESS\\n\")\n",
    "        f.write(f\"{'-' * 50}\\n\")\n",
    "    \n",
    "    # Training Progress\n",
    "    for epoch in range(1, n_epoch + 1):\n",
    "        print(f\"EPOCH-{epoch}\")\n",
    "        with open(f\"../../logs/comick/{hyperparams.context_size}_contexts/{path_name}/training_history.txt\", \"a\") as f:\n",
    "            f.write(f\"EPOCH-{epoch}\\n\")\n",
    "        \n",
    "        batch_losses, batch_metric_scores = training_step(dataloader, model, optimizer, criterion, metric, path_name=path_name)\n",
    "        epoch_loss = torch.mean(torch.FloatTensor(batch_losses))\n",
    "\n",
    "        epoch_loss = torch.mean(torch.FloatTensor(batch_losses))\n",
    "        epoch_losses.append(epoch_loss.item())\n",
    "\n",
    "        epoch_metric_score = torch.mean(torch.FloatTensor(batch_metric_scores))\n",
    "        epoch_metric_scores.append(epoch_metric_score.item())\n",
    "        \n",
    "        with open(f\"../../logs/comick/{hyperparams.context_size}_contexts/{path_name}/training_history.txt\", \"a\") as f:\n",
    "            if monitor == \"loss\":\n",
    "                if epoch == 1:\n",
    "                    best_state_dict = model.state_dict()\n",
    "                    best_loss = (epoch_loss)\n",
    "                    best_metric = (epoch_metric_score)\n",
    "                    \n",
    "                    print(f\"\\nMean {str(criterion).split('(')[0]}: {(epoch_loss):.4f} | Mean {str(metric).split('(')[0]}: {(epoch_metric_score):.4f}\")\n",
    "                    \n",
    "                    f.write(f\"\\nMean {str(criterion).split('(')[0]}: {(epoch_loss):.4f} | Mean {str(metric).split('(')[0]}: {(epoch_metric_score):.4f}\\n\")\n",
    "                elif epoch_losses[-1] < epoch_losses[-2]:\n",
    "                    best_state_dict = model.state_dict()\n",
    "                    best_loss = (epoch_loss)\n",
    "                    best_metric = (epoch_metric_score)\n",
    "                    \n",
    "                    print(\"\\nYeah ðŸŽ‰ðŸ˜„! Model improved.\")\n",
    "                    print(f\"Mean {str(criterion).split('(')[0]}: {(epoch_loss):.4f} | Mean {str(metric).split('(')[0]}: {(epoch_metric_score):.4f}\")\n",
    "                    \n",
    "                    f.write(\"\\nYeah ðŸŽ‰ðŸ˜„! Model improved.\\n\")\n",
    "                    f.write(f\"Mean {str(criterion).split('(')[0]}: {(epoch_loss):.4f} | Mean {str(metric).split('(')[0]}: {(epoch_metric_score):.4f}\\n\")\n",
    "                else:\n",
    "                    patience_counter += 1\n",
    "                    \n",
    "                    print(\"\\nHuft ðŸ˜¥! Model not improved.\")\n",
    "                    print(f\"Mean {str(criterion).split('(')[0]}: {(epoch_loss):.4f} | Mean {str(metric).split('(')[0]}: {(epoch_metric_score):.4f}\")\n",
    "                    print(f\"Patience = {patience_counter}/{patience}â—\")\n",
    "                    \n",
    "                    f.write(\"\\nHuft ðŸ˜¥! Model not improved.\\n\")\n",
    "                    f.write(f\"Mean {str(criterion).split('(')[0]}: {(epoch_loss):.4f} | Mean {str(metric).split('(')[0]}: {(epoch_metric_score):.4f}\\n\")                    \n",
    "                    f.write(f\"Patience = {patience_counter}/{patience}â—\\n\")\n",
    "            else:\n",
    "                if epoch == 1:\n",
    "                    best_state_dict = model.state_dict()\n",
    "                    best_loss = (epoch_loss)\n",
    "                    best_metric = (epoch_metric_score)\n",
    "                    \n",
    "                    print(f\"\\nMean {str(criterion).split('(')[0]}: {(epoch_loss):.4f} | Mean {str(metric).split('(')[0]}: {(epoch_metric_score):.4f}\")\n",
    "                    \n",
    "                    f.write(f\"\\nMean {str(criterion).split('(')[0]}: {(epoch_loss):.4f} | Mean {str(metric).split('(')[0]}: {(epoch_metric_score):.4f}\\n\")\n",
    "                elif epoch_metric_scores[-1] > epoch_metric_scores[-2]:\n",
    "                    best_state_dict = model.state_dict()\n",
    "                    best_loss = (epoch_loss)\n",
    "                    best_metric = (epoch_metric_score)\n",
    "                    \n",
    "                    print(\"\\nYeah ðŸŽ‰ðŸ˜„! Model improved.\")\n",
    "                    print(f\"Mean {str(criterion).split('(')[0]}: {(epoch_loss):.4f} | Mean Mean {str(metric).split('(')[0]}: {(epoch_metric_score):.4f}\")\n",
    "                    \n",
    "                    f.write(\"\\nYeah ðŸŽ‰ðŸ˜„! Model improved.\\n\")\n",
    "                    f.write(f\"Mean {str(criterion).split('(')[0]}: {(epoch_loss):.4f} | Mean {str(metric).split('(')[0]}: {(epoch_metric_score):.4f}\\n\")\n",
    "                else:\n",
    "                    patience_counter += 1\n",
    "                    \n",
    "                    print(\"\\nHuft ðŸ˜¥! Model not improved.\")\n",
    "                    print(f\"Mean {str(criterion).split('(')[0]}: {(epoch_loss):.4f} | Mean {str(metric).split('(')[0]}: {(epoch_metric_score):.4f}\\n\")\n",
    "                    print(f\"Patience = {patience_counter}/{patience}â—\\n\")\n",
    "                    \n",
    "                    f.write(\"\\nHuft ðŸ˜¥! Model not improved.\\n\")\n",
    "                    f.write(f\"Mean {str(criterion).split('(')[0]}: {(epoch_loss):.4f} | Mean {str(metric).split('(')[0]}: {(epoch_metric_score):.4f}\\n\")\n",
    "                    f.write(f\"Patience = {patience_counter}/{patience}â—\\n\")\n",
    "                    \n",
    "            print(\"=\" * 50, end=\"\\n\\n\")\n",
    "            f.write(f\"{'=' * 50}\\n\\n\")\n",
    "            \n",
    "            if patience_counter == patience:\n",
    "                print(f\"Early stopping, patience = {patience_counter}/{patience}â—\\n\")\n",
    "                f.write(f\"Early stopping, patience = {patience_counter}/{patience}â—\\n\")\n",
    "                break\n",
    "        \n",
    "        metric.reset()\n",
    "    \n",
    "    finish_time = time()\n",
    "    \n",
    "    # Training plot \n",
    "    fig, (ax_loss, ax_metric_score) = plt.subplots(nrows=1, ncols=2, figsize=(15, 5))\n",
    "\n",
    "    fig.suptitle(f\"Training with context size = {hyperparams.context_size}\")\n",
    "\n",
    "    ax_loss.set_title(\"Loss\")\n",
    "    ax_loss.set_xlabel(\"Epoch\")\n",
    "    ax_loss.set_ylabel(\"Score\")\n",
    "    ax_loss.plot(epoch_losses, \"green\")\n",
    "    ax_loss.grid()\n",
    "\n",
    "    ax_metric_score.set_title(\"F1 Score\")\n",
    "    ax_metric_score.set_xlabel(\"Epoch\")\n",
    "    ax_metric_score.set_ylabel(\"Score\")\n",
    "    ax_metric_score.plot(epoch_metric_scores, \"orange\")\n",
    "    ax_metric_score.grid()\n",
    "\n",
    "    plt.savefig(f\"../../logs/comick/{hyperparams.context_size}_contexts/{path_name}/training_plot.jpg\", dpi=200)                        \n",
    "    \n",
    "    print(\"TRAINING SUMMARY\")\n",
    "    criterion_name = \"Best \" + str(criterion).split('(')[0]\n",
    "    metric_name = \"Best \" + str(metric).split('(')[0]\n",
    "    \n",
    "    print(f\"{criterion_name.ljust(18)}: {best_loss:.4f}\")\n",
    "    print(f\"{metric_name.ljust(18)}: {best_metric:.4f}\")\n",
    "    print(f\"{'Training duration'.ljust(18)}: {((finish_time - start_time) / 60):.3f} minutes.\")\n",
    "    print(f\"{'Training date'.ljust(18)}: {now}\")\n",
    "    \n",
    "    with open(f\"../../logs/comick/{hyperparams.context_size}_contexts/{path_name}/training_history.txt\", \"a\") as f:\n",
    "        f.write(\"\\nTRAINING SUMMARY\\n\")\n",
    "        f.write(f\"{'-' * 50}\\n\")\n",
    "        f.write(f\"{criterion_name.ljust(18)}: {best_loss:.4f}\\n\")\n",
    "        f.write(f\"{metric_name.ljust(18)}: {best_metric:.4f}\\n\")\n",
    "        f.write(f\"{'Training duration'.ljust(18)}: {((finish_time - start_time) / 60):.3f} minutes.\\n\")\n",
    "        f.write(f\"{'Training date'.ljust(18)}: {now}\\n\")\n",
    "    \n",
    "    # Save epoch losses, epoch metric scores, model, state dict, and oov embedding dict\n",
    "    filename_model_params = f\"../../logs/comick/{hyperparams.context_size}_contexts/{path_name}/model_params.pth\"\n",
    "    filename_oov_embedding_dict = open(f\"../../logs/comick/{hyperparams.context_size}_contexts/{path_name}/oov_embedding_dict.pkl\", \"ab\")\n",
    "    \n",
    "    pd.DataFrame(\n",
    "        data={\n",
    "            \"epoch\": list(range(1, len(epoch_losses) + 1)),\n",
    "            \"loss\": epoch_losses\n",
    "        }\n",
    "    ).to_csv(f\"../../logs/comick/{hyperparams.context_size}_contexts/{path_name}/epoch_losses.csv\", index=False)\n",
    "    \n",
    "    pd.DataFrame(\n",
    "        data={\n",
    "            \"epoch\": list(range(1, len(epoch_metric_scores) + 1)),\n",
    "            \"f1_score\": epoch_metric_scores\n",
    "        }\n",
    "    ).to_csv(f\"../../logs/comick/{hyperparams.context_size}_contexts/{path_name}/epoch_metric_scores.csv\", index=False)\n",
    "    \n",
    "    torch.save(best_state_dict, filename_model_params)\n",
    "    pickle.dump({token : embedding for token, embedding in zip(list(labels_to_idx.keys()), model.embedding)}, filename_oov_embedding_dict)\n",
    "    \n",
    "    return epoch_losses, epoch_metric_scores\n",
    "\n",
    "epoch_losses, epoch_metric_scores = looping_step(dataloader, model, optimizer, criterion, metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfef50c-e71c-4288-a9f3-6fd8831033b0",
   "metadata": {},
   "source": [
    "# END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92debcb3-d6ea-4299-a3e9-37be5b63d2b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.601892  , -0.07298523, -2.244749  , ...,  7.298557  ,\n",
       "         0.2855679 , -2.7030878 ],\n",
       "       [ 0.97588235,  7.2211456 , -1.2655089 , ...,  2.7916858 ,\n",
       "         2.588202  ,  1.4704989 ],\n",
       "       [ 0.75321954,  5.6476417 , -2.2231045 , ..., -1.5505563 ,\n",
       "        -1.3629488 , -2.7280757 ],\n",
       "       ...,\n",
       "       [-0.04665082, -4.3244243 ,  6.062445  , ...,  4.805164  ,\n",
       "         1.6028614 ,  0.61766773],\n",
       "       [ 0.16663542,  2.376115  ,  7.6425767 , ...,  1.1819327 ,\n",
       "         7.832189  ,  1.0052701 ],\n",
       "       [ 2.3024282 ,  3.7703881 , -4.207958  , ..., -1.5739542 ,\n",
       "         5.229251  , -1.1864946 ]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27ce78c3-ac2c-4a84-a8e8-4d8e85d26563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('bilstm_left_context_feature.weight_ih_l0',\n",
       "              tensor([[ 0.1342,  0.1299, -0.1404,  ...,  0.1896,  0.1654, -0.2612],\n",
       "                      [ 0.0799, -0.0790, -0.2439,  ..., -0.3522,  0.0441,  0.2765],\n",
       "                      [ 0.2742, -0.1410, -0.0873,  ..., -0.2782,  0.0991, -0.3104],\n",
       "                      ...,\n",
       "                      [ 0.2157, -0.3912, -0.0363,  ..., -0.1150,  0.2360, -0.5251],\n",
       "                      [ 0.1368, -0.0360,  0.0492,  ...,  0.0396,  0.0623, -0.0514],\n",
       "                      [ 0.0865, -0.2370,  0.0431,  ...,  0.1589,  0.1967, -0.0190]])),\n",
       "             ('bilstm_left_context_feature.weight_hh_l0',\n",
       "              tensor([[ 0.2283, -0.1450,  0.2155,  ...,  0.0404,  0.1337, -0.0233],\n",
       "                      [ 0.1903,  0.1866, -0.0988,  ...,  0.0700,  0.0766, -0.0916],\n",
       "                      [ 0.2148, -0.2673,  0.1639,  ...,  0.0982,  0.1791, -0.0135],\n",
       "                      ...,\n",
       "                      [ 0.1349, -0.0858,  0.2362,  ...,  0.1857,  0.0629,  0.0623],\n",
       "                      [ 0.1217, -0.1445, -0.1609,  ..., -0.0520, -0.0808, -0.2934],\n",
       "                      [ 0.2629, -0.2432, -0.1874,  ..., -0.0335,  0.1069, -0.3137]])),\n",
       "             ('bilstm_left_context_feature.bias_ih_l0',\n",
       "              tensor([-1.9737e-01, -2.4833e-01, -3.2310e-01, -1.8802e-01, -3.4506e-02,\n",
       "                      -8.9371e-02, -2.0426e-01, -5.1945e-02, -2.3026e-01, -9.8724e-02,\n",
       "                      -1.2342e-01, -2.1383e-01, -9.2418e-02, -1.4512e-01, -2.3589e-01,\n",
       "                      -1.3445e-01, -1.4351e-01, -1.5765e-01, -1.7548e-01, -3.1511e-01,\n",
       "                      -2.8991e-01, -1.9685e-01,  3.6692e-02, -9.0690e-02, -1.5403e-01,\n",
       "                      -3.6787e-01, -9.2316e-02, -1.3046e-01, -3.4342e-02, -1.4263e-01,\n",
       "                      -4.3979e-02, -1.5251e-01, -3.0998e-01, -2.0951e-01, -1.7636e-01,\n",
       "                      -1.0440e-01, -2.7602e-01, -3.8830e-01, -2.4793e-02, -4.0067e-01,\n",
       "                      -2.1143e-01, -2.2189e-01, -1.5008e-01, -2.6295e-01, -2.2771e-01,\n",
       "                      -1.8896e-01, -1.8661e-01, -3.0187e-01, -1.6726e-01, -5.1792e-02,\n",
       "                      -2.6790e-01, -1.6025e-02, -1.2407e-01, -2.6469e-01, -1.5256e-02,\n",
       "                      -2.0914e-01, -2.4329e-01, -2.8516e-01, -1.6037e-01, -2.0907e-01,\n",
       "                      -1.8371e-01, -2.1073e-01, -2.9978e-01, -3.8929e-01, -1.9637e-01,\n",
       "                      -1.2497e-01, -2.1921e-01, -3.0150e-01, -1.9576e-01, -9.1643e-02,\n",
       "                      -2.4496e-01, -1.3328e-01, -2.2194e-01, -2.0811e-01, -2.5730e-01,\n",
       "                      -3.0797e-01, -2.5766e-01, -3.4051e-01, -1.2661e-01, -2.4773e-01,\n",
       "                      -2.3049e-01, -1.6889e-01, -2.1497e-01, -1.5628e-01, -9.6497e-02,\n",
       "                      -4.5063e-02, -1.7607e-01, -2.7746e-01, -2.2645e-01, -2.1765e-01,\n",
       "                      -1.4906e-01, -2.1662e-01, -2.0507e-01, -2.1766e-01, -2.0367e-01,\n",
       "                      -3.5653e-02, -2.6604e-01, -2.1249e-01, -2.5820e-01, -2.5917e-01,\n",
       "                      -2.3306e-01, -1.8949e-01, -1.6343e-01, -2.5797e-01, -1.7001e-01,\n",
       "                      -1.4324e-01, -1.4475e-01, -1.9221e-01, -2.2642e-01, -2.9098e-01,\n",
       "                      -1.6975e-01, -6.9283e-02, -1.0217e-01, -9.7360e-02, -7.8018e-03,\n",
       "                      -3.2604e-01, -2.4106e-01, -3.2472e-01, -2.6141e-01, -6.5182e-02,\n",
       "                      -7.5854e-02, -1.9436e-01, -2.4658e-01, -1.2255e-01, -1.1965e-01,\n",
       "                      -1.8004e-01, -2.4607e-01, -9.6730e-02, -1.6398e-01, -2.2669e-01,\n",
       "                      -9.2479e-02, -1.8784e-01, -1.5846e-01, -1.7273e-01, -2.0167e-01,\n",
       "                      -8.5619e-02, -2.0371e-01, -1.0913e-01, -1.6678e-01, -1.6047e-01,\n",
       "                      -1.1793e-01, -1.2766e-01, -1.1361e-01, -1.8194e-01, -7.4771e-02,\n",
       "                      -9.4769e-02, -1.3996e-01, -1.2447e-01, -1.9451e-01, -1.6798e-01,\n",
       "                      -1.4517e-01, -3.5640e-02, -1.4209e-01, -2.0934e-01, -1.7921e-01,\n",
       "                      -1.3008e-01, -5.0532e-02, -2.1012e-01, -1.0472e-01, -1.0072e-01,\n",
       "                      -1.6991e-01, -7.8128e-02, -1.4160e-01, -1.0860e-01, -1.7152e-01,\n",
       "                      -1.4076e-01, -1.3973e-01, -1.7897e-02, -9.6885e-02, -1.1925e-01,\n",
       "                      -1.9573e-01, -1.2906e-01, -1.2444e-01, -1.8545e-01, -6.5500e-02,\n",
       "                      -4.8395e-02, -3.3424e-02, -5.4764e-02, -1.2111e-01, -2.3461e-02,\n",
       "                       2.5436e-02, -4.6336e-02, -1.8463e-01, -1.7292e-01, -1.0269e-01,\n",
       "                      -8.7229e-02, -1.1348e-01, -1.3769e-01, -1.6142e-01, -1.1203e-01,\n",
       "                      -1.4335e-01, -1.2296e-01, -1.6039e-01, -1.4540e-01,  6.6380e-02,\n",
       "                      -1.0013e-01, -1.7949e-01, -1.5431e-01, -1.0919e-01, -1.7039e-01,\n",
       "                      -1.2972e-01, -1.2619e-01, -9.0637e-02, -6.0573e-02, -1.4578e-01,\n",
       "                      -4.6946e-02, -1.7635e-01, -2.0528e-01, -2.1433e-01, -1.2112e-01,\n",
       "                      -1.3122e-01, -8.4932e-02, -1.6353e-01, -8.3436e-02, -1.7457e-01,\n",
       "                      -1.4213e-01, -1.9547e-01, -8.6708e-02, -1.2653e-01, -1.3528e-01,\n",
       "                      -2.1882e-01, -1.4567e-01, -9.3716e-02, -7.3406e-02, -9.8030e-02,\n",
       "                      -4.3849e-02, -1.6047e-01, -2.3862e-01, -2.1483e-01, -2.4740e-01,\n",
       "                      -1.4967e-01, -1.0624e-01, -1.6442e-01, -1.3121e-01, -7.2363e-02,\n",
       "                      -1.8834e-01, -1.1791e-01, -1.5315e-01, -1.8074e-01, -1.5155e-01,\n",
       "                      -1.7448e-01, -2.6033e-01, -1.2873e-01, -2.7133e-01, -1.5190e-01,\n",
       "                      -1.6191e-01, -4.2358e-02, -1.6369e-01, -8.8530e-02, -1.6078e-01,\n",
       "                       6.6623e-02, -1.7076e-01, -2.3253e-01, -1.7105e-01, -2.6409e-01,\n",
       "                      -1.6518e-01, -6.7324e-02, -9.3762e-02, -4.7907e-03, -2.2344e-02,\n",
       "                       1.4348e-01, -3.0661e-02,  1.5457e-02,  4.4546e-02, -1.0893e-01,\n",
       "                       1.6961e-03,  5.7964e-02, -3.8430e-02, -2.9348e-02, -3.3816e-02,\n",
       "                       1.2282e-02, -3.2626e-02, -7.0737e-02, -9.1015e-02, -5.2266e-02,\n",
       "                      -1.6610e-02,  2.5416e-02, -3.8860e-02,  5.0346e-02, -5.0593e-02,\n",
       "                       2.8706e-03,  1.0786e-01,  5.8667e-02,  1.1881e-02, -1.4123e-01,\n",
       "                      -1.3158e-03, -3.8868e-02,  9.7033e-03,  4.6939e-02, -6.3288e-03,\n",
       "                      -2.6390e-03, -1.1610e-01,  3.6290e-02,  4.4535e-03, -2.4861e-02,\n",
       "                      -1.9795e-02, -2.1741e-02, -9.2480e-02,  4.0195e-02, -1.8907e-02,\n",
       "                       1.7302e-03,  4.5555e-02,  6.4188e-02,  7.7150e-02,  1.8997e-02,\n",
       "                      -1.5632e-02, -8.2049e-02, -1.6911e-02,  5.0798e-02, -1.0478e-02,\n",
       "                      -2.9645e-02,  6.0118e-02,  1.0709e-02, -3.8291e-02, -7.3066e-02,\n",
       "                       3.1871e-02,  9.0146e-03,  2.2781e-03,  8.4375e-02, -1.1068e-03,\n",
       "                       4.3754e-03, -1.1127e-01, -8.5701e-03, -3.8743e-02,  7.8340e-02,\n",
       "                       3.4806e-03, -8.8569e-03, -6.2465e-03, -2.1813e-02,  1.4618e-02,\n",
       "                       1.5182e-02,  2.0183e-04, -1.0840e-02, -6.6245e-02, -6.6478e-02,\n",
       "                      -1.1925e-01,  1.7769e-01, -1.7842e-03, -2.5176e-02, -2.7717e-02,\n",
       "                      -1.4481e-02,  9.5411e-04, -1.0884e-02, -2.2057e-02,  2.7258e-02,\n",
       "                      -7.7702e-02, -1.7364e-02, -3.4116e-02, -1.5746e-01,  1.7662e-02,\n",
       "                       6.7853e-02, -5.6804e-02,  7.0748e-03, -6.2256e-02, -2.7512e-02,\n",
       "                      -6.5648e-03,  2.5329e-02, -6.8247e-03,  9.9877e-02,  9.3058e-03,\n",
       "                       7.5723e-02,  1.4448e-01,  4.8956e-02, -8.3059e-02, -3.8011e-02,\n",
       "                      -2.5668e-02, -6.2920e-02, -1.7543e-02,  9.0021e-02,  4.2836e-02,\n",
       "                      -5.1526e-03,  6.6594e-02, -7.9077e-02,  1.5429e-02, -3.2124e-02,\n",
       "                      -2.3108e-02, -5.9152e-02, -6.0362e-02,  8.7646e-02,  1.2034e-02,\n",
       "                      -1.3759e-01,  1.1107e-01,  3.3793e-03,  1.0834e-01, -1.6645e-01,\n",
       "                      -1.2763e-01, -2.7347e-01, -2.1890e-01, -2.9140e-03, -1.5988e-01,\n",
       "                      -7.1748e-02, -5.3340e-02, -1.8862e-01, -2.0275e-01, -1.8424e-01,\n",
       "                      -1.8690e-01, -7.0944e-02, -1.6712e-01, -1.7436e-01, -5.8593e-02,\n",
       "                      -9.2828e-02, -1.5446e-01, -2.5633e-01, -2.0796e-01, -2.4403e-01,\n",
       "                      -1.8373e-01, -3.3696e-02, -1.8548e-01, -1.6605e-01, -2.1937e-01,\n",
       "                      -1.2692e-01, -1.6558e-01, -1.3456e-01, -2.0098e-01, -1.2607e-01,\n",
       "                      -2.5385e-01, -1.8841e-01, -7.2757e-02, -6.7021e-02, -1.1999e-01,\n",
       "                      -2.7660e-01, -6.8172e-02, -1.5510e-01, -2.7931e-01, -2.0573e-01,\n",
       "                      -2.3055e-01, -2.8400e-01, -1.5019e-01, -1.9875e-01, -1.6027e-01,\n",
       "                      -2.0014e-01, -1.8986e-01, -2.1997e-01, -1.8107e-02, -5.1472e-02,\n",
       "                      -6.3560e-02, -8.7429e-02, -1.0095e-01, -7.9903e-02, -8.0146e-02,\n",
       "                      -1.6177e-01, -2.4017e-01, -2.7276e-01, -1.7408e-01, -3.4038e-02,\n",
       "                      -1.0142e-01, -3.0228e-01, -1.7992e-01, -1.9418e-01, -2.3967e-01,\n",
       "                      -1.1810e-01, -2.7853e-01, -2.4148e-01, -1.6266e-01, -1.6862e-01,\n",
       "                      -2.2341e-01, -1.3379e-01, -1.2419e-01, -1.0429e-01, -3.5299e-01,\n",
       "                      -1.0957e-01, -2.1288e-01, -1.3267e-01, -1.9525e-01, -3.5245e-01,\n",
       "                      -2.2876e-01, -2.3910e-01, -1.3845e-01, -2.1908e-01, -1.3214e-01,\n",
       "                      -2.2214e-01, -1.5691e-01, -1.0981e-01, -1.6762e-01, -6.2522e-02,\n",
       "                      -2.9214e-02, -9.1710e-02, -2.3797e-01, -1.9762e-01, -1.1508e-01,\n",
       "                      -2.8827e-01, -2.5193e-01, -1.2740e-01, -3.0076e-01, -2.4615e-01,\n",
       "                      -1.5885e-01,  2.0455e-02, -2.5254e-01, -2.1964e-01, -2.3602e-01,\n",
       "                      -2.3674e-01, -1.6202e-01, -1.7671e-01, -3.1455e-01, -3.8487e-02,\n",
       "                      -3.5921e-02, -1.7230e-01, -1.3890e-01, -9.5231e-02, -2.9320e-01,\n",
       "                      -2.6986e-01, -2.5899e-01, -5.1956e-02, -1.7782e-01,  1.0189e-02,\n",
       "                      -1.8084e-01, -2.1637e-01, -2.2535e-02, -1.2818e-01, -3.7211e-01,\n",
       "                      -2.5945e-01, -1.6834e-01])),\n",
       "             ('bilstm_left_context_feature.bias_hh_l0',\n",
       "              tensor([-7.6127e-02, -2.5144e-01, -1.9304e-01, -1.5558e-01, -3.0884e-02,\n",
       "                      -1.4199e-01, -1.0447e-01, -8.8885e-02, -1.1453e-01, -1.8599e-01,\n",
       "                      -2.0825e-01, -2.8273e-01, -2.1377e-01, -2.0370e-01, -1.6118e-01,\n",
       "                      -1.6174e-01, -1.1981e-01, -2.4885e-01, -8.7248e-02, -1.2619e-01,\n",
       "                      -1.7030e-01, -1.2016e-01, -6.2550e-02, -1.4760e-01, -6.9556e-02,\n",
       "                      -2.0936e-01, -1.1026e-01, -8.5904e-02, -1.7747e-01, -2.1537e-01,\n",
       "                      -1.2968e-01, -2.5431e-01, -2.0209e-01, -2.0102e-01, -1.7948e-01,\n",
       "                      -1.9595e-01, -2.0772e-01, -1.9751e-01, -5.5416e-02, -2.0768e-01,\n",
       "                      -2.6217e-01, -1.5350e-01, -1.6087e-01, -3.3165e-01, -1.0986e-01,\n",
       "                      -1.6085e-01, -2.8405e-01, -1.9622e-01, -1.5087e-01, -1.9874e-01,\n",
       "                      -1.2744e-01, -1.4248e-02, -1.0829e-01, -1.3377e-01, -4.8073e-02,\n",
       "                      -1.5766e-01, -6.0718e-02, -1.2618e-01, -3.1123e-01, -2.1399e-01,\n",
       "                      -6.5864e-02, -1.5904e-01, -1.8436e-01, -2.5807e-01, -2.5504e-01,\n",
       "                      -2.2538e-01, -2.6380e-01, -2.1992e-01, -2.4330e-01, -2.0270e-01,\n",
       "                      -4.6743e-02, -1.5262e-01, -3.0804e-01, -3.1815e-01, -2.0896e-01,\n",
       "                      -2.8361e-01, -5.1443e-02, -2.6014e-01, -1.2584e-01, -2.5824e-01,\n",
       "                      -2.6099e-01, -6.2603e-02, -2.4540e-01, -1.2217e-01, -1.4910e-01,\n",
       "                      -3.0521e-02, -1.6497e-01, -3.6815e-01, -9.4717e-02, -2.4980e-01,\n",
       "                      -1.8298e-01, -2.5350e-01, -5.7551e-02, -1.9135e-01, -1.8851e-01,\n",
       "                      -1.0798e-01, -2.1962e-01, -1.2432e-01, -9.1977e-02, -2.8601e-01,\n",
       "                      -6.5505e-02, -2.3280e-01, -6.7343e-02, -2.8276e-01, -1.9684e-01,\n",
       "                      -1.7685e-01, -2.0533e-01, -3.7533e-01, -1.7383e-01, -2.4422e-01,\n",
       "                      -8.2831e-02, -8.9594e-02, -1.0242e-01, -1.2282e-01, -1.8740e-01,\n",
       "                      -2.5533e-01, -2.8282e-01, -1.7958e-01, -4.6117e-01, -1.8939e-02,\n",
       "                       6.8116e-02, -1.7746e-01, -2.1460e-01, -1.2122e-01, -1.2426e-01,\n",
       "                      -2.0091e-01, -3.2699e-01, -6.7428e-02, -7.0750e-02, -1.7983e-01,\n",
       "                      -1.6905e-01, -3.0092e-01, -6.9794e-02, -2.9770e-02, -1.1730e-01,\n",
       "                      -1.6368e-01, -1.0229e-01, -1.1051e-01, -1.0557e-01, -1.4764e-01,\n",
       "                      -7.3028e-02, -2.7882e-01, -5.3922e-02, -1.7846e-01, -1.8712e-01,\n",
       "                      -5.8102e-02, -3.5856e-02,  1.8868e-02, -1.1367e-01, -2.2215e-01,\n",
       "                      -9.5508e-02, -1.1859e-01, -1.8015e-01, -1.5932e-01, -1.5396e-01,\n",
       "                      -1.8322e-01, -1.4009e-01, -1.0135e-01, -1.6225e-01, -2.9099e-01,\n",
       "                      -2.7004e-01, -1.6076e-01, -2.4704e-01, -7.0548e-02, -1.7191e-01,\n",
       "                      -1.0993e-01, -1.3998e-01, -1.9673e-01, -1.2895e-01, -6.6543e-02,\n",
       "                      -1.4293e-01, -2.0470e-01, -7.9074e-02, -1.5838e-01, -1.6093e-01,\n",
       "                       2.1413e-02, -1.6284e-01, -1.5845e-01, -1.1277e-01, -1.6134e-01,\n",
       "                       1.6745e-02, -3.9586e-02, -2.0396e-02, -4.4699e-02, -8.6345e-02,\n",
       "                      -1.8244e-01, -8.0119e-02, -1.2770e-01, -6.0551e-02, -2.1751e-01,\n",
       "                      -1.8160e-01, -2.1126e-04, -2.6755e-01, -1.8020e-01, -1.3166e-01,\n",
       "                      -1.0813e-01, -1.2045e-01, -1.2424e-01, -1.3454e-01, -1.4329e-01,\n",
       "                      -1.5726e-01, -2.5143e-01, -9.8962e-02, -5.4347e-02, -1.3879e-01,\n",
       "                      -1.5142e-01, -7.9399e-02, -9.3036e-02, -2.7991e-01, -1.3392e-01,\n",
       "                      -1.9986e-01, -7.6030e-02, -1.3566e-01, -8.1203e-02, -2.1561e-01,\n",
       "                      -1.1375e-01, -7.4498e-02, -1.3747e-01, -7.0879e-02,  9.2639e-03,\n",
       "                      -2.5609e-01, -1.5089e-01, -1.3629e-01, -1.4661e-01, -1.9724e-01,\n",
       "                      -5.4895e-02, -6.3600e-02, -2.8256e-01, -8.9099e-02, -1.6602e-01,\n",
       "                      -7.3317e-02, -2.6576e-01, -2.2977e-01, -1.9740e-01, -2.7826e-01,\n",
       "                      -2.2298e-01, -5.4777e-02, -8.8361e-02, -9.1136e-02, -1.5123e-01,\n",
       "                      -3.6891e-02, -2.0252e-01, -2.6507e-01, -2.5046e-01, -2.1108e-01,\n",
       "                      -1.1069e-01, -1.2631e-01, -1.3765e-01, -7.4402e-02, -1.2121e-01,\n",
       "                      -9.3778e-02, -1.8307e-01, -1.7253e-01, -1.3443e-01, -2.0047e-01,\n",
       "                      -1.6455e-01, -2.0189e-02,  3.3861e-02, -4.7930e-02,  7.1638e-02,\n",
       "                       1.3715e-01, -2.1474e-02, -7.0963e-02,  1.0532e-01, -6.8437e-02,\n",
       "                       3.5853e-02,  1.0444e-02, -1.6319e-02,  9.6707e-02,  5.8585e-02,\n",
       "                      -4.0653e-02,  6.5311e-04,  2.0016e-02, -6.2404e-02,  9.1387e-02,\n",
       "                       6.7257e-02, -4.0170e-02,  1.4073e-01,  6.2104e-02,  1.7831e-02,\n",
       "                       5.1271e-02,  1.3552e-02, -7.0334e-02, -7.6359e-02, -2.4034e-02,\n",
       "                       2.8341e-02, -7.0527e-02,  1.5982e-02,  7.5697e-03,  9.2909e-03,\n",
       "                      -5.8280e-02, -7.3693e-02, -8.6797e-03, -1.1853e-03,  1.3251e-01,\n",
       "                       4.0694e-02,  5.1887e-02,  5.6743e-02, -5.5321e-03,  1.0151e-02,\n",
       "                       1.8426e-02, -1.4088e-03, -5.7889e-02,  8.6004e-02,  1.2567e-02,\n",
       "                       1.6743e-03, -1.8847e-02, -7.7486e-02,  5.6154e-02,  2.3618e-02,\n",
       "                       4.1587e-02,  1.4171e-02,  8.2366e-02, -6.6846e-03,  8.4060e-02,\n",
       "                       5.0793e-02,  9.1075e-03,  7.1782e-02, -8.3534e-02, -6.6595e-03,\n",
       "                       3.6834e-02,  7.9163e-02,  1.3873e-02,  7.2571e-02, -1.0513e-01,\n",
       "                      -1.0650e-02,  4.5214e-02,  5.2178e-02,  3.6034e-02,  2.9732e-03,\n",
       "                      -8.0976e-02,  3.1546e-02, -3.6780e-03, -4.6810e-02,  7.9465e-02,\n",
       "                       1.6455e-01, -1.1374e-01,  4.8290e-02,  7.0402e-02,  6.9296e-02,\n",
       "                      -2.2085e-02, -2.2779e-02, -2.1780e-02,  3.2367e-02, -1.6523e-02,\n",
       "                       5.4614e-02, -1.6148e-02, -8.7254e-02,  9.1576e-02, -1.2945e-02,\n",
       "                       2.7583e-02, -5.9539e-02, -1.6973e-02,  2.0554e-02, -8.9590e-03,\n",
       "                      -9.7891e-02,  4.1700e-02,  2.3570e-02,  1.8374e-05, -2.4559e-02,\n",
       "                       8.8326e-03,  4.2498e-02, -1.4067e-02,  1.8441e-02, -2.6902e-02,\n",
       "                      -1.1447e-02, -4.1321e-02,  4.3840e-02, -4.1223e-02,  1.4217e-02,\n",
       "                      -1.8041e-02,  3.6566e-03,  1.8320e-01, -4.5280e-02,  1.6185e-01,\n",
       "                       1.5596e-01, -6.2158e-02, -1.1846e-02, -9.7033e-02,  9.1502e-03,\n",
       "                       1.0279e-01,  2.8748e-02,  5.6124e-02, -2.9481e-03, -1.1734e-01,\n",
       "                      -2.3806e-01, -1.5516e-01, -2.0293e-01, -1.6768e-01, -2.3605e-01,\n",
       "                      -3.3304e-01, -6.9222e-02, -1.4796e-01, -1.3702e-01, -1.9560e-01,\n",
       "                      -9.2248e-02, -9.2564e-02, -1.2761e-01, -7.2254e-02, -2.2927e-01,\n",
       "                      -1.0704e-01, -9.3109e-02, -1.0142e-01, -2.3069e-01, -8.5610e-02,\n",
       "                      -1.8460e-01, -1.0486e-01, -1.0195e-01, -2.4444e-01, -2.2632e-01,\n",
       "                      -1.8723e-01, -1.0023e-01, -2.5702e-01, -1.2452e-01, -1.2589e-01,\n",
       "                      -2.7052e-01, -2.4473e-01, -1.9440e-01, -9.5741e-02, -1.7361e-01,\n",
       "                      -4.1713e-01, -1.5902e-01, -1.9010e-01, -2.8127e-01, -2.2979e-01,\n",
       "                      -1.4011e-01, -1.9819e-01, -1.8541e-01, -1.4097e-01, -2.3348e-01,\n",
       "                      -1.5823e-01, -1.4870e-01, -9.6398e-02, -7.4189e-02, -1.8650e-01,\n",
       "                      -9.9534e-02, -9.0029e-03, -1.5975e-01, -1.2471e-01, -1.8061e-01,\n",
       "                      -2.3828e-01, -2.3604e-01, -2.0284e-01, -1.9871e-01, -6.8004e-02,\n",
       "                      -9.9667e-02, -2.6426e-01, -1.8426e-01, -2.6793e-01, -3.9562e-02,\n",
       "                      -1.2670e-01, -2.0255e-01, -2.2323e-01, -1.8697e-01, -3.1051e-01,\n",
       "                      -2.1607e-01, -1.1062e-01, -1.0346e-01, -2.4237e-01, -1.5624e-01,\n",
       "                      -1.7644e-01, -1.8361e-01, -2.0547e-01, -1.8147e-01, -2.0379e-01,\n",
       "                      -1.7335e-01, -2.3901e-01, -8.8094e-02, -2.0537e-01, -3.1172e-02,\n",
       "                      -2.3645e-01, -5.9418e-02, -1.6022e-01, -1.7437e-01, -9.3813e-02,\n",
       "                      -1.9331e-01, -1.1329e-01, -3.3457e-01, -7.0360e-02, -1.3388e-01,\n",
       "                      -1.4711e-01, -5.4283e-02, -1.8381e-01, -1.1744e-01, -2.0561e-01,\n",
       "                      -1.2678e-01, -1.6325e-01, -2.1919e-01, -3.8004e-01, -2.4171e-01,\n",
       "                      -1.6529e-01, -2.1745e-01, -1.3490e-01, -1.8216e-01, -2.8683e-02,\n",
       "                      -1.2524e-01, -1.2509e-01, -2.0122e-01, -1.9752e-01, -1.9173e-01,\n",
       "                      -2.0964e-01, -2.5996e-01, -2.1488e-01, -1.9320e-02, -1.5700e-01,\n",
       "                      -2.5447e-01, -1.4077e-01, -7.8924e-02, -1.5891e-01, -1.7143e-01,\n",
       "                      -1.7612e-01, -1.3791e-01])),\n",
       "             ('bilstm_left_context_feature.weight_ih_l0_reverse',\n",
       "              tensor([[ 0.5062, -0.2753, -0.3693,  ..., -0.4358, -0.0032,  0.1940],\n",
       "                      [-0.0353,  0.4177,  0.3587,  ...,  0.2114,  0.0633,  0.4545],\n",
       "                      [ 0.0475, -0.5496, -0.1405,  ..., -0.0534,  0.0812,  0.3072],\n",
       "                      ...,\n",
       "                      [-0.1891,  0.1414,  0.0062,  ...,  0.1942, -0.1075,  0.0124],\n",
       "                      [ 0.3655,  0.0039, -0.1971,  ..., -0.4232,  0.2897, -0.2174],\n",
       "                      [ 0.1781, -0.1665, -0.1966,  ..., -0.1649,  0.0976, -0.4150]])),\n",
       "             ('bilstm_left_context_feature.weight_hh_l0_reverse',\n",
       "              tensor([[ 0.1443, -0.0580, -0.1840,  ..., -0.1486, -0.0926,  0.1394],\n",
       "                      [-0.1949, -0.1018,  0.3451,  ..., -0.4050, -0.1341,  0.3619],\n",
       "                      [-0.0493,  0.0489,  0.0706,  ..., -0.1150,  0.2340,  0.0331],\n",
       "                      ...,\n",
       "                      [ 0.1430,  0.1193,  0.1452,  ...,  0.1589, -0.0917,  0.1184],\n",
       "                      [-0.1345, -0.2125, -0.2141,  ..., -0.0881, -0.2146,  0.0070],\n",
       "                      [-0.1242,  0.1331,  0.1929,  ..., -0.1408,  0.1840,  0.2944]])),\n",
       "             ('bilstm_left_context_feature.bias_ih_l0_reverse',\n",
       "              tensor([ 3.1416e-02,  1.6901e-02, -2.8688e-03,  2.3401e-01, -8.2265e-03,\n",
       "                       1.9813e-01,  3.1621e-02,  2.0046e-01,  1.5224e-01,  2.7844e-03,\n",
       "                       1.3283e-01, -6.8144e-02, -1.2473e-01,  7.9660e-02, -7.0213e-02,\n",
       "                       1.4881e-01, -3.9553e-02, -2.2280e-02,  3.4746e-02,  7.6407e-02,\n",
       "                      -1.4707e-01,  9.1641e-02,  4.6080e-02, -1.0087e-01,  2.2491e-02,\n",
       "                       1.0345e-01,  1.6389e-01, -1.0035e-01, -9.0331e-02,  9.9059e-02,\n",
       "                       7.3113e-02, -5.2435e-02,  1.8091e-01,  1.6667e-02, -6.0248e-02,\n",
       "                       8.7128e-02, -1.0053e-02,  8.4929e-02, -2.2762e-02, -5.1210e-02,\n",
       "                      -1.0902e-02,  2.2129e-03,  1.2015e-01,  5.7795e-02,  9.7862e-03,\n",
       "                       1.2648e-01, -9.6715e-03,  1.0403e-01, -8.9050e-02, -7.8488e-02,\n",
       "                       1.5625e-01,  1.8119e-01, -1.8256e-01, -1.0603e-01, -1.2235e-01,\n",
       "                      -1.1422e-02, -3.7277e-02, -5.9549e-03,  2.1536e-01,  1.0227e-02,\n",
       "                      -7.1065e-02,  4.5210e-02,  8.4574e-02,  4.2102e-02,  1.3083e-01,\n",
       "                       1.2110e-01, -2.2778e-02,  2.1547e-01,  2.0039e-02, -5.9059e-02,\n",
       "                       1.3866e-02,  1.8098e-01,  4.7441e-02,  1.9894e-01,  3.5898e-02,\n",
       "                       2.0261e-01,  2.1280e-02,  2.0629e-01,  2.2698e-02,  8.4533e-02,\n",
       "                       3.9848e-02,  3.7616e-02,  3.1741e-02,  2.4314e-02, -5.1925e-02,\n",
       "                       4.6423e-02, -7.4368e-03,  1.5540e-01,  1.5866e-01,  7.0885e-02,\n",
       "                      -1.6309e-02, -1.3571e-02,  1.7184e-01,  7.0164e-02,  6.8006e-02,\n",
       "                      -2.0595e-02, -5.1525e-02,  1.9332e-02,  9.9109e-02, -4.5832e-02,\n",
       "                       2.3996e-01,  5.9998e-02, -4.7480e-02, -2.5875e-02, -1.3460e-01,\n",
       "                      -3.8045e-02, -1.1111e-02,  1.7404e-01, -4.7426e-02,  2.4319e-02,\n",
       "                       9.2324e-02,  1.0666e-01, -8.9998e-03, -3.7307e-02, -5.2422e-02,\n",
       "                       4.8747e-02, -3.1534e-02,  4.4631e-02,  2.6869e-01,  3.9394e-02,\n",
       "                       2.6739e-01, -1.1073e-01,  1.0126e-01, -2.0539e-02, -1.0045e-02,\n",
       "                       4.1960e-02,  1.0614e-01, -4.6972e-02, -5.7180e-02, -1.0051e-01,\n",
       "                      -2.0036e-02, -2.1054e-02, -6.0013e-02, -2.5077e-02, -1.2117e-01,\n",
       "                      -8.7084e-02, -1.5517e-01,  2.2345e-02, -2.2131e-01, -5.1116e-02,\n",
       "                      -1.3371e-01,  2.7708e-02,  3.5856e-02, -1.6202e-01, -8.3065e-02,\n",
       "                      -1.5251e-01,  7.2649e-02,  4.3089e-02, -7.4259e-02, -4.7758e-02,\n",
       "                      -1.2460e-01, -7.1365e-02, -1.0379e-02, -1.4393e-01,  3.3351e-04,\n",
       "                       2.1235e-02, -2.1417e-01, -1.7677e-01,  4.7115e-02,  2.1631e-01,\n",
       "                      -1.5886e-01, -6.4585e-02, -3.7231e-02, -7.1310e-02, -8.3576e-02,\n",
       "                      -3.8581e-02, -8.8164e-02,  5.8397e-02, -1.2100e-01,  6.3140e-02,\n",
       "                      -5.2939e-02, -7.0388e-02, -2.1647e-01, -1.0989e-01, -1.8202e-01,\n",
       "                      -2.6682e-02, -1.2792e-01,  6.6512e-02, -2.0872e-02, -5.9096e-02,\n",
       "                      -3.5961e-01, -2.8059e-02,  3.4858e-02, -1.0230e-01, -4.0535e-02,\n",
       "                       7.0830e-02, -1.3828e-01,  8.1033e-02, -7.4476e-02, -1.1093e-01,\n",
       "                      -2.4492e-02, -1.2893e-01,  9.8299e-03, -1.2864e-01, -4.9703e-02,\n",
       "                      -1.4467e-01, -1.2551e-02, -1.4952e-01, -1.5786e-02,  6.4811e-02,\n",
       "                      -3.8907e-02, -2.7062e-02, -1.5982e-01,  6.3061e-02, -7.8324e-02,\n",
       "                      -1.1708e-01,  6.1500e-02,  3.9778e-02, -3.9402e-02, -1.2391e-01,\n",
       "                       8.6640e-03, -1.6025e-02, -1.2605e-01, -1.1589e-01, -1.4503e-01,\n",
       "                       6.1934e-02, -4.4033e-02, -4.4026e-02, -1.1946e-01, -1.2813e-01,\n",
       "                      -2.2750e-01, -6.9744e-02,  4.0842e-02, -9.3593e-02, -1.9034e-02,\n",
       "                       1.1202e-02, -1.0663e-01, -1.1122e-03, -5.3396e-02, -1.0497e-02,\n",
       "                      -9.3472e-02, -1.5417e-01, -7.7117e-02,  8.2339e-03, -3.4614e-02,\n",
       "                      -1.2208e-01, -5.3383e-02,  1.1647e-01, -4.0457e-02, -1.6632e-01,\n",
       "                      -5.6997e-02, -1.9504e-01, -9.9299e-02, -7.6249e-02, -1.4589e-01,\n",
       "                       6.7842e-02, -2.5009e-01, -1.4805e-01, -4.4396e-02, -2.1945e-01,\n",
       "                      -1.6968e-02,  1.5070e-02, -6.3768e-02, -1.0686e-01,  1.8957e-02,\n",
       "                      -1.9901e-01,  4.8369e-03,  2.3654e-02, -8.9763e-04,  9.4381e-02,\n",
       "                      -1.6422e-01, -1.1226e-01, -1.0250e-01, -6.9482e-03,  6.5627e-02,\n",
       "                      -9.4340e-02,  2.3809e-02,  3.8605e-02,  1.2520e-01,  7.5488e-02,\n",
       "                       6.8274e-02, -8.3846e-02, -5.9884e-02,  4.7142e-03, -3.3582e-02,\n",
       "                       1.2906e-01, -4.0952e-02, -6.4573e-02, -7.4285e-04, -4.2756e-02,\n",
       "                      -2.5775e-02,  1.4198e-02, -1.0147e-02, -1.2943e-01,  1.9126e-02,\n",
       "                      -2.4303e-02,  8.6754e-02, -9.4214e-02,  1.3260e-01,  5.8905e-02,\n",
       "                       3.8064e-02, -2.4569e-02, -5.3461e-02, -5.3725e-02, -1.1643e-01,\n",
       "                       6.6693e-02,  1.0730e-01, -4.4637e-02,  1.9952e-02, -1.5113e-02,\n",
       "                      -6.3035e-02, -4.2036e-02, -3.1511e-02,  9.8966e-02,  5.5484e-02,\n",
       "                      -1.0736e-02,  3.4827e-02,  7.9409e-02, -6.0463e-02,  2.2574e-02,\n",
       "                       6.6629e-02,  8.4741e-02, -7.6162e-02,  9.2003e-02,  1.2728e-01,\n",
       "                      -1.9896e-01, -4.4428e-03, -1.6922e-02, -3.0631e-02,  1.2217e-01,\n",
       "                      -6.4072e-02, -7.3547e-02, -2.5462e-03,  1.4506e-01,  3.2712e-02,\n",
       "                      -7.5675e-02,  1.9642e-02, -6.5536e-02,  5.7543e-02,  2.0064e-02,\n",
       "                       4.5241e-03, -5.3219e-02, -8.8425e-02,  7.1187e-02, -7.3138e-02,\n",
       "                       4.2312e-02, -5.2485e-02, -1.9376e-02, -2.9912e-02, -3.8409e-02,\n",
       "                       2.1718e-02, -5.1797e-02,  1.1504e-01, -1.1141e-01,  2.7661e-02,\n",
       "                      -3.9999e-03, -4.2426e-02,  1.0984e-02,  4.4249e-02, -4.6754e-02,\n",
       "                      -3.0361e-02, -1.3589e-01,  9.9265e-03,  2.2295e-03,  1.1396e-01,\n",
       "                       3.7873e-02,  4.9359e-02, -8.5300e-02, -6.7314e-02, -8.2398e-02,\n",
       "                       1.5265e-02,  7.5506e-02, -7.8588e-03,  1.9226e-02, -4.3308e-02,\n",
       "                      -6.7691e-02,  4.2333e-02, -6.7398e-03,  2.5254e-02, -5.4991e-02,\n",
       "                       1.5979e-02,  9.5267e-02, -3.5031e-02, -9.3494e-02,  1.0097e-01,\n",
       "                      -1.5795e-01,  2.8954e-02,  1.2899e-03,  4.2173e-02, -7.5564e-02,\n",
       "                       3.0941e-02, -3.5068e-02, -1.4572e-02,  2.8302e-02, -6.1227e-03,\n",
       "                      -2.2675e-02, -6.1317e-02,  1.9597e-01, -1.4352e-01,  1.4469e-01,\n",
       "                       1.0757e-01, -7.7590e-03,  8.5201e-02,  8.2722e-02,  1.1426e-01,\n",
       "                       3.4486e-03,  3.3691e-02,  5.3686e-02,  1.5326e-01,  1.6486e-01,\n",
       "                       6.9573e-02,  3.7549e-02, -3.9230e-02,  1.3045e-01,  1.2285e-03,\n",
       "                      -5.7684e-02,  2.8972e-02, -5.1747e-02,  8.0755e-02,  1.9105e-02,\n",
       "                       2.3904e-01, -4.2398e-02, -1.2355e-01,  2.7363e-01, -1.0114e-01,\n",
       "                       1.0226e-01,  7.9965e-02, -2.7349e-02,  7.2478e-03, -4.1414e-03,\n",
       "                       1.1967e-01, -6.0918e-03, -4.1585e-02, -6.5640e-02,  7.3504e-02,\n",
       "                      -2.1695e-02,  1.1039e-01,  6.4756e-02,  1.2810e-01,  4.9954e-02,\n",
       "                       6.2405e-02,  1.4996e-01, -3.1106e-02,  1.7660e-01,  8.6943e-02,\n",
       "                       5.0981e-02, -2.6995e-01, -8.8178e-03, -3.2300e-02,  7.2449e-02,\n",
       "                      -1.6639e-01,  7.6989e-02,  2.2153e-01, -6.5942e-03,  1.0274e-01,\n",
       "                      -2.3211e-02,  1.7586e-02, -4.2932e-02,  1.6730e-01,  1.8158e-02,\n",
       "                       2.5859e-02,  1.9987e-01,  1.7965e-02, -7.2665e-02, -3.9524e-02,\n",
       "                       3.3697e-01, -4.1446e-02,  6.3262e-02,  1.1345e-01,  2.3888e-02,\n",
       "                      -1.7278e-02,  1.1002e-01,  5.0061e-02, -4.4051e-02, -1.8790e-02,\n",
       "                       3.9414e-02,  1.3528e-02,  4.9969e-02, -1.4331e-01,  7.8696e-02,\n",
       "                       2.0939e-02,  2.2030e-01, -2.6132e-02, -3.3353e-02,  1.5981e-01,\n",
       "                       4.1016e-02,  9.6826e-02,  1.4117e-02,  8.3727e-03, -9.2820e-02,\n",
       "                       7.5998e-03,  4.8420e-02,  1.9248e-01,  1.1526e-01,  2.2955e-01,\n",
       "                       2.1581e-02,  1.7886e-01,  3.6619e-02,  5.3346e-02, -6.0161e-03,\n",
       "                       6.3509e-03,  2.6267e-01,  1.8153e-02,  3.4843e-02,  8.4394e-02,\n",
       "                       1.6477e-01,  4.1527e-02,  1.5758e-02, -1.1326e-01,  4.4167e-02,\n",
       "                      -4.4267e-02,  7.4539e-02,  1.7132e-01,  7.6874e-02,  3.7983e-02,\n",
       "                       3.0758e-02,  1.5143e-01,  4.4718e-02, -2.9059e-02,  6.8085e-02,\n",
       "                       2.2627e-01,  1.3200e-01])),\n",
       "             ('bilstm_left_context_feature.bias_hh_l0_reverse',\n",
       "              tensor([-8.4716e-02,  1.3358e-02,  1.3603e-01,  8.2087e-02, -2.8455e-02,\n",
       "                       9.6604e-02,  6.3010e-02, -1.3123e-02,  8.5774e-02, -1.5121e-03,\n",
       "                       9.8868e-02, -9.7159e-03, -2.2204e-02, -8.4497e-02, -4.5179e-02,\n",
       "                       8.5356e-02, -2.8518e-03,  5.8348e-02,  3.6854e-02,  1.2508e-01,\n",
       "                       1.9275e-02,  1.6458e-01,  7.0970e-02, -1.0670e-01,  6.9225e-02,\n",
       "                       1.5668e-01,  1.6611e-01,  2.4669e-02, -1.2583e-01, -1.0844e-04,\n",
       "                      -1.6290e-01, -3.1527e-02,  9.7633e-02,  1.9371e-01,  1.1905e-02,\n",
       "                      -1.2572e-01, -1.3392e-01,  8.7600e-03,  1.1516e-02, -3.3695e-02,\n",
       "                       8.1134e-02,  3.2642e-02,  1.8863e-01,  8.1031e-02, -3.8671e-02,\n",
       "                       6.3917e-02,  1.1486e-01,  1.7684e-01, -5.9558e-02,  1.2180e-01,\n",
       "                       8.1297e-03, -5.7851e-02, -1.7652e-01,  8.8731e-03,  2.1086e-02,\n",
       "                       9.0362e-02, -5.7478e-02, -5.1483e-02,  1.6275e-01,  5.0619e-02,\n",
       "                      -2.0143e-02,  3.8647e-02, -1.0264e-02, -5.1300e-02,  1.6841e-01,\n",
       "                       1.4298e-01, -8.8154e-02,  1.6592e-01, -2.4274e-02, -7.5196e-03,\n",
       "                       6.5037e-02,  1.6974e-01,  1.5759e-01, -1.9259e-02,  3.4855e-02,\n",
       "                       5.1993e-02,  2.6856e-02,  8.9803e-02,  6.8772e-02,  1.2472e-01,\n",
       "                       5.5494e-02,  1.2802e-01,  4.1495e-02,  6.7226e-03, -1.6608e-01,\n",
       "                      -7.4529e-02,  1.3041e-02,  4.5158e-02, -1.1426e-03, -1.1440e-01,\n",
       "                       3.8398e-02,  1.1269e-01,  1.0019e-02,  1.3071e-01,  2.1445e-02,\n",
       "                      -9.5157e-02,  3.7175e-02,  2.6263e-03,  4.5033e-02, -1.1513e-01,\n",
       "                       2.4551e-01,  5.9512e-02,  1.2115e-02, -4.5348e-02, -1.1000e-02,\n",
       "                       5.6374e-02,  7.5429e-02,  2.1572e-01,  5.9441e-02,  4.7390e-03,\n",
       "                       1.3212e-01,  8.7865e-02, -1.2362e-01,  2.0025e-02,  9.7593e-02,\n",
       "                       1.3821e-02,  1.1496e-01,  2.3300e-02,  2.2588e-02,  5.2362e-02,\n",
       "                       3.7939e-02, -1.0853e-01,  6.3638e-02, -4.2746e-02, -1.3895e-01,\n",
       "                       9.8635e-02,  1.1230e-01, -2.1140e-03, -6.8316e-02, -1.3296e-01,\n",
       "                       1.8244e-03,  7.2697e-02, -4.9777e-02, -2.8171e-02, -8.5618e-02,\n",
       "                      -1.5775e-01, -8.4168e-02, -8.9985e-02, -1.1180e-01, -2.5786e-01,\n",
       "                       8.9951e-02,  1.5830e-02,  8.1049e-02, -2.2942e-01, -3.8153e-02,\n",
       "                      -9.7943e-02, -7.9787e-02,  1.1911e-01, -7.9173e-02, -7.6936e-02,\n",
       "                       6.1448e-02,  5.7101e-02, -8.0732e-02, -1.9497e-01, -5.6894e-02,\n",
       "                      -1.0914e-01, -4.3949e-02, -1.2833e-01, -8.1015e-03,  1.4118e-01,\n",
       "                      -8.4670e-02, -1.9321e-01, -8.9437e-02, -2.3902e-01, -1.1508e-02,\n",
       "                      -1.0221e-01,  1.2050e-02,  5.6906e-02, -5.4435e-02,  1.1087e-01,\n",
       "                      -1.1843e-01,  5.8732e-03, -1.0722e-01, -9.0458e-02, -5.1558e-02,\n",
       "                       9.0125e-02,  6.4933e-02, -1.3795e-01, -8.8676e-02, -7.4614e-04,\n",
       "                      -2.0542e-01,  8.3542e-02, -4.7459e-02, -7.0382e-02, -1.3223e-01,\n",
       "                      -6.5565e-02, -2.3672e-01,  9.7332e-02, -3.7239e-02,  2.0292e-02,\n",
       "                       6.4893e-02, -1.9514e-01, -2.5448e-02, -2.6646e-01, -2.4418e-02,\n",
       "                      -1.4496e-01, -8.3056e-02, -8.5538e-02,  2.0407e-02, -4.7095e-02,\n",
       "                       1.8664e-02, -9.2255e-02,  4.8128e-02, -1.7298e-02, -4.3064e-03,\n",
       "                      -1.0674e-01, -3.6375e-02, -4.4658e-02, -8.7389e-02, -1.1331e-01,\n",
       "                      -1.2767e-02, -1.4906e-02, -4.6082e-02, -3.5063e-02, -1.1414e-01,\n",
       "                      -3.0147e-02, -4.5145e-02, -8.5384e-03, -1.6585e-01, -7.3646e-02,\n",
       "                      -1.1898e-01, -2.1498e-01,  4.1980e-02, -5.7240e-02, -2.3670e-02,\n",
       "                      -1.8619e-01, -1.2337e-01, -3.0179e-02,  9.2542e-02, -9.0883e-03,\n",
       "                      -1.1194e-01, -1.5964e-01, -2.3989e-01, -5.6812e-02, -9.2586e-02,\n",
       "                      -4.0560e-02, -9.7941e-02, -5.3600e-02,  9.6928e-03, -2.1706e-01,\n",
       "                      -3.5517e-02, -2.1327e-02, -1.6386e-01, -2.7166e-02, -8.9455e-03,\n",
       "                       3.0565e-02, -1.0074e-01, -2.5685e-01, -1.9842e-02, -1.0220e-01,\n",
       "                      -1.1648e-01, -3.7780e-02, -6.1572e-02,  9.3966e-03, -8.3787e-02,\n",
       "                      -9.4899e-02,  2.6520e-02,  8.2197e-02, -3.9223e-03,  5.9069e-02,\n",
       "                      -1.5617e-01,  3.0739e-02,  4.8135e-02,  2.6355e-02,  4.4420e-02,\n",
       "                      -6.9548e-02,  6.4943e-02,  2.6108e-03, -1.1726e-03,  5.4621e-03,\n",
       "                       1.7346e-02, -8.7168e-02, -1.1015e-02,  1.3170e-02,  1.4042e-02,\n",
       "                       3.8354e-02, -7.6796e-02, -3.6080e-02, -1.8964e-02, -6.8444e-02,\n",
       "                       3.7443e-02, -7.7614e-02, -2.2214e-03, -1.3523e-01, -1.9192e-02,\n",
       "                      -7.6587e-02, -4.1926e-02,  4.4714e-02, -5.0948e-02,  5.1640e-02,\n",
       "                       3.8304e-02,  9.9130e-02, -1.6341e-02, -6.3727e-02,  5.6210e-03,\n",
       "                       4.9980e-02, -6.8991e-02, -7.9815e-02, -1.3001e-01, -2.4824e-02,\n",
       "                      -2.0675e-02, -3.8653e-03,  6.5276e-02,  8.5289e-02, -9.1297e-02,\n",
       "                       4.7423e-02, -1.3958e-02, -5.7047e-02, -5.8809e-02, -3.7550e-02,\n",
       "                      -9.3392e-02,  6.4350e-02,  1.0048e-01,  1.0038e-01,  7.4348e-02,\n",
       "                      -1.0341e-01, -1.3022e-02,  5.1676e-02,  4.9061e-02,  1.4303e-01,\n",
       "                       1.3119e-01, -8.1506e-02, -9.0088e-02,  2.9188e-02,  4.8692e-02,\n",
       "                      -8.5040e-02,  6.5028e-02,  3.5244e-03,  6.1228e-02,  6.1937e-02,\n",
       "                      -5.2843e-02, -6.5970e-03,  4.8211e-03,  8.9311e-02,  5.7943e-02,\n",
       "                       6.9144e-02, -2.5556e-02, -1.3046e-02, -3.4328e-02, -3.0515e-03,\n",
       "                       2.8850e-03,  9.1974e-02, -8.1589e-02, -3.2694e-02, -7.9927e-03,\n",
       "                      -3.3329e-02,  3.9905e-02,  8.8082e-03,  1.9980e-02,  3.0372e-02,\n",
       "                      -6.3653e-02,  1.4789e-01, -8.2425e-02, -2.4205e-02, -1.7532e-02,\n",
       "                       3.2551e-02, -7.5927e-02, -1.9266e-02,  5.0465e-05, -5.0623e-02,\n",
       "                       9.2128e-02,  9.9209e-04, -1.5729e-01,  7.9918e-02, -9.7252e-02,\n",
       "                       1.9298e-02,  8.3992e-02, -8.3045e-03, -9.4897e-02,  6.9180e-02,\n",
       "                       1.2844e-01, -1.0020e-01,  6.3197e-02,  3.5617e-02,  5.3270e-02,\n",
       "                      -8.0542e-02,  7.8029e-02, -9.7280e-02,  5.3633e-02, -6.1089e-02,\n",
       "                       3.8184e-02, -1.1279e-01,  7.9579e-02, -2.3523e-02,  6.8054e-02,\n",
       "                       6.7325e-02, -1.4523e-01,  2.3464e-01, -5.0614e-02,  2.2048e-01,\n",
       "                      -8.7529e-02, -4.6120e-02,  2.4718e-02, -1.3856e-02,  1.0353e-01,\n",
       "                       8.6177e-02, -2.3638e-02,  6.8393e-02,  7.4251e-02,  8.1718e-02,\n",
       "                      -9.8737e-02,  4.5478e-02,  9.1467e-02,  2.1064e-01,  9.5293e-03,\n",
       "                       7.0663e-03,  1.8150e-02, -8.1073e-02,  1.7555e-01,  1.1658e-01,\n",
       "                       1.3471e-01, -1.1391e-01, -5.3449e-02,  1.2094e-01,  6.2495e-02,\n",
       "                      -1.1019e-01, -6.2525e-02, -5.5433e-03, -2.1075e-02,  2.8540e-03,\n",
       "                       1.9273e-01, -1.0897e-01, -1.2084e-01,  8.3984e-02,  2.8588e-02,\n",
       "                      -3.4588e-02,  7.0923e-02,  6.3717e-02,  1.0706e-02,  7.5438e-03,\n",
       "                       1.6928e-01,  1.3458e-01,  7.1452e-02,  2.6158e-02,  1.7106e-02,\n",
       "                       1.9394e-02, -9.3888e-02, -7.6429e-02, -1.3870e-01,  1.1631e-01,\n",
       "                      -3.1308e-02,  3.3551e-02,  2.0325e-01,  3.0254e-02,  8.7873e-02,\n",
       "                       1.0430e-01,  8.7178e-02, -8.3175e-02,  1.4639e-01,  2.5206e-02,\n",
       "                       9.4112e-02,  1.7487e-01,  4.5776e-02, -1.1673e-01, -3.9603e-02,\n",
       "                       2.3101e-01, -1.0717e-01,  9.0462e-02,  1.0776e-01,  2.6463e-02,\n",
       "                       1.5881e-01,  1.1477e-01,  6.4525e-02,  1.2831e-02,  8.1258e-03,\n",
       "                      -1.1878e-01,  9.8335e-03,  9.2654e-02, -4.4697e-02, -7.2028e-03,\n",
       "                       6.1136e-02,  8.5894e-02,  7.6342e-02, -8.8181e-02,  3.6786e-02,\n",
       "                       7.2701e-02,  1.6419e-01, -7.2348e-02,  1.1674e-02, -5.3033e-02,\n",
       "                      -8.4434e-02,  1.7468e-02,  2.0250e-01,  4.8336e-02,  1.2701e-01,\n",
       "                      -4.4628e-02,  1.8041e-01,  7.5153e-02,  4.0812e-03, -4.9554e-02,\n",
       "                       1.3819e-01,  2.1386e-01,  4.4117e-03,  4.3637e-02,  4.1007e-02,\n",
       "                       2.6071e-01,  2.9698e-03,  4.1874e-03, -5.7253e-02,  1.0710e-01,\n",
       "                       9.7731e-02, -1.3260e-02,  1.2722e-01,  2.5156e-02,  5.5732e-02,\n",
       "                      -5.4067e-02,  8.8057e-02, -1.0170e-01,  8.7990e-03,  3.8913e-02,\n",
       "                       1.6024e-01,  2.9080e-02])),\n",
       "             ('bilstm_oov_context_feature.weight_ih_l0',\n",
       "              tensor([[ 0.2542, -0.2124,  0.4180,  ..., -0.2851, -0.4230,  0.0727],\n",
       "                      [ 0.1805,  0.1146,  0.6374,  ...,  0.3011, -0.0498, -0.3219],\n",
       "                      [-0.0052,  0.1858, -0.2965,  ...,  0.0720,  0.0439, -0.2727],\n",
       "                      ...,\n",
       "                      [ 0.0214,  0.6216, -0.2153,  ..., -0.0129,  0.3957,  0.0282],\n",
       "                      [-0.4245, -0.0898,  0.6041,  ..., -0.1286,  0.2025,  0.0454],\n",
       "                      [ 0.0527,  0.3251, -0.2336,  ..., -0.1349, -0.6871, -0.4769]])),\n",
       "             ('bilstm_oov_context_feature.weight_hh_l0',\n",
       "              tensor([[ 0.1739,  0.0844,  0.0832,  ...,  0.1713,  0.1665,  0.1038],\n",
       "                      [ 0.1502, -0.3035, -0.0605,  ...,  0.1200,  0.1073, -0.0316],\n",
       "                      [-0.0265,  0.0261,  0.3291,  ...,  0.0349, -0.0304,  0.0626],\n",
       "                      ...,\n",
       "                      [ 0.0622,  0.1920, -0.3413,  ...,  0.0253,  0.1928, -0.1980],\n",
       "                      [-0.1807, -0.1386, -0.2265,  ...,  0.2161, -0.2022, -0.2431],\n",
       "                      [ 0.3854,  0.1033, -0.0382,  ..., -0.0535, -0.1762, -0.1102]])),\n",
       "             ('bilstm_oov_context_feature.bias_ih_l0',\n",
       "              tensor([-2.4575e-02, -9.4133e-02, -9.6904e-02, -1.5069e-01, -1.6818e-01,\n",
       "                      -1.8967e-01, -1.5400e-01, -1.4312e-01, -1.5224e-01, -6.6977e-02,\n",
       "                      -1.6820e-01, -1.2041e-01, -1.5775e-01, -2.4406e-02, -1.0830e-01,\n",
       "                      -2.6657e-01, -1.6925e-01, -1.8758e-01, -2.9049e-01, -4.2196e-02,\n",
       "                      -1.5996e-02, -1.1634e-01, -2.2560e-01, -1.0805e-01, -9.2161e-02,\n",
       "                      -1.5057e-01,  3.1215e-02, -8.8459e-02, -1.5459e-01, -3.0790e-01,\n",
       "                      -1.6634e-01, -1.8753e-01,  1.0337e-01, -1.1808e-01, -9.1039e-02,\n",
       "                      -1.4809e-01, -1.6219e-01, -1.8025e-02, -1.6204e-02, -1.3550e-01,\n",
       "                      -2.0744e-02,  6.8070e-02, -2.3731e-01, -2.9770e-02, -1.7245e-01,\n",
       "                      -6.4124e-02, -2.4613e-01, -2.2034e-01, -8.6958e-02,  1.2815e-01,\n",
       "                      -1.1454e-02, -1.7416e-01, -1.3116e-01,  4.1956e-02, -1.1229e-01,\n",
       "                      -1.4832e-01, -1.4047e-01, -1.2457e-01, -1.5845e-01, -1.0269e-01,\n",
       "                      -7.4704e-02, -3.7134e-02, -2.0846e-01, -1.4818e-01, -1.3784e-01,\n",
       "                      -2.4820e-01, -1.5748e-01, -6.6621e-02, -8.3852e-02, -2.7684e-01,\n",
       "                      -8.9819e-02, -8.8917e-02, -1.4649e-01, -9.7502e-02, -8.3829e-02,\n",
       "                      -1.3340e-01, -8.0661e-02, -1.1577e-01,  3.4413e-02, -1.8036e-01,\n",
       "                      -3.1741e-02, -1.7502e-01, -1.7511e-01, -1.6552e-01, -5.3882e-02,\n",
       "                      -3.3097e-02, -7.0541e-02, -2.7343e-01, -1.2749e-01, -3.3340e-01,\n",
       "                      -1.0446e-01, -1.6055e-01, -1.5093e-01, -1.7281e-01, -3.9672e-02,\n",
       "                      -7.1164e-02, -1.5048e-01, -1.1446e-01, -2.5210e-01, -1.2225e-01,\n",
       "                      -8.4733e-02,  4.0037e-02, -1.6663e-01, -1.7345e-01, -1.0080e-02,\n",
       "                      -2.1128e-01, -3.1469e-01,  2.8214e-02, -7.1341e-02, -1.5625e-01,\n",
       "                       5.5170e-02, -1.2896e-01, -9.1854e-02, -2.7391e-01, -9.9708e-02,\n",
       "                      -5.1461e-02, -8.5461e-02, -8.1038e-02, -2.2046e-01, -1.4845e-01,\n",
       "                      -1.5422e-01, -2.0599e-01, -2.1819e-01, -1.7992e-01, -8.5862e-02,\n",
       "                       1.6615e-02, -2.4800e-01, -6.8921e-03,  1.8043e-02, -3.2661e-01,\n",
       "                      -1.4258e-01,  1.2028e-01,  3.0350e-02, -3.0959e-02, -7.9513e-02,\n",
       "                      -6.9786e-02,  1.9843e-02, -1.2286e-01, -1.7006e-01, -3.9921e-02,\n",
       "                       5.0890e-02,  1.9481e-03, -9.5213e-02, -2.7363e-01,  3.5756e-02,\n",
       "                      -1.2397e-03, -1.3653e-01, -3.2325e-02, -1.4775e-01, -2.2046e-01,\n",
       "                      -1.4125e-01, -1.1419e-01, -9.0744e-04, -8.3552e-02, -2.3744e-03,\n",
       "                      -1.3802e-01, -3.0074e-01, -1.4928e-01, -1.2890e-01, -1.5719e-01,\n",
       "                       1.8156e-01,  1.7267e-02, -1.9572e-01, -7.9980e-02, -9.3680e-02,\n",
       "                       1.8724e-03,  6.7074e-02, -3.6894e-02,  1.3732e-01, -5.5480e-02,\n",
       "                      -5.6690e-02, -1.2033e-01, -1.0675e-01,  3.3999e-02, -5.9811e-02,\n",
       "                      -4.9748e-02,  8.9075e-02,  4.9565e-03, -1.0849e-01,  4.7338e-02,\n",
       "                      -9.3780e-02,  1.9500e-02, -1.3498e-01, -1.5054e-02, -2.0812e-01,\n",
       "                       4.9582e-02, -6.1514e-02, -9.6070e-02, -6.2882e-02, -1.8106e-01,\n",
       "                      -2.0948e-01, -1.6420e-01, -1.0605e-01, -6.6054e-03, -2.3848e-02,\n",
       "                       4.7968e-02, -1.0270e-01, -1.4609e-02, -8.6344e-02,  1.2955e-01,\n",
       "                      -5.7659e-02,  7.4928e-04, -2.6058e-01, -2.2703e-01, -1.2686e-01,\n",
       "                       2.8178e-02, -6.4980e-03, -1.7550e-01,  2.1400e-01, -1.2162e-01,\n",
       "                      -2.8041e-01, -1.1634e-01, -1.5177e-01,  9.4957e-02, -1.4893e-01,\n",
       "                      -8.3464e-02, -9.1813e-02, -2.2298e-01,  8.3477e-02,  1.9720e-02,\n",
       "                       1.2140e-02, -6.3073e-02, -1.0216e-01, -2.5509e-02, -1.3994e-01,\n",
       "                      -1.3305e-01, -1.7503e-01, -8.5532e-02, -1.6637e-01, -8.9715e-02,\n",
       "                      -1.4004e-01, -6.3870e-03,  1.7107e-01, -6.6785e-02, -1.6525e-01,\n",
       "                       5.6776e-02, -1.6490e-01, -9.0263e-02,  1.0599e-01, -3.4928e-02,\n",
       "                      -2.1157e-01, -9.5933e-02, -1.3324e-01,  5.2169e-02, -1.8588e-02,\n",
       "                       1.1902e-01, -8.9918e-02, -5.6081e-02,  6.9674e-02, -2.2724e-01,\n",
       "                      -1.0866e-01, -2.3601e-01, -1.3622e-01,  1.5584e-01, -1.0651e-01,\n",
       "                       2.3023e-02,  8.3343e-02,  5.0882e-02,  3.5237e-02,  4.0781e-02,\n",
       "                       4.6276e-02,  6.3104e-02, -6.7309e-02,  7.8537e-02,  1.2053e-01,\n",
       "                      -3.0046e-02, -6.9814e-02,  7.4716e-02,  5.8836e-02,  9.9803e-02,\n",
       "                       1.5081e-02, -6.0487e-02,  6.1370e-02,  7.1613e-02,  5.8357e-02,\n",
       "                      -6.4374e-02, -1.2246e-01, -6.1248e-02,  1.1973e-01,  1.1384e-01,\n",
       "                       3.2989e-02, -7.8341e-02,  7.5755e-03, -6.5563e-02,  3.4042e-02,\n",
       "                      -1.1651e-01,  1.4160e-02,  1.0074e-01,  4.0672e-02, -4.7835e-02,\n",
       "                      -5.0221e-02, -8.5752e-04,  2.0042e-02, -3.2384e-02, -1.2489e-02,\n",
       "                      -3.6240e-02, -6.1050e-02,  1.3686e-01, -9.8033e-02, -5.4542e-02,\n",
       "                       1.0403e-01, -6.8523e-02, -1.2217e-01,  7.6366e-02,  6.6101e-02,\n",
       "                      -1.0079e-01, -8.4790e-04,  9.4341e-02, -3.5919e-03,  2.5209e-03,\n",
       "                       5.3064e-02, -1.6970e-02,  2.5993e-02, -8.1496e-02,  5.6908e-02,\n",
       "                      -6.7028e-02,  6.1714e-02,  7.4360e-02,  2.8968e-02, -2.2300e-02,\n",
       "                       1.0571e-01,  5.1738e-02,  8.8398e-02, -3.7778e-02,  7.0777e-02,\n",
       "                      -3.2461e-02, -6.6163e-02, -2.7271e-02,  1.4541e-02,  2.9505e-02,\n",
       "                      -2.4359e-02,  8.8079e-02,  1.2667e-02, -6.7168e-02,  8.6331e-02,\n",
       "                       3.0119e-02,  3.9589e-02, -3.1327e-04, -1.0215e-01, -7.5442e-02,\n",
       "                      -4.7351e-03, -1.0515e-02,  6.4946e-02,  6.3760e-02,  1.0241e-01,\n",
       "                       7.2423e-02, -5.1619e-02,  1.0215e-01, -4.9171e-03, -1.1725e-02,\n",
       "                       9.3391e-02,  1.1998e-01,  2.9296e-03,  4.3745e-02, -5.5493e-03,\n",
       "                       7.2369e-02,  8.4103e-03, -3.3571e-02,  7.1218e-02, -6.3628e-03,\n",
       "                       1.2707e-02,  7.2271e-02, -9.9190e-05,  6.4916e-02,  5.6628e-02,\n",
       "                      -1.6736e-03,  1.3922e-01,  2.3389e-02,  1.5719e-03, -7.0447e-04,\n",
       "                      -1.0007e-01, -4.1488e-02, -6.6570e-02, -4.4978e-02,  6.6413e-02,\n",
       "                      -4.3355e-02, -3.8768e-02, -1.6823e-01,  8.2305e-02,  8.0372e-02,\n",
       "                      -2.2019e-02,  1.3748e-03, -1.4952e-02, -1.3561e-01, -1.3806e-02,\n",
       "                      -8.5796e-02, -3.7837e-02, -1.2261e-02, -1.2069e-01, -1.4836e-01,\n",
       "                      -1.1470e-01, -2.7735e-01, -9.9602e-02, -1.8157e-01, -1.4153e-01,\n",
       "                      -1.2710e-01, -1.7052e-01, -5.9548e-02, -6.2393e-02, -2.8086e-01,\n",
       "                      -1.0774e-01, -7.6594e-02, -2.4249e-01, -1.5657e-01,  4.2287e-02,\n",
       "                      -1.4633e-01, -2.4689e-01, -5.7827e-02,  1.8787e-02, -2.6281e-01,\n",
       "                      -3.8597e-02, -3.3997e-02, -2.1358e-01, -2.7108e-01, -9.0311e-02,\n",
       "                      -2.6114e-01, -3.2041e-02, -6.9624e-02, -3.7866e-02, -8.3459e-02,\n",
       "                      -3.6690e-02, -9.3579e-02, -3.2640e-02, -3.0934e-01, -2.7318e-02,\n",
       "                      -6.3413e-02, -1.8900e-01,  6.6363e-03, -2.2204e-01, -1.6197e-01,\n",
       "                      -2.2611e-01, -1.3180e-01, -7.0140e-02, -1.1015e-01, -1.0493e-01,\n",
       "                      -1.6836e-02, -8.1177e-02,  4.6198e-03, -1.2020e-01, -1.3863e-01,\n",
       "                      -1.7791e-01, -1.0511e-02, -1.0968e-01, -9.1049e-02,  9.6183e-03,\n",
       "                      -1.9351e-01, -2.8263e-01, -7.0586e-02, -9.8779e-02, -1.9494e-01,\n",
       "                      -8.2979e-02, -9.5174e-02, -9.8526e-02, -1.2057e-01,  8.5390e-03,\n",
       "                       1.4798e-01, -1.7125e-01, -1.5929e-01,  2.2266e-02, -1.2281e-01,\n",
       "                      -1.6510e-01, -2.0284e-01, -8.2869e-02, -1.4129e-01, -2.1304e-02,\n",
       "                      -1.2340e-01, -1.7428e-01, -6.5479e-03, -1.2129e-01, -1.3582e-02,\n",
       "                      -3.3992e-02, -2.7762e-01, -5.3247e-02, -3.0275e-01, -7.7618e-02,\n",
       "                      -1.3709e-01, -6.4680e-02, -1.1622e-01,  9.4961e-04, -1.4910e-02,\n",
       "                      -2.7785e-01, -1.3583e-01, -1.0589e-01,  1.2577e-03, -1.9191e-01,\n",
       "                      -1.3407e-01, -1.2945e-01, -1.4130e-01, -1.3527e-01, -5.7253e-02,\n",
       "                      -1.6739e-01,  8.9998e-03, -3.1015e-01, -2.3569e-01,  5.9223e-02,\n",
       "                      -1.6731e-01, -1.2479e-01, -1.5183e-01, -1.8694e-01, -1.6423e-01,\n",
       "                      -2.3474e-01,  1.3712e-01, -2.0172e-01,  2.4834e-02, -1.3231e-01,\n",
       "                      -2.5044e-01, -2.0003e-01, -7.3204e-03, -1.5672e-01, -1.4033e-01,\n",
       "                      -1.9929e-01,  3.7766e-02])),\n",
       "             ('bilstm_oov_context_feature.bias_hh_l0',\n",
       "              tensor([-9.8537e-02, -1.7713e-01, -5.8250e-02,  2.3926e-02, -1.2887e-01,\n",
       "                      -1.6595e-01, -1.4170e-01, -8.3012e-02, -8.4310e-02, -1.2124e-01,\n",
       "                      -2.2699e-01, -2.9022e-01, -1.5605e-01, -4.5743e-02, -1.0649e-01,\n",
       "                      -1.8235e-01, -2.0488e-01, -8.3599e-02, -1.8638e-01, -1.7614e-02,\n",
       "                      -4.9272e-02, -1.8161e-01, -1.5575e-01, -1.7556e-01,  2.8560e-02,\n",
       "                      -1.3845e-01, -3.6514e-02, -9.5284e-02, -2.4960e-01, -1.9398e-01,\n",
       "                      -1.7746e-01, -2.2045e-01,  1.8405e-02, -1.5274e-01, -5.2546e-02,\n",
       "                      -1.7898e-01, -8.3824e-02, -2.7245e-02,  3.1142e-02, -1.3704e-01,\n",
       "                       1.6813e-02,  1.7577e-02, -1.6545e-01,  1.4745e-02, -4.6245e-02,\n",
       "                      -1.4170e-01, -2.6622e-01, -1.0005e-01, -1.3544e-01, -2.5184e-02,\n",
       "                      -3.5196e-02,  3.7630e-02, -6.1850e-02, -2.8513e-02, -1.3367e-01,\n",
       "                      -1.1160e-01, -1.8025e-02, -1.6860e-01, -1.6794e-01, -2.1389e-01,\n",
       "                       8.1561e-03, -4.1372e-02, -1.7347e-01, -2.1224e-01, -1.4989e-01,\n",
       "                      -5.5470e-02, -1.9138e-01,  1.9471e-03, -3.7771e-02, -2.4593e-01,\n",
       "                      -1.3162e-01, -1.8101e-01, -4.8120e-03, -2.4522e-01, -1.7467e-01,\n",
       "                      -1.9363e-01, -9.2282e-02, -2.3543e-01, -7.8601e-02, -1.7001e-01,\n",
       "                      -3.4812e-02, -1.7072e-01, -3.1034e-01, -9.6878e-03, -1.5978e-01,\n",
       "                       6.9249e-02,  4.4203e-02, -2.9040e-01, -9.1479e-02, -3.2676e-01,\n",
       "                      -6.7114e-02, -1.9010e-02, -1.8414e-01, -7.6471e-02,  3.6247e-02,\n",
       "                      -8.1996e-02, -8.2372e-02, -1.4140e-02, -3.9668e-02, -1.8213e-01,\n",
       "                      -2.7397e-02, -2.2678e-02, -1.4287e-01, -1.5024e-01, -4.0627e-02,\n",
       "                      -3.0109e-01, -3.1309e-01, -1.1524e-01, -2.3687e-01, -5.5178e-02,\n",
       "                       3.2763e-02, -6.6139e-02, -1.7660e-02, -1.5564e-01, -6.6898e-02,\n",
       "                      -1.3997e-01, -1.2474e-01,  4.5651e-02, -7.1738e-02, -1.2327e-01,\n",
       "                      -2.0647e-01, -1.8126e-01, -2.0147e-01, -1.9582e-01, -6.5406e-02,\n",
       "                      -1.0470e-01, -1.6646e-01,  5.0980e-03, -8.6810e-02, -1.7634e-01,\n",
       "                      -9.9823e-02, -6.2283e-02, -9.4379e-02, -1.4036e-01, -1.8518e-02,\n",
       "                      -1.6558e-01, -1.0429e-01, -8.0250e-02, -1.8039e-01, -1.5374e-01,\n",
       "                      -5.5140e-02, -4.8471e-02, -1.9908e-01, -2.8529e-01, -1.1211e-02,\n",
       "                       5.8781e-02, -1.3494e-01, -1.1960e-01, -6.2457e-02, -2.4523e-02,\n",
       "                      -1.1412e-01, -8.9084e-02,  1.7317e-02, -2.2728e-01, -1.0840e-01,\n",
       "                      -1.6471e-02, -2.0481e-01, -1.1519e-01, -3.0654e-02, -2.7573e-01,\n",
       "                       2.0878e-01,  1.2503e-01,  1.7431e-03, -1.7826e-02,  7.4757e-02,\n",
       "                       2.2046e-02, -1.8561e-02, -1.0931e-01,  1.6639e-01,  2.5408e-02,\n",
       "                      -1.0092e-01, -7.1843e-02, -1.6347e-01, -1.3716e-03, -2.5693e-01,\n",
       "                       3.7521e-02,  1.1017e-01, -1.9078e-02, -1.5226e-02,  1.5644e-01,\n",
       "                       4.6707e-02, -9.2025e-02, -1.2471e-01, -9.3699e-02, -1.7674e-02,\n",
       "                       1.0313e-01, -8.9187e-02, -3.5004e-02, -6.6263e-03, -9.1258e-02,\n",
       "                      -1.7029e-01, -1.6745e-01, -1.0313e-01, -1.0210e-01, -9.4515e-02,\n",
       "                      -6.5189e-02, -1.5136e-01, -9.1819e-02,  1.2812e-01,  1.2705e-01,\n",
       "                      -8.2497e-02, -3.1378e-02, -2.2215e-01, -7.1970e-02, -3.7030e-02,\n",
       "                       2.9776e-02, -2.2376e-02, -8.7570e-02,  1.8693e-01, -1.5897e-01,\n",
       "                      -1.9349e-01, -9.9590e-02, -6.5413e-02,  4.9414e-02, -1.5357e-01,\n",
       "                      -8.4484e-02, -1.5159e-01, -2.7110e-01,  2.1772e-02, -8.1393e-02,\n",
       "                      -2.4894e-01, -1.4463e-01,  1.4535e-01, -1.6873e-01, -1.3986e-01,\n",
       "                      -6.9799e-02, -3.3777e-02, -8.7492e-02, -8.1867e-02,  7.2141e-02,\n",
       "                      -2.0609e-01, -9.7070e-02,  8.4316e-02, -1.2682e-01, -2.2866e-01,\n",
       "                      -2.2989e-03, -1.8516e-01, -6.6804e-02,  3.9701e-02, -1.2191e-01,\n",
       "                      -1.5873e-01, -7.4953e-02, -7.9388e-02, -7.9841e-02,  3.9876e-02,\n",
       "                       1.6723e-01,  1.3479e-02,  4.4147e-02, -1.8190e-01, -2.0548e-01,\n",
       "                      -2.6665e-01, -9.3416e-02,  1.5570e-02,  5.6814e-02, -1.1717e-01,\n",
       "                      -1.4362e-01, -2.2798e-01, -4.3938e-02, -1.0765e-01,  2.2088e-02,\n",
       "                      -4.3600e-03,  1.0516e-01,  2.2154e-02, -6.2714e-02, -1.1636e-01,\n",
       "                       1.2951e-01, -5.1943e-02,  1.2964e-02, -1.0642e-01, -3.0491e-02,\n",
       "                       1.1350e-01, -2.7386e-02,  1.9708e-02,  2.0711e-02,  3.1033e-02,\n",
       "                       5.2683e-02, -9.3338e-05, -1.4935e-02,  1.7029e-02,  4.1614e-02,\n",
       "                       1.0527e-02, -1.8399e-02, -3.1743e-02, -1.5359e-01, -1.1934e-01,\n",
       "                      -7.0486e-02, -9.5116e-02,  1.2401e-01, -3.3155e-02, -3.9279e-02,\n",
       "                       9.6967e-03, -6.8877e-02, -1.2062e-01, -1.0027e-01,  3.7527e-02,\n",
       "                      -1.5875e-02, -3.6544e-02,  6.3219e-02, -1.5201e-01,  6.7485e-02,\n",
       "                       1.8695e-02, -1.3558e-02,  1.3983e-02, -3.0516e-03, -1.3037e-01,\n",
       "                      -1.5553e-01, -1.1007e-01, -8.7158e-02, -3.2403e-02,  8.4273e-02,\n",
       "                      -1.6524e-01,  5.6967e-02,  6.7990e-02, -1.2914e-01,  3.8155e-02,\n",
       "                       5.4363e-02,  8.3418e-02,  5.7699e-02,  7.9396e-02, -1.7476e-02,\n",
       "                      -2.8417e-02, -1.2749e-01, -7.6958e-02, -1.9121e-01,  1.6833e-02,\n",
       "                       1.1983e-02,  1.1764e-01,  3.3353e-02,  2.7043e-02,  6.0995e-02,\n",
       "                       5.9885e-02,  1.1517e-01, -6.2382e-04, -1.6770e-02,  6.3095e-02,\n",
       "                      -6.7776e-02,  5.7628e-02,  5.1232e-02, -5.9354e-02,  4.0699e-03,\n",
       "                       4.5722e-02,  4.7555e-02,  2.5352e-02, -3.2501e-03,  2.1152e-01,\n",
       "                      -4.4401e-02, -1.5825e-02,  1.6265e-02,  8.7768e-02, -1.3966e-02,\n",
       "                       2.5701e-02,  2.1549e-02,  1.7037e-02,  5.1881e-02, -1.2093e-01,\n",
       "                       9.2541e-03, -2.8580e-02,  6.0557e-02, -2.6033e-02,  2.7991e-02,\n",
       "                      -3.2287e-02,  7.8522e-02,  7.7384e-02,  7.2757e-03, -1.6579e-02,\n",
       "                       4.8696e-02,  7.9761e-02,  6.1083e-02,  4.1888e-02, -7.3953e-02,\n",
       "                      -7.4102e-02,  2.8387e-02, -6.8528e-02,  3.9186e-02, -2.2185e-02,\n",
       "                       8.8177e-03, -7.6945e-02,  2.7624e-02,  1.1517e-01,  9.2313e-02,\n",
       "                      -7.3088e-02,  3.0930e-02,  1.8457e-02, -9.7374e-02, -1.3390e-01,\n",
       "                      -1.7455e-01, -1.6532e-01,  4.9042e-03, -6.2276e-02, -1.2495e-01,\n",
       "                      -1.1446e-01, -1.6874e-01, -1.9155e-01, -1.1147e-01, -2.1198e-01,\n",
       "                      -1.3202e-01, -1.4688e-01, -1.1562e-01,  1.3022e-02, -2.7605e-01,\n",
       "                      -6.8605e-02,  4.9036e-02, -2.2725e-01, -7.9164e-02,  1.8851e-03,\n",
       "                      -1.0254e-01, -3.0158e-01, -1.6153e-01, -4.2029e-02, -1.0610e-01,\n",
       "                       5.5264e-03, -8.7885e-02, -1.8582e-01, -1.0656e-01, -1.7373e-02,\n",
       "                      -2.8737e-01,  7.9533e-02, -9.1051e-03, -7.8153e-02, -1.2550e-01,\n",
       "                      -1.1209e-02, -6.0484e-02, -5.7690e-02, -1.0303e-01,  3.1380e-04,\n",
       "                      -1.6907e-01, -9.4924e-02, -1.0300e-01, -1.7593e-01, -9.8475e-02,\n",
       "                      -2.5774e-01, -1.0240e-01, -5.0763e-02, -4.6429e-02, -9.3619e-02,\n",
       "                       1.2454e-01, -4.3851e-02, -1.0468e-02, -2.5443e-02, -2.2911e-01,\n",
       "                      -2.0032e-01, -1.3628e-01, -2.3803e-01, -1.9972e-01, -2.0859e-01,\n",
       "                      -1.5410e-01, -1.6225e-01, -2.1051e-01, -1.2957e-01, -7.7857e-02,\n",
       "                      -4.0729e-02, -3.2953e-02, -1.9411e-01, -5.9296e-02,  5.1033e-02,\n",
       "                       1.9838e-01, -8.2967e-02, -2.1562e-01, -3.9936e-02, -2.3876e-01,\n",
       "                      -1.2783e-01, -6.1075e-02, -1.8262e-02,  5.2860e-02,  1.0724e-01,\n",
       "                      -2.4500e-01, -1.5837e-02, -2.9069e-01, -5.8865e-02, -7.0313e-02,\n",
       "                      -1.2038e-01, -1.6038e-01, -1.2453e-01, -2.7358e-01, -1.4427e-01,\n",
       "                      -5.9280e-02, -1.1144e-01, -1.3986e-01, -6.1002e-02,  8.2009e-02,\n",
       "                      -2.1867e-01, -2.3108e-01, -2.4334e-01, -1.1876e-01, -1.2194e-01,\n",
       "                       1.4821e-02, -2.0976e-01, -1.0771e-01, -1.1280e-01, -4.3814e-02,\n",
       "                      -2.5004e-01, -8.1008e-02, -2.3555e-01, -5.7620e-04,  1.1242e-01,\n",
       "                      -1.3355e-01, -1.4552e-01, -6.8234e-02, -1.6454e-01, -8.9803e-02,\n",
       "                      -1.6351e-01,  2.4705e-01, -7.7725e-02, -1.5509e-02, -1.7567e-01,\n",
       "                      -1.8404e-01, -1.9430e-01, -9.1863e-02, -2.0794e-02, -1.1231e-01,\n",
       "                      -1.8740e-01, -1.2908e-02])),\n",
       "             ('bilstm_oov_context_feature.weight_ih_l0_reverse',\n",
       "              tensor([[-0.7808, -0.0502, -0.4258,  ...,  0.7673,  0.3290, -0.0515],\n",
       "                      [ 0.0481, -0.4813,  0.2141,  ..., -0.0710,  0.3998, -0.3801],\n",
       "                      [-0.4575, -0.1532, -0.4825,  ..., -0.0431,  0.2082,  0.3722],\n",
       "                      ...,\n",
       "                      [-0.2935,  0.3016,  0.0750,  ...,  0.2670,  0.1483,  0.2585],\n",
       "                      [-0.1171,  0.0357, -0.1393,  ...,  0.0871, -0.0528, -0.0643],\n",
       "                      [-0.1706, -0.4218, -0.1808,  ..., -0.0730, -0.3300, -0.7234]])),\n",
       "             ('bilstm_oov_context_feature.weight_hh_l0_reverse',\n",
       "              tensor([[ 0.3297, -0.2518, -0.2455,  ...,  0.1898,  0.2123, -0.0208],\n",
       "                      [-0.1426, -0.0334,  0.0851,  ..., -0.0562,  0.1751, -0.1000],\n",
       "                      [-0.0914,  0.4007, -0.1677,  ...,  0.0831,  0.0026, -0.1179],\n",
       "                      ...,\n",
       "                      [-0.0116,  0.1214, -0.4782,  ..., -0.2489,  0.0593,  0.1524],\n",
       "                      [ 0.1935,  0.0979,  0.2902,  ..., -0.4351,  0.0256, -0.2354],\n",
       "                      [-0.0237, -0.1163, -0.1102,  ...,  0.1856, -0.1374, -0.0224]])),\n",
       "             ('bilstm_oov_context_feature.bias_ih_l0_reverse',\n",
       "              tensor([ 0.1416,  0.1419,  0.1285,  0.1161,  0.2696,  0.3392,  0.2399,  0.0662,\n",
       "                       0.2124,  0.0634,  0.1657,  0.0661,  0.1085,  0.0381,  0.2097,  0.1355,\n",
       "                       0.0871,  0.0640,  0.3304,  0.0007,  0.1261,  0.2699,  0.0272, -0.0142,\n",
       "                       0.1843,  0.2427,  0.2080,  0.2141,  0.1746,  0.0307,  0.0436,  0.0083,\n",
       "                       0.1737,  0.1285,  0.0466,  0.2130,  0.0811,  0.2601,  0.2210,  0.1811,\n",
       "                       0.3114,  0.0908,  0.1650,  0.0693,  0.1904,  0.1980,  0.0461,  0.1237,\n",
       "                      -0.1219,  0.1045,  0.1963,  0.1477,  0.1646,  0.1788, -0.0102,  0.0880,\n",
       "                       0.2271,  0.0605,  0.3139,  0.1474,  0.2038,  0.2601,  0.2543,  0.1703,\n",
       "                       0.2114,  0.1731, -0.0287,  0.1511,  0.0709,  0.2212,  0.1590,  0.1727,\n",
       "                       0.3535,  0.3075,  0.0945,  0.2020,  0.0924, -0.0870,  0.1616, -0.0596,\n",
       "                       0.2045,  0.1788,  0.0404,  0.1164, -0.0111,  0.2164,  0.1785,  0.2368,\n",
       "                       0.0723,  0.0594,  0.2299,  0.2735,  0.2295,  0.1455,  0.2197, -0.0163,\n",
       "                       0.1697,  0.1387,  0.3495,  0.2375,  0.1033,  0.2145,  0.0486,  0.1699,\n",
       "                       0.1309,  0.0976,  0.2196,  0.1030,  0.1359,  0.0112,  0.1607,  0.3191,\n",
       "                       0.1208,  0.2665,  0.3931,  0.2782,  0.1441,  0.0656, -0.0421,  0.0463,\n",
       "                       0.2138,  0.1585,  0.1712,  0.0807,  0.0277,  0.1625, -0.0680,  0.1582,\n",
       "                       0.0846,  0.0829,  0.0458, -0.0780,  0.0361, -0.1298,  0.0927, -0.0665,\n",
       "                      -0.0876, -0.0522,  0.0404, -0.0104,  0.0380,  0.0365, -0.0353, -0.0664,\n",
       "                       0.0496,  0.0984,  0.1035,  0.0353,  0.0992, -0.0715,  0.0688,  0.0602,\n",
       "                      -0.1221,  0.0779,  0.0775,  0.1178,  0.1283,  0.1236,  0.0688,  0.0706,\n",
       "                       0.1005,  0.0726,  0.0140, -0.1398,  0.0663,  0.0974,  0.0682,  0.0765,\n",
       "                       0.0383, -0.0319, -0.1324, -0.0321,  0.0442,  0.0991,  0.1278, -0.1113,\n",
       "                      -0.0065,  0.1846,  0.2090,  0.0020,  0.1667,  0.1533,  0.1040, -0.0686,\n",
       "                       0.1213,  0.0757, -0.0893, -0.1111,  0.1920,  0.0708,  0.2449, -0.0497,\n",
       "                       0.0930,  0.0385, -0.0563,  0.1987,  0.0570,  0.0254, -0.0019, -0.0347,\n",
       "                       0.0295,  0.0863, -0.0179,  0.0415,  0.0300,  0.1456,  0.1985,  0.1664,\n",
       "                       0.0842,  0.1283,  0.2608, -0.0611,  0.1576,  0.0726,  0.0388, -0.0441,\n",
       "                       0.0720, -0.0605,  0.1922,  0.0498, -0.0043, -0.0359,  0.0191,  0.0151,\n",
       "                      -0.0470,  0.1360, -0.0178,  0.0443,  0.0432, -0.0061,  0.0569, -0.0318,\n",
       "                      -0.0023,  0.1620,  0.0094,  0.0400,  0.0185,  0.1477,  0.0802, -0.0973,\n",
       "                       0.1663, -0.0095, -0.0539,  0.1089, -0.0851, -0.0815, -0.0053,  0.0267,\n",
       "                      -0.0698,  0.1161,  0.1313,  0.0888, -0.0673,  0.1051,  0.0759,  0.0318,\n",
       "                      -0.0084, -0.1160, -0.0094,  0.0244,  0.0723, -0.1020, -0.0088,  0.0986,\n",
       "                      -0.0091, -0.0398, -0.0302, -0.0964, -0.1158, -0.1332,  0.0887, -0.1115,\n",
       "                       0.0542, -0.0368,  0.0233, -0.0054,  0.0115, -0.0170, -0.0496,  0.0237,\n",
       "                       0.1539,  0.0907,  0.0890,  0.0131,  0.0055, -0.0319,  0.1125,  0.0022,\n",
       "                      -0.0019,  0.0612, -0.0263, -0.0032,  0.0119, -0.0380,  0.0952, -0.0149,\n",
       "                       0.0088,  0.0455,  0.0419, -0.0543, -0.0072, -0.1868, -0.0142,  0.1599,\n",
       "                      -0.0524, -0.0028,  0.0241, -0.0532, -0.1371, -0.0081, -0.0351, -0.1082,\n",
       "                       0.0350, -0.0703, -0.0198, -0.0207,  0.0242,  0.0006, -0.0117,  0.0175,\n",
       "                      -0.1096,  0.0618,  0.0146,  0.0226,  0.1065, -0.0032, -0.0997,  0.0525,\n",
       "                       0.0683,  0.0152,  0.0693,  0.0669,  0.0411,  0.0872,  0.0240,  0.0378,\n",
       "                       0.0192, -0.0340,  0.0202, -0.0814,  0.0242,  0.0283, -0.0118,  0.1823,\n",
       "                      -0.0185,  0.0763, -0.0477,  0.0621,  0.1640, -0.0335, -0.0801, -0.1272,\n",
       "                      -0.1024,  0.0578,  0.0278,  0.0726, -0.0142,  0.0016,  0.0753,  0.0662,\n",
       "                       0.1433,  0.0314, -0.0736,  0.1077, -0.0187, -0.0674, -0.0503, -0.0370,\n",
       "                      -0.0345,  0.1567, -0.0688,  0.0291, -0.0428,  0.0377, -0.0239,  0.0558,\n",
       "                       0.0009, -0.0133,  0.1322,  0.0429,  0.1493,  0.0921, -0.0268,  0.1132,\n",
       "                       0.1376,  0.3536,  0.2563,  0.0670,  0.1780,  0.3778,  0.2759,  0.1495,\n",
       "                       0.1859,  0.0284,  0.0379, -0.0373,  0.0981,  0.2074, -0.0802,  0.0690,\n",
       "                       0.0623,  0.1563,  0.2287, -0.0135, -0.0010,  0.3550,  0.1578, -0.0492,\n",
       "                       0.1807,  0.1761,  0.2790,  0.0229,  0.0611,  0.0868,  0.1566,  0.1662,\n",
       "                       0.2231,  0.0653, -0.0296,  0.1708,  0.1498,  0.2883,  0.1214,  0.1408,\n",
       "                       0.3098,  0.2155,  0.2435,  0.2701, -0.0170,  0.2530,  0.1834,  0.2291,\n",
       "                       0.1298,  0.0648,  0.0631,  0.0587, -0.0244,  0.1446,  0.1997,  0.1688,\n",
       "                       0.0814,  0.0183,  0.2996,  0.1588,  0.1286,  0.1302,  0.0664,  0.1184,\n",
       "                       0.0194,  0.1136, -0.1221,  0.0546,  0.2085,  0.0049,  0.0877,  0.2197,\n",
       "                       0.1201,  0.0458, -0.0004,  0.0018,  0.1887, -0.0859,  0.2075,  0.0831,\n",
       "                       0.2091,  0.0367,  0.1477,  0.1091,  0.0561,  0.0170,  0.2662,  0.2074,\n",
       "                       0.0870,  0.1626,  0.0562,  0.0118,  0.0557,  0.2181,  0.1294,  0.1515,\n",
       "                       0.0486,  0.2387,  0.2131,  0.1684,  0.2849,  0.2121, -0.0272,  0.0791,\n",
       "                       0.0504,  0.0662,  0.2057,  0.1361,  0.0179,  0.0560,  0.0142,  0.2028,\n",
       "                       0.0796,  0.3370,  0.2326,  0.0725,  0.2185,  0.1139, -0.0410,  0.0154,\n",
       "                      -0.0010,  0.1275,  0.2988,  0.1056, -0.0053,  0.1739,  0.1109,  0.1012])),\n",
       "             ('bilstm_oov_context_feature.bias_hh_l0_reverse',\n",
       "              tensor([ 3.6833e-02,  1.7672e-01, -1.1959e-03, -6.8555e-04,  1.0184e-01,\n",
       "                       2.9254e-01,  2.3635e-01,  1.7317e-01,  3.1353e-01,  7.8072e-02,\n",
       "                       1.1454e-01,  1.3263e-02, -6.3375e-02,  1.7799e-01,  1.6154e-01,\n",
       "                      -1.0090e-01,  9.5897e-02, -4.2255e-02,  1.8792e-01, -7.3228e-02,\n",
       "                       5.5290e-03,  2.3854e-01, -3.1965e-02,  2.5376e-02,  9.7194e-02,\n",
       "                       2.8670e-01,  1.3881e-01,  2.4388e-01,  1.8370e-01,  9.5850e-02,\n",
       "                       2.7906e-02,  4.1839e-02,  1.0685e-01, -6.2052e-02,  1.4753e-02,\n",
       "                       1.1865e-01,  1.3172e-01,  2.8096e-01,  1.6140e-01,  8.2068e-02,\n",
       "                       3.0422e-01,  8.8703e-02,  2.9027e-01,  1.8963e-01,  1.8899e-01,\n",
       "                       2.2964e-01, -3.2189e-02,  1.9819e-01, -1.0737e-01,  1.5935e-01,\n",
       "                       2.1214e-01,  1.6379e-01,  1.3329e-01,  1.8395e-01,  1.0940e-01,\n",
       "                       6.3058e-02,  1.0930e-01,  9.8449e-02,  1.9274e-01, -5.7484e-02,\n",
       "                       3.2724e-02,  2.8171e-01,  2.9090e-01, -6.3054e-03,  1.1370e-01,\n",
       "                       1.7225e-01,  1.8909e-02,  1.8141e-01,  1.5512e-01,  1.5637e-01,\n",
       "                       1.9644e-01,  2.6013e-01,  2.8210e-01,  2.5113e-01, -7.2710e-02,\n",
       "                       1.2987e-01,  9.5623e-02,  7.4921e-02,  9.1681e-02, -6.0440e-02,\n",
       "                       2.1402e-01,  2.1713e-01,  4.1375e-02,  5.8524e-02, -6.4560e-02,\n",
       "                       1.9806e-01,  1.2358e-01,  2.3563e-01,  1.4221e-01, -1.9445e-02,\n",
       "                       9.5271e-02,  2.4934e-01,  2.0455e-01,  6.2578e-02,  3.1871e-01,\n",
       "                       1.1171e-03,  4.4144e-02, -3.8649e-02,  3.8383e-01,  8.6293e-02,\n",
       "                       8.9626e-02,  1.6814e-01,  6.9873e-02,  2.9619e-01,  3.4058e-01,\n",
       "                       1.3563e-01,  1.8827e-01,  1.2318e-01, -5.7869e-02, -1.3283e-01,\n",
       "                       2.1952e-01,  2.8274e-01,  1.6996e-01,  1.6357e-01,  3.5978e-01,\n",
       "                       9.4704e-02,  2.2063e-01,  3.5680e-02,  8.6718e-02,  2.1356e-02,\n",
       "                       2.3108e-01, -2.2768e-03,  1.8545e-01,  8.9526e-02, -3.7626e-02,\n",
       "                       1.1969e-01,  5.1358e-02,  5.6162e-02,  5.6332e-03, -4.2866e-03,\n",
       "                       9.5897e-02,  4.6320e-03,  4.7742e-02, -2.1145e-02, -1.6226e-01,\n",
       "                      -1.1568e-01, -1.0559e-01, -4.9524e-02, -2.2426e-02,  7.3257e-02,\n",
       "                       8.0905e-02,  1.5708e-01, -3.5090e-02,  5.5716e-02,  8.9953e-02,\n",
       "                       1.4629e-01,  3.0518e-02,  1.2125e-02,  4.5355e-02, -1.2335e-02,\n",
       "                       1.4049e-01, -9.4175e-02, -4.6844e-02,  6.6998e-02,  5.5666e-02,\n",
       "                       1.4367e-01, -9.2559e-02,  8.8349e-03, -3.3063e-02,  8.2213e-02,\n",
       "                       5.8830e-02, -7.7444e-03,  2.9124e-02, -1.4079e-01,  1.3293e-02,\n",
       "                       1.4642e-01, -9.8264e-03,  5.5325e-02,  2.7726e-02, -3.6901e-02,\n",
       "                       4.9932e-02,  8.3371e-02, -8.0348e-02,  3.3282e-02,  1.1514e-01,\n",
       "                       1.0514e-02, -4.9098e-02,  1.0026e-01,  1.2920e-02, -3.9069e-02,\n",
       "                       9.7958e-02,  1.4833e-01,  5.8384e-02,  4.3694e-02, -1.0097e-02,\n",
       "                       1.4411e-01, -2.3228e-02,  6.2529e-02,  8.8721e-02,  7.0824e-02,\n",
       "                       2.1765e-01,  7.3617e-02,  1.3134e-01,  9.9070e-02,  5.7227e-02,\n",
       "                       2.8411e-02,  9.4303e-02, -7.6602e-03,  3.3673e-02, -2.3810e-03,\n",
       "                       5.9510e-03,  1.4456e-01, -3.5845e-02,  9.2304e-03,  1.2027e-01,\n",
       "                       1.4790e-01,  1.4186e-01,  2.6000e-01,  1.8054e-01,  1.4937e-01,\n",
       "                       1.1535e-01, -9.5829e-02,  1.7348e-01, -7.6844e-02,  5.0809e-02,\n",
       "                      -9.1734e-02,  5.4646e-02,  4.1543e-02,  7.5302e-02, -2.5687e-02,\n",
       "                       6.9357e-02, -8.5639e-02,  6.5418e-03,  6.4903e-02,  1.1782e-02,\n",
       "                       8.8949e-02, -6.1409e-02,  2.8519e-02,  2.6583e-02, -3.4586e-04,\n",
       "                       9.1356e-02, -4.9279e-02, -1.7834e-02,  4.0602e-02, -3.4620e-02,\n",
       "                       1.4388e-01,  3.4173e-02,  7.3553e-02,  1.0258e-01, -3.4101e-02,\n",
       "                      -8.6843e-02,  5.4760e-02, -3.7236e-02, -3.6127e-03,  9.8858e-02,\n",
       "                       3.7540e-02,  3.2164e-02,  3.5914e-02,  5.4672e-02,  1.1779e-01,\n",
       "                       5.5896e-02,  2.0050e-02,  4.1600e-03,  8.4423e-02, -6.9048e-03,\n",
       "                      -1.1504e-01,  1.0701e-01, -1.1621e-02, -5.7097e-02, -4.8618e-02,\n",
       "                       2.1157e-02, -1.2278e-01, -4.3647e-02, -4.3757e-02,  2.6665e-03,\n",
       "                       1.0092e-04,  3.7873e-02,  1.1791e-01,  4.9305e-02, -5.7453e-02,\n",
       "                       1.3985e-01,  3.3025e-02, -5.4154e-02,  1.1422e-01,  1.8962e-02,\n",
       "                      -7.3010e-02, -5.8193e-02, -1.0274e-01, -7.7189e-02,  1.6917e-01,\n",
       "                       2.5002e-03,  7.8039e-02, -2.9959e-02,  6.3031e-02,  5.0151e-02,\n",
       "                      -6.0567e-03, -5.5575e-05, -2.9695e-02, -3.0457e-02,  7.7372e-03,\n",
       "                      -9.6474e-02,  9.8896e-02, -6.9835e-03, -4.7193e-03, -1.1285e-01,\n",
       "                      -1.1330e-02, -8.5703e-03,  2.0330e-02, -2.6963e-02,  3.8039e-02,\n",
       "                       4.0599e-02, -9.3565e-02,  4.5070e-02, -4.0629e-03,  1.9972e-02,\n",
       "                       3.0888e-02,  1.1220e-02, -3.0909e-02, -6.5868e-02,  5.4804e-02,\n",
       "                       4.3107e-02, -4.4432e-02,  2.3012e-02, -6.4596e-02, -7.5210e-02,\n",
       "                      -2.5236e-02,  1.3382e-01,  1.2508e-01, -1.3440e-02, -1.3193e-01,\n",
       "                      -1.9881e-02,  7.1544e-02, -1.2201e-01,  8.8819e-02,  6.4634e-02,\n",
       "                      -6.1639e-02,  3.4689e-02,  4.8199e-02,  6.6258e-02, -5.8295e-02,\n",
       "                      -8.7439e-02,  6.3297e-02,  2.4805e-02,  1.9611e-02, -2.9238e-02,\n",
       "                       3.8266e-03, -5.5452e-02,  4.9416e-02,  9.1027e-03, -1.2596e-01,\n",
       "                      -1.0766e-01, -8.0858e-02,  1.0727e-03,  1.0982e-02, -8.1858e-03,\n",
       "                       9.3588e-02,  1.5162e-02,  9.9153e-02,  6.4748e-02,  9.7242e-02,\n",
       "                      -1.4105e-01,  6.7711e-02, -1.3691e-01,  8.0261e-02,  5.5168e-02,\n",
       "                       3.7401e-02, -1.9485e-03,  8.5600e-02,  7.7599e-02, -2.5181e-02,\n",
       "                      -2.5922e-02,  5.4874e-02, -6.2132e-02,  4.9721e-02,  1.5263e-01,\n",
       "                       4.4483e-02,  8.1392e-02, -7.2372e-02, -5.2318e-02,  3.1661e-02,\n",
       "                       3.8576e-02, -4.5223e-02,  5.8916e-02,  1.1900e-02, -4.4716e-02,\n",
       "                       1.8502e-02, -6.2410e-02,  4.2516e-02,  6.8832e-02, -2.2240e-02,\n",
       "                       1.1449e-01,  3.7817e-02,  8.1716e-02,  3.4948e-02,  2.2449e-01,\n",
       "                       2.4828e-01,  1.7487e-01,  1.5168e-01,  1.9438e-01,  4.0676e-01,\n",
       "                       2.3023e-01,  1.6140e-01,  2.1326e-01,  2.0988e-02,  8.8511e-02,\n",
       "                       5.0500e-02,  1.8273e-02,  1.9865e-01, -7.9547e-02,  5.0472e-02,\n",
       "                       9.1191e-02,  1.1763e-01,  2.9185e-01,  2.0763e-02,  9.5478e-03,\n",
       "                       2.8354e-01,  2.6145e-01, -4.9524e-02,  1.2857e-01,  1.6543e-01,\n",
       "                       1.9049e-01,  5.9732e-02,  4.8951e-02,  2.3163e-02,  1.3790e-01,\n",
       "                       1.2911e-01,  5.9008e-02,  1.0261e-01, -4.9416e-02,  2.1081e-01,\n",
       "                       1.2124e-01,  1.4984e-01,  8.0024e-02,  3.3271e-02,  2.8538e-01,\n",
       "                       2.0110e-01,  1.9389e-01,  1.4469e-01,  7.5806e-02,  3.3810e-01,\n",
       "                       2.7242e-01,  2.0455e-01,  2.0275e-01,  2.4731e-03, -5.8700e-02,\n",
       "                       5.2160e-02,  6.7560e-02,  3.4350e-02,  1.3988e-01,  1.0712e-01,\n",
       "                       1.6946e-01,  4.8384e-02,  4.1288e-01,  1.9492e-01,  1.5996e-01,\n",
       "                       3.8540e-01,  1.6620e-01, -1.8943e-02, -1.4744e-02,  1.7413e-01,\n",
       "                      -5.2782e-02,  3.1090e-02,  2.0267e-01,  1.7279e-01,  1.7253e-01,\n",
       "                       2.9436e-01,  2.2573e-01,  5.6458e-02,  5.7491e-02, -6.8054e-02,\n",
       "                       2.5787e-01, -2.6709e-02,  1.7173e-01,  1.0078e-01,  2.3283e-01,\n",
       "                       4.9968e-02,  1.3789e-01,  1.9382e-01,  1.9688e-01, -4.6296e-02,\n",
       "                       2.3330e-01,  1.4807e-01,  6.8881e-02,  1.8132e-01,  6.7237e-02,\n",
       "                       8.3803e-02,  2.2657e-01,  2.2448e-01,  2.4756e-01, -2.8962e-03,\n",
       "                       5.1900e-02,  1.5502e-01,  2.0572e-01,  1.2366e-01,  3.2204e-01,\n",
       "                       2.7019e-01,  1.9354e-02,  9.4938e-02,  2.3603e-01,  1.3219e-01,\n",
       "                       3.6088e-02,  6.8844e-02,  2.9283e-02,  1.7617e-01, -5.6304e-02,\n",
       "                       1.9505e-01,  5.2163e-02,  2.4504e-01,  3.7986e-01,  1.1418e-01,\n",
       "                       2.7253e-01,  1.8440e-01,  1.4231e-01, -3.5026e-02,  7.7676e-02,\n",
       "                       1.0629e-01,  1.0064e-01,  3.1416e-01,  7.6560e-02,  1.6218e-01,\n",
       "                       6.3584e-02,  1.6980e-01])),\n",
       "             ('bilstm_right_context_feature.weight_ih_l0',\n",
       "              tensor([[-1.5760e-01, -5.1874e-02,  2.6606e-02,  ..., -5.3358e-02,\n",
       "                       -4.1743e-02, -1.5308e-01],\n",
       "                      [ 3.2266e-01, -1.1642e-01,  1.8507e-02,  ..., -1.3181e-01,\n",
       "                       -2.8937e-02, -4.6523e-01],\n",
       "                      [ 1.3377e-01, -1.2715e-01, -2.9131e-01,  ..., -1.3226e-01,\n",
       "                        2.2245e-01, -5.3568e-01],\n",
       "                      ...,\n",
       "                      [ 4.2131e-02, -2.0953e-01, -8.4032e-02,  ..., -1.3568e-01,\n",
       "                        5.0432e-04,  4.2434e-02],\n",
       "                      [-3.2804e-02,  2.0266e-01,  2.1078e-02,  ...,  9.6885e-03,\n",
       "                       -2.9596e-02, -6.4268e-02],\n",
       "                      [ 2.2846e-01, -2.7650e-01, -1.8617e-01,  ..., -1.4642e-01,\n",
       "                        9.8583e-04, -3.8268e-01]])),\n",
       "             ('bilstm_right_context_feature.weight_hh_l0',\n",
       "              tensor([[ 0.2102,  0.0615,  0.0532,  ..., -0.2164,  0.0948,  0.1463],\n",
       "                      [ 0.1497,  0.1006, -0.1193,  ..., -0.2187,  0.0757,  0.0496],\n",
       "                      [ 0.1829,  0.1587, -0.0926,  ...,  0.0641,  0.3071,  0.0421],\n",
       "                      ...,\n",
       "                      [ 0.3271,  0.1549, -0.1367,  ...,  0.0361,  0.0143,  0.1121],\n",
       "                      [ 0.1001,  0.0081, -0.0029,  ...,  0.0291, -0.2671,  0.1515],\n",
       "                      [ 0.1126,  0.2702, -0.0943,  ...,  0.0877, -0.1493,  0.0167]])),\n",
       "             ('bilstm_right_context_feature.bias_ih_l0',\n",
       "              tensor([-0.1280, -0.1414, -0.2118, -0.1276, -0.1535, -0.1778, -0.1390, -0.0282,\n",
       "                      -0.1682, -0.2016, -0.2205, -0.1429, -0.1834, -0.1779, -0.3407, -0.1713,\n",
       "                      -0.2583, -0.1788, -0.1704, -0.2767, -0.1393, -0.1000,  0.0287, -0.0340,\n",
       "                      -0.1618, -0.2613, -0.0318,  0.0221, -0.1299, -0.2837, -0.2710, -0.2512,\n",
       "                      -0.1959, -0.1287, -0.1431, -0.0643, -0.1867, -0.1282, -0.1293, -0.0817,\n",
       "                      -0.2706, -0.1304, -0.1536, -0.2351, -0.1297, -0.1073, -0.1591, -0.0821,\n",
       "                      -0.1431, -0.1649, -0.2216, -0.1626, -0.0586, -0.1322, -0.1717, -0.1479,\n",
       "                      -0.0958, -0.1968, -0.2344, -0.1813, -0.2251, -0.1059, -0.2313, -0.0763,\n",
       "                      -0.1745, -0.2261, -0.1659, -0.2055, -0.0624, -0.1454, -0.1037, -0.1238,\n",
       "                      -0.2529, -0.1315, -0.0760, -0.2817, -0.0458, -0.2151, -0.2576, -0.1491,\n",
       "                      -0.2283, -0.0741, -0.2179, -0.2404, -0.1361, -0.0953, -0.1274, -0.3558,\n",
       "                      -0.1083, -0.1894, -0.1902, -0.1867, -0.1994, -0.1939, -0.0692, -0.0542,\n",
       "                      -0.1143, -0.1467, -0.1059, -0.1981, -0.1524, -0.1094, -0.2226, -0.1092,\n",
       "                      -0.1559,  0.0344, -0.1647, -0.2506, -0.2189, -0.0769, -0.1744, -0.2951,\n",
       "                      -0.2577, -0.2606, -0.1419, -0.2500, -0.2381, -0.1295, -0.1147, -0.2008,\n",
       "                      -0.1925, -0.1691, -0.1951, -0.1033, -0.1799, -0.1619, -0.0134, -0.1494,\n",
       "                      -0.1162, -0.1510, -0.2006, -0.2598, -0.0847, -0.0922, -0.1499, -0.0038,\n",
       "                      -0.0983, -0.2232, -0.1755, -0.1312, -0.0563, -0.2667, -0.1051, -0.0477,\n",
       "                      -0.1333, -0.0848, -0.1476, -0.1540, -0.1738, -0.1096, -0.1768, -0.1290,\n",
       "                      -0.1603, -0.1577, -0.2007, -0.1705, -0.1299, -0.1048, -0.1996, -0.2533,\n",
       "                      -0.2220, -0.1994, -0.1629, -0.1245, -0.1591, -0.0961, -0.0271, -0.0729,\n",
       "                      -0.0458, -0.0227, -0.0045, -0.1337, -0.0935,  0.0433, -0.0668,  0.0168,\n",
       "                      -0.2284, -0.1344, -0.1738, -0.0322, -0.1848, -0.1962, -0.0814, -0.0644,\n",
       "                       0.0134, -0.1145, -0.1625, -0.0405, -0.1101, -0.1426, -0.2230, -0.1340,\n",
       "                      -0.0679, -0.1762, -0.1270, -0.1346, -0.1270,  0.0670,  0.0157, -0.1215,\n",
       "                      -0.1816, -0.0477, -0.1099, -0.2400, -0.1168, -0.2032, -0.1091, -0.1094,\n",
       "                      -0.1617, -0.0060, -0.1331, -0.1701, -0.0486, -0.2215, -0.1158, -0.1741,\n",
       "                      -0.1988, -0.2698, -0.1011, -0.0919, -0.1355, -0.1411, -0.0532, -0.1297,\n",
       "                      -0.1553, -0.0631, -0.0466, -0.2326, -0.0492, -0.0711, -0.1360, -0.1438,\n",
       "                      -0.1757, -0.0185, -0.2222, -0.0566, -0.0439,  0.0230,  0.0356, -0.0315,\n",
       "                      -0.1775, -0.1486, -0.0926, -0.2065, -0.1260, -0.2100, -0.0363,  0.0059,\n",
       "                      -0.1557, -0.1319, -0.0978, -0.1443, -0.2105, -0.1364,  0.0031, -0.1699,\n",
       "                      -0.1469, -0.0926, -0.0652,  0.0828, -0.0852,  0.0385,  0.1101, -0.0590,\n",
       "                      -0.0705, -0.0400,  0.0696, -0.0056, -0.0432, -0.0643, -0.1113, -0.0447,\n",
       "                      -0.0140,  0.0601, -0.0783,  0.0339, -0.0270,  0.0457, -0.0098, -0.0012,\n",
       "                      -0.0007, -0.1235, -0.0093, -0.0006,  0.0302, -0.0135, -0.0969, -0.0834,\n",
       "                      -0.0014, -0.0047, -0.0105,  0.0212,  0.0231, -0.0488, -0.0211,  0.0869,\n",
       "                      -0.0973, -0.0265, -0.1237, -0.0188, -0.0084, -0.1075, -0.0152,  0.0145,\n",
       "                      -0.0518, -0.0148, -0.0310, -0.0693, -0.0290,  0.0893, -0.0883, -0.0372,\n",
       "                      -0.0267,  0.0393, -0.0270, -0.0447, -0.0169,  0.0391, -0.0390, -0.0899,\n",
       "                      -0.0404, -0.0061,  0.0840,  0.0477, -0.0040, -0.0457,  0.0083,  0.0788,\n",
       "                      -0.0432, -0.0004, -0.0224,  0.0816,  0.0393,  0.0419, -0.1150,  0.0553,\n",
       "                      -0.0026,  0.0653, -0.0387,  0.0504, -0.0287, -0.0518,  0.0425, -0.0272,\n",
       "                       0.0226, -0.1017, -0.0224, -0.0263, -0.0530,  0.1035, -0.0010,  0.0952,\n",
       "                      -0.0954, -0.0173, -0.0344, -0.1849, -0.0254,  0.1013, -0.1127,  0.0571,\n",
       "                      -0.0400,  0.1119,  0.0186,  0.1269,  0.0338,  0.0091,  0.0016, -0.0142,\n",
       "                      -0.0947,  0.0464,  0.1125,  0.0591,  0.0663,  0.0565, -0.0469,  0.0335,\n",
       "                      -0.0391,  0.0393, -0.0083, -0.0776, -0.0016,  0.0316,  0.0530, -0.1083,\n",
       "                      -0.0547, -0.1205, -0.0514, -0.2244, -0.1448, -0.1184, -0.1972, -0.1619,\n",
       "                      -0.0969, -0.1365, -0.2334, -0.1517, -0.1332, -0.2253, -0.2913, -0.1748,\n",
       "                      -0.1973, -0.1202, -0.1775, -0.1949, -0.0920, -0.2847, -0.0629, -0.1373,\n",
       "                      -0.1971, -0.0890, -0.1746, -0.1099, -0.1711, -0.1076, -0.0740, -0.2928,\n",
       "                      -0.1056, -0.0632, -0.2222, -0.1610, -0.1930, -0.1153, -0.1393, -0.1002,\n",
       "                      -0.2234, -0.0644, -0.1406, -0.1970, -0.0588, -0.0922, -0.1461, -0.1073,\n",
       "                      -0.1250, -0.1869, -0.2868, -0.1247, -0.1809, -0.1544, -0.1252, -0.0677,\n",
       "                      -0.1623, -0.0972, -0.2551, -0.2365, -0.1090, -0.0612, -0.1334, -0.1352,\n",
       "                      -0.0958, -0.1301, -0.1618, -0.1939, -0.1118, -0.0419, -0.1985, -0.0323,\n",
       "                      -0.1383, -0.1196, -0.0825, -0.2693, -0.1419, -0.2341, -0.2492, -0.2032,\n",
       "                      -0.2307, -0.0645, -0.1258, -0.0823, -0.1716, -0.2203, -0.0393, -0.1669,\n",
       "                      -0.0741, -0.1900, -0.2313, -0.0932, -0.2652, -0.2696, -0.2539, -0.2128,\n",
       "                      -0.0960, -0.0801, -0.1442, -0.1572, -0.2227, -0.1632, -0.3310, -0.0813,\n",
       "                      -0.1433, -0.1354, -0.2118, -0.0733, -0.2031, -0.0444, -0.1417, -0.2185,\n",
       "                      -0.1669, -0.2968, -0.0742, -0.3873, -0.2493, -0.1863, -0.0790, -0.0682,\n",
       "                      -0.2478, -0.2594, -0.1439, -0.1250, -0.2620, -0.2155, -0.0859, -0.2382])),\n",
       "             ('bilstm_right_context_feature.bias_hh_l0',\n",
       "              tensor([-1.6688e-01, -8.8432e-02, -1.3717e-01, -2.4799e-01, -3.3231e-02,\n",
       "                      -1.6955e-01, -2.4638e-01, -1.7901e-01, -1.6873e-01, -1.8194e-01,\n",
       "                      -2.2703e-01, -2.1530e-01, -8.4490e-02, -1.7416e-01, -2.3308e-01,\n",
       "                      -1.7398e-01, -9.1019e-02, -6.4847e-02, -8.6756e-02, -1.1372e-01,\n",
       "                      -2.7263e-01, -2.2777e-01, -1.9856e-02, -1.4363e-01, -1.0140e-01,\n",
       "                      -1.0892e-01, -2.0138e-01, -5.7729e-02, -2.8125e-02, -1.6745e-01,\n",
       "                      -1.3556e-01, -2.5152e-01, -7.9389e-02, -2.7809e-01, -1.9282e-01,\n",
       "                      -2.6061e-01, -1.0276e-01, -1.4602e-01, -1.6573e-01, -3.7512e-02,\n",
       "                      -1.6381e-01,  2.3577e-02, -1.1058e-01, -6.6300e-02, -2.0998e-01,\n",
       "                      -4.0644e-02, -2.2754e-01, -1.5936e-01, -2.9047e-01, -2.1261e-01,\n",
       "                      -2.7236e-01, -1.7342e-01, -2.3392e-01, -2.6459e-01, -1.5972e-01,\n",
       "                      -1.5841e-01, -8.8653e-02, -1.6882e-01, -1.8801e-01, -2.7965e-01,\n",
       "                      -1.3064e-01, -1.7357e-01, -1.7947e-01, -1.9406e-01, -1.3979e-01,\n",
       "                      -1.9891e-01, -1.2190e-01, -2.3323e-01, -1.8745e-02, -1.4232e-01,\n",
       "                      -1.2941e-01, -9.0026e-02, -1.9239e-02, -1.0282e-01, -1.7402e-01,\n",
       "                      -2.1762e-01, -2.0210e-01, -1.7151e-01, -1.4719e-01, -6.2441e-02,\n",
       "                      -2.8488e-01, -8.0434e-02, -5.9548e-02, -1.7660e-01, -1.9558e-01,\n",
       "                      -1.3197e-01, -1.1547e-01, -3.4893e-01, -1.2657e-01, -2.3244e-01,\n",
       "                      -1.7067e-01, -1.1420e-01, -2.6045e-01, -2.6242e-01, -2.4187e-01,\n",
       "                      -9.2721e-03, -1.0774e-02, -2.2125e-01, -1.2853e-01, -6.1248e-02,\n",
       "                      -1.6059e-01, -1.0346e-01, -1.5613e-01, -3.7473e-02, -1.3135e-01,\n",
       "                      -1.1276e-01, -2.5964e-01, -1.4890e-01, -1.7665e-01, -6.5568e-02,\n",
       "                      -1.7901e-01, -1.8180e-01, -1.8696e-01, -9.8383e-02, -1.2402e-01,\n",
       "                      -2.0423e-01, -1.8596e-01, -2.0370e-01, -2.0956e-01, -1.3664e-01,\n",
       "                      -2.8234e-01, -3.1411e-01, -8.2429e-02, -2.7536e-01, -2.0578e-01,\n",
       "                      -6.5532e-02, -2.3668e-01, -2.6701e-01, -2.0319e-02, -1.6288e-01,\n",
       "                      -4.6032e-02, -2.3427e-01, -1.2405e-01, -1.0152e-01, -1.8884e-01,\n",
       "                      -1.1595e-01, -1.3972e-01, -1.4618e-01, -2.4615e-01, -1.7780e-01,\n",
       "                      -1.1742e-01, -1.9406e-01, -3.9453e-01, -8.8517e-02, -1.7788e-01,\n",
       "                      -1.8541e-01, -1.4527e-01, -2.8077e-02, -1.7720e-01, -1.3566e-01,\n",
       "                       1.3609e-02, -1.1974e-01, -1.9760e-01, -2.0359e-01, -7.4511e-02,\n",
       "                      -4.9670e-02, -1.7208e-01, -1.8139e-01, -2.0692e-01, -5.1515e-02,\n",
       "                      -6.4902e-02, -2.1032e-01, -7.4837e-02, -3.8376e-02, -9.9644e-02,\n",
       "                      -1.4652e-01, -1.2809e-01, -7.6771e-02, -7.3299e-02, -6.1056e-02,\n",
       "                      -1.5430e-01, -1.2072e-01, -8.7302e-02, -2.5882e-02, -1.2583e-01,\n",
       "                      -2.1311e-03, -1.4893e-01, -2.1601e-01, -1.3890e-01, -8.9988e-02,\n",
       "                      -1.9267e-01, -1.3402e-01, -1.2091e-01, -1.7036e-01, -1.8981e-01,\n",
       "                      -1.5557e-01, -3.7287e-02, -1.2534e-01, -7.0977e-02, -1.2465e-01,\n",
       "                      -1.1080e-01, -2.5058e-02, -1.5363e-01, -1.8493e-01, -1.3208e-01,\n",
       "                      -1.8128e-01, -1.2707e-01, -4.1249e-02, -1.1968e-01, -8.0002e-02,\n",
       "                      -5.7155e-02, -1.2093e-01, -1.8611e-01, -2.7741e-01, -7.6591e-02,\n",
       "                      -1.0689e-01, -2.2195e-01, -8.1415e-02, -8.7654e-02, -5.0073e-02,\n",
       "                      -1.3617e-01, -5.2478e-02, -8.9096e-02, -1.1055e-01, -1.7437e-01,\n",
       "                      -1.2198e-01, -6.8437e-02, -1.4412e-01, -3.6659e-01, -5.5000e-02,\n",
       "                      -1.7858e-01, -2.7962e-01, -1.5942e-01, -8.7316e-02, -1.5773e-01,\n",
       "                      -1.1178e-01, -9.0135e-02, -1.1836e-01, -5.6260e-02, -2.0302e-01,\n",
       "                      -2.3425e-01, -1.5269e-02, -8.2636e-02, -1.0395e-01, -5.0220e-02,\n",
       "                      -1.3045e-01, -1.2273e-01, -1.4648e-01, -1.4435e-01, -3.1187e-02,\n",
       "                      -2.0527e-01, -2.5052e-01, -1.9334e-01, -3.0950e-01, -1.9963e-01,\n",
       "                      -7.0957e-02, -1.1116e-01, -1.1272e-01, -2.5458e-01, -8.1815e-02,\n",
       "                      -1.6746e-01, -1.3828e-01, -2.0851e-01, -1.3807e-01, -1.1145e-01,\n",
       "                      -1.2629e-01, -4.7346e-02,  6.3993e-02,  1.7805e-02, -7.7679e-02,\n",
       "                      -1.3319e-02,  1.2645e-02, -2.8855e-02,  5.0682e-02,  1.8407e-01,\n",
       "                      -1.1636e-01, -3.1699e-02, -1.6235e-02,  4.2371e-02,  7.3654e-02,\n",
       "                       4.8309e-02,  6.2112e-03,  1.0785e-02,  5.5360e-02,  1.0657e-01,\n",
       "                       7.2008e-02, -6.2549e-02, -1.2680e-01, -1.0649e-01, -1.4656e-02,\n",
       "                       6.4749e-03,  5.6506e-02,  1.0485e-01, -1.1841e-01,  6.3313e-02,\n",
       "                       7.1582e-02, -2.6817e-02,  4.7219e-02, -8.1124e-03,  1.5809e-02,\n",
       "                      -5.5574e-02, -5.4364e-02,  2.1674e-02, -7.0285e-03, -1.4388e-01,\n",
       "                       5.4451e-02,  9.1823e-02, -1.0549e-01, -2.7727e-02,  1.4332e-03,\n",
       "                      -2.6114e-02, -7.6649e-02,  6.2287e-02,  2.0119e-02, -5.6813e-02,\n",
       "                       4.1926e-02,  8.3044e-02, -6.8397e-03, -1.8894e-03, -1.1576e-02,\n",
       "                      -1.0984e-02, -6.0607e-02,  7.8657e-02,  9.1122e-02,  7.5939e-03,\n",
       "                       4.5283e-02, -4.9164e-02,  3.4961e-02,  8.6378e-02,  4.1035e-02,\n",
       "                      -2.5171e-03,  6.7604e-02,  2.2607e-02, -5.5096e-02,  6.3226e-02,\n",
       "                       7.4324e-02,  5.7215e-02,  5.3270e-03,  4.2820e-02, -8.2098e-02,\n",
       "                       8.9846e-02, -1.2403e-01,  3.2371e-02, -5.7973e-03,  2.8034e-03,\n",
       "                      -8.7130e-03, -2.8416e-02,  4.3407e-02, -1.1976e-01,  6.2113e-02,\n",
       "                       4.5958e-02,  3.7184e-02,  8.3878e-02,  5.7967e-03,  4.8747e-02,\n",
       "                      -2.7535e-02,  6.5738e-02, -4.6911e-02,  1.2751e-01, -1.7930e-01,\n",
       "                      -1.2114e-03,  3.3515e-02, -1.9480e-03,  5.5388e-02, -4.0867e-02,\n",
       "                      -2.4347e-04, -1.8562e-02, -8.4580e-02,  4.3214e-02,  2.7200e-02,\n",
       "                       2.8960e-02, -1.2910e-01,  6.3392e-02,  6.7174e-02,  5.9614e-02,\n",
       "                      -3.1123e-02, -9.2405e-02, -3.0545e-02,  3.6586e-02,  3.3205e-02,\n",
       "                      -1.0054e-02, -1.6877e-02, -3.7939e-03, -6.0774e-03,  4.6812e-02,\n",
       "                       2.4564e-02,  7.5726e-02,  1.5170e-02, -8.8796e-02, -4.7169e-02,\n",
       "                       3.6320e-02,  2.0597e-02, -2.4722e-02, -4.8158e-03, -6.0369e-02,\n",
       "                      -9.4822e-02, -1.3336e-01, -1.7811e-01, -1.0964e-01, -2.3036e-01,\n",
       "                      -1.7820e-01, -1.5699e-01, -1.8119e-01, -2.4855e-01, -2.6691e-01,\n",
       "                      -3.3854e-01, -2.2209e-01, -1.2327e-01, -1.4057e-01, -1.4177e-01,\n",
       "                      -1.0651e-01, -1.2289e-01, -4.1985e-02, -5.4313e-02, -3.2135e-02,\n",
       "                      -1.5606e-01,  3.3176e-02, -6.2499e-02, -2.1326e-01, -9.0909e-02,\n",
       "                      -1.0998e-01, -1.8067e-02, -6.9241e-02, -1.3004e-01, -7.9711e-02,\n",
       "                      -1.1770e-01, -1.2010e-01, -2.0295e-01, -1.3141e-01, -1.3762e-01,\n",
       "                      -8.9374e-02, -9.0253e-02, -3.2214e-02, -1.8961e-01, -1.2819e-01,\n",
       "                      -4.8330e-02, -1.4218e-01, -1.7237e-01, -1.0115e-01, -8.2685e-02,\n",
       "                      -5.4348e-02, -2.4176e-01, -2.2542e-01, -9.1925e-02, -3.0727e-01,\n",
       "                      -1.2841e-01, -2.1357e-01, -1.4446e-01, -1.0502e-01, -2.7394e-02,\n",
       "                      -7.1938e-02, -3.2812e-01, -1.7965e-01, -9.9007e-02, -2.8317e-01,\n",
       "                      -1.5013e-01, -1.4372e-01, -1.6451e-01, -2.1316e-01, -1.5536e-01,\n",
       "                      -1.5081e-01, -1.2709e-01, -5.7180e-02, -7.9015e-02, -1.1018e-01,\n",
       "                      -1.1222e-01, -1.3931e-02, -6.7824e-02, -1.1626e-02, -1.7203e-01,\n",
       "                      -1.9037e-01, -1.2410e-01, -1.0362e-01, -1.9879e-01, -1.8772e-01,\n",
       "                      -6.0381e-02, -1.1558e-01, -1.6762e-01, -1.2394e-01, -1.6438e-01,\n",
       "                      -1.3526e-01, -3.7673e-01, -2.0338e-01, -2.4855e-01, -3.1029e-01,\n",
       "                      -1.8414e-01, -1.1964e-01, -1.7446e-01, -2.0657e-01, -5.2583e-02,\n",
       "                      -1.2928e-01, -4.3000e-02, -6.6966e-02, -1.3223e-01, -1.3737e-01,\n",
       "                      -2.1188e-01, -1.9163e-01,  3.1263e-02, -1.5728e-02, -1.9247e-01,\n",
       "                      -3.0757e-02, -1.2715e-01, -1.0045e-01, -1.4847e-01, -1.1873e-01,\n",
       "                      -1.1344e-01, -1.5711e-01, -1.9623e-01, -2.4468e-02, -1.6120e-01,\n",
       "                      -2.2705e-01, -5.3311e-02, -2.1411e-01, -1.5119e-01, -2.7137e-01,\n",
       "                      -6.3829e-02, -1.7039e-01, -1.4354e-01, -3.5427e-01, -1.0597e-01,\n",
       "                      -1.2808e-01, -2.3947e-01])),\n",
       "             ('bilstm_right_context_feature.weight_ih_l0_reverse',\n",
       "              tensor([[ 0.1525, -0.0300, -0.2464,  ..., -0.0978,  0.3127, -0.0464],\n",
       "                      [ 0.0518, -0.0365, -0.1388,  ..., -0.1964,  0.0320, -0.2297],\n",
       "                      [ 0.0798,  0.4308,  0.0536,  ...,  0.0083,  0.1809,  0.0207],\n",
       "                      ...,\n",
       "                      [-0.2269,  0.2447, -0.0136,  ..., -0.2891, -0.2405, -0.3584],\n",
       "                      [ 0.0450,  0.0846,  0.2547,  ..., -0.0460,  0.0456, -0.4180],\n",
       "                      [-0.1102,  0.0710,  0.0082,  ..., -0.1534, -0.0467, -0.0267]])),\n",
       "             ('bilstm_right_context_feature.weight_hh_l0_reverse',\n",
       "              tensor([[-0.0929, -0.2007, -0.0555,  ..., -0.3765,  0.1885,  0.0161],\n",
       "                      [-0.0707, -0.2435,  0.0576,  ...,  0.1451, -0.0955, -0.4083],\n",
       "                      [ 0.0780,  0.0306, -0.0995,  ..., -0.0355, -0.1527, -0.1940],\n",
       "                      ...,\n",
       "                      [ 0.1175,  0.0597, -0.3147,  ...,  0.0514,  0.2211,  0.1255],\n",
       "                      [-0.1225, -0.0712, -0.0558,  ...,  0.0864,  0.2190,  0.1249],\n",
       "                      [ 0.1837, -0.0519,  0.1969,  ...,  0.1138,  0.3388, -0.0387]])),\n",
       "             ('bilstm_right_context_feature.bias_ih_l0_reverse',\n",
       "              tensor([-7.1642e-02,  5.3417e-02,  7.1505e-02,  2.0543e-01, -1.4396e-01,\n",
       "                       1.6525e-01,  7.7747e-02, -5.0929e-02,  1.1719e-01,  8.8017e-02,\n",
       "                       4.6737e-02,  1.3336e-01,  5.4094e-02,  5.1409e-02,  2.2318e-02,\n",
       "                       3.7044e-02,  8.8781e-02, -9.6009e-03, -3.3927e-02,  7.9100e-02,\n",
       "                      -1.9551e-02,  1.2875e-01,  1.3963e-01, -8.6636e-02, -3.2464e-02,\n",
       "                       1.3699e-02,  1.6958e-03,  1.1504e-01,  1.4667e-01,  1.4788e-01,\n",
       "                      -1.2534e-01,  5.6098e-02,  7.3337e-02,  1.1150e-01,  8.3079e-02,\n",
       "                      -6.4846e-02,  1.6113e-02,  1.2956e-01,  8.7308e-02,  5.3099e-02,\n",
       "                       2.1927e-01,  1.7309e-01, -8.9871e-03,  1.2054e-01,  1.6429e-02,\n",
       "                      -1.6398e-02,  4.2118e-02,  4.1227e-02, -2.3284e-02,  8.9681e-02,\n",
       "                      -8.8570e-02, -8.3452e-03,  8.1177e-02,  8.6087e-02,  2.0078e-01,\n",
       "                      -2.9749e-02, -1.2330e-01,  9.4099e-02,  1.4065e-01, -1.0976e-01,\n",
       "                       9.0687e-02, -1.1433e-01,  4.7755e-02, -1.7895e-02, -7.8902e-02,\n",
       "                      -4.4285e-02, -1.1948e-02,  1.1225e-01,  8.9081e-02,  8.6080e-02,\n",
       "                      -5.4728e-02,  6.2664e-02,  3.3857e-02,  1.9865e-01,  5.4910e-02,\n",
       "                       2.3967e-01, -4.4675e-02, -4.0317e-02, -5.4725e-02,  2.5721e-01,\n",
       "                       3.3883e-01,  1.0752e-01,  1.0987e-01, -3.8850e-02,  9.0799e-02,\n",
       "                       9.0643e-02, -1.1844e-01, -1.5599e-01, -3.9622e-02,  1.5321e-02,\n",
       "                       1.5902e-02, -8.6248e-03,  1.4220e-01,  1.4291e-01, -6.3352e-02,\n",
       "                       1.6155e-01,  2.3177e-02,  9.1697e-02,  1.5928e-01,  5.8276e-02,\n",
       "                       1.5746e-01,  7.1769e-02,  2.5280e-02,  1.2413e-01,  1.0775e-01,\n",
       "                      -2.4111e-04,  6.2202e-02,  1.8669e-01,  2.1968e-02, -7.5448e-02,\n",
       "                       7.7728e-02,  1.1190e-01, -8.1243e-02, -6.2827e-02,  6.2312e-02,\n",
       "                       8.4521e-03,  1.9018e-01,  8.7326e-02,  1.2932e-01, -1.1832e-02,\n",
       "                       5.8492e-02,  1.2608e-01,  4.1556e-02,  4.0482e-02,  1.0133e-01,\n",
       "                      -1.4874e-01,  7.4250e-02,  1.0566e-01, -9.2714e-02, -1.0347e-01,\n",
       "                      -1.0714e-02,  8.1014e-03, -7.3523e-02,  2.2837e-02, -9.7885e-02,\n",
       "                       4.4784e-02, -1.8881e-01, -2.6171e-02,  4.8133e-02, -4.9274e-02,\n",
       "                      -1.4707e-02, -5.3870e-02, -3.5535e-02, -2.0275e-02, -1.5511e-01,\n",
       "                      -2.4066e-01,  2.9671e-02,  5.7057e-02, -9.1103e-02,  1.0174e-01,\n",
       "                      -1.8762e-01, -2.1702e-02,  4.6984e-02, -8.3624e-02, -1.2863e-01,\n",
       "                      -1.2856e-02,  4.0669e-02,  2.5382e-02, -9.0477e-02, -1.9657e-01,\n",
       "                       3.0490e-02, -2.4886e-03, -3.1634e-02, -2.0472e-01, -7.8175e-02,\n",
       "                      -3.1181e-01, -1.2800e-01, -9.0898e-02,  8.3795e-02, -1.0935e-01,\n",
       "                       1.1714e-01,  3.1818e-02, -9.7693e-02, -5.2193e-02,  2.6498e-02,\n",
       "                      -3.5340e-02, -4.7149e-02, -3.6910e-02,  9.5078e-02, -4.4035e-02,\n",
       "                      -1.1899e-01, -1.7555e-01, -7.4477e-02,  7.2300e-02, -1.2787e-01,\n",
       "                      -4.2936e-02, -1.1430e-01, -8.0950e-03,  6.2050e-02, -1.0674e-01,\n",
       "                      -2.5044e-01,  6.1849e-03,  2.0366e-02, -1.6958e-02,  4.3699e-02,\n",
       "                      -5.4352e-02,  2.1503e-02, -6.3286e-02, -1.2238e-01, -1.5070e-02,\n",
       "                      -4.3491e-02, -4.8639e-03, -1.2254e-01, -1.1785e-01,  1.1042e-01,\n",
       "                      -1.0605e-02, -3.9552e-03, -1.3331e-01, -7.5628e-02, -7.6209e-02,\n",
       "                      -9.7162e-02, -2.6794e-01,  7.8584e-02, -8.2054e-02, -1.1880e-01,\n",
       "                      -1.4580e-01, -1.3228e-01, -6.2757e-02, -2.2512e-01, -2.7942e-03,\n",
       "                      -6.8042e-02, -3.0929e-02, -8.4430e-02, -8.0034e-02, -9.3707e-02,\n",
       "                       5.3766e-02, -9.2103e-03, -1.2506e-01,  4.4891e-02, -1.2387e-01,\n",
       "                       3.1406e-02, -2.0710e-02,  8.2541e-03, -1.1437e-01, -5.0222e-02,\n",
       "                      -1.4085e-01,  3.9798e-02,  1.1948e-02, -3.7752e-02, -1.4701e-02,\n",
       "                       1.7826e-02, -2.2823e-02, -2.5708e-02, -1.5133e-02, -5.3529e-02,\n",
       "                       3.9331e-02,  1.0162e-01, -2.1527e-03, -1.3290e-01, -8.3959e-02,\n",
       "                      -4.4548e-02, -7.7022e-02,  6.9581e-02,  6.0237e-02, -8.5085e-02,\n",
       "                      -1.5789e-02,  2.1272e-02,  5.0358e-02, -5.4471e-02, -5.2113e-02,\n",
       "                       1.9000e-02,  1.2445e-01,  1.0071e-01,  9.5445e-02,  2.6210e-02,\n",
       "                      -2.9610e-02, -1.2172e-01,  1.6674e-01,  1.5482e-02, -4.5046e-02,\n",
       "                      -1.9780e-02,  4.1751e-02, -1.0349e-03,  7.7481e-02,  3.4943e-02,\n",
       "                      -4.8327e-02,  1.9430e-02,  6.3592e-02, -1.9857e-03,  3.8518e-02,\n",
       "                       8.8273e-02,  5.6463e-02, -1.5720e-01, -2.0204e-01,  5.1366e-02,\n",
       "                       9.3169e-03,  6.7093e-02,  3.3284e-02, -8.8424e-02, -2.5131e-02,\n",
       "                       7.6631e-02, -2.3542e-02,  5.1946e-02, -3.4692e-02, -1.7556e-02,\n",
       "                      -3.8402e-02,  1.7696e-01,  5.2095e-02,  1.4485e-03,  1.7969e-02,\n",
       "                       1.1521e-01,  1.2599e-01,  8.0262e-02, -7.4183e-02,  1.8520e-02,\n",
       "                      -4.4966e-02,  3.1309e-02, -3.0514e-02,  6.5030e-04,  1.6069e-02,\n",
       "                       1.5202e-01, -5.3278e-02,  2.8885e-02,  1.0195e-01,  1.5455e-03,\n",
       "                       7.5309e-02,  8.7180e-02, -6.1256e-02,  5.3127e-03,  4.9127e-02,\n",
       "                      -2.1391e-02, -5.9670e-02, -8.6888e-02, -2.7423e-02,  1.2258e-01,\n",
       "                      -4.3581e-02, -3.2454e-03, -1.4442e-01,  9.0559e-02, -9.4137e-03,\n",
       "                      -3.7927e-02, -3.2691e-02,  5.0654e-04, -8.4352e-02, -1.0784e-01,\n",
       "                      -4.6380e-02,  7.2064e-02,  1.4112e-02, -6.6653e-02,  9.5099e-02,\n",
       "                       1.1764e-01, -7.0669e-02, -1.1694e-01,  8.9585e-03, -3.1794e-02,\n",
       "                      -5.9811e-02,  5.7017e-02,  4.6561e-02,  1.4639e-01, -1.3815e-01,\n",
       "                      -9.3039e-02, -1.1896e-01, -6.4078e-02,  4.7497e-02,  1.4582e-01,\n",
       "                      -4.2522e-02,  1.1220e-01,  1.2092e-01, -2.1545e-02, -9.1505e-02,\n",
       "                       6.9800e-02, -2.9973e-02,  8.8592e-02, -8.3967e-02, -2.5759e-02,\n",
       "                       1.2756e-02, -1.0996e-01,  7.0051e-02,  1.6789e-02,  2.4355e-02,\n",
       "                       5.3572e-02, -5.2416e-02,  1.1625e-01, -3.5664e-02, -1.8030e-03,\n",
       "                      -5.1130e-02, -9.3367e-02,  7.2954e-02,  6.4040e-02,  5.8876e-02,\n",
       "                      -7.7284e-02,  9.2417e-02, -6.5343e-02,  5.6233e-02, -1.5844e-01,\n",
       "                       1.3981e-02,  1.0776e-01,  9.6052e-02, -3.0741e-02,  4.3867e-02,\n",
       "                       1.1767e-01,  1.7958e-01, -3.7423e-03, -2.0243e-02,  1.2835e-02,\n",
       "                       3.1598e-02, -1.6379e-02,  1.8575e-01, -2.9827e-02, -1.5312e-02,\n",
       "                       6.1318e-02,  8.2516e-02, -1.5643e-02,  1.5639e-01,  8.1693e-02,\n",
       "                       1.3390e-01,  2.1937e-01, -6.8408e-03,  5.1210e-02,  2.8255e-02,\n",
       "                       8.1375e-02,  5.2768e-02,  9.7612e-02,  8.5898e-03, -1.8399e-02,\n",
       "                       4.3535e-02,  8.9773e-02, -9.5457e-02,  5.8758e-02, -9.1094e-02,\n",
       "                       1.4492e-01,  2.4766e-01,  1.3545e-01,  1.4673e-01,  2.0185e-01,\n",
       "                      -3.9265e-02, -4.7384e-02,  2.2407e-01,  9.1483e-02, -4.9134e-02,\n",
       "                      -5.6296e-02, -7.2368e-02, -8.2406e-02,  6.1327e-02, -2.8971e-02,\n",
       "                       1.2322e-01,  6.3986e-02,  2.2694e-01,  2.0985e-01,  1.8705e-01,\n",
       "                      -3.7397e-02,  2.2808e-02,  5.1578e-02, -4.0495e-02,  9.0297e-02,\n",
       "                       3.3603e-03,  7.0524e-02,  1.6525e-02,  5.9321e-02, -9.7244e-03,\n",
       "                       9.2303e-02, -1.1399e-01, -3.7933e-02,  1.2038e-01,  5.9536e-02,\n",
       "                       1.4814e-01, -7.1552e-02,  1.4496e-01, -8.0057e-02,  2.0553e-01,\n",
       "                       1.3229e-01,  8.6446e-02, -7.3443e-03,  1.9301e-01,  2.3782e-01,\n",
       "                       5.7155e-02,  9.1536e-02, -1.3120e-01,  5.4503e-02,  6.2993e-02,\n",
       "                       1.9994e-02,  8.0036e-02,  3.3982e-02, -3.3641e-02,  1.5815e-01,\n",
       "                      -2.4585e-02,  4.2985e-02,  3.3013e-01,  1.1133e-01, -1.4393e-01,\n",
       "                       1.5325e-01,  3.6081e-02,  1.0845e-01, -5.5510e-02, -4.9640e-02,\n",
       "                      -6.3403e-02,  4.9612e-02,  3.4211e-02,  2.2063e-02, -1.3261e-01,\n",
       "                       2.3904e-01, -1.3694e-02,  5.6378e-02,  9.8612e-03,  1.4409e-01,\n",
       "                       2.0051e-01, -8.1924e-02, -8.3485e-02,  3.3126e-02, -6.6018e-02,\n",
       "                       6.7940e-04, -3.0221e-02,  4.0557e-02, -2.6793e-02,  1.1862e-01,\n",
       "                       2.1857e-01, -3.5151e-02,  4.6445e-02,  1.5863e-01,  1.5678e-02,\n",
       "                       1.4615e-01,  1.7157e-01])),\n",
       "             ('bilstm_right_context_feature.bias_hh_l0_reverse',\n",
       "              tensor([-9.5553e-02,  1.6253e-01,  1.9058e-04,  1.4441e-01, -3.6570e-02,\n",
       "                      -1.0525e-01,  1.1954e-01,  1.1931e-01, -3.3322e-02, -2.5119e-02,\n",
       "                       1.2837e-01, -2.4001e-02,  5.1721e-02, -5.3731e-04, -1.3360e-01,\n",
       "                       4.0576e-02,  2.8686e-02,  4.7748e-02,  6.2806e-02,  6.0484e-02,\n",
       "                       4.3380e-02,  1.0477e-01,  1.4994e-01, -9.3061e-02,  6.6274e-02,\n",
       "                      -1.0818e-01,  5.5645e-02,  1.6203e-01,  1.2598e-01,  1.5669e-01,\n",
       "                      -7.3707e-02, -5.3790e-02,  1.0725e-01,  3.0947e-02,  9.9902e-02,\n",
       "                      -5.8268e-03,  1.3738e-01,  1.6468e-02,  8.8352e-02,  1.8019e-01,\n",
       "                       2.0106e-01,  4.2039e-02, -1.6853e-01,  9.0490e-02, -1.3047e-02,\n",
       "                      -6.0470e-02, -3.0327e-04, -1.1505e-01,  4.4382e-03,  6.0035e-02,\n",
       "                      -3.2408e-02, -1.2193e-01,  2.7184e-02,  2.4878e-01,  2.0761e-01,\n",
       "                       6.2929e-03, -7.8625e-02, -5.6152e-02,  2.7637e-02, -1.2227e-01,\n",
       "                      -1.1804e-01, -1.0584e-01,  1.1238e-01,  1.0654e-01, -1.2968e-01,\n",
       "                      -9.7699e-02,  6.0639e-02,  4.0753e-02, -1.5402e-02,  1.2694e-01,\n",
       "                       6.4587e-02,  1.0236e-01, -6.3299e-02,  6.7206e-02,  2.1205e-02,\n",
       "                       9.4182e-02,  1.3586e-01,  7.2062e-02, -7.2662e-02,  2.1720e-01,\n",
       "                       3.0095e-01,  1.4040e-01,  1.7356e-01, -5.5564e-02,  1.4102e-01,\n",
       "                       2.0397e-01, -9.7506e-02, -6.6654e-02, -9.7392e-02, -1.4420e-02,\n",
       "                       6.6291e-02, -6.0812e-02,  4.6301e-02,  7.9270e-02, -9.5245e-02,\n",
       "                      -1.2888e-02, -3.5434e-02,  1.9298e-01,  2.2599e-01,  6.0299e-02,\n",
       "                       1.7854e-01,  3.8746e-02,  5.1053e-02,  9.7338e-02,  4.4968e-02,\n",
       "                      -6.3171e-02,  5.1380e-02, -5.1601e-02, -4.9066e-02, -7.1787e-02,\n",
       "                       9.5463e-02,  1.6733e-01, -6.9452e-02, -2.0635e-01, -1.2779e-01,\n",
       "                      -4.2513e-02,  3.8045e-02, -4.2839e-02,  6.6024e-02, -1.2436e-01,\n",
       "                       3.6036e-02, -4.9387e-02, -4.2462e-02,  5.3347e-02,  1.7154e-01,\n",
       "                      -1.5264e-01,  8.3857e-02,  2.4931e-01, -1.2154e-01, -1.0810e-01,\n",
       "                      -4.7315e-02, -5.3860e-02, -2.1750e-02,  4.8030e-03, -1.7943e-01,\n",
       "                      -4.9761e-02, -1.8814e-01,  8.0654e-02, -9.6325e-02, -1.0807e-01,\n",
       "                      -3.9743e-02, -1.6017e-01,  5.9618e-04,  3.1341e-02, -1.8980e-01,\n",
       "                      -4.2685e-02,  1.8481e-02, -6.5530e-02, -4.0434e-02, -7.7645e-03,\n",
       "                      -4.6983e-02, -1.3761e-01, -1.1494e-01, -4.9286e-02,  3.8190e-02,\n",
       "                      -1.7340e-01,  5.5762e-04, -1.3417e-01, -1.0538e-01, -2.5018e-01,\n",
       "                      -8.4467e-03,  2.9140e-02,  9.5489e-02, -1.1645e-01, -1.9850e-02,\n",
       "                      -2.8267e-01, -2.2745e-01, -1.0704e-01, -7.9121e-03, -9.0482e-02,\n",
       "                       3.1843e-02,  3.1187e-02, -8.9968e-02, -3.5191e-02, -2.6344e-02,\n",
       "                      -1.1136e-01, -9.1815e-03,  5.4435e-02,  2.8090e-02,  3.2068e-02,\n",
       "                      -2.9408e-01, -1.2856e-01, -5.2289e-02,  1.4197e-01, -8.5324e-02,\n",
       "                      -1.6081e-02, -1.3947e-01, -1.6109e-01,  7.5756e-03, -2.7435e-01,\n",
       "                      -7.9814e-03,  1.4749e-01, -2.9007e-02, -4.5361e-02,  1.1642e-01,\n",
       "                      -5.0415e-02, -3.0722e-02,  2.8966e-02, -9.3078e-02, -9.2906e-03,\n",
       "                      -2.0623e-02, -1.0699e-03, -5.6984e-02, -2.8753e-01,  5.9160e-02,\n",
       "                      -5.6677e-02, -7.6467e-02, -6.4659e-02, -1.6640e-01, -6.6455e-02,\n",
       "                      -4.4696e-02, -7.2722e-02, -3.6563e-02, -1.3822e-01,  1.1337e-01,\n",
       "                      -1.1199e-01,  2.7309e-02, -7.7543e-02, -1.1244e-01,  9.3452e-02,\n",
       "                       1.0257e-01,  2.5160e-02, -1.4803e-01, -8.9711e-02,  5.2892e-02,\n",
       "                       4.5501e-02,  2.7724e-02, -5.1734e-02, -7.4711e-02, -6.9219e-02,\n",
       "                      -5.7030e-02,  1.8743e-01, -1.5096e-01, -6.9448e-02,  1.1345e-01,\n",
       "                      -1.1803e-01, -8.8088e-02,  6.6688e-02,  7.5827e-02,  3.0726e-02,\n",
       "                       1.0202e-01, -1.2857e-01, -1.1392e-01, -1.0862e-01, -8.5553e-02,\n",
       "                      -1.1653e-01,  8.1912e-02, -1.4924e-01, -8.6123e-02, -5.7730e-02,\n",
       "                      -4.6636e-02, -8.0670e-03, -1.1359e-01,  7.8315e-02, -6.1426e-02,\n",
       "                      -7.4054e-02, -1.5438e-02, -2.5626e-03,  5.5716e-02,  1.5059e-02,\n",
       "                       1.1961e-01,  1.4411e-01,  5.5272e-02,  3.0509e-02,  1.7482e-02,\n",
       "                      -1.7171e-02, -4.8173e-02,  3.5419e-02,  5.6614e-02, -2.3871e-02,\n",
       "                      -1.0430e-01,  1.3576e-01, -6.4622e-02, -7.8673e-03,  5.9936e-02,\n",
       "                      -6.2144e-02,  4.1165e-02,  1.4708e-01, -1.8210e-01,  1.6960e-02,\n",
       "                      -3.8772e-02, -1.1473e-02, -9.1521e-03, -2.6684e-02, -7.7776e-02,\n",
       "                      -6.5053e-02,  4.1618e-02, -1.1249e-01, -1.0727e-02,  9.9356e-02,\n",
       "                      -1.6138e-02, -6.6945e-02, -1.2114e-02, -1.0509e-01, -1.0094e-02,\n",
       "                       1.4007e-01,  1.6746e-01,  7.5889e-02, -1.9741e-01, -7.5516e-02,\n",
       "                       8.5999e-02,  4.3584e-02,  9.9325e-03,  9.9616e-02,  1.7391e-02,\n",
       "                       2.9994e-02,  8.5589e-02, -1.1223e-01,  6.7897e-02,  9.5646e-02,\n",
       "                       9.9886e-02, -6.6029e-02, -1.5967e-02,  1.2158e-02, -2.9780e-02,\n",
       "                       5.9420e-02, -2.7525e-03,  3.7095e-02, -6.2114e-02,  1.6621e-02,\n",
       "                       8.9338e-02,  1.6072e-02, -5.2981e-02,  1.8156e-02, -8.6834e-02,\n",
       "                       3.7813e-02, -5.5454e-02, -3.5245e-02, -5.5805e-02,  1.5814e-02,\n",
       "                       3.4238e-02,  5.3373e-02, -7.1565e-02,  1.9569e-02,  4.0096e-02,\n",
       "                      -4.7921e-02, -9.9389e-02,  7.6946e-02, -1.3029e-01,  5.5229e-02,\n",
       "                       2.5515e-02, -1.6841e-02, -1.4087e-01, -8.3527e-03, -2.0281e-01,\n",
       "                      -4.1762e-03,  4.4281e-03, -1.0306e-02,  2.4467e-02, -6.7326e-02,\n",
       "                       3.2693e-02,  1.0546e-01, -3.0616e-02, -1.3216e-01,  1.6696e-01,\n",
       "                       9.3813e-02, -3.7853e-02,  5.8990e-02, -1.8686e-02, -1.0042e-01,\n",
       "                       6.5412e-02,  8.1337e-03,  7.8728e-02, -8.3526e-02, -1.9291e-02,\n",
       "                      -9.2218e-02,  4.8566e-02,  6.6651e-02, -1.3034e-02,  1.1771e-01,\n",
       "                       3.3838e-02, -2.1126e-02, -2.9936e-02, -1.5455e-01, -2.1646e-01,\n",
       "                      -7.6439e-02,  5.3470e-02, -3.1530e-02,  5.9120e-02, -7.3064e-02,\n",
       "                       5.3861e-02,  1.4589e-02,  4.5968e-02,  1.1276e-01, -7.1702e-02,\n",
       "                      -1.6841e-02, -9.9585e-02,  5.6467e-02, -3.6449e-02,  7.2964e-02,\n",
       "                       2.5197e-01,  1.9019e-01,  6.7073e-02, -1.3799e-01,  9.5499e-02,\n",
       "                       3.2098e-02,  1.3312e-01, -2.1183e-02, -5.3340e-03,  1.3403e-02,\n",
       "                       5.8793e-02,  7.4746e-02, -2.8766e-02,  1.1659e-01,  4.1242e-02,\n",
       "                       1.2032e-01,  1.7543e-01, -9.0038e-02,  1.7702e-01, -1.0949e-01,\n",
       "                      -5.4815e-02,  2.0917e-01,  3.4801e-02, -1.7548e-02, -1.3946e-01,\n",
       "                       1.5928e-02, -8.6940e-02, -4.5346e-02, -2.8783e-02,  3.4842e-02,\n",
       "                       7.7675e-02,  1.9503e-01,  9.9291e-02, -4.4029e-02,  3.6738e-01,\n",
       "                       5.1006e-02,  1.0816e-02,  1.7893e-01,  5.2781e-02, -2.3061e-02,\n",
       "                       5.9292e-02,  2.1496e-02,  3.8127e-02,  4.2904e-02,  8.2934e-03,\n",
       "                       8.8621e-03,  8.1431e-02,  1.2679e-01,  2.4122e-01,  1.3620e-01,\n",
       "                       4.5376e-02,  1.6168e-02,  1.6422e-02, -1.6640e-01,  2.6232e-02,\n",
       "                       8.8857e-03,  1.4869e-01,  3.0868e-02,  9.2692e-02, -2.9718e-02,\n",
       "                      -9.5660e-02,  2.7389e-02,  2.6605e-02,  2.3383e-01,  3.2183e-02,\n",
       "                       8.0651e-02, -1.9751e-03,  2.6540e-01, -1.6447e-01,  2.1341e-01,\n",
       "                       4.8414e-02,  1.0740e-01,  2.4079e-03,  2.4734e-01,  1.5885e-01,\n",
       "                       4.9493e-02,  1.5618e-01, -3.7704e-02,  1.4985e-02, -4.0050e-02,\n",
       "                       1.7553e-02, -7.5203e-02,  4.8656e-02, -1.7540e-02,  1.9515e-01,\n",
       "                       1.7564e-02,  8.8522e-02,  2.8346e-01,  4.1909e-02, -8.2773e-03,\n",
       "                       7.3959e-02,  1.5149e-01,  2.4636e-01, -5.7661e-02,  7.0321e-03,\n",
       "                       6.6537e-02,  2.0254e-01,  9.5474e-02,  6.4444e-02, -2.0832e-02,\n",
       "                       2.0830e-01,  1.6228e-02,  7.0088e-02,  7.3186e-03,  9.6741e-02,\n",
       "                       2.2931e-01, -7.7942e-02, -7.6496e-02, -1.2142e-01, -9.4630e-02,\n",
       "                       1.3512e-01,  9.0630e-02,  1.3936e-01, -9.7692e-02,  6.8324e-02,\n",
       "                       1.1535e-01, -1.0732e-01, -7.8854e-02,  2.0147e-01, -5.1786e-02,\n",
       "                       1.5809e-01,  1.6606e-01])),\n",
       "             ('fc.0.weight',\n",
       "              tensor([[ 0.1003,  0.0957,  0.1126,  ..., -0.0684,  0.0434,  0.0133],\n",
       "                      [-0.0286, -0.1557, -0.0991,  ..., -0.1089,  0.0172, -0.0948],\n",
       "                      [-0.0668,  0.1787,  0.0311,  ...,  0.3063, -0.1444,  0.2410],\n",
       "                      ...,\n",
       "                      [-0.0815, -0.0582,  0.0392,  ...,  0.1743, -0.1375, -0.2064],\n",
       "                      [-0.1493, -0.0804, -0.1239,  ...,  0.0985,  0.0956,  0.0168],\n",
       "                      [ 0.0085, -0.0953, -0.0771,  ..., -0.0712,  0.0215,  0.1866]])),\n",
       "             ('fc.0.bias',\n",
       "              tensor([-0.0024,  0.1491,  0.1099,  0.2085,  0.0817, -0.2110, -0.3063, -0.0250,\n",
       "                       0.0669,  0.0569,  0.2015,  0.0388,  0.2331, -0.1324,  0.0349, -0.0663,\n",
       "                       0.0023,  0.1071,  0.0639, -0.0634,  0.3633,  0.1463, -0.1401,  0.1971,\n",
       "                      -0.0278,  0.0519, -0.0685,  0.1624,  0.0718,  0.0304,  0.0779, -0.0609,\n",
       "                       0.1195, -0.0213, -0.1004, -0.1818, -0.2774, -0.1882, -0.0892, -0.0879,\n",
       "                       0.1302,  0.0933, -0.2391, -0.0004,  0.0451,  0.1632,  0.0339,  0.1142,\n",
       "                       0.0753,  0.0697, -0.0892, -0.1738,  0.0874,  0.0539,  0.0523, -0.2602,\n",
       "                      -0.1334, -0.0271, -0.0984,  0.0006,  0.2789,  0.0902, -0.2441,  0.0861])),\n",
       "             ('oov_embedding.weight',\n",
       "              tensor([[-0.0592, -0.1682, -0.0502,  ...,  0.3934,  0.1185,  0.0114],\n",
       "                      [-0.1171,  0.1583, -0.2299,  ..., -0.1194, -0.0419, -0.0797],\n",
       "                      [-0.0450, -0.4361,  0.1210,  ...,  0.0277,  0.2056, -0.2450],\n",
       "                      ...,\n",
       "                      [ 0.1343,  0.4550,  0.1108,  ..., -0.2828,  0.2298, -0.0476],\n",
       "                      [ 0.2986,  0.0132,  0.0113,  ...,  0.1971,  0.0261, -0.1604],\n",
       "                      [-0.2265, -0.2124, -0.0310,  ...,  0.0011,  0.1113,  0.1997]])),\n",
       "             ('oov_embedding.bias',\n",
       "              tensor([-0.0055,  0.0056,  0.2103, -0.2788, -0.0889, -0.1388,  0.2270,  0.1496,\n",
       "                      -0.1091,  0.1127,  0.1930,  0.3644, -0.0981, -0.1015, -0.1680,  0.1206,\n",
       "                       0.0633, -0.1712, -0.1853, -0.2155,  0.0369,  0.0369,  0.0518, -0.1132,\n",
       "                      -0.0484, -0.2648,  0.2750, -0.4633, -0.0957, -0.3444, -0.1174, -0.1565,\n",
       "                      -0.0663,  0.1088, -0.3383, -0.0614,  0.1740, -0.1918, -0.1030,  0.0348,\n",
       "                      -0.0274,  0.0845,  0.2444, -0.1648, -0.1604,  0.0140,  0.1346,  0.2395,\n",
       "                       0.0135, -0.0545, -0.1514, -0.3651,  0.0575, -0.0042,  0.0374,  0.0079,\n",
       "                       0.2848,  0.0359, -0.1932,  0.1583,  0.0836, -0.1754, -0.0753,  0.0216])),\n",
       "             ('prob.0.weight',\n",
       "              tensor([[-0.1287, -0.0512, -0.1074,  ..., -0.0370, -0.0186,  0.1198],\n",
       "                      [ 0.3117, -0.0611, -0.0608,  ...,  0.0990,  0.0237,  0.1117],\n",
       "                      [ 0.0416, -0.0155,  0.1827,  ...,  0.0819, -0.5029, -0.1260],\n",
       "                      ...,\n",
       "                      [-0.0962,  0.0250,  0.1382,  ..., -0.0150,  0.0707,  0.0546],\n",
       "                      [-0.0434,  0.0193,  0.0344,  ...,  0.0948,  0.4360,  0.1047],\n",
       "                      [ 0.0006,  0.3347, -0.2868,  ..., -0.0395, -0.0707,  0.0340]])),\n",
       "             ('prob.0.bias',\n",
       "              tensor([-0.7478, -0.0852, -0.3232,  ..., -0.4328, -0.0706, -0.0512]))])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1616de6-2ec1-4a77-980a-addd6d77d6d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
