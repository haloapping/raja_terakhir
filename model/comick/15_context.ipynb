{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13fc63c4-da08-43a8-9972-2615d377d1fa",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "313363b9-24d1-4b87-87cd-a0b7dd5fc128",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pytz\n",
    "import torch\n",
    "import timeit\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from itertools import chain\n",
    "from time import time\n",
    "from torch import nn, optim\n",
    "from torchmetrics import F1Score\n",
    "from torch.optim import lr_scheduler\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from polyglot.mapping import Embedding, CaseExpander, DigitExpander"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b49405-006a-4a45-ae79-0e22f6a7172e",
   "metadata": {},
   "source": [
    "# Hyperparameters Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68709d29-24a1-45bf-b549-804952fd1db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hyperparams:\n",
    "     def __init__(\n",
    "        self,\n",
    "        context_size=15,\n",
    "        input_size_left_context=64,\n",
    "        input_size_oov_context=20,\n",
    "        input_size_right_context=64,\n",
    "        batch_size=32,\n",
    "        num_hidden_layer=1,\n",
    "        hidden_size=128,\n",
    "        output_size=3611,\n",
    "        shuffle=True,\n",
    "        lr=0.001,\n",
    "        batch_first=True,\n",
    "        bidirectional=True,\n",
    "        init_wb_with_kaiming_normal=True,\n",
    "        n_epoch=20,\n",
    "        patience=20,\n",
    "        device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    ):\n",
    "        self.context_size = context_size\n",
    "        self.input_size_left_context = input_size_left_context\n",
    "        self.input_size_oov_context = input_size_oov_context\n",
    "        self.input_size_right_context = input_size_right_context\n",
    "        self.batch_size = batch_size\n",
    "        self.num_hidden_layer = num_hidden_layer\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.shuffle = shuffle\n",
    "        self.lr = lr\n",
    "        self.batch_first = batch_first\n",
    "        self.bidirectional = bidirectional\n",
    "        self.init_wb_with_kaiming_normal = init_wb_with_kaiming_normal\n",
    "        self.n_epoch = n_epoch\n",
    "        self.patience = patience\n",
    "        self.device = device\n",
    "        \n",
    "hyperparams = Hyperparams()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f750b1-d4a7-4a2a-9fe1-369a61f28a2b",
   "metadata": {},
   "source": [
    "# Prepare Feature Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f241f20b-fb34-4db2-b887-1687f137b141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left context shape: (16562, 15)\n",
      "OOV context shape: (16562, 28)\n",
      "Right context shape: (16562, 15)\n",
      "Actual lable shape: (16562,)\n"
     ]
    }
   ],
   "source": [
    "def convert_doc_to_idxs(docs, dict_vocabs):\n",
    "    doc_to_idx = []\n",
    "    \n",
    "    for doc in docs:\n",
    "        doc_to_idx.append([dict_vocabs[token] for token in doc])\n",
    "        \n",
    "    return np.array(doc_to_idx)\n",
    "\n",
    "# Left context\n",
    "left_context = open(f\"../../datasets/features/{hyperparams.context_size}_context/left_context_with_pad.pkl\", \"rb\")\n",
    "left_context = pickle.load(left_context)\n",
    "left_context_to_idx = open(f\"../../datasets/features/{hyperparams.context_size}_context/token2idx_left_context.pkl\", \"rb\")\n",
    "left_context_to_idx = pickle.load(left_context_to_idx)\n",
    "doc_left_context_to_idx = convert_doc_to_idxs(left_context, left_context_to_idx)\n",
    "\n",
    "# OOV context\n",
    "oov_context = open(f\"../../datasets/features/{hyperparams.context_size}_context/oov_context_with_pad.pkl\", \"rb\")\n",
    "oov_context = pickle.load(oov_context)\n",
    "oov_context_to_idx = open(f\"../../datasets/features/{hyperparams.context_size}_context/token2idx_oov_context.pkl\", \"rb\")\n",
    "oov_context_to_idx = pickle.load(oov_context_to_idx)\n",
    "doc_oov_context_to_idx = convert_doc_to_idxs(oov_context, oov_context_to_idx)\n",
    "\n",
    "# Right context\n",
    "right_context = open(f\"../../datasets/features/{hyperparams.context_size}_context/right_context_with_pad.pkl\", \"rb\")\n",
    "right_context = pickle.load(right_context)\n",
    "right_context_to_idx = open(f\"../../datasets/features/{hyperparams.context_size}_context/token2idx_right_context.pkl\", \"rb\")\n",
    "right_context_to_idx = pickle.load(right_context_to_idx)\n",
    "doc_right_context_to_idx = convert_doc_to_idxs(right_context, right_context_to_idx)\n",
    "\n",
    "# Actual labels\n",
    "labels_context = open(f\"../../datasets/features/{hyperparams.context_size}_context/lables.pkl\", \"rb\")\n",
    "labels_context = pickle.load(labels_context)\n",
    "labels_to_idx = open(f\"../../datasets/features/{hyperparams.context_size}_context/lable_vocabs.pkl\", \"rb\")\n",
    "labels_to_idx = pickle.load(labels_to_idx)\n",
    "doc_labels_to_idx = convert_doc_to_idxs(labels_context, labels_to_idx).flatten()\n",
    "\n",
    "print(f\"Left context shape: {doc_left_context_to_idx.shape}\")\n",
    "print(f\"OOV context shape: {doc_oov_context_to_idx.shape}\")\n",
    "print(f\"Right context shape: {doc_right_context_to_idx.shape}\")\n",
    "print(f\"Actual lable shape: {doc_labels_to_idx.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe386c1f-3e1d-4589-b18e-42e4bc4055ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to Tensor\n",
    "left_contexts = torch.LongTensor(doc_left_context_to_idx)\n",
    "oov_contexts = torch.LongTensor(doc_oov_context_to_idx)\n",
    "right_contexts = torch.LongTensor(doc_right_context_to_idx)\n",
    "actual_labels = torch.LongTensor(doc_labels_to_idx)\n",
    "dataset = TensorDataset(left_contexts, oov_contexts, right_contexts, actual_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8806cc8-c1d1-450a-833d-f25375c52949",
   "metadata": {},
   "source": [
    "# Char and Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86595b81-a95e-4469-acad-49b9ed2c9662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word Embedding\n",
    "word_embeddings = Embedding.load(\"../../word_embeddings/polyglot/idn_embeddings.tar.bz2\")\n",
    "word_embeddings.apply_expansion(DigitExpander)\n",
    "word_embeddings.apply_expansion(CaseExpander)\n",
    "\n",
    "left_vocabs = open(f\"../../datasets/features/{hyperparams.context_size}_context/left_context_vocabs.pkl\", \"rb\")\n",
    "left_vocabs = pickle.load(left_vocabs)\n",
    "\n",
    "right_vocabs = open(f\"../../datasets/features/{hyperparams.context_size}_context/right_context_vocabs.pkl\", \"rb\")\n",
    "right_vocabs = pickle.load(right_vocabs)\n",
    "\n",
    "left_word_embedding_dict = {left_context_to_idx[vocab] : word_embeddings[vocab] for vocab in left_vocabs}\n",
    "right_word_embedding_dict = {right_context_to_idx[vocab] : word_embeddings[vocab] for vocab in right_vocabs}\n",
    "\n",
    "# Char Embedding\n",
    "char_embedding_dict = open(\"../../word_embeddings/chars_embedding/char_embeddings.pkl\", \"rb\")\n",
    "char_embedding_dict = pickle.load(char_embedding_dict)\n",
    "\n",
    "# Context embedding\n",
    "left_context_embedding = nn.Embedding.from_pretrained(torch.FloatTensor(np.array(list(left_word_embedding_dict.values()))), padding_idx=left_vocabs.index(\"<PAD>\"), freeze=True)\n",
    "oov_context_embedding = nn.Embedding.from_pretrained(torch.FloatTensor(np.array(list(char_embedding_dict.values()))), padding_idx=list(char_embedding_dict.keys()).index(\"PAD\"), freeze=True)\n",
    "right_context_embedding = nn.Embedding.from_pretrained(torch.FloatTensor(np.array(list(right_word_embedding_dict.values()))), padding_idx=right_vocabs.index(\"<PAD>\"), freeze=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593ddcfe-1525-41ae-bf02-c9ebf3d957aa",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "998fb38d-da64-4b4c-9371-75e06ebfc8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=hyperparams.batch_size, shuffle=hyperparams.shuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5be550-2f41-41b4-9df4-ac67744041c5",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed852446-c649-4727-b9ff-64375cf7e966",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Comick(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size_left_context=hyperparams.input_size_left_context,\n",
    "        input_size_oov_context=hyperparams.input_size_oov_context,\n",
    "        input_size_right_context=hyperparams.input_size_right_context,\n",
    "        hidden_size=hyperparams.hidden_size,\n",
    "        num_layers=hyperparams.num_hidden_layer,\n",
    "        output_size=hyperparams.output_size,\n",
    "        batch_first=hyperparams.batch_first,\n",
    "        bidirectional=hyperparams.bidirectional,\n",
    "        init_wb_with_kaiming_normal=hyperparams.init_wb_with_kaiming_normal\n",
    "    ):\n",
    "        super(Comick, self).__init__()\n",
    "        \n",
    "        self.input_size_left_context = input_size_left_context\n",
    "        self.input_size_oov_context = input_size_oov_context\n",
    "        self.input_size_right_context = input_size_right_context\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.output_size = output_size\n",
    "        self.batch_first = batch_first\n",
    "        self.bidirectional = bidirectional\n",
    "        \n",
    "        self.bilstm_left_context_feature = nn.LSTM(\n",
    "            input_size = self.input_size_left_context,\n",
    "            hidden_size = self.hidden_size,\n",
    "            num_layers = self.num_layers,\n",
    "            batch_first = self.batch_first,\n",
    "            bidirectional = self.bidirectional\n",
    "        )\n",
    "        \n",
    "        self.bilstm_oov_context_feature = nn.LSTM(\n",
    "            input_size = self.input_size_oov_context,\n",
    "            hidden_size = self.hidden_size,\n",
    "            num_layers = self.num_layers,\n",
    "            batch_first = self.batch_first,\n",
    "            bidirectional = self.bidirectional\n",
    "        )\n",
    "        \n",
    "        self.bilstm_right_context_feature = nn.LSTM(\n",
    "            input_size = self.input_size_right_context,\n",
    "            hidden_size = self.hidden_size,\n",
    "            num_layers = self.num_layers,\n",
    "            batch_first = self.batch_first,\n",
    "            bidirectional = self.bidirectional\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(2 * self.hidden_size, 64),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "        self.oov_embedding = nn.Linear(in_features=3 * 64, out_features=64)\n",
    "        \n",
    "        self.embedding = np.empty((output_size, 64), dtype=np.float32)\n",
    "        \n",
    "        self.prob = nn.Sequential(\n",
    "            nn.Linear(64, self.output_size),\n",
    "            nn.LogSoftmax(dim=1)\n",
    "        )\n",
    "                \n",
    "        if init_wb_with_kaiming_normal:\n",
    "            self.init_wb()\n",
    "            \n",
    "    def init_wb(self):\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, (nn.Linear, nn.LSTM)):\n",
    "                for name, param in module.named_parameters():\n",
    "                    if \"weight\" in name:\n",
    "                        nn.init.kaiming_normal_(param)\n",
    "                    else:\n",
    "                        nn.init.kaiming_normal_(param.reshape(1, -1))\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_left_context,\n",
    "        input_oov_context,\n",
    "        input_right_context,\n",
    "        idxs_target,\n",
    "        hidden_left_context=None,\n",
    "        hidden_oov_context=None,\n",
    "        hidden_right_context=None,\n",
    "    ):\n",
    "        # BiLSTM left, oov, and right context\n",
    "        output_left_context, (hidden_left_context, memory_left_context) = self.bilstm_left_context_feature(input_left_context, hidden_left_context)\n",
    "        output_oov_context, (hidden_oov_context, memory_oov_context) = self.bilstm_oov_context_feature(input_oov_context, hidden_oov_context)\n",
    "        output_right_context, (hidden_right_context, memory_right_context) = self.bilstm_right_context_feature(input_right_context, hidden_right_context)\n",
    "                \n",
    "        # Concate hidden (forward and backward hidden BiLSTM)\n",
    "        hidden_left_bidirectional = torch.cat((hidden_left_context[0], hidden_left_context[-1]), dim=1)\n",
    "        hidden_oov_bidirectional = torch.cat((hidden_oov_context[0], hidden_oov_context[-1]), dim=1)\n",
    "        hidden_right_bidirectional = torch.cat((hidden_right_context[0], hidden_right_context[-1]), dim=1)\n",
    "        \n",
    "        # Fully connected\n",
    "        output_left_fc = self.fc(hidden_left_bidirectional)\n",
    "        output_oov_fc = self.fc(hidden_oov_bidirectional)\n",
    "        output_right_fc = self.fc(hidden_right_bidirectional)\n",
    "        \n",
    "        # Concate output left, oov, and right context feature\n",
    "        output = torch.cat((output_left_fc, output_oov_fc, output_right_fc), dim=1)\n",
    "        \n",
    "        # OOV embedding\n",
    "        output = self.oov_embedding(output)\n",
    "                \n",
    "        # save OOV embedding\n",
    "        self.embedding[idxs_target.tolist()] = output.cpu().detach().numpy()\n",
    "        \n",
    "        # Projection OOV embedding\n",
    "        prob = self.prob(output)\n",
    "        \n",
    "        return prob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992eb40b-9062-47f1-9703-65e80d6cb07d",
   "metadata": {},
   "source": [
    "# Model, Optimizer, Criterion, Metric, and Learning Rate Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b08d05fc-0bb5-426e-aa7b-eb930ba9f06b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Comick(\n",
       "  (bilstm_left_context_feature): LSTM(64, 128, batch_first=True, bidirectional=True)\n",
       "  (bilstm_oov_context_feature): LSTM(20, 128, batch_first=True, bidirectional=True)\n",
       "  (bilstm_right_context_feature): LSTM(64, 128, batch_first=True, bidirectional=True)\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (1): Tanh()\n",
       "  )\n",
       "  (oov_embedding): Linear(in_features=192, out_features=64, bias=True)\n",
       "  (prob): Sequential(\n",
       "    (0): Linear(in_features=64, out_features=3611, bias=True)\n",
       "    (1): LogSoftmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Comick().to(hyperparams.device)\n",
    "model.prob[0].requires_grad_ = False # disable gradient for projection layer\n",
    "optimizer = optim.Adam(model.parameters(), lr=hyperparams.lr)\n",
    "criterion = nn.NLLLoss(ignore_index=list(char_embedding_dict.keys()).index(\"PAD\")).to(hyperparams.device)\n",
    "metric = F1Score(ignore_index=list(char_embedding_dict.keys()).index(\"PAD\")).to(hyperparams.device)\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.5)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d463d75-dd43-4b45-9eec-8f4aca21b018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "814,427\n"
     ]
    }
   ],
   "source": [
    "print(f\"{sum([param.numel() for param in model.parameters() if param.requires_grad_]):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "494a567d-acbc-46c2-adc8-b9a512366c17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.8663413e+17,  4.5763605e-41,  1.8663413e+17, ...,\n",
       "         4.5762204e-41, -1.2623962e+08,  4.5762204e-41],\n",
       "       [ 9.3411957e-41,  0.0000000e+00, -8.8393088e+07, ...,\n",
       "         0.0000000e+00, -8.8395648e+07,  4.5762204e-41],\n",
       "       [-1.2624525e+08,  4.5762204e-41,  9.3427371e-41, ...,\n",
       "         4.5762204e-41,  9.3441384e-41,  0.0000000e+00],\n",
       "       ...,\n",
       "       [-1.2692160e+08,  4.5762204e-41,  9.5159376e-41, ...,\n",
       "         4.5762204e-41,  9.5173389e-41,  0.0000000e+00],\n",
       "       [-9.4544800e+06,  4.5762204e-41, -1.2692723e+08, ...,\n",
       "         4.5762204e-41, -1.2693235e+08,  4.5762204e-41],\n",
       "       [ 9.5188803e-41,  0.0000000e+00, -9.4548320e+06, ...,\n",
       "         0.0000000e+00, -9.4551520e+06,  4.5762204e-41]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b39ba3-b103-44da-ae1e-34fd12ad2d2f",
   "metadata": {},
   "source": [
    "# Training Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c51a3a6-a4af-425f-aa1f-34ffe9ff8248",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_step(dataloader, model, optimizer, criterion, metric, scheduler=None, path_name=None):\n",
    "    model.train()\n",
    "    \n",
    "    batch_losses = []\n",
    "    batch_metric_scores = []\n",
    "    \n",
    "    for batch, (input_left_context, input_oov_context, input_right_context, actual_label) in enumerate(tqdm(dataloader), 1):\n",
    "        # Forward Propagation\n",
    "        prob = model(\n",
    "            left_context_embedding(input_left_context).to(hyperparams.device),\n",
    "            oov_context_embedding(input_oov_context).to(hyperparams.device),\n",
    "            right_context_embedding(input_right_context).to(hyperparams.device),\n",
    "            actual_label.to(hyperparams.device)\n",
    "        )\n",
    "                \n",
    "        loss = criterion(prob, actual_label.to(hyperparams.device))\n",
    "        metric_score = metric(prob.argmax(dim=1), actual_label.to(hyperparams.device))\n",
    "        metric_score = metric.compute()\n",
    "        \n",
    "        if scheduler is not None:\n",
    "            scheduler.step(loss)\n",
    "        \n",
    "        batch_losses.append(loss.item())\n",
    "        batch_metric_scores.append(metric_score)\n",
    "        \n",
    "        if batch % 50 == 0 or batch == len(dataloader):\n",
    "            batch_name = \"Batch-\" + str(batch)\n",
    "            print(f\"{batch_name.ljust(9)}: {str(criterion).split('(')[0]}={(loss.item()):.4f} | {str(metric).split('(')[0]}={(metric_score):.4f}\")\n",
    "            with open(f\"../../logs/comick/{hyperparams.context_size}_contexts/{path_name}/training_history.txt\", \"a\") as f:\n",
    "                f.write(f\"{batch_name.ljust(9)}: {str(criterion).split('(')[0]}={(loss.item()):.4f} | {str(metric).split('(')[0]}={(metric_score):.4f}\\n\")\n",
    "\n",
    "        # Backward Propagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    return batch_losses, batch_metric_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3043a1-39cb-4b38-8024-54f909a565a9",
   "metadata": {},
   "source": [
    "# Looping Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e139244-b036-4d45-beca-1de5bd7b5e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH-1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7af0b857ab4490e9d878c4afe1ca478",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=5.9828 | F1Score=0.2744\n",
      "Batch-100: NLLLoss=4.5442 | F1Score=0.2906\n",
      "Batch-150: NLLLoss=5.1247 | F1Score=0.3084\n",
      "Batch-200: NLLLoss=4.7580 | F1Score=0.3352\n",
      "Batch-250: NLLLoss=2.9342 | F1Score=0.3540\n",
      "Batch-300: NLLLoss=4.2674 | F1Score=0.3741\n",
      "Batch-350: NLLLoss=4.1455 | F1Score=0.3904\n",
      "Batch-400: NLLLoss=3.1451 | F1Score=0.4056\n",
      "Batch-450: NLLLoss=4.3019 | F1Score=0.4200\n",
      "Batch-500: NLLLoss=3.2857 | F1Score=0.4322\n",
      "Batch-518: NLLLoss=4.0384 | F1Score=0.4350\n",
      "\n",
      "Mean NLLLoss: 4.5228 | Mean F1Score: 0.3487\n",
      "==================================================\n",
      "\n",
      "EPOCH-2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cccb8f6696a42e380e87d02a102dbb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=3.0697 | F1Score=0.5944\n",
      "Batch-100: NLLLoss=2.3977 | F1Score=0.6020\n",
      "Batch-150: NLLLoss=3.0060 | F1Score=0.6071\n",
      "Batch-200: NLLLoss=2.5795 | F1Score=0.6121\n",
      "Batch-250: NLLLoss=2.5705 | F1Score=0.6170\n",
      "Batch-300: NLLLoss=2.9766 | F1Score=0.6237\n",
      "Batch-350: NLLLoss=1.9871 | F1Score=0.6276\n",
      "Batch-400: NLLLoss=1.9546 | F1Score=0.6309\n",
      "Batch-450: NLLLoss=1.8107 | F1Score=0.6350\n",
      "Batch-500: NLLLoss=2.4928 | F1Score=0.6400\n",
      "Batch-518: NLLLoss=3.0042 | F1Score=0.6415\n",
      "\n",
      "Yeah ðŸŽ‰ðŸ˜„! Model improved.\n",
      "Mean NLLLoss: 2.6899 | Mean F1Score: 0.6188\n",
      "==================================================\n",
      "\n",
      "EPOCH-3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e59d8b03bd624446ba1cc77e27c3d343",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=1.6630 | F1Score=0.7277\n",
      "Batch-100: NLLLoss=2.4170 | F1Score=0.7295\n",
      "Batch-150: NLLLoss=1.3805 | F1Score=0.7330\n",
      "Batch-200: NLLLoss=1.2598 | F1Score=0.7354\n",
      "Batch-250: NLLLoss=2.2348 | F1Score=0.7384\n",
      "Batch-300: NLLLoss=2.5978 | F1Score=0.7402\n",
      "Batch-350: NLLLoss=1.4772 | F1Score=0.7420\n",
      "Batch-400: NLLLoss=1.4521 | F1Score=0.7426\n",
      "Batch-450: NLLLoss=1.3910 | F1Score=0.7444\n",
      "Batch-500: NLLLoss=2.7551 | F1Score=0.7465\n",
      "Batch-518: NLLLoss=2.8046 | F1Score=0.7471\n",
      "\n",
      "Yeah ðŸŽ‰ðŸ˜„! Model improved.\n",
      "Mean NLLLoss: 1.7774 | Mean F1Score: 0.7373\n",
      "==================================================\n",
      "\n",
      "EPOCH-4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "285d9038e7ab4900911ba2354a05a3e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=1.7845 | F1Score=0.7981\n",
      "Batch-100: NLLLoss=1.4171 | F1Score=0.8076\n",
      "Batch-150: NLLLoss=0.9111 | F1Score=0.8045\n",
      "Batch-200: NLLLoss=0.6291 | F1Score=0.8057\n",
      "Batch-250: NLLLoss=0.6303 | F1Score=0.8076\n",
      "Batch-300: NLLLoss=1.2219 | F1Score=0.8090\n",
      "Batch-350: NLLLoss=1.3499 | F1Score=0.8123\n",
      "Batch-400: NLLLoss=0.5033 | F1Score=0.8151\n",
      "Batch-450: NLLLoss=0.7472 | F1Score=0.8153\n",
      "Batch-500: NLLLoss=0.7495 | F1Score=0.8154\n",
      "Batch-518: NLLLoss=1.0565 | F1Score=0.8166\n",
      "\n",
      "Yeah ðŸŽ‰ðŸ˜„! Model improved.\n",
      "Mean NLLLoss: 1.1586 | Mean F1Score: 0.8073\n",
      "==================================================\n",
      "\n",
      "EPOCH-5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad3ebc56f1a14017b6445661975b601e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=0.6324 | F1Score=0.9031\n",
      "Batch-100: NLLLoss=0.6336 | F1Score=0.8945\n",
      "Batch-150: NLLLoss=0.4886 | F1Score=0.8901\n",
      "Batch-200: NLLLoss=0.8198 | F1Score=0.8848\n",
      "Batch-250: NLLLoss=0.5416 | F1Score=0.8806\n",
      "Batch-300: NLLLoss=0.7762 | F1Score=0.8770\n",
      "Batch-350: NLLLoss=0.9847 | F1Score=0.8751\n",
      "Batch-400: NLLLoss=0.4666 | F1Score=0.8722\n",
      "Batch-450: NLLLoss=0.4298 | F1Score=0.8707\n",
      "Batch-500: NLLLoss=1.2016 | F1Score=0.8714\n",
      "Batch-518: NLLLoss=0.5875 | F1Score=0.8717\n",
      "\n",
      "Yeah ðŸŽ‰ðŸ˜„! Model improved.\n",
      "Mean NLLLoss: 0.6884 | Mean F1Score: 0.8827\n",
      "==================================================\n",
      "\n",
      "EPOCH-6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeb9e9a2c92748aba323d5303bf258e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=0.2179 | F1Score=0.9603\n",
      "Batch-100: NLLLoss=0.4363 | F1Score=0.9580\n",
      "Batch-150: NLLLoss=0.2633 | F1Score=0.9574\n",
      "Batch-200: NLLLoss=0.3602 | F1Score=0.9551\n",
      "Batch-250: NLLLoss=0.2141 | F1Score=0.9504\n",
      "Batch-300: NLLLoss=0.3564 | F1Score=0.9503\n",
      "Batch-350: NLLLoss=0.2104 | F1Score=0.9467\n",
      "Batch-400: NLLLoss=0.6490 | F1Score=0.9434\n",
      "Batch-450: NLLLoss=0.4592 | F1Score=0.9428\n",
      "Batch-500: NLLLoss=0.4061 | F1Score=0.9413\n",
      "Batch-518: NLLLoss=0.0977 | F1Score=0.9406\n",
      "\n",
      "Yeah ðŸŽ‰ðŸ˜„! Model improved.\n",
      "Mean NLLLoss: 0.3265 | Mean F1Score: 0.9512\n",
      "==================================================\n",
      "\n",
      "EPOCH-7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0057e5cb9075453babf92b0137385f9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=0.0616 | F1Score=0.9912\n",
      "Batch-100: NLLLoss=0.2074 | F1Score=0.9912\n",
      "Batch-150: NLLLoss=0.0132 | F1Score=0.9929\n",
      "Batch-200: NLLLoss=0.0785 | F1Score=0.9927\n",
      "Batch-250: NLLLoss=0.0512 | F1Score=0.9936\n",
      "Batch-300: NLLLoss=0.0945 | F1Score=0.9929\n",
      "Batch-350: NLLLoss=0.1795 | F1Score=0.9915\n",
      "Batch-400: NLLLoss=0.1385 | F1Score=0.9907\n",
      "Batch-450: NLLLoss=0.2021 | F1Score=0.9899\n",
      "Batch-500: NLLLoss=0.1009 | F1Score=0.9895\n",
      "Batch-518: NLLLoss=0.1410 | F1Score=0.9893\n",
      "\n",
      "Yeah ðŸŽ‰ðŸ˜„! Model improved.\n",
      "Mean NLLLoss: 0.1057 | Mean F1Score: 0.9915\n",
      "==================================================\n",
      "\n",
      "EPOCH-8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e608a52f18d438e881beb5e67d6cbdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=0.0159 | F1Score=0.9994\n",
      "Batch-100: NLLLoss=0.0199 | F1Score=0.9978\n",
      "Batch-150: NLLLoss=0.0161 | F1Score=0.9981\n",
      "Batch-200: NLLLoss=0.0220 | F1Score=0.9983\n",
      "Batch-250: NLLLoss=0.0302 | F1Score=0.9979\n",
      "Batch-300: NLLLoss=0.0137 | F1Score=0.9982\n",
      "Batch-350: NLLLoss=0.0320 | F1Score=0.9983\n",
      "Batch-400: NLLLoss=0.0363 | F1Score=0.9984\n",
      "Batch-450: NLLLoss=0.0252 | F1Score=0.9982\n",
      "Batch-500: NLLLoss=0.0258 | F1Score=0.9982\n",
      "Batch-518: NLLLoss=0.0637 | F1Score=0.9981\n",
      "\n",
      "Yeah ðŸŽ‰ðŸ˜„! Model improved.\n",
      "Mean NLLLoss: 0.0332 | Mean F1Score: 0.9983\n",
      "==================================================\n",
      "\n",
      "EPOCH-9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c91adf439cde47cba09466d87b6d613d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=0.0038 | F1Score=0.9987\n",
      "Batch-100: NLLLoss=0.0181 | F1Score=0.9991\n",
      "Batch-150: NLLLoss=0.0130 | F1Score=0.9992\n",
      "Batch-200: NLLLoss=0.0160 | F1Score=0.9989\n",
      "Batch-250: NLLLoss=0.0163 | F1Score=0.9986\n",
      "Batch-300: NLLLoss=0.0077 | F1Score=0.9987\n",
      "Batch-350: NLLLoss=0.0078 | F1Score=0.9986\n",
      "Batch-400: NLLLoss=0.0160 | F1Score=0.9987\n",
      "Batch-450: NLLLoss=0.0053 | F1Score=0.9989\n",
      "Batch-500: NLLLoss=0.0068 | F1Score=0.9989\n",
      "Batch-518: NLLLoss=0.0011 | F1Score=0.9990\n",
      "\n",
      "Yeah ðŸŽ‰ðŸ˜„! Model improved.\n",
      "Mean NLLLoss: 0.0138 | Mean F1Score: 0.9988\n",
      "==================================================\n",
      "\n",
      "EPOCH-10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c4504329fa549829bb29d42165aaae1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=0.0054 | F1Score=1.0000\n",
      "Batch-100: NLLLoss=0.0047 | F1Score=0.9992\n",
      "Batch-150: NLLLoss=0.0041 | F1Score=0.9995\n",
      "Batch-200: NLLLoss=0.0051 | F1Score=0.9993\n",
      "Batch-250: NLLLoss=0.0083 | F1Score=0.9994\n",
      "Batch-300: NLLLoss=0.0069 | F1Score=0.9995\n",
      "Batch-350: NLLLoss=0.0033 | F1Score=0.9995\n",
      "Batch-400: NLLLoss=0.0037 | F1Score=0.9996\n",
      "Batch-450: NLLLoss=0.0054 | F1Score=0.9996\n",
      "Batch-500: NLLLoss=0.0065 | F1Score=0.9996\n",
      "Batch-518: NLLLoss=0.0017 | F1Score=0.9996\n",
      "\n",
      "Yeah ðŸŽ‰ðŸ˜„! Model improved.\n",
      "Mean NLLLoss: 0.0066 | Mean F1Score: 0.9995\n",
      "==================================================\n",
      "\n",
      "EPOCH-11\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4e283caa6414653afdda0d1e5247ffd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=0.0034 | F1Score=0.9994\n",
      "Batch-100: NLLLoss=0.0039 | F1Score=0.9997\n",
      "Batch-150: NLLLoss=0.0029 | F1Score=0.9995\n",
      "Batch-200: NLLLoss=0.0158 | F1Score=0.9993\n",
      "Batch-250: NLLLoss=0.0025 | F1Score=0.9994\n",
      "Batch-300: NLLLoss=0.0033 | F1Score=0.9995\n",
      "Batch-350: NLLLoss=0.0031 | F1Score=0.9996\n",
      "Batch-400: NLLLoss=0.0059 | F1Score=0.9996\n",
      "Batch-450: NLLLoss=0.0037 | F1Score=0.9997\n",
      "Batch-500: NLLLoss=0.0036 | F1Score=0.9996\n",
      "Batch-518: NLLLoss=0.0038 | F1Score=0.9996\n",
      "\n",
      "Yeah ðŸŽ‰ðŸ˜„! Model improved.\n",
      "Mean NLLLoss: 0.0046 | Mean F1Score: 0.9994\n",
      "==================================================\n",
      "\n",
      "EPOCH-12\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15d5ca1757494118906221162e3ed728",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=0.0024 | F1Score=1.0000\n",
      "Batch-100: NLLLoss=0.0029 | F1Score=1.0000\n",
      "Batch-150: NLLLoss=0.0017 | F1Score=0.9996\n",
      "Batch-200: NLLLoss=0.0036 | F1Score=0.9997\n",
      "Batch-250: NLLLoss=0.0040 | F1Score=0.9997\n",
      "Batch-300: NLLLoss=0.0034 | F1Score=0.9997\n",
      "Batch-350: NLLLoss=0.0057 | F1Score=0.9996\n",
      "Batch-400: NLLLoss=0.0026 | F1Score=0.9996\n",
      "Batch-450: NLLLoss=0.0038 | F1Score=0.9997\n",
      "Batch-500: NLLLoss=0.0037 | F1Score=0.9996\n",
      "Batch-518: NLLLoss=0.0019 | F1Score=0.9996\n",
      "\n",
      "Huft ðŸ˜¥! Model not improved.\n",
      "Mean NLLLoss: 0.0055 | Mean F1Score: 0.9997\n",
      "Patience = 1/20â—\n",
      "==================================================\n",
      "\n",
      "EPOCH-13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d05efe04f1474cab85b2d695aed265c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=0.0030 | F1Score=0.9997\n",
      "Batch-100: NLLLoss=0.0013 | F1Score=0.9998\n",
      "Batch-150: NLLLoss=0.0018 | F1Score=0.9999\n",
      "Batch-200: NLLLoss=0.0016 | F1Score=0.9999\n",
      "Batch-250: NLLLoss=0.0018 | F1Score=0.9999\n",
      "Batch-300: NLLLoss=0.0075 | F1Score=0.9997\n",
      "Batch-350: NLLLoss=0.0110 | F1Score=0.9996\n",
      "Batch-400: NLLLoss=0.6417 | F1Score=0.9935\n",
      "Batch-450: NLLLoss=0.3823 | F1Score=0.9784\n",
      "Batch-500: NLLLoss=0.7328 | F1Score=0.9684\n",
      "Batch-518: NLLLoss=0.6543 | F1Score=0.9667\n",
      "\n",
      "Huft ðŸ˜¥! Model not improved.\n",
      "Mean NLLLoss: 0.1371 | Mean F1Score: 0.9945\n",
      "Patience = 2/20â—\n",
      "==================================================\n",
      "\n",
      "EPOCH-14\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb6e7d7f41e14f2180f4b48407424613",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=0.1842 | F1Score=0.9488\n",
      "Batch-100: NLLLoss=0.1857 | F1Score=0.9497\n",
      "Batch-150: NLLLoss=0.2385 | F1Score=0.9499\n",
      "Batch-200: NLLLoss=0.2774 | F1Score=0.9516\n",
      "Batch-250: NLLLoss=0.1956 | F1Score=0.9538\n",
      "Batch-300: NLLLoss=0.1474 | F1Score=0.9549\n",
      "Batch-350: NLLLoss=0.2771 | F1Score=0.9553\n",
      "Batch-400: NLLLoss=0.1062 | F1Score=0.9571\n",
      "Batch-450: NLLLoss=0.1675 | F1Score=0.9590\n",
      "Batch-500: NLLLoss=0.0458 | F1Score=0.9606\n",
      "Batch-518: NLLLoss=0.2062 | F1Score=0.9612\n",
      "\n",
      "Huft ðŸ˜¥! Model not improved.\n",
      "Mean NLLLoss: 0.1562 | Mean F1Score: 0.9542\n",
      "Patience = 3/20â—\n",
      "==================================================\n",
      "\n",
      "EPOCH-15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fddfeb17bd44cc18e2e892cf29a3fe3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=0.0136 | F1Score=0.9969\n",
      "Batch-100: NLLLoss=0.0147 | F1Score=0.9981\n",
      "Batch-150: NLLLoss=0.0190 | F1Score=0.9979\n",
      "Batch-200: NLLLoss=0.0047 | F1Score=0.9978\n",
      "Batch-250: NLLLoss=0.0043 | F1Score=0.9981\n",
      "Batch-300: NLLLoss=0.0031 | F1Score=0.9982\n",
      "Batch-350: NLLLoss=0.0093 | F1Score=0.9983\n",
      "Batch-400: NLLLoss=0.0068 | F1Score=0.9984\n",
      "Batch-450: NLLLoss=0.0636 | F1Score=0.9985\n",
      "Batch-500: NLLLoss=0.0044 | F1Score=0.9985\n",
      "Batch-518: NLLLoss=0.0022 | F1Score=0.9986\n",
      "\n",
      "Yeah ðŸŽ‰ðŸ˜„! Model improved.\n",
      "Mean NLLLoss: 0.0123 | Mean F1Score: 0.9981\n",
      "==================================================\n",
      "\n",
      "EPOCH-16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91e7a1d88fac40bf9094b8d1eb32f17f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=0.0013 | F1Score=0.9994\n",
      "Batch-100: NLLLoss=0.0044 | F1Score=0.9997\n",
      "Batch-150: NLLLoss=0.0205 | F1Score=0.9998\n",
      "Batch-200: NLLLoss=0.0050 | F1Score=0.9998\n",
      "Batch-250: NLLLoss=0.0008 | F1Score=0.9999\n",
      "Batch-300: NLLLoss=0.0008 | F1Score=0.9999\n",
      "Batch-350: NLLLoss=0.0087 | F1Score=0.9998\n",
      "Batch-400: NLLLoss=0.0012 | F1Score=0.9998\n",
      "Batch-450: NLLLoss=0.0020 | F1Score=0.9999\n",
      "Batch-500: NLLLoss=0.0016 | F1Score=0.9999\n",
      "Batch-518: NLLLoss=0.0024 | F1Score=0.9999\n",
      "\n",
      "Yeah ðŸŽ‰ðŸ˜„! Model improved.\n",
      "Mean NLLLoss: 0.0020 | Mean F1Score: 0.9998\n",
      "==================================================\n",
      "\n",
      "EPOCH-17\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdefe75170f348dba43f76132c3d9d5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=0.0015 | F1Score=1.0000\n",
      "Batch-100: NLLLoss=0.0017 | F1Score=1.0000\n",
      "Batch-150: NLLLoss=0.0010 | F1Score=1.0000\n",
      "Batch-200: NLLLoss=0.0006 | F1Score=1.0000\n",
      "Batch-250: NLLLoss=0.0011 | F1Score=1.0000\n",
      "Batch-300: NLLLoss=0.0012 | F1Score=0.9999\n",
      "Batch-350: NLLLoss=0.0012 | F1Score=1.0000\n",
      "Batch-400: NLLLoss=0.0019 | F1Score=1.0000\n",
      "Batch-450: NLLLoss=0.0009 | F1Score=0.9998\n",
      "Batch-500: NLLLoss=0.0006 | F1Score=0.9998\n",
      "Batch-518: NLLLoss=0.0009 | F1Score=0.9998\n",
      "\n",
      "Yeah ðŸŽ‰ðŸ˜„! Model improved.\n",
      "Mean NLLLoss: 0.0016 | Mean F1Score: 1.0000\n",
      "==================================================\n",
      "\n",
      "EPOCH-18\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cf1bb59257f4ae18e7803b7b55c132a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=0.0010 | F1Score=1.0000\n",
      "Batch-100: NLLLoss=0.0010 | F1Score=0.9998\n",
      "Batch-150: NLLLoss=0.0010 | F1Score=0.9999\n",
      "Batch-200: NLLLoss=0.0015 | F1Score=0.9999\n",
      "Batch-250: NLLLoss=0.0011 | F1Score=0.9998\n",
      "Batch-300: NLLLoss=0.0006 | F1Score=0.9998\n",
      "Batch-350: NLLLoss=0.0009 | F1Score=0.9999\n",
      "Batch-400: NLLLoss=0.0007 | F1Score=0.9999\n",
      "Batch-450: NLLLoss=0.0016 | F1Score=0.9999\n",
      "Batch-500: NLLLoss=0.0012 | F1Score=0.9999\n",
      "Batch-518: NLLLoss=0.0007 | F1Score=0.9999\n",
      "\n",
      "Yeah ðŸŽ‰ðŸ˜„! Model improved.\n",
      "Mean NLLLoss: 0.0012 | Mean F1Score: 0.9999\n",
      "==================================================\n",
      "\n",
      "EPOCH-19\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a0771edfab84cdb9aee432f26b22dd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=0.0007 | F1Score=1.0000\n",
      "Batch-100: NLLLoss=0.0009 | F1Score=0.9997\n",
      "Batch-150: NLLLoss=0.0010 | F1Score=0.9998\n",
      "Batch-200: NLLLoss=0.0006 | F1Score=0.9998\n",
      "Batch-250: NLLLoss=0.0007 | F1Score=0.9999\n",
      "Batch-300: NLLLoss=0.0008 | F1Score=0.9999\n",
      "Batch-350: NLLLoss=0.0021 | F1Score=0.9997\n",
      "Batch-400: NLLLoss=0.0013 | F1Score=0.9997\n",
      "Batch-450: NLLLoss=0.0011 | F1Score=0.9998\n",
      "Batch-500: NLLLoss=0.0014 | F1Score=0.9997\n",
      "Batch-518: NLLLoss=0.0016 | F1Score=0.9997\n",
      "\n",
      "Huft ðŸ˜¥! Model not improved.\n",
      "Mean NLLLoss: 0.0013 | Mean F1Score: 0.9998\n",
      "Patience = 4/20â—\n",
      "==================================================\n",
      "\n",
      "EPOCH-20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af089481a953484fa713c3fef160b759",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-50 : NLLLoss=0.0005 | F1Score=0.9997\n",
      "Batch-100: NLLLoss=0.0016 | F1Score=0.9994\n",
      "Batch-150: NLLLoss=0.0008 | F1Score=0.9994\n",
      "Batch-200: NLLLoss=0.0013 | F1Score=0.9995\n",
      "Batch-250: NLLLoss=0.0006 | F1Score=0.9995\n",
      "Batch-300: NLLLoss=0.0017 | F1Score=0.9995\n",
      "Batch-350: NLLLoss=0.0024 | F1Score=0.9996\n",
      "Batch-400: NLLLoss=0.0005 | F1Score=0.9996\n",
      "Batch-450: NLLLoss=0.0009 | F1Score=0.9997\n",
      "Batch-500: NLLLoss=0.0011 | F1Score=0.9996\n",
      "Batch-518: NLLLoss=0.0027 | F1Score=0.9995\n",
      "\n",
      "Huft ðŸ˜¥! Model not improved.\n",
      "Mean NLLLoss: 0.0035 | Mean F1Score: 0.9996\n",
      "Patience = 5/20â—\n",
      "==================================================\n",
      "\n",
      "TRAINING SUMMARY\n",
      "Best NLLLoss      : 0.0012\n",
      "Best F1Score      : 0.9999\n",
      "Training duration : 21.721 minutes.\n",
      "Training date     : 2022-10-11 11:34:47.983464+08:00\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def looping_step(dataloader, model, optimizer, criterion, metric, n_epoch=hyperparams.n_epoch, patience=hyperparams.patience, monitor=\"loss\"):    \n",
    "    start_time = time()\n",
    "    \n",
    "    epoch_losses = []\n",
    "    epoch_metric_scores = []\n",
    "    patience_counter = 0\n",
    "    \n",
    "    now = datetime.now(pytz.timezone(\"Asia/Ujung_Pandang\"))\n",
    "    path_name = now.strftime(\"%m-%d-%Y_%H-%M-%S\")\n",
    "    os.makedirs(f\"../../logs/comick/{hyperparams.context_size}_contexts/{path_name}\")\n",
    "    \n",
    "    # Hyperparameters\n",
    "    with open(f\"../../logs/comick/{hyperparams.context_size}_contexts/{path_name}/training_history.txt\", \"a\") as f:\n",
    "        f.write(f\"HYPERPARAMETERS\\n\")\n",
    "        f.write(f\"{'-' * 50}\\n\")\n",
    "        for name, value in vars(hyperparams).items():\n",
    "            f.write(f\"{name}: {value}\\n\")\n",
    "        \n",
    "        f.write(\"\\n\\nTRAINING PROGRESS\\n\")\n",
    "        f.write(f\"{'-' * 50}\\n\")\n",
    "    \n",
    "    # Training Progress\n",
    "    for epoch in range(1, n_epoch + 1):\n",
    "        print(f\"EPOCH-{epoch}\")\n",
    "        with open(f\"../../logs/comick/{hyperparams.context_size}_contexts/{path_name}/training_history.txt\", \"a\") as f:\n",
    "            f.write(f\"EPOCH-{epoch}\\n\")\n",
    "        \n",
    "        batch_losses, batch_metric_scores = training_step(dataloader, model, optimizer, criterion, metric, path_name=path_name)\n",
    "        epoch_loss = torch.mean(torch.FloatTensor(batch_losses))\n",
    "\n",
    "        epoch_loss = torch.mean(torch.FloatTensor(batch_losses))\n",
    "        epoch_losses.append(epoch_loss.item())\n",
    "\n",
    "        epoch_metric_score = torch.mean(torch.FloatTensor(batch_metric_scores))\n",
    "        epoch_metric_scores.append(epoch_metric_score.item())\n",
    "        \n",
    "        with open(f\"../../logs/comick/{hyperparams.context_size}_contexts/{path_name}/training_history.txt\", \"a\") as f:\n",
    "            if monitor == \"loss\":\n",
    "                if epoch == 1:\n",
    "                    best_state_dict = model.state_dict()\n",
    "                    best_loss = (epoch_loss)\n",
    "                    best_metric = (epoch_metric_score)\n",
    "                    \n",
    "                    print(f\"\\nMean {str(criterion).split('(')[0]}: {(epoch_loss):.4f} | Mean {str(metric).split('(')[0]}: {(epoch_metric_score):.4f}\")\n",
    "                    \n",
    "                    f.write(f\"\\nMean {str(criterion).split('(')[0]}: {(epoch_loss):.4f} | Mean {str(metric).split('(')[0]}: {(epoch_metric_score):.4f}\\n\")\n",
    "                elif epoch_losses[-1] < epoch_losses[-2]:\n",
    "                    best_state_dict = model.state_dict()\n",
    "                    best_loss = (epoch_loss)\n",
    "                    best_metric = (epoch_metric_score)\n",
    "                    \n",
    "                    print(\"\\nYeah ðŸŽ‰ðŸ˜„! Model improved.\")\n",
    "                    print(f\"Mean {str(criterion).split('(')[0]}: {(epoch_loss):.4f} | Mean {str(metric).split('(')[0]}: {(epoch_metric_score):.4f}\")\n",
    "                    \n",
    "                    f.write(\"\\nYeah ðŸŽ‰ðŸ˜„! Model improved.\\n\")\n",
    "                    f.write(f\"Mean {str(criterion).split('(')[0]}: {(epoch_loss):.4f} | Mean {str(metric).split('(')[0]}: {(epoch_metric_score):.4f}\\n\")\n",
    "                else:\n",
    "                    patience_counter += 1\n",
    "                    \n",
    "                    print(\"\\nHuft ðŸ˜¥! Model not improved.\")\n",
    "                    print(f\"Mean {str(criterion).split('(')[0]}: {(epoch_loss):.4f} | Mean {str(metric).split('(')[0]}: {(epoch_metric_score):.4f}\")\n",
    "                    print(f\"Patience = {patience_counter}/{patience}â—\")\n",
    "                    \n",
    "                    f.write(\"\\nHuft ðŸ˜¥! Model not improved.\\n\")\n",
    "                    f.write(f\"Mean {str(criterion).split('(')[0]}: {(epoch_loss):.4f} | Mean {str(metric).split('(')[0]}: {(epoch_metric_score):.4f}\\n\")                    \n",
    "                    f.write(f\"Patience = {patience_counter}/{patience}â—\\n\")\n",
    "            else:\n",
    "                if epoch == 1:\n",
    "                    best_state_dict = model.state_dict()\n",
    "                    best_loss = (epoch_loss)\n",
    "                    best_metric = (epoch_metric_score)\n",
    "                    \n",
    "                    print(f\"\\nMean {str(criterion).split('(')[0]}: {(epoch_loss):.4f} | Mean {str(metric).split('(')[0]}: {(epoch_metric_score):.4f}\")\n",
    "                    \n",
    "                    f.write(f\"\\nMean {str(criterion).split('(')[0]}: {(epoch_loss):.4f} | Mean {str(metric).split('(')[0]}: {(epoch_metric_score):.4f}\\n\")\n",
    "                elif epoch_metric_scores[-1] > epoch_metric_scores[-2]:\n",
    "                    best_state_dict = model.state_dict()\n",
    "                    best_loss = (epoch_loss)\n",
    "                    best_metric = (epoch_metric_score)\n",
    "                    \n",
    "                    print(\"\\nYeah ðŸŽ‰ðŸ˜„! Model improved.\")\n",
    "                    print(f\"Mean {str(criterion).split('(')[0]}: {(epoch_loss):.4f} | Mean Mean {str(metric).split('(')[0]}: {(epoch_metric_score):.4f}\")\n",
    "                    \n",
    "                    f.write(\"\\nYeah ðŸŽ‰ðŸ˜„! Model improved.\\n\")\n",
    "                    f.write(f\"Mean {str(criterion).split('(')[0]}: {(epoch_loss):.4f} | Mean {str(metric).split('(')[0]}: {(epoch_metric_score):.4f}\\n\")\n",
    "                else:\n",
    "                    patience_counter += 1\n",
    "                    \n",
    "                    print(\"\\nHuft ðŸ˜¥! Model not improved.\")\n",
    "                    print(f\"Mean {str(criterion).split('(')[0]}: {(epoch_loss):.4f} | Mean {str(metric).split('(')[0]}: {(epoch_metric_score):.4f}\\n\")\n",
    "                    print(f\"Patience = {patience_counter}/{patience}â—\\n\")\n",
    "                    \n",
    "                    f.write(\"\\nHuft ðŸ˜¥! Model not improved.\\n\")\n",
    "                    f.write(f\"Mean {str(criterion).split('(')[0]}: {(epoch_loss):.4f} | Mean {str(metric).split('(')[0]}: {(epoch_metric_score):.4f}\\n\")\n",
    "                    f.write(f\"Patience = {patience_counter}/{patience}â—\\n\")\n",
    "                    \n",
    "            print(\"=\" * 50, end=\"\\n\\n\")\n",
    "            f.write(f\"{'=' * 50}\\n\\n\")\n",
    "            \n",
    "            if patience_counter == patience:\n",
    "                print(f\"Early stopping, patience = {patience_counter}/{patience}â—\\n\")\n",
    "                f.write(f\"Early stopping, patience = {patience_counter}/{patience}â—\\n\")\n",
    "                break\n",
    "        \n",
    "        metric.reset()\n",
    "    \n",
    "    finish_time = time()\n",
    "    \n",
    "    # Training plot \n",
    "    fig, (ax_loss, ax_metric_score) = plt.subplots(nrows=1, ncols=2, figsize=(15, 5))\n",
    "\n",
    "    fig.suptitle(f\"Training with context size = {hyperparams.context_size}\")\n",
    "\n",
    "    ax_loss.set_title(\"Loss\")\n",
    "    ax_loss.set_xlabel(\"Epoch\")\n",
    "    ax_loss.set_ylabel(\"Score\")\n",
    "    ax_loss.plot(epoch_losses, \"green\")\n",
    "    ax_loss.grid()\n",
    "\n",
    "    ax_metric_score.set_title(\"F1 Score\")\n",
    "    ax_metric_score.set_xlabel(\"Epoch\")\n",
    "    ax_metric_score.set_ylabel(\"Score\")\n",
    "    ax_metric_score.plot(epoch_metric_scores, \"orange\")\n",
    "    ax_metric_score.grid()\n",
    "\n",
    "    plt.savefig(f\"../../logs/comick/{hyperparams.context_size}_contexts/{path_name}/training_plot.jpg\", dpi=200)                        \n",
    "    \n",
    "    print(\"TRAINING SUMMARY\")\n",
    "    criterion_name = \"Best \" + str(criterion).split('(')[0]\n",
    "    metric_name = \"Best \" + str(metric).split('(')[0]\n",
    "    \n",
    "    print(f\"{criterion_name.ljust(18)}: {best_loss:.4f}\")\n",
    "    print(f\"{metric_name.ljust(18)}: {best_metric:.4f}\")\n",
    "    print(f\"{'Training duration'.ljust(18)}: {((finish_time - start_time) / 60):.3f} minutes.\")\n",
    "    print(f\"{'Training date'.ljust(18)}: {now}\")\n",
    "    \n",
    "    with open(f\"../../logs/comick/{hyperparams.context_size}_contexts/{path_name}/training_history.txt\", \"a\") as f:\n",
    "        f.write(\"\\nTRAINING SUMMARY\\n\")\n",
    "        f.write(f\"{'-' * 50}\\n\")\n",
    "        f.write(f\"{criterion_name.ljust(18)}: {best_loss:.4f}\\n\")\n",
    "        f.write(f\"{metric_name.ljust(18)}: {best_metric:.4f}\\n\")\n",
    "        f.write(f\"{'Training duration'.ljust(18)}: {((finish_time - start_time) / 60):.3f} minutes.\\n\")\n",
    "        f.write(f\"{'Training date'.ljust(18)}: {now}\\n\")\n",
    "    \n",
    "    # Save epoch losses, epoch metric scores, model, state dict, and oov embedding dict\n",
    "    filename_model_params = f\"../../logs/comick/{hyperparams.context_size}_contexts/{path_name}/model_params.pth\"\n",
    "    filename_oov_embedding_dict = open(f\"../../logs/comick/{hyperparams.context_size}_contexts/{path_name}/oov_embedding_dict.pkl\", \"ab\")\n",
    "    \n",
    "    pd.DataFrame(\n",
    "        data={\n",
    "            \"epoch\": list(range(1, len(epoch_losses) + 1)),\n",
    "            \"loss\": epoch_losses\n",
    "        }\n",
    "    ).to_csv(f\"../../logs/comick/{hyperparams.context_size}_contexts/{path_name}/epoch_losses.csv\", index=False)\n",
    "    \n",
    "    pd.DataFrame(\n",
    "        data={\n",
    "            \"epoch\": list(range(1, len(epoch_metric_scores) + 1)),\n",
    "            \"f1_score\": epoch_metric_scores\n",
    "        }\n",
    "    ).to_csv(f\"../../logs/comick/{hyperparams.context_size}_contexts/{path_name}/epoch_metric_scores.csv\", index=False)\n",
    "    \n",
    "    torch.save(best_state_dict, filename_model_params)\n",
    "    pickle.dump({token : embedding for token, embedding in zip(list(labels_to_idx.keys()), model.embedding)}, filename_oov_embedding_dict)\n",
    "    \n",
    "    return epoch_losses, epoch_metric_scores\n",
    "\n",
    "epoch_losses, epoch_metric_scores = looping_step(dataloader, model, optimizer, criterion, metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfef50c-e71c-4288-a9f3-6fd8831033b0",
   "metadata": {},
   "source": [
    "# END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92debcb3-d6ea-4299-a3e9-37be5b63d2b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.240182  , -2.58694   , -2.325591  , ...,  2.127207  ,\n",
       "         2.9860823 ,  3.769742  ],\n",
       "       [-0.19076535, -2.2472458 ,  6.5896807 , ...,  2.0483723 ,\n",
       "         1.8878412 ,  0.38142273],\n",
       "       [-3.202799  , -2.3245232 ,  5.219937  , ..., -0.09933946,\n",
       "         0.6275703 , -0.5291314 ],\n",
       "       ...,\n",
       "       [ 0.86392426,  1.0079362 , -0.27138656, ..., -1.1736001 ,\n",
       "        -5.03642   , -7.9797435 ],\n",
       "       [ 1.8164444 , -0.9626991 , -5.253956  , ...,  4.703753  ,\n",
       "        -1.7967918 , -1.1990857 ],\n",
       "       [ 4.353201  , -0.5155281 ,  6.64803   , ...,  1.9702537 ,\n",
       "        -2.6974626 ,  3.6210704 ]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27ce78c3-ac2c-4a84-a8e8-4d8e85d26563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('bilstm_left_context_feature.weight_ih_l0',\n",
       "              tensor([[-0.1290, -0.0399,  0.4547,  ...,  0.1357,  0.0728, -0.4019],\n",
       "                      [-0.0408,  0.4714, -0.2353,  ..., -0.1084, -0.0359, -0.4547],\n",
       "                      [ 0.1179, -0.1528,  0.3386,  ..., -0.4945,  0.2738, -0.2103],\n",
       "                      ...,\n",
       "                      [ 0.2050, -0.1286,  0.0833,  ..., -0.1802, -0.0137, -0.2195],\n",
       "                      [-0.0473, -0.0474,  0.0129,  ...,  0.1488, -0.1149, -0.0763],\n",
       "                      [ 0.4812,  0.1022,  0.4288,  ...,  0.1392, -0.0710, -0.2928]])),\n",
       "             ('bilstm_left_context_feature.weight_hh_l0',\n",
       "              tensor([[-0.2266, -0.1427,  0.0995,  ...,  0.2183,  0.0083, -0.1749],\n",
       "                      [-0.0448, -0.2028, -0.0414,  ...,  0.1205, -0.0916,  0.0997],\n",
       "                      [-0.0153, -0.1904, -0.0372,  ...,  0.0472, -0.3141, -0.0431],\n",
       "                      ...,\n",
       "                      [ 0.2459,  0.0664,  0.1019,  ..., -0.0975, -0.1314,  0.1895],\n",
       "                      [-0.2198,  0.0055,  0.2071,  ...,  0.1909, -0.1784, -0.2600],\n",
       "                      [-0.3325,  0.4980, -0.2472,  ..., -0.0866,  0.2424,  0.2308]])),\n",
       "             ('bilstm_left_context_feature.bias_ih_l0',\n",
       "              tensor([ 9.4272e-02, -4.5982e-02,  1.3540e-01, -4.0094e-02, -6.8133e-02,\n",
       "                       1.1827e-02, -9.4657e-02, -1.1358e-01,  5.8807e-02, -9.3030e-02,\n",
       "                       4.7063e-02, -3.1473e-02, -3.7083e-02, -8.9923e-02, -1.4215e-01,\n",
       "                      -6.7639e-02,  7.8485e-02, -6.5556e-02, -3.7651e-02, -7.7137e-02,\n",
       "                      -5.0876e-02,  1.0305e-02, -7.2360e-02, -1.2689e-01, -4.4228e-02,\n",
       "                      -1.7346e-02, -5.2569e-03, -2.8918e-02,  1.3509e-01,  1.7076e-03,\n",
       "                      -7.3862e-02, -1.6880e-01,  5.6276e-02,  4.5428e-02, -3.4256e-02,\n",
       "                      -3.2725e-02,  6.1566e-02,  5.0705e-04, -2.7816e-03,  4.7218e-02,\n",
       "                      -1.2992e-01, -1.0208e-01, -8.5604e-03,  1.1917e-03, -6.8992e-02,\n",
       "                      -1.2095e-01,  1.6250e-01, -8.8192e-02,  1.5695e-01, -4.2314e-02,\n",
       "                       8.8124e-03, -6.6413e-02, -1.5313e-01,  5.4881e-02, -1.9424e-03,\n",
       "                       1.7265e-01, -1.0092e-01,  7.3958e-03, -7.2248e-02, -5.6995e-03,\n",
       "                       1.7566e-03,  5.2751e-02, -2.2220e-02, -1.1797e-01, -1.7829e-01,\n",
       "                      -3.9807e-02, -1.1443e-01, -1.6504e-01, -1.7402e-01, -9.2907e-02,\n",
       "                      -2.4323e-01,  1.6448e-01, -1.8115e-01,  1.6523e-01, -4.0666e-03,\n",
       "                       6.6009e-02, -9.8454e-03, -7.1858e-03,  6.6873e-04,  3.4873e-02,\n",
       "                      -2.8858e-02, -9.9544e-03, -8.4261e-02,  5.0651e-02, -1.1397e-01,\n",
       "                      -7.6486e-03,  1.1595e-01,  3.8442e-02, -3.5609e-02,  7.9998e-03,\n",
       "                       9.0390e-02,  3.4973e-02, -7.1148e-02, -6.5679e-02,  4.3486e-02,\n",
       "                      -7.3248e-03, -4.6470e-03,  6.5762e-02, -1.9416e-01,  4.5631e-02,\n",
       "                      -7.5589e-02,  4.5679e-02, -6.9538e-02, -1.4370e-02,  9.6630e-02,\n",
       "                      -5.9614e-02, -1.9945e-01, -4.2076e-02, -6.3987e-03, -1.5167e-01,\n",
       "                      -1.5811e-01, -6.5108e-02, -1.5701e-01, -1.9135e-01,  5.2134e-02,\n",
       "                      -1.8954e-01, -6.1232e-02, -1.0218e-01, -1.8638e-01, -1.1364e-02,\n",
       "                       3.1272e-02, -1.1209e-01,  8.0753e-02,  3.1833e-02,  3.7239e-02,\n",
       "                      -1.6924e-01, -4.5366e-02, -1.5240e-01, -3.5183e-02,  6.3477e-03,\n",
       "                      -8.8249e-02, -1.8642e-01, -2.0347e-01, -1.0559e-01, -1.3081e-01,\n",
       "                      -1.0779e-01, -3.0738e-02,  2.2180e-02, -2.5838e-02, -1.5118e-01,\n",
       "                      -1.5212e-01, -9.4381e-02, -1.0414e-01,  1.5680e-02, -3.2939e-04,\n",
       "                       1.4678e-01, -1.1989e-01,  4.9888e-02, -1.0057e-01, -1.1421e-01,\n",
       "                      -2.3287e-02, -4.6229e-02, -8.3022e-02, -3.7756e-02, -9.4502e-02,\n",
       "                       9.2677e-03, -1.0384e-01, -6.4885e-02,  1.2799e-01, -1.7379e-01,\n",
       "                      -7.4598e-02, -1.0992e-01,  1.0815e-01, -2.3842e-03,  7.4543e-02,\n",
       "                      -1.1047e-01, -3.8801e-02, -1.4057e-01, -2.8775e-03, -1.1901e-01,\n",
       "                       1.3396e-02,  7.8252e-02, -1.7724e-02, -1.3085e-01, -9.2954e-03,\n",
       "                      -2.1528e-03,  3.3387e-02, -1.2207e-02, -5.6284e-02, -1.4258e-01,\n",
       "                       1.1682e-03, -1.5205e-02, -1.0807e-01, -7.1368e-02, -1.3129e-01,\n",
       "                      -1.0827e-01, -1.7939e-01, -1.0704e-01, -1.1569e-01,  4.1530e-02,\n",
       "                       2.6035e-02,  5.3010e-03, -2.7532e-03, -8.9876e-02,  7.0937e-03,\n",
       "                      -2.0912e-02, -4.8313e-02, -3.0089e-02, -1.6549e-01, -1.9414e-02,\n",
       "                       3.1649e-02, -3.0573e-02, -8.1996e-02,  3.9431e-02,  6.9799e-02,\n",
       "                      -1.1271e-03,  4.4865e-02, -1.1845e-01,  8.0830e-02,  1.5955e-02,\n",
       "                       4.1757e-02, -4.5886e-02, -1.3597e-02, -1.5953e-02,  1.0947e-04,\n",
       "                      -5.3356e-02, -3.6657e-02, -5.6879e-02, -8.2090e-02, -5.1243e-02,\n",
       "                      -6.7108e-02,  6.2608e-02, -1.4709e-02,  3.1865e-02, -3.2403e-01,\n",
       "                      -1.3570e-01,  1.2784e-01, -3.2464e-02, -1.1364e-01, -1.0596e-02,\n",
       "                      -3.4513e-02, -4.5510e-02, -1.0426e-01,  3.6269e-02, -1.3129e-01,\n",
       "                       1.0350e-01,  1.3603e-03, -1.2868e-01, -7.8181e-02, -9.3772e-02,\n",
       "                      -1.1911e-01, -4.6756e-02, -1.3668e-01, -9.8419e-02,  1.6328e-02,\n",
       "                      -4.4528e-02, -3.5594e-02,  2.8983e-02, -9.4693e-02,  1.2942e-01,\n",
       "                      -4.8667e-02, -1.1232e-01,  1.1925e-01, -6.2074e-02, -6.1718e-02,\n",
       "                      -9.1521e-02, -1.7857e-02,  1.6203e-02, -3.7875e-02,  5.8686e-02,\n",
       "                      -2.6405e-02,  2.7559e-03, -1.4300e-02,  1.3873e-01, -1.0618e-01,\n",
       "                       3.4841e-02,  1.8167e-01,  1.8072e-03, -9.7911e-02, -8.3019e-02,\n",
       "                      -5.3978e-02, -2.6874e-02, -5.3825e-02,  2.4026e-02,  1.0918e-02,\n",
       "                      -4.9685e-02,  2.9251e-02, -1.0348e-02, -4.9411e-02, -2.8381e-02,\n",
       "                      -4.6144e-03,  4.1657e-02, -5.6898e-02,  6.6635e-02, -6.4619e-02,\n",
       "                      -3.4127e-02, -5.3517e-03, -4.5981e-02,  1.0945e-01,  7.4653e-02,\n",
       "                      -1.1862e-01, -8.3283e-02, -2.2226e-03,  8.5619e-02, -6.4797e-02,\n",
       "                      -2.2437e-02,  4.0249e-02, -5.2951e-03,  5.2790e-02,  1.3284e-02,\n",
       "                      -2.8030e-02, -6.0392e-02,  1.8013e-02,  4.7964e-02,  7.4483e-02,\n",
       "                       1.0827e-01, -2.5017e-02,  2.3443e-02,  5.6343e-03,  4.2883e-02,\n",
       "                       3.5985e-02, -1.0255e-01, -2.8377e-02,  2.5333e-02, -7.2805e-02,\n",
       "                       7.2926e-02,  2.1608e-02, -1.5765e-02,  2.0987e-02,  9.8459e-02,\n",
       "                      -1.3136e-02,  1.3774e-02, -7.6414e-02,  6.1765e-03, -5.3541e-02,\n",
       "                      -2.1613e-02,  5.8287e-02,  2.1667e-02, -1.9474e-02, -4.5714e-02,\n",
       "                       1.5386e-03,  3.6986e-02, -7.6325e-04,  2.2268e-02, -2.2633e-02,\n",
       "                       3.4299e-02, -1.0734e-02,  5.1028e-02, -4.0276e-02, -2.6672e-02,\n",
       "                       4.9090e-02, -4.9106e-02, -6.7888e-02, -6.1263e-02, -4.9359e-02,\n",
       "                       3.2527e-02,  2.7925e-02,  8.2577e-02, -5.3101e-02,  2.5782e-02,\n",
       "                       5.0493e-02,  7.3054e-02, -1.3982e-04,  2.7348e-04, -4.6970e-02,\n",
       "                      -4.7417e-03, -2.4514e-03, -3.7208e-02, -5.1862e-02, -4.2692e-02,\n",
       "                      -8.8397e-02,  3.2176e-02, -4.0013e-02, -2.9338e-02,  2.7903e-02,\n",
       "                      -2.5136e-02,  5.6406e-02, -2.4372e-02,  2.0223e-02,  6.8981e-02,\n",
       "                       6.7391e-02, -1.1658e-01,  1.9954e-01, -6.9034e-02,  8.7696e-02,\n",
       "                      -1.2294e-01, -5.7519e-02, -1.4594e-01, -3.1233e-02,  1.4584e-01,\n",
       "                       5.4465e-02, -6.0804e-03,  2.6543e-02,  4.6959e-02,  9.2487e-02,\n",
       "                       8.9547e-02,  8.0472e-02, -2.6501e-02, -1.2464e-01,  1.5415e-01,\n",
       "                      -7.8994e-02, -5.6985e-02,  8.7441e-02, -9.0732e-02,  1.0935e-01,\n",
       "                      -1.2933e-01, -1.3239e-02,  1.5391e-02, -1.0066e-01,  3.5363e-02,\n",
       "                      -2.9983e-02, -3.4284e-02, -3.0618e-02, -9.0899e-03, -3.9302e-02,\n",
       "                       8.2530e-02, -1.1353e-01, -1.4637e-02, -2.0542e-02,  8.2697e-02,\n",
       "                      -1.0318e-02, -9.4995e-02,  2.7360e-01,  5.1382e-02, -7.0608e-02,\n",
       "                       9.6974e-04,  1.5863e-02,  1.0983e-01,  7.2086e-02,  1.7024e-02,\n",
       "                       2.4358e-02,  7.2351e-03,  4.6749e-02,  1.2918e-01, -7.2344e-02,\n",
       "                      -6.1276e-02,  8.5808e-02, -5.0305e-02,  9.5511e-02, -1.2280e-01,\n",
       "                       3.4389e-02, -1.3023e-01,  1.4471e-01,  1.9978e-01,  3.4106e-02,\n",
       "                       4.6096e-02, -1.4074e-01,  6.1905e-02, -2.0504e-02,  7.3036e-02,\n",
       "                      -1.1081e-01,  2.8923e-02, -2.3007e-01, -5.2967e-02,  2.3520e-02,\n",
       "                      -7.5938e-04, -2.2176e-02,  2.3127e-02,  9.3358e-03,  2.6838e-02,\n",
       "                      -7.4065e-03,  4.1162e-03, -1.6382e-02, -1.1323e-01, -1.8646e-01,\n",
       "                       1.4864e-01, -1.7881e-01,  1.2313e-01, -2.4625e-02, -7.4968e-02,\n",
       "                       4.7518e-02, -1.8074e-01, -2.3629e-02,  4.1868e-03, -5.6510e-02,\n",
       "                       3.3559e-02, -4.3114e-02,  9.6753e-02,  5.8360e-02,  1.9785e-01,\n",
       "                      -4.2980e-02,  2.0793e-02, -1.1052e-01, -9.3896e-02,  8.1514e-02,\n",
       "                       1.1963e-01,  5.9575e-02, -1.9246e-02,  2.1659e-02,  9.6664e-02,\n",
       "                      -2.5095e-02,  1.1472e-01,  2.4020e-02, -1.7655e-02, -1.2662e-02,\n",
       "                       1.9296e-02,  8.0880e-02,  7.6109e-02,  1.0449e-02,  8.5888e-02,\n",
       "                      -8.9286e-02, -7.4618e-02, -1.1653e-01, -2.7881e-02, -1.4123e-01,\n",
       "                      -4.2273e-02, -2.7791e-02, -6.9269e-02,  3.9485e-03, -5.1464e-02,\n",
       "                      -3.8325e-02, -5.9741e-03,  8.9263e-02, -2.5963e-02,  5.8799e-02,\n",
       "                       9.5242e-02,  1.5838e-01, -1.1034e-01,  5.4439e-02, -1.1361e-02,\n",
       "                       4.4927e-02, -1.4745e-01])),\n",
       "             ('bilstm_left_context_feature.bias_hh_l0',\n",
       "              tensor([-5.4474e-02, -1.2603e-02,  4.7656e-02, -3.5028e-02, -6.5649e-02,\n",
       "                       4.1604e-02, -6.0017e-02,  2.5916e-02,  1.9809e-02,  3.1950e-02,\n",
       "                      -3.6125e-02, -2.2817e-02, -5.2716e-02, -1.2391e-01, -6.3150e-02,\n",
       "                      -1.5860e-01, -2.5310e-02, -1.2885e-01, -9.4988e-02, -1.0961e-01,\n",
       "                      -5.0136e-02, -1.4098e-02, -6.0776e-02, -1.7815e-01, -5.9133e-02,\n",
       "                       3.4244e-02, -2.1190e-02, -7.1915e-02,  1.6541e-01, -1.2894e-01,\n",
       "                       1.4248e-02,  2.2790e-02, -2.9117e-02, -1.0520e-01,  5.0803e-02,\n",
       "                      -9.5737e-02,  1.8699e-02,  3.5295e-02, -1.0242e-01, -2.7823e-02,\n",
       "                      -5.7953e-03, -7.0192e-02, -8.5477e-03,  6.0056e-02,  3.5606e-02,\n",
       "                       4.1259e-02,  1.4494e-01, -3.2817e-02,  8.9457e-02,  3.3579e-02,\n",
       "                       1.5116e-03,  4.0952e-02,  8.6508e-02, -1.9365e-02, -7.7690e-03,\n",
       "                       9.0368e-02, -1.4489e-02, -1.0513e-01,  1.7477e-02, -3.1490e-02,\n",
       "                       9.3805e-03,  4.0060e-02, -8.0433e-06, -8.1296e-02, -1.2246e-01,\n",
       "                      -1.1757e-01, -1.7931e-01, -1.2625e-01, -1.7887e-01, -9.1430e-02,\n",
       "                      -6.0062e-02,  2.9884e-02, -1.0947e-01,  6.0048e-02,  2.2990e-02,\n",
       "                      -2.5581e-02, -1.1740e-01, -1.8636e-02,  9.1483e-02,  4.4321e-02,\n",
       "                      -4.5219e-02, -1.9976e-04, -1.7581e-01,  2.7652e-02, -1.0858e-01,\n",
       "                      -3.0102e-02,  3.3273e-02,  2.0730e-02, -3.8313e-02,  1.1071e-01,\n",
       "                       3.2910e-02, -3.9695e-03, -1.2121e-01, -6.6925e-02,  1.3683e-02,\n",
       "                       1.8316e-01, -1.4967e-01, -2.6673e-01, -7.6755e-02,  9.7399e-02,\n",
       "                      -5.6762e-02,  1.3423e-01,  9.9250e-02,  8.7533e-02, -2.2921e-02,\n",
       "                       7.8442e-02, -1.8747e-01,  4.0313e-02, -3.7250e-02, -2.1691e-02,\n",
       "                      -8.8038e-02, -2.5468e-02, -7.2004e-02, -7.3893e-02, -4.9793e-03,\n",
       "                      -1.5618e-01, -7.9827e-02,  8.9151e-02, -1.4961e-01,  1.4805e-01,\n",
       "                       8.9238e-02,  1.2454e-01,  8.8586e-02, -5.3687e-02,  1.3436e-01,\n",
       "                      -1.4109e-01, -2.6213e-03, -3.6962e-02, -1.8415e-01,  7.6208e-03,\n",
       "                      -2.3065e-01, -3.9098e-02, -8.5457e-02, -5.5873e-02, -3.2363e-02,\n",
       "                      -8.0674e-02, -1.4043e-01, -1.5313e-01,  1.1785e-02, -6.9578e-02,\n",
       "                      -1.5905e-01,  9.0031e-02,  4.0269e-02,  1.1246e-01, -8.2706e-02,\n",
       "                       6.2445e-02,  2.3824e-02, -1.2824e-01, -1.0134e-01, -1.2254e-01,\n",
       "                      -1.0853e-01, -6.8703e-02, -8.3630e-02, -4.0671e-02, -5.7018e-02,\n",
       "                      -1.2862e-02,  8.5308e-02, -1.5543e-01, -5.2487e-03, -8.3130e-02,\n",
       "                      -2.6852e-02, -6.4393e-02,  1.6436e-02, -5.2288e-02,  4.7823e-02,\n",
       "                      -1.2649e-01, -1.2725e-01, -1.3234e-01, -1.2170e-01, -1.0824e-01,\n",
       "                      -6.2983e-02,  1.3166e-01, -7.0343e-02, -1.0431e-01, -7.2678e-02,\n",
       "                      -2.5166e-02, -4.3649e-02, -4.8405e-02, -5.4820e-02, -7.7392e-03,\n",
       "                      -5.7119e-02, -1.6569e-01, -1.4749e-01, -9.6922e-02, -9.7809e-02,\n",
       "                      -1.5236e-01, -8.8261e-02, -1.1535e-01,  1.0426e-02, -1.5177e-01,\n",
       "                       1.3237e-01,  6.4531e-02,  3.2877e-02, -1.0722e-01, -2.4284e-02,\n",
       "                      -9.3401e-03, -1.5706e-01, -1.0058e-01, -2.8878e-02,  2.1973e-02,\n",
       "                      -3.3355e-02,  1.8366e-01,  4.7984e-02,  3.8637e-02,  2.6672e-03,\n",
       "                      -5.4882e-03,  1.0533e-02, -3.2570e-02,  6.2052e-02, -4.8934e-02,\n",
       "                      -1.5067e-02,  5.5512e-03,  1.0118e-01, -3.0095e-02, -1.0965e-01,\n",
       "                      -3.9756e-02, -8.9644e-02, -2.3490e-02, -6.9993e-02, -6.9459e-02,\n",
       "                      -2.6402e-02,  1.1441e-01,  3.3310e-02, -1.0530e-02, -2.5074e-01,\n",
       "                      -9.8298e-02, -1.0246e-02,  7.1512e-02, -1.0852e-01, -2.0154e-01,\n",
       "                      -7.9272e-02, -6.6454e-02, -1.6210e-01,  6.6586e-02, -1.2610e-01,\n",
       "                      -6.2523e-02, -7.2307e-02, -4.9317e-02, -4.8061e-02, -3.9430e-02,\n",
       "                      -3.8536e-02, -1.1459e-01, -3.7226e-02,  6.2145e-02, -4.1864e-02,\n",
       "                      -4.9577e-02,  2.0764e-02, -3.2322e-02,  7.0033e-02,  9.1341e-03,\n",
       "                       4.7523e-02,  3.6873e-02,  3.5699e-03, -7.8118e-02, -2.0253e-02,\n",
       "                       5.4732e-03,  8.2790e-02, -2.2239e-02,  2.9555e-02, -5.1503e-02,\n",
       "                      -3.5156e-02,  4.3644e-02, -1.2045e-01,  1.7926e-02, -1.1457e-02,\n",
       "                       6.8200e-03, -6.8890e-02, -1.0066e-01, -3.4383e-02, -1.7666e-02,\n",
       "                      -6.0248e-05,  5.5901e-02,  1.4086e-03,  1.9125e-02,  1.3495e-02,\n",
       "                       4.1609e-02,  3.6393e-02,  2.6615e-02,  1.7060e-01,  2.3948e-02,\n",
       "                       3.2303e-03, -1.2778e-02,  1.1567e-01,  5.5526e-02,  7.1228e-02,\n",
       "                       7.5698e-02, -5.9941e-02, -7.2419e-02, -1.5423e-02, -2.6966e-02,\n",
       "                       6.6143e-03,  2.2968e-02,  6.1431e-03, -2.4143e-02,  6.5709e-02,\n",
       "                      -4.2207e-02, -3.9394e-02,  4.5357e-03, -1.1513e-01, -2.1309e-02,\n",
       "                      -4.4704e-02,  1.0419e-01,  5.0081e-02,  5.8525e-02,  5.1603e-02,\n",
       "                       7.9784e-02, -1.5926e-02,  9.0029e-03,  9.5192e-02, -4.7097e-02,\n",
       "                       1.5334e-01, -7.7790e-02,  1.4293e-02,  7.5057e-02, -6.3604e-02,\n",
       "                      -9.9963e-02,  1.4197e-01,  2.3970e-02,  5.4510e-02,  1.2236e-03,\n",
       "                      -2.6813e-02, -2.5553e-02,  1.4009e-02,  1.7824e-02, -1.7457e-02,\n",
       "                       1.4734e-02,  3.3561e-02, -6.9697e-02,  1.0508e-01, -4.4664e-02,\n",
       "                      -1.8167e-02,  1.1102e-01, -2.4396e-02, -2.2698e-02,  1.6347e-02,\n",
       "                       4.7470e-02, -1.0809e-02, -1.2635e-01,  9.3067e-02, -8.7187e-02,\n",
       "                       4.6025e-02, -5.5149e-02,  3.6831e-03, -4.2882e-02, -3.1460e-02,\n",
       "                       1.2910e-01, -1.1251e-01, -4.9004e-02, -1.2271e-02,  1.0653e-02,\n",
       "                      -4.7615e-02, -9.4155e-03,  5.8374e-02,  3.7140e-02,  1.0461e-01,\n",
       "                       2.8777e-02,  1.1506e-02, -7.7757e-02,  3.9506e-02,  1.9806e-02,\n",
       "                       1.4211e-02,  1.1606e-01, -4.9244e-02, -8.7749e-02,  6.5627e-02,\n",
       "                       6.2632e-02, -1.9546e-01,  3.2894e-02, -4.1474e-05,  1.0559e-02,\n",
       "                       1.1297e-02, -1.8713e-03,  3.8063e-02,  3.9388e-02,  1.6084e-02,\n",
       "                      -3.4060e-02,  5.6708e-03, -3.8134e-02,  2.1968e-02,  1.1062e-02,\n",
       "                      -1.3039e-01,  6.4613e-02, -4.8364e-02,  2.2515e-02, -3.6455e-02,\n",
       "                       6.3570e-02,  1.4995e-01, -6.9473e-02, -1.2847e-01,  1.9531e-01,\n",
       "                      -1.9804e-02,  1.1388e-02,  1.4529e-01, -3.0497e-02,  9.5406e-02,\n",
       "                      -7.1601e-02, -1.2570e-02, -4.1345e-02, -9.8849e-02,  2.3681e-02,\n",
       "                      -8.2071e-02, -1.1562e-02, -7.5231e-02, -2.1442e-03, -4.1665e-02,\n",
       "                      -2.4781e-02, -4.2356e-02, -8.1962e-02, -3.3682e-02, -2.9028e-02,\n",
       "                      -1.5934e-01,  2.2226e-02,  6.9797e-02,  7.6020e-02,  2.4948e-03,\n",
       "                      -1.6584e-01,  7.3045e-02, -3.5773e-02,  2.3708e-02,  6.8507e-02,\n",
       "                       1.4418e-01, -8.0502e-02,  5.2302e-02,  9.4016e-02,  2.1039e-02,\n",
       "                      -2.7207e-02,  1.9785e-01,  6.5383e-02,  3.4073e-02, -9.5999e-02,\n",
       "                       1.7403e-01, -4.6729e-03,  6.9321e-02,  1.0109e-01,  6.6852e-02,\n",
       "                       3.8129e-02, -4.2296e-02,  6.4453e-02,  7.5847e-02,  1.0164e-01,\n",
       "                      -1.1444e-01, -1.1285e-01, -6.9882e-02,  4.0092e-02,  1.0064e-01,\n",
       "                       1.2379e-01,  1.5442e-01, -2.6412e-02, -4.5973e-04, -8.1940e-02,\n",
       "                      -1.1131e-01, -1.0495e-01, -1.0781e-01, -5.8570e-02, -1.7140e-01,\n",
       "                       4.7525e-02, -8.5076e-02, -2.5245e-02, -4.6876e-02, -2.6089e-02,\n",
       "                      -1.7827e-02,  1.1720e-02, -9.2565e-03,  7.4798e-02,  3.3321e-02,\n",
       "                      -1.4527e-02, -5.5529e-03, -3.6626e-03, -3.3255e-02, -7.4000e-02,\n",
       "                      -1.6537e-02,  4.6883e-02,  2.2717e-02,  7.0252e-02,  1.5193e-01,\n",
       "                       1.3267e-01, -1.0043e-01,  3.7133e-03,  2.5924e-02,  5.0613e-02,\n",
       "                       9.8125e-03, -1.3933e-01,  2.2267e-02,  1.3048e-02,  6.2602e-02,\n",
       "                       1.2687e-01,  8.2453e-02,  2.4307e-02, -4.4858e-02,  9.0922e-02,\n",
       "                      -2.3950e-01,  3.6179e-02,  3.1754e-02, -1.8839e-02, -5.2856e-02,\n",
       "                      -7.8144e-02,  8.0101e-02, -2.0769e-01, -4.3230e-02, -1.8200e-01,\n",
       "                       1.5163e-02,  3.1702e-02,  9.9655e-03,  1.5448e-01,  5.0381e-02,\n",
       "                       3.0566e-02,  1.4616e-01, -4.3553e-02,  1.4640e-01,  1.1426e-01,\n",
       "                      -5.5661e-02, -9.4248e-02])),\n",
       "             ('bilstm_left_context_feature.weight_ih_l0_reverse',\n",
       "              tensor([[ 0.0447,  0.1185, -0.2080,  ..., -0.2307,  0.2422, -0.1720],\n",
       "                      [ 0.5554,  0.0798, -0.0844,  ...,  0.0762, -0.0498,  0.2250],\n",
       "                      [-0.1135,  0.0972, -0.1907,  ...,  0.0404, -0.1908,  0.0721],\n",
       "                      ...,\n",
       "                      [ 0.1786,  0.3116, -0.0233,  ...,  0.1950, -0.3210, -0.1618],\n",
       "                      [ 0.0309, -0.3854, -0.0128,  ..., -0.2221, -0.1025, -0.0980],\n",
       "                      [-0.3785, -0.0347, -0.2664,  ..., -0.4650,  0.1016, -0.3000]])),\n",
       "             ('bilstm_left_context_feature.weight_hh_l0_reverse',\n",
       "              tensor([[ 0.1206, -0.0237,  0.0279,  ...,  0.0099,  0.2052, -0.0832],\n",
       "                      [-0.0175, -0.1697,  0.0401,  ...,  0.0713, -0.2344, -0.1107],\n",
       "                      [ 0.0676,  0.1072, -0.0658,  ..., -0.1268,  0.0851, -0.0462],\n",
       "                      ...,\n",
       "                      [ 0.2231, -0.3162, -0.1418,  ..., -0.1556, -0.3124,  0.2006],\n",
       "                      [-0.2032,  0.3142,  0.1400,  ...,  0.3276,  0.0279,  0.0523],\n",
       "                      [ 0.1585,  0.0498, -0.1105,  ..., -0.1772, -0.0644, -0.0511]])),\n",
       "             ('bilstm_left_context_feature.bias_ih_l0_reverse',\n",
       "              tensor([ 2.1991e-01,  1.7805e-01, -5.8030e-02,  1.0658e-01,  5.9558e-02,\n",
       "                       4.8955e-02, -2.2399e-01,  1.9872e-01,  1.2913e-02,  1.1041e-02,\n",
       "                       2.5527e-01,  1.8193e-02,  8.7171e-02, -2.4210e-02,  1.1350e-01,\n",
       "                      -1.1704e-02,  4.1001e-02, -7.3187e-02, -6.6149e-02, -6.4615e-02,\n",
       "                      -6.5401e-02, -2.3286e-02, -1.1550e-01,  2.1152e-01,  9.2903e-02,\n",
       "                      -1.4787e-02, -1.4394e-02,  1.6104e-01, -9.9670e-02,  1.4993e-01,\n",
       "                       1.3342e-01,  2.0417e-01,  4.5602e-02, -1.4959e-02,  1.0212e-01,\n",
       "                       6.2696e-02,  7.2721e-03,  3.6132e-02, -1.3245e-01,  1.7503e-01,\n",
       "                       1.6925e-01,  2.9061e-03, -4.7037e-02,  2.6093e-01, -3.7793e-02,\n",
       "                       5.6621e-02, -6.8266e-02,  9.1543e-02,  2.7576e-02, -6.7116e-03,\n",
       "                      -6.3685e-02, -8.7691e-02,  4.0507e-02,  1.5825e-02,  6.1614e-02,\n",
       "                      -1.8375e-02,  1.1493e-01,  1.4112e-01,  3.2443e-03,  1.3453e-01,\n",
       "                      -3.4068e-02, -5.3267e-02,  2.6480e-02,  2.2381e-02, -1.6430e-03,\n",
       "                       6.3080e-02,  3.8010e-02,  1.5296e-02,  6.8273e-02,  8.3581e-02,\n",
       "                       1.0105e-01, -1.3320e-02,  1.0771e-01, -9.4967e-02, -3.7792e-02,\n",
       "                      -5.3401e-02,  1.4292e-02,  3.6351e-01,  2.3849e-02, -1.9750e-01,\n",
       "                       6.4434e-03, -2.6920e-02,  2.9774e-02,  3.0838e-02, -1.5239e-01,\n",
       "                       3.4833e-02, -6.1856e-02,  8.3372e-02,  1.2244e-01,  1.7845e-01,\n",
       "                      -1.2099e-01, -3.2185e-02,  1.2086e-01,  1.2880e-01, -4.5206e-02,\n",
       "                      -1.2446e-02, -3.5126e-02,  1.8473e-02,  8.8918e-02,  1.1787e-01,\n",
       "                      -8.2236e-02, -3.5808e-03,  3.1812e-02,  1.8644e-01,  2.8316e-02,\n",
       "                       1.1518e-01,  1.2640e-02, -5.8950e-02,  8.0761e-02, -2.1519e-01,\n",
       "                       1.7132e-01, -1.5767e-02,  1.2904e-01, -8.3044e-02,  1.4262e-01,\n",
       "                      -9.1531e-02, -1.7697e-03,  9.1173e-02,  1.2342e-01,  6.5500e-02,\n",
       "                      -8.1752e-02,  2.7866e-02,  2.2999e-01,  1.1805e-01, -2.2546e-02,\n",
       "                       1.1411e-01, -9.3688e-02, -8.4345e-04,  3.9531e-02,  5.2319e-02,\n",
       "                      -9.9780e-02, -6.1793e-02,  4.0937e-02, -1.1069e-01,  1.4151e-02,\n",
       "                      -1.3225e-02,  1.2014e-01, -1.7816e-01, -1.0882e-01,  1.3398e-01,\n",
       "                      -4.2526e-02, -6.4327e-02,  4.9674e-02, -4.7323e-02, -1.8337e-01,\n",
       "                      -2.0337e-01,  4.7826e-02, -3.7821e-02,  2.1616e-02, -6.0486e-02,\n",
       "                       1.2242e-01, -1.0179e-01, -2.2747e-02,  6.3668e-02, -9.7915e-02,\n",
       "                      -1.1008e-03, -4.1277e-03, -7.2327e-02,  7.9196e-02,  1.3580e-02,\n",
       "                      -1.3994e-01,  3.9048e-02, -1.4171e-01, -2.6717e-02, -7.0697e-03,\n",
       "                      -1.6399e-01,  8.8679e-02, -5.7540e-02, -6.1121e-02, -4.5197e-02,\n",
       "                      -2.4928e-01,  5.9975e-02, -1.0280e-01, -1.1708e-01, -1.3707e-02,\n",
       "                      -1.2758e-02,  1.2192e-01, -1.6529e-02, -1.3350e-01, -2.3520e-01,\n",
       "                      -1.7785e-01, -1.8634e-01, -4.1020e-02, -1.8589e-02, -5.6901e-02,\n",
       "                      -5.9446e-02, -7.7775e-02,  1.4274e-02, -3.4329e-02, -1.2166e-01,\n",
       "                      -1.2597e-02, -1.1571e-01, -2.1489e-02, -2.2272e-01, -5.8597e-02,\n",
       "                      -1.9862e-01, -1.0942e-01, -7.9725e-02, -2.4227e-02,  1.0601e-01,\n",
       "                      -2.3485e-01, -1.7923e-01, -1.0793e-01, -1.8543e-01, -1.1895e-01,\n",
       "                      -1.1385e-01, -1.2714e-01, -9.3313e-02,  1.0753e-01, -1.4138e-02,\n",
       "                      -1.8007e-02,  5.0552e-02, -1.4111e-01,  4.4591e-02,  2.0798e-01,\n",
       "                      -4.9671e-02,  4.5514e-02,  3.3690e-02, -4.9074e-02, -2.4532e-01,\n",
       "                      -7.8560e-03, -1.0431e-01,  6.0686e-03, -2.0567e-02,  2.8056e-02,\n",
       "                      -7.2208e-02, -3.6454e-02, -7.7884e-02,  2.0637e-02, -1.1539e-01,\n",
       "                       3.6688e-02,  8.2226e-02, -8.5546e-02, -1.0139e-01, -5.1389e-02,\n",
       "                      -1.2762e-01, -1.6203e-02, -1.9488e-01, -4.4235e-02, -2.1881e-02,\n",
       "                       4.6922e-03, -1.1678e-02, -1.0193e-01, -8.9232e-03, -4.5079e-02,\n",
       "                      -8.8286e-02,  1.2653e-01, -7.0673e-02, -1.0880e-01,  3.0532e-02,\n",
       "                      -1.9579e-01,  3.0217e-02, -1.5806e-01, -1.1917e-02,  6.0910e-02,\n",
       "                      -4.6025e-02, -4.8250e-02, -3.9660e-02,  2.6228e-02, -3.4382e-02,\n",
       "                       1.2581e-01,  2.1914e-02,  8.5992e-03, -2.1681e-02, -1.4579e-02,\n",
       "                      -7.3811e-02, -1.0525e-01, -1.0218e-01, -5.6972e-02, -1.0208e-03,\n",
       "                      -5.1842e-02,  5.2009e-02,  5.5066e-02, -3.2525e-02, -1.4685e-02,\n",
       "                      -1.3262e-04, -4.3246e-02,  1.6851e-02,  1.9161e-02,  2.6772e-03,\n",
       "                       6.5267e-02, -7.2117e-02,  9.5096e-02, -5.2667e-02, -8.9591e-02,\n",
       "                      -9.9063e-02, -9.4773e-02,  7.2096e-02,  3.5372e-02,  5.1796e-02,\n",
       "                      -7.1751e-02, -1.0902e-02,  1.2185e-01, -3.0923e-02, -2.3073e-01,\n",
       "                       8.7929e-02, -1.7754e-02,  7.1963e-02, -1.6171e-02, -2.4371e-02,\n",
       "                      -3.5323e-02,  1.0220e-02,  2.3713e-02,  2.0770e-02, -5.0150e-02,\n",
       "                      -3.3120e-02, -3.9342e-02, -1.1067e-02, -9.8180e-02, -1.8952e-02,\n",
       "                      -3.1221e-02, -8.6160e-03, -2.6497e-02, -8.4029e-02, -1.6167e-01,\n",
       "                       5.0633e-02,  1.5295e-01, -8.9357e-02,  8.3662e-02,  3.7602e-02,\n",
       "                      -1.1244e-02, -9.6660e-04, -5.8617e-02, -6.3739e-02,  3.2757e-02,\n",
       "                      -1.2654e-02, -2.4589e-02,  9.9157e-02,  3.9198e-03, -5.5450e-02,\n",
       "                       7.3530e-02, -8.2979e-02,  3.7411e-02, -8.9684e-02,  5.0534e-02,\n",
       "                       4.1584e-02,  7.4236e-02, -3.6104e-02, -6.2785e-02, -1.6561e-02,\n",
       "                      -1.2540e-01,  3.3293e-02, -5.3726e-02,  3.2408e-02, -2.8549e-02,\n",
       "                       6.3097e-02,  7.0307e-02,  1.8047e-02, -4.7501e-02,  3.1225e-02,\n",
       "                      -1.0420e-01, -2.3003e-02,  1.4042e-01, -8.6544e-03,  2.7518e-02,\n",
       "                       2.9313e-02, -4.1983e-02,  4.7234e-03, -5.6231e-02, -3.5115e-02,\n",
       "                       6.9890e-03, -1.1331e-02,  8.4446e-02, -6.0867e-02,  5.1561e-02,\n",
       "                      -1.5377e-01,  5.6605e-02, -3.9680e-02,  3.1126e-02,  8.4330e-03,\n",
       "                      -2.1327e-02,  1.2284e-01,  5.7476e-02, -8.1397e-03, -4.3241e-02,\n",
       "                       8.0076e-02,  7.5118e-02,  3.6955e-03,  3.8646e-02, -2.5128e-02,\n",
       "                      -6.6128e-02, -7.4762e-02, -3.2236e-02, -6.1007e-03,  7.6389e-02,\n",
       "                       4.4172e-02,  9.9222e-02, -5.6354e-02,  1.2109e-01,  9.3671e-02,\n",
       "                      -4.9112e-02,  1.4672e-01,  3.4094e-02,  7.1485e-02,  1.6555e-01,\n",
       "                       1.4442e-02,  3.6330e-02,  7.7151e-03,  8.8570e-02,  9.2265e-03,\n",
       "                       2.5401e-02,  2.5850e-02, -5.3094e-03,  7.0411e-02, -6.1022e-02,\n",
       "                       1.7169e-03,  9.5909e-02,  2.3759e-01,  2.5152e-01, -1.0245e-01,\n",
       "                       2.9848e-02,  1.9632e-01, -2.8613e-03,  1.1030e-01,  9.2465e-02,\n",
       "                       1.3534e-01,  6.2503e-02,  1.1972e-01,  5.6521e-02,  3.4760e-03,\n",
       "                       2.7429e-03,  8.2568e-03,  1.0567e-02,  2.6416e-01,  3.1392e-02,\n",
       "                      -5.3380e-02,  2.9723e-05,  1.2931e-01,  5.8940e-02,  1.6542e-01,\n",
       "                       3.2810e-03,  9.8159e-02,  1.9655e-02, -8.4817e-02,  4.6177e-02,\n",
       "                       6.1409e-02, -1.1233e-01, -1.9971e-02,  1.1579e-02, -3.2562e-02,\n",
       "                       1.8829e-01,  1.4831e-02, -6.5026e-03,  1.3610e-01, -8.3110e-02,\n",
       "                       4.0014e-02, -2.0280e-03, -2.4606e-02,  4.6349e-02,  7.7081e-02,\n",
       "                      -5.7416e-02,  6.0994e-02,  1.4748e-01,  7.5184e-02,  1.3147e-01,\n",
       "                       2.4971e-02,  1.2871e-01,  2.7838e-02,  1.2983e-02, -5.1454e-03,\n",
       "                       4.6943e-02,  1.9069e-01,  3.0997e-02,  6.4230e-03,  1.4092e-01,\n",
       "                       1.0637e-01, -1.8523e-02, -2.3231e-02, -1.7292e-01,  9.3180e-02,\n",
       "                      -7.3260e-02,  2.1775e-02,  1.2795e-01,  6.9026e-02, -1.1568e-01,\n",
       "                       8.1903e-02, -2.9664e-02,  2.9795e-01,  2.6861e-02, -1.1980e-01,\n",
       "                      -8.9192e-02,  1.1916e-01, -2.2689e-04, -2.0018e-02, -4.5517e-02,\n",
       "                       5.5279e-03,  6.4168e-02,  1.0019e-01, -6.9388e-02,  1.5852e-01,\n",
       "                       9.3288e-02,  2.6954e-02,  9.7404e-04, -9.9419e-02,  5.2252e-02,\n",
       "                       8.2382e-03,  1.3389e-01, -1.1286e-02,  3.7148e-02,  2.2085e-01,\n",
       "                       4.6112e-02,  3.6578e-02,  9.7974e-02,  2.8983e-02, -2.0303e-02,\n",
       "                      -5.2331e-02,  1.5499e-01,  1.1736e-01, -2.1729e-03, -2.7663e-02,\n",
       "                      -2.4253e-02,  8.3512e-02])),\n",
       "             ('bilstm_left_context_feature.bias_hh_l0_reverse',\n",
       "              tensor([ 3.5470e-02, -2.7999e-02,  2.1443e-02,  5.3215e-02,  1.8580e-01,\n",
       "                       1.9809e-01, -2.1856e-01,  2.1596e-01, -2.9708e-02,  1.2507e-01,\n",
       "                       2.7910e-01,  4.1666e-02, -2.7371e-02,  1.2589e-02,  7.9537e-02,\n",
       "                      -4.6676e-02,  1.4731e-01, -2.6175e-02, -3.4970e-02,  1.7828e-02,\n",
       "                      -9.3688e-02,  3.4797e-02, -1.6264e-02,  2.5464e-01,  2.0400e-01,\n",
       "                       1.8593e-01,  2.5088e-02,  2.8464e-02,  6.8710e-02,  2.2994e-01,\n",
       "                       1.1692e-01,  1.2188e-01,  4.6060e-02,  1.2387e-02,  1.3449e-01,\n",
       "                      -3.9397e-02, -6.3183e-02,  6.7044e-02,  1.1171e-01,  1.2662e-01,\n",
       "                       2.2328e-01, -2.3835e-02, -5.9515e-02,  9.2826e-02, -1.6017e-02,\n",
       "                       9.0432e-02, -6.8886e-02,  7.2102e-02,  9.4065e-02,  1.3463e-02,\n",
       "                      -1.0455e-01, -3.1221e-02, -6.7499e-02,  1.1314e-01,  4.9157e-02,\n",
       "                      -5.3282e-03,  2.9030e-02,  7.5748e-02,  4.1309e-02,  9.5096e-02,\n",
       "                      -1.1956e-01,  8.4756e-02,  1.1141e-01,  4.4320e-02, -1.4328e-01,\n",
       "                      -2.4011e-02,  3.5850e-02,  4.4160e-02, -8.5607e-03,  2.2228e-01,\n",
       "                       1.5420e-03,  1.1685e-01,  1.4173e-01, -1.4722e-01, -6.7884e-02,\n",
       "                       3.2113e-02,  8.6908e-02,  3.2103e-01, -1.3888e-02, -6.4826e-02,\n",
       "                       4.7219e-02,  1.3745e-01,  9.8151e-02,  6.3830e-02, -1.3656e-01,\n",
       "                      -5.3178e-02, -3.5881e-02,  1.5135e-01,  1.4862e-01,  3.2825e-02,\n",
       "                      -1.0203e-01, -3.4029e-02,  1.2557e-01,  2.2274e-01,  3.5353e-02,\n",
       "                       1.1947e-01,  4.3327e-02,  7.9934e-02,  1.0084e-01,  1.4728e-01,\n",
       "                      -1.0676e-01,  1.1202e-01, -3.2228e-02,  4.1200e-02,  3.7546e-02,\n",
       "                       1.1454e-01, -3.0749e-03, -2.9736e-02, -1.7818e-02, -1.0652e-01,\n",
       "                       2.8191e-01,  8.1018e-03,  5.7388e-02, -1.4632e-01, -4.9372e-02,\n",
       "                       1.2305e-01, -9.7587e-02,  1.6300e-01,  6.7650e-02,  2.7381e-01,\n",
       "                      -3.4525e-02,  3.0831e-02,  1.5961e-01,  8.8488e-02, -1.2085e-01,\n",
       "                       1.4157e-01, -1.6603e-01,  1.7540e-01,  1.0426e-01, -1.2032e-02,\n",
       "                      -2.1749e-03, -1.0666e-01, -6.0943e-02, -1.2545e-01, -2.0091e-01,\n",
       "                      -9.6982e-03,  1.1233e-01, -5.1052e-02, -1.0652e-01,  9.4263e-02,\n",
       "                      -1.2568e-01, -3.0525e-02, -2.5972e-02, -2.4334e-02, -3.0251e-01,\n",
       "                      -1.3993e-01,  7.9351e-03,  2.9231e-02, -8.8458e-02,  4.2921e-03,\n",
       "                       3.7261e-02, -7.3002e-02,  3.6632e-02,  2.1168e-02,  4.3864e-03,\n",
       "                       3.6789e-04,  3.4598e-02, -8.7201e-02,  1.0015e-01, -1.2723e-01,\n",
       "                       4.4156e-02, -1.2902e-02, -1.6160e-01, -1.4093e-01, -5.5926e-02,\n",
       "                      -6.7436e-02,  7.8308e-02, -9.1735e-02, -1.1118e-01, -1.0346e-01,\n",
       "                      -1.9769e-01, -6.9621e-02, -1.5176e-01, -8.6511e-02,  2.9691e-02,\n",
       "                      -1.6011e-01,  4.0218e-02, -9.2335e-02, -1.9371e-01,  9.0281e-03,\n",
       "                      -5.2767e-03, -6.2167e-02,  1.1666e-01, -1.3587e-01, -9.2932e-02,\n",
       "                      -5.0506e-02,  8.7270e-02, -9.9195e-02, -7.4790e-02, -1.5461e-01,\n",
       "                      -9.4613e-02, -1.7477e-01,  1.1004e-01, -1.1617e-01, -6.9794e-02,\n",
       "                      -1.2942e-01, -1.0059e-01, -3.1175e-02,  3.1579e-04,  7.9103e-02,\n",
       "                      -1.4710e-01, -1.7673e-01, -1.1754e-01, -1.5283e-01, -9.4018e-02,\n",
       "                      -2.0398e-03, -1.2025e-01, -9.3535e-02,  6.4592e-02,  1.5314e-02,\n",
       "                       1.7725e-01,  2.9922e-02, -1.4682e-01,  1.0617e-02, -6.3244e-03,\n",
       "                      -1.9958e-01,  3.8840e-02,  9.2908e-03, -8.0942e-02, -1.7041e-01,\n",
       "                      -1.3688e-01,  8.1802e-02,  2.7329e-02, -3.3919e-03, -3.9875e-02,\n",
       "                      -1.2517e-01, -7.4098e-02, -1.0597e-01, -1.3873e-03, -1.6572e-02,\n",
       "                      -8.6913e-03,  1.0319e-01, -1.3689e-01,  6.7128e-02,  2.2732e-02,\n",
       "                      -2.6078e-01,  6.0095e-02, -1.0648e-01,  7.8939e-03, -2.0866e-02,\n",
       "                      -4.3919e-02, -1.2594e-01,  2.4092e-02, -8.2270e-02,  4.7554e-02,\n",
       "                      -3.0168e-02, -1.2439e-01, -5.2403e-02, -3.0167e-02,  2.6963e-02,\n",
       "                      -2.2509e-01,  2.1911e-02, -1.7079e-01, -1.3129e-01, -2.2602e-02,\n",
       "                      -3.8362e-02,  9.8041e-02,  1.3541e-01, -6.2409e-02,  8.3377e-02,\n",
       "                      -3.1589e-02,  8.6120e-03, -8.7430e-02, -5.7646e-02, -1.6416e-01,\n",
       "                      -7.9489e-02,  4.4925e-02,  5.3662e-02,  9.0408e-02, -1.8304e-02,\n",
       "                       2.2392e-02, -9.7107e-02, -4.6189e-02,  6.4693e-02,  2.4881e-02,\n",
       "                      -4.2722e-03,  1.7658e-02,  6.6761e-03, -9.0078e-02, -7.5627e-02,\n",
       "                      -4.9345e-03,  4.6242e-02, -1.0890e-01, -1.1280e-01, -9.2471e-02,\n",
       "                       5.3381e-02, -2.8540e-02,  8.6610e-02, -9.1494e-02,  6.9676e-02,\n",
       "                       4.2358e-02,  2.5597e-02,  1.0082e-01, -1.7277e-02, -3.7908e-03,\n",
       "                      -6.0238e-02,  7.3405e-02, -8.3732e-02,  4.1057e-03,  8.0593e-02,\n",
       "                       2.8704e-02,  8.1380e-03,  2.8307e-02,  2.7738e-02, -9.4518e-03,\n",
       "                       6.1833e-02, -3.0129e-02, -1.4352e-01,  6.6731e-02,  2.0985e-02,\n",
       "                       4.5971e-02,  2.6111e-02, -4.5278e-02,  1.1063e-02, -7.6538e-02,\n",
       "                       1.2239e-01,  2.6284e-02,  4.0208e-02,  9.1772e-02,  8.5744e-02,\n",
       "                       4.2612e-03,  3.1885e-02,  1.1589e-01,  6.6213e-02, -4.6474e-02,\n",
       "                       1.2730e-01, -3.2241e-02, -7.0662e-02, -6.6194e-02, -4.2424e-02,\n",
       "                       4.9939e-02,  4.2151e-02, -3.4364e-02, -1.1233e-01, -2.4674e-03,\n",
       "                      -4.7903e-02,  7.4440e-02, -5.5793e-02, -6.5186e-02,  2.7781e-02,\n",
       "                      -1.5756e-02, -1.6234e-02,  1.1398e-02,  1.0742e-02, -9.7906e-02,\n",
       "                       8.0131e-02, -2.2838e-02, -4.6453e-02,  6.6195e-04,  8.3502e-02,\n",
       "                      -1.0271e-02, -7.2674e-02, -1.5829e-02, -7.0308e-02, -3.7743e-02,\n",
       "                       1.3002e-02,  4.8701e-02,  2.7570e-02, -3.8039e-02,  1.3276e-01,\n",
       "                       2.7503e-02,  9.1348e-02, -6.4619e-02,  2.4501e-02, -9.5452e-03,\n",
       "                      -1.7256e-02, -5.6175e-02,  5.7203e-02, -5.6057e-02,  9.2703e-02,\n",
       "                      -6.5640e-02,  1.0064e-01, -2.6468e-03,  4.1634e-02,  7.6338e-02,\n",
       "                      -3.3369e-02, -1.4872e-02, -7.7353e-03,  8.2156e-02,  3.3208e-02,\n",
       "                       6.8873e-02, -4.1671e-02,  5.5046e-02, -1.4707e-02,  3.7954e-02,\n",
       "                       4.7409e-02,  6.0005e-02,  9.5333e-02,  7.9774e-02,  1.0334e-01,\n",
       "                      -9.9041e-02,  1.1283e-01,  9.7190e-02,  2.3164e-01,  2.5207e-01,\n",
       "                       7.9222e-02,  1.4733e-01,  2.4395e-02,  8.0785e-02,  4.5916e-02,\n",
       "                      -1.0376e-01, -5.4467e-02,  7.8768e-03, -4.8422e-02,  1.4587e-02,\n",
       "                       3.1613e-02, -8.1286e-02,  2.8891e-01,  9.3914e-02,  9.0082e-02,\n",
       "                       5.1293e-03,  1.3979e-01,  1.3174e-02,  1.3033e-01, -2.7741e-02,\n",
       "                       1.3204e-01,  4.5253e-02,  1.1304e-01,  6.5534e-02, -7.2162e-03,\n",
       "                       1.5003e-01,  4.8569e-02,  5.3571e-02,  1.2726e-01,  2.1581e-01,\n",
       "                       3.1162e-02,  2.0608e-03,  1.2631e-01,  1.2247e-01,  4.8122e-02,\n",
       "                       6.5096e-02,  6.8984e-02,  3.6647e-03,  2.8058e-02,  7.8044e-03,\n",
       "                       1.7064e-02, -5.7367e-02, -7.9256e-02,  1.4818e-01, -4.7412e-02,\n",
       "                       1.8607e-01,  1.5717e-01, -1.5510e-02,  2.5642e-01,  2.1424e-03,\n",
       "                       3.1294e-02,  3.4383e-02, -4.2284e-02,  1.2921e-01, -6.9552e-03,\n",
       "                      -2.2050e-03,  1.6988e-01,  4.3091e-02,  1.3450e-01,  8.9622e-02,\n",
       "                       8.0664e-02,  1.3801e-01,  7.7969e-02,  2.1609e-02,  1.0579e-01,\n",
       "                      -1.0154e-01,  1.4351e-01,  2.1450e-02, -1.1028e-01,  2.2492e-01,\n",
       "                       4.6659e-02, -3.8412e-02,  3.1658e-02, -4.5375e-02, -1.1678e-02,\n",
       "                       2.5007e-03,  7.5577e-02,  7.6721e-02, -2.5667e-02, -9.0282e-02,\n",
       "                       6.6543e-02,  6.3004e-02,  1.9482e-01, -3.7756e-02,  1.5231e-01,\n",
       "                      -1.1538e-01,  7.7172e-02,  9.3034e-02, -3.0812e-02,  5.0078e-02,\n",
       "                       4.7844e-02, -5.5226e-02, -6.9925e-02, -8.3033e-02,  5.1185e-02,\n",
       "                      -1.6111e-01, -2.6996e-02, -3.8108e-02,  1.4846e-02,  8.5082e-02,\n",
       "                       1.8279e-01,  3.6583e-02,  7.5210e-02,  6.5679e-02,  9.6958e-02,\n",
       "                      -9.7495e-02, -6.7489e-02,  1.0925e-01,  7.3414e-02,  2.3440e-02,\n",
       "                      -3.8739e-02,  2.6796e-01, -8.5788e-02, -1.6531e-02,  6.1671e-03,\n",
       "                      -5.0637e-02,  1.3909e-02])),\n",
       "             ('bilstm_oov_context_feature.weight_ih_l0',\n",
       "              tensor([[-0.4159,  0.2246,  0.0381,  ..., -0.4195, -0.2368,  0.0558],\n",
       "                      [ 0.6021,  0.2049,  0.2958,  ..., -0.0412,  0.3100,  0.1629],\n",
       "                      [-0.2140, -0.4298,  0.5190,  ...,  0.1632, -0.1186, -0.0665],\n",
       "                      ...,\n",
       "                      [-0.3002, -0.7069,  0.2442,  ..., -0.0611, -0.1302,  0.2642],\n",
       "                      [-0.4110, -0.2691, -0.0013,  ...,  0.1525, -0.5499, -0.2138],\n",
       "                      [ 0.1658,  0.2691,  0.2784,  ..., -0.5152,  0.1259,  0.6818]])),\n",
       "             ('bilstm_oov_context_feature.weight_hh_l0',\n",
       "              tensor([[ 0.1555,  0.1979,  0.0572,  ..., -0.0560, -0.2137, -0.0269],\n",
       "                      [ 0.0811, -0.0499, -0.0246,  ...,  0.0211,  0.0210, -0.2631],\n",
       "                      [ 0.2080,  0.1947,  0.0923,  ..., -0.1763,  0.1209, -0.0253],\n",
       "                      ...,\n",
       "                      [ 0.0313,  0.0630, -0.1449,  ...,  0.1481,  0.2305, -0.2210],\n",
       "                      [ 0.2697, -0.2280, -0.2047,  ...,  0.0080,  0.0733,  0.2230],\n",
       "                      [ 0.0462,  0.2262, -0.0004,  ...,  0.0251,  0.0387,  0.0038]])),\n",
       "             ('bilstm_oov_context_feature.bias_ih_l0',\n",
       "              tensor([-1.6156e-01, -1.3983e-01, -8.7549e-02, -9.2692e-02, -1.3022e-01,\n",
       "                       2.7767e-03, -1.3697e-01, -8.1202e-02, -1.0657e-01, -9.3422e-03,\n",
       "                      -4.4154e-03, -1.1473e-01, -3.1206e-02, -6.9662e-02, -2.2369e-01,\n",
       "                      -1.4556e-01, -2.7788e-02, -2.1088e-01, -1.0829e-01, -1.7942e-01,\n",
       "                      -7.2143e-02, -2.3284e-02, -1.1150e-01,  6.1039e-02,  1.9041e-02,\n",
       "                      -1.8784e-01, -1.0534e-01, -3.6102e-02, -1.6560e-01, -9.7366e-02,\n",
       "                       1.3415e-01, -1.1598e-01, -2.2566e-02, -5.2440e-02, -1.5613e-02,\n",
       "                      -1.2820e-01, -2.3557e-01, -1.6224e-01, -9.2100e-02,  4.0483e-02,\n",
       "                      -1.4727e-01, -1.4917e-01, -1.2199e-01, -2.0268e-03, -1.8076e-01,\n",
       "                       7.6273e-03,  5.1634e-02, -7.3833e-03, -4.1798e-02, -1.5759e-01,\n",
       "                      -1.1350e-01,  2.9999e-03, -5.2184e-02, -2.0783e-01, -4.8791e-02,\n",
       "                      -1.2008e-01, -4.7820e-02, -1.1718e-01, -1.5064e-01, -5.3528e-02,\n",
       "                      -1.0871e-01, -1.0427e-01, -1.2754e-01, -1.4974e-01, -1.3326e-02,\n",
       "                      -2.8218e-01, -6.6969e-02, -9.2277e-02, -8.0850e-02, -1.0865e-01,\n",
       "                      -1.5276e-01, -1.0398e-01, -1.5075e-01,  4.0829e-02, -1.9378e-01,\n",
       "                      -8.7036e-02, -9.8114e-02, -5.2274e-02, -4.3211e-02, -1.2591e-01,\n",
       "                       2.7412e-02, -3.7159e-02, -1.2729e-01, -2.1172e-02, -6.4156e-02,\n",
       "                      -6.9217e-02, -7.8849e-02, -9.7769e-02, -1.1340e-01,  1.5973e-02,\n",
       "                      -1.4937e-02, -8.3973e-02, -4.4774e-02,  6.5207e-02, -8.4333e-02,\n",
       "                      -3.1225e-01, -1.2557e-01, -1.3044e-01, -2.2050e-01,  5.8162e-02,\n",
       "                      -1.2687e-01, -9.2932e-02, -4.3017e-02, -8.9858e-02, -1.7595e-01,\n",
       "                      -1.2695e-01, -1.0317e-01, -1.4576e-01, -4.1905e-02, -1.8502e-01,\n",
       "                      -8.6220e-02, -1.3299e-01, -5.2597e-02,  9.1150e-02, -9.0386e-02,\n",
       "                       2.8057e-03, -1.2812e-01, -2.6035e-03, -1.3790e-01, -6.3527e-02,\n",
       "                      -1.4844e-01, -2.0737e-02, -4.4791e-02, -1.1410e-01, -8.3250e-02,\n",
       "                      -3.2961e-02, -6.4668e-02, -4.8920e-02, -1.2654e-01, -1.9801e-01,\n",
       "                       4.4556e-02, -1.4463e-01, -6.3314e-02, -7.2216e-02,  4.2740e-02,\n",
       "                      -1.4720e-01,  8.8469e-03, -3.6057e-02,  3.8136e-02, -2.6244e-02,\n",
       "                       8.5157e-03,  7.0905e-02,  8.6487e-02, -5.1150e-02,  8.9730e-03,\n",
       "                      -6.6260e-02, -1.4587e-02, -2.5183e-01, -1.9567e-01, -1.1994e-01,\n",
       "                       3.5518e-02, -4.8348e-02, -6.4941e-02,  4.6042e-03,  2.2480e-02,\n",
       "                      -1.9476e-01,  4.3637e-02, -5.3006e-02,  7.0568e-03, -1.1208e-01,\n",
       "                       1.6000e-01, -2.3135e-02, -1.7258e-01, -1.3737e-01, -2.7510e-02,\n",
       "                       5.5585e-02, -3.9364e-02,  1.3356e-01, -1.7765e-01, -8.4958e-02,\n",
       "                      -1.1151e-01,  1.1257e-01, -1.8057e-01, -1.2021e-01,  1.1257e-02,\n",
       "                      -8.1787e-02, -1.1828e-01, -1.8763e-01, -8.3500e-02, -1.5755e-01,\n",
       "                      -2.4541e-02, -1.9941e-01, -1.0460e-01, -5.3307e-02,  5.4123e-02,\n",
       "                      -5.8671e-02, -1.4198e-01, -2.3951e-02, -9.5136e-02, -7.7953e-02,\n",
       "                       1.8637e-02, -7.7805e-02,  8.2856e-02, -1.2992e-01,  2.0284e-02,\n",
       "                      -2.1965e-01, -1.2553e-01,  1.4815e-02, -1.9141e-01,  1.4837e-02,\n",
       "                      -1.2836e-01,  7.3827e-02, -6.2304e-02, -5.2939e-02, -1.8607e-01,\n",
       "                       6.1212e-03, -3.0004e-02, -1.0659e-01,  7.7451e-02,  1.1031e-01,\n",
       "                       3.1804e-02, -1.3500e-01,  3.1224e-02,  7.2309e-02, -1.0620e-01,\n",
       "                      -1.1473e-01, -5.1883e-02, -2.0701e-04,  1.1481e-01, -1.7447e-01,\n",
       "                      -3.0247e-02,  1.1000e-01, -1.2115e-01, -2.8534e-01,  1.3906e-01,\n",
       "                      -1.1935e-01, -8.5063e-02, -1.4300e-02,  5.8262e-02, -9.4394e-02,\n",
       "                      -1.2163e-01,  1.4013e-01, -1.2618e-01,  1.6921e-02,  1.5141e-01,\n",
       "                      -1.7240e-01,  1.7720e-01, -1.1418e-01,  1.6480e-02, -1.0043e-01,\n",
       "                      -7.0932e-02,  1.1070e-01, -1.5130e-01, -1.4976e-01,  1.9580e-02,\n",
       "                       1.1559e-03,  5.9525e-02,  1.4588e-01, -4.4593e-03,  5.9631e-02,\n",
       "                       6.9302e-02, -9.9959e-02, -8.3777e-02, -7.7878e-02, -2.6946e-02,\n",
       "                      -5.7854e-02,  1.3676e-01, -4.1886e-02, -6.0435e-02, -2.9586e-03,\n",
       "                       2.3242e-02, -6.4420e-02,  3.1650e-03,  2.1223e-04,  1.3579e-01,\n",
       "                      -1.0336e-01,  7.6169e-02,  4.6888e-02,  7.9876e-02,  4.6534e-02,\n",
       "                       1.4103e-01,  1.9068e-02, -1.0140e-01,  1.7529e-01, -1.0749e-01,\n",
       "                      -6.9877e-04, -7.6896e-02,  1.2463e-01, -1.9772e-02,  7.4851e-02,\n",
       "                       6.4445e-02,  5.3106e-02, -6.2836e-02,  4.2021e-02, -4.2843e-03,\n",
       "                       1.4742e-01, -4.8435e-02, -3.8249e-02,  8.7359e-02, -1.5518e-02,\n",
       "                      -5.5638e-02, -2.5976e-02, -3.0865e-02, -6.7425e-04, -5.3910e-02,\n",
       "                      -5.7181e-03,  1.0871e-01, -3.0867e-02, -5.3351e-02, -6.1469e-02,\n",
       "                       1.0515e-01,  1.3685e-01,  2.8952e-02,  3.7039e-02, -6.5420e-02,\n",
       "                       9.1603e-03,  3.2385e-02,  9.6578e-02, -2.4922e-02, -5.0584e-02,\n",
       "                       9.8421e-02, -3.2756e-02,  2.3378e-02,  4.0042e-02,  1.6448e-01,\n",
       "                      -7.6311e-04,  7.9020e-03,  7.2086e-03, -4.1888e-02,  4.5956e-02,\n",
       "                      -9.8881e-02, -2.9997e-03,  2.8764e-02, -2.5758e-02, -3.6868e-02,\n",
       "                      -5.6878e-02, -2.4339e-02, -8.9393e-02,  3.7548e-02, -2.6785e-02,\n",
       "                      -1.4688e-01, -7.6646e-02,  1.1693e-02, -1.0226e-01, -8.5102e-02,\n",
       "                       3.4753e-02,  2.5738e-02,  4.9456e-02, -5.3519e-02,  5.3253e-02,\n",
       "                      -4.5833e-02, -1.7129e-02, -3.9553e-05,  8.5536e-02, -3.2855e-02,\n",
       "                      -3.6760e-02, -1.7050e-02, -2.9473e-02,  1.6533e-02, -9.0871e-03,\n",
       "                      -3.7868e-02,  1.1830e-01, -4.8193e-02,  2.3622e-02,  5.0391e-02,\n",
       "                       3.4343e-02, -1.1488e-02,  6.4752e-02,  4.2193e-02, -7.8264e-02,\n",
       "                      -8.0333e-02,  8.5869e-02,  7.5755e-02, -4.9965e-02,  1.9743e-02,\n",
       "                       4.5480e-02,  3.6232e-02, -5.6852e-02, -8.1859e-02, -6.9093e-02,\n",
       "                      -3.2175e-02, -4.1516e-02,  5.3666e-02, -1.2504e-01,  8.1041e-02,\n",
       "                       9.9931e-03, -2.9610e-02,  7.0642e-02,  1.4086e-02,  1.5338e-02,\n",
       "                      -5.9902e-02, -2.8195e-02, -4.0975e-02, -1.7334e-02, -1.2432e-01,\n",
       "                      -1.9339e-01, -1.1388e-01, -1.6793e-01, -8.3092e-02, -1.4428e-01,\n",
       "                       5.7867e-02, -1.4665e-02, -9.8047e-02, -7.7410e-02, -1.3141e-01,\n",
       "                      -1.3335e-01, -1.0355e-01, -5.2682e-02, -1.2019e-01, -1.8810e-01,\n",
       "                      -1.0090e-01, -2.5896e-02, -6.0803e-02, -2.2093e-02, -1.3775e-01,\n",
       "                      -1.5692e-01, -6.9233e-02, -9.5158e-02,  2.5392e-02, -1.7209e-01,\n",
       "                       1.0134e-02, -4.3618e-02, -1.5066e-01, -8.1501e-02,  6.8966e-02,\n",
       "                      -1.0159e-01,  4.9596e-02,  4.3855e-02, -5.0802e-02, -1.5883e-01,\n",
       "                      -3.1908e-02,  6.8361e-02, -3.9116e-02,  9.5810e-02, -2.3929e-01,\n",
       "                      -1.8597e-01, -6.0397e-02, -2.0108e-02, -1.8355e-01, -6.0059e-02,\n",
       "                      -8.6267e-02, -2.3999e-01, -1.1123e-01, -2.2772e-01, -1.7423e-01,\n",
       "                       1.1861e-01, -1.9149e-01, -2.1382e-01, -1.6726e-01,  6.5146e-02,\n",
       "                      -1.3984e-01, -1.2191e-01, -1.1965e-01, -1.4200e-02, -1.4515e-01,\n",
       "                      -1.8789e-01, -8.5862e-02, -2.7679e-02,  4.5095e-02, -1.2367e-01,\n",
       "                      -4.0790e-02, -5.8281e-02, -6.7037e-02, -1.2356e-02, -1.1033e-01,\n",
       "                      -8.9818e-02, -5.2394e-02, -6.4963e-02,  1.9256e-02, -1.3253e-01,\n",
       "                      -1.7183e-01, -4.5020e-04, -2.1196e-01, -1.5493e-01, -1.7924e-02,\n",
       "                      -1.1173e-01, -6.0885e-02,  2.6887e-02,  3.4044e-02, -1.0284e-02,\n",
       "                      -6.1591e-02, -4.0973e-02, -1.2195e-01,  3.4749e-02, -9.6426e-02,\n",
       "                      -6.3676e-02, -1.9345e-02, -7.8488e-02, -4.5104e-02, -2.0394e-01,\n",
       "                      -6.6302e-03, -8.0204e-02, -6.0981e-02, -4.3672e-03, -1.0626e-01,\n",
       "                      -8.8134e-02,  5.2121e-02, -1.0838e-01,  7.6345e-03, -1.8287e-01,\n",
       "                      -1.7950e-01, -8.5515e-02, -4.0755e-02, -7.8387e-02, -1.5451e-02,\n",
       "                      -1.3800e-01,  4.9420e-02, -1.1436e-01, -1.2161e-01, -7.0232e-02,\n",
       "                      -1.0304e-01, -2.0886e-02, -5.9104e-02,  5.6399e-02,  2.7619e-02,\n",
       "                       3.7142e-02, -1.0795e-01, -2.7114e-02, -2.0253e-01, -1.4470e-03,\n",
       "                       7.9885e-03, -8.1793e-02])),\n",
       "             ('bilstm_oov_context_feature.bias_hh_l0',\n",
       "              tensor([-1.6231e-01, -2.4928e-01, -6.1179e-02, -4.5089e-02, -9.9343e-02,\n",
       "                      -7.2441e-02, -7.9181e-02, -3.0071e-02, -1.3139e-01,  4.9337e-02,\n",
       "                      -3.7593e-02, -8.4225e-02, -7.8897e-02, -1.2120e-01, -1.3010e-01,\n",
       "                      -1.0967e-01, -6.0696e-02, -1.0938e-01, -1.9668e-02, -1.2918e-01,\n",
       "                      -1.4883e-01, -1.5125e-01, -1.7309e-01,  6.4142e-03, -7.2956e-03,\n",
       "                      -4.8881e-02, -6.3377e-02, -7.6146e-02, -1.9692e-01, -1.6108e-01,\n",
       "                      -1.4807e-02, -1.1132e-01,  9.3335e-02, -1.2806e-01, -1.0356e-02,\n",
       "                      -2.2539e-01, -1.2496e-01, -8.7298e-02, -3.9739e-02, -3.2021e-02,\n",
       "                      -1.3219e-01, -3.4557e-02,  1.8533e-02, -1.4652e-02, -9.4385e-02,\n",
       "                      -1.8120e-01, -1.9298e-01,  2.9083e-02, -8.0770e-02, -4.2194e-02,\n",
       "                      -2.3544e-01, -2.7019e-03,  1.8008e-03, -2.0826e-01, -1.1957e-01,\n",
       "                      -3.1987e-02, -1.9419e-02, -2.6887e-01, -1.8665e-01, -5.5807e-02,\n",
       "                      -1.7181e-02, -1.1380e-01,  5.3172e-02, -1.2171e-01, -1.3066e-01,\n",
       "                      -1.5652e-01, -8.8498e-02, -1.3513e-01,  7.3085e-02, -2.1589e-01,\n",
       "                      -1.4317e-01, -1.1800e-01, -1.5084e-01,  1.3788e-02, -1.2845e-01,\n",
       "                      -3.2320e-02, -1.1735e-01, -5.9442e-02,  3.1569e-02, -1.0338e-01,\n",
       "                       2.3193e-02, -1.3970e-01, -5.8055e-02, -1.3177e-02, -8.9668e-02,\n",
       "                      -4.4419e-02, -3.2533e-02, -1.1278e-01, -1.5200e-01, -3.2577e-04,\n",
       "                       1.5257e-02, -8.6010e-02, -8.9531e-02, -7.2620e-02, -4.9272e-02,\n",
       "                      -2.2941e-01, -1.3767e-02, -5.5844e-02, -8.9559e-02, -6.4848e-02,\n",
       "                      -8.9290e-02,  4.1957e-02, -2.0215e-01, -1.1003e-01, -7.4874e-02,\n",
       "                      -1.8049e-01, -9.4607e-02, -1.7219e-01, -7.7136e-02, -5.4759e-02,\n",
       "                      -6.6343e-02,  8.6228e-02,  8.0393e-02,  3.5177e-02, -1.8672e-01,\n",
       "                      -1.1461e-01, -1.3762e-01, -6.8660e-02, -1.7560e-01, -8.9928e-02,\n",
       "                      -1.6210e-01, -1.1800e-01,  4.5092e-02, -7.2539e-02, -1.5230e-01,\n",
       "                       7.6910e-02, -2.7088e-02,  7.0093e-03, -4.2880e-02, -1.2066e-01,\n",
       "                       1.8247e-02, -9.0478e-02, -1.9126e-01, -1.6414e-01, -4.9728e-02,\n",
       "                      -4.0705e-02,  3.8981e-02, -6.2473e-03, -3.0237e-02, -9.5346e-03,\n",
       "                       1.6456e-01,  1.2336e-01, -4.3662e-02, -5.2577e-02, -1.3752e-01,\n",
       "                      -1.7350e-01, -1.8035e-01, -8.4236e-02, -8.9302e-02, -1.0886e-01,\n",
       "                      -1.5310e-01, -4.0462e-02, -1.0240e-02, -1.5632e-01, -1.5754e-01,\n",
       "                      -1.2975e-01, -4.0513e-02, -2.1887e-02, -1.7929e-02, -2.1531e-03,\n",
       "                       9.7417e-02,  1.0387e-01, -2.2323e-01, -6.6232e-02, -1.1773e-02,\n",
       "                       1.0120e-02,  5.9917e-02,  9.5563e-02, -9.4941e-02, -7.8991e-02,\n",
       "                      -1.7399e-01, -8.5721e-02, -5.5012e-02, -1.3629e-02, -4.5592e-02,\n",
       "                      -2.2660e-02, -1.1879e-01, -1.0557e-01, -1.2583e-01, -1.5278e-01,\n",
       "                      -7.5647e-02, -2.7520e-01, -2.2037e-01, -8.9629e-02,  7.4044e-02,\n",
       "                      -6.8732e-02, -1.0539e-01, -5.3798e-02, -3.1259e-02, -1.4996e-01,\n",
       "                      -2.5746e-02,  9.6629e-03,  1.6081e-01, -1.2612e-01, -4.5977e-03,\n",
       "                       3.3434e-03, -7.9124e-03,  2.7109e-02, -5.4710e-02,  2.9644e-02,\n",
       "                      -8.5393e-02,  2.1524e-02, -1.1087e-01, -8.1762e-02, -1.9087e-01,\n",
       "                       7.8983e-03, -1.2995e-01, -1.7600e-01,  1.4056e-01,  3.2237e-02,\n",
       "                       5.5369e-02, -1.8975e-01,  1.0693e-01, -1.3778e-01, -3.7003e-02,\n",
       "                      -5.9236e-02, -6.1517e-02, -8.6432e-02,  2.5142e-02, -1.7188e-01,\n",
       "                      -9.8996e-02, -5.2376e-02, -2.0164e-02, -1.4405e-01,  2.2642e-02,\n",
       "                      -1.4213e-01,  3.3541e-03,  1.0761e-03, -1.5677e-01, -1.6351e-01,\n",
       "                      -5.5539e-02,  7.1520e-02, -8.0265e-02, -4.2277e-02, -1.8645e-02,\n",
       "                      -7.6065e-02,  1.8585e-01, -1.4027e-01,  2.8439e-02,  1.8916e-02,\n",
       "                       9.6774e-02, -2.6769e-02, -9.0895e-02, -1.2474e-01, -6.4315e-02,\n",
       "                       2.0139e-02, -4.0931e-02, -1.6045e-03, -1.6289e-01, -2.8184e-03,\n",
       "                       1.4083e-01, -6.6883e-02, -3.7814e-02, -2.2504e-04,  9.7952e-04,\n",
       "                      -2.6204e-02,  7.4457e-02,  5.7960e-02,  3.5787e-02, -4.6389e-02,\n",
       "                      -4.2921e-02,  2.4263e-02,  2.7205e-02,  3.4413e-02, -3.7591e-02,\n",
       "                      -9.3733e-02, -4.0423e-02, -5.9924e-04,  5.3112e-02,  1.3370e-02,\n",
       "                       8.7999e-02,  2.0002e-02, -5.0448e-02, -1.2287e-01, -4.9078e-03,\n",
       "                       6.4045e-02,  8.7344e-02, -1.0004e-01, -4.4690e-02,  1.8113e-02,\n",
       "                      -5.3260e-02,  2.7458e-02, -1.3153e-01, -5.0814e-03,  1.2405e-02,\n",
       "                       7.8482e-02,  1.2292e-01, -4.6805e-02,  7.9355e-02,  4.4938e-02,\n",
       "                      -5.1799e-02,  2.9346e-02, -8.6445e-02, -8.6541e-02, -6.5344e-03,\n",
       "                      -6.2450e-02, -9.8402e-02,  7.4762e-03, -7.7193e-02,  6.6711e-02,\n",
       "                       7.1999e-02, -1.3931e-01,  6.5672e-02,  9.5214e-02,  2.2319e-02,\n",
       "                      -4.5573e-02,  6.3903e-02,  8.0589e-02,  7.2905e-02,  4.1599e-03,\n",
       "                      -5.4167e-02,  8.8106e-03, -6.4328e-02,  8.0582e-02, -4.8969e-02,\n",
       "                       3.4196e-02, -1.3389e-02,  6.8737e-02, -5.4153e-02,  6.5758e-02,\n",
       "                       3.4309e-02,  7.1611e-02, -5.0436e-02,  3.5122e-02, -1.9485e-02,\n",
       "                      -1.2229e-01,  7.6250e-02,  5.7103e-03, -1.3293e-01, -5.6845e-02,\n",
       "                      -1.3616e-01, -8.0834e-02,  2.9295e-02,  3.8971e-02, -7.5812e-02,\n",
       "                      -2.7526e-02, -2.0457e-02,  6.0558e-02,  1.3086e-01,  3.0814e-02,\n",
       "                       1.7306e-02,  4.2618e-02,  6.7448e-02, -2.5132e-02, -2.1887e-02,\n",
       "                       3.8133e-03, -4.3034e-02,  5.6907e-02,  2.8148e-02,  7.2469e-02,\n",
       "                       7.3196e-02, -1.1150e-02,  8.5995e-02,  3.5486e-03,  7.0623e-02,\n",
       "                      -4.2232e-02,  2.7528e-02,  2.2675e-03, -1.3547e-02,  1.3326e-02,\n",
       "                       2.7058e-02,  4.1387e-02, -3.2293e-03,  4.0089e-03, -7.9304e-02,\n",
       "                       7.4217e-02,  5.4499e-02, -7.5928e-02, -4.7670e-02,  4.7831e-02,\n",
       "                       7.1729e-03, -7.4730e-02,  6.3568e-02, -4.5645e-03,  1.0250e-02,\n",
       "                      -9.1820e-03,  3.8859e-02, -1.7593e-02,  7.6082e-02,  5.5161e-02,\n",
       "                       6.2596e-02,  1.0457e-02, -1.5569e-02,  1.5795e-02, -1.3934e-01,\n",
       "                      -8.7255e-02, -9.5100e-02, -1.0254e-01, -2.2080e-01, -4.8881e-02,\n",
       "                      -2.2655e-02, -4.6200e-02, -1.4594e-01, -7.4610e-02, -1.3787e-01,\n",
       "                      -2.1755e-01, -1.2394e-01, -1.2870e-01, -1.5860e-01,  6.9066e-02,\n",
       "                      -6.4898e-03, -1.8499e-01, -4.9527e-02, -1.4258e-01, -1.8921e-01,\n",
       "                      -2.3739e-01, -1.5852e-01, -1.2591e-01, -7.3935e-02, -3.4044e-02,\n",
       "                      -2.8149e-03, -3.6582e-02, -2.3728e-02, -1.3151e-01, -6.2977e-02,\n",
       "                      -4.2138e-02,  1.4614e-02, -5.2356e-02, -1.0056e-01, -8.8447e-02,\n",
       "                      -1.0565e-01,  7.2364e-02, -5.0647e-02,  1.6571e-01, -1.5630e-01,\n",
       "                      -1.0507e-01, -5.5534e-02, -1.0696e-01, -8.4956e-02, -1.6884e-01,\n",
       "                      -4.0924e-02, -1.6951e-01,  5.3694e-03, -5.4735e-02, -9.9991e-02,\n",
       "                      -1.1559e-01, -1.1782e-01, -1.3863e-01, -1.0153e-01,  2.9677e-02,\n",
       "                      -8.0929e-02, -2.0214e-01, -1.0556e-01,  5.5448e-02, -7.9926e-02,\n",
       "                      -1.8997e-01, -7.4707e-02, -9.1467e-02,  3.9900e-02, -1.6510e-01,\n",
       "                       3.8526e-02, -1.1902e-01,  1.2539e-01,  1.0296e-02, -6.7386e-02,\n",
       "                      -9.7787e-02, -2.1652e-01, -7.8801e-02, -1.0868e-01, -5.6802e-02,\n",
       "                      -4.5119e-02,  1.6424e-02, -1.8148e-01, -2.9561e-02, -1.2497e-02,\n",
       "                      -2.6319e-02, -3.6554e-02,  5.1475e-03,  5.2946e-03, -8.3784e-02,\n",
       "                      -2.1433e-01,  8.3650e-02, -2.4103e-01, -1.4781e-01,  4.1545e-03,\n",
       "                      -8.0926e-02,  9.9121e-03, -8.5479e-02,  8.8572e-02, -2.0953e-01,\n",
       "                      -2.1922e-02, -5.6725e-02, -3.6705e-02, -9.9265e-02, -1.4732e-02,\n",
       "                      -8.9047e-02,  2.3523e-02,  5.7986e-02, -6.8148e-02, -7.9845e-02,\n",
       "                      -1.0029e-01, -2.5927e-01, -3.6883e-02, -1.1754e-01, -6.4022e-02,\n",
       "                      -1.7844e-01,  1.2543e-02, -2.0373e-01, -9.7596e-03, -2.4785e-02,\n",
       "                      -1.2671e-01,  5.4660e-02, -8.6415e-02, -3.2898e-02, -3.0946e-02,\n",
       "                      -1.6493e-02, -3.2582e-02, -1.0468e-01, -1.7407e-01,  4.4059e-04,\n",
       "                      -2.3054e-02, -8.0759e-02])),\n",
       "             ('bilstm_oov_context_feature.weight_ih_l0_reverse',\n",
       "              tensor([[ 0.2088,  0.1520, -0.8650,  ..., -0.1600,  0.8747,  0.3640],\n",
       "                      [-0.3857, -0.3634,  0.4729,  ...,  0.6750,  0.3722, -0.0050],\n",
       "                      [-0.0849, -0.2982,  0.0731,  ..., -0.3044,  0.0816,  0.1098],\n",
       "                      ...,\n",
       "                      [ 0.4740, -0.1626, -0.2379,  ..., -0.5449, -0.1140, -0.2341],\n",
       "                      [-0.1842,  0.1901,  0.0757,  ..., -0.1774, -0.2169,  0.0202],\n",
       "                      [-0.2736, -0.1381, -0.0909,  ...,  0.0095,  0.1495, -0.0585]])),\n",
       "             ('bilstm_oov_context_feature.weight_hh_l0_reverse',\n",
       "              tensor([[ 0.3943, -0.0385, -0.0845,  ..., -0.1460,  0.0932,  0.1549],\n",
       "                      [ 0.3439, -0.1101,  0.1423,  ...,  0.0161, -0.0462,  0.0503],\n",
       "                      [-0.0858, -0.0964, -0.1090,  ..., -0.1586, -0.0554,  0.2894],\n",
       "                      ...,\n",
       "                      [ 0.3850, -0.0848, -0.3058,  ..., -0.0289,  0.0281,  0.0231],\n",
       "                      [ 0.0219, -0.0338, -0.0251,  ...,  0.0392, -0.0718,  0.0488],\n",
       "                      [ 0.1379,  0.0282,  0.1965,  ..., -0.0619, -0.2138,  0.2562]])),\n",
       "             ('bilstm_oov_context_feature.bias_ih_l0_reverse',\n",
       "              tensor([ 1.8530e-01, -6.3745e-04,  2.3853e-01,  2.8191e-01,  1.1139e-01,\n",
       "                       1.3839e-01,  1.8937e-01,  1.4443e-01, -7.7754e-02,  1.5265e-01,\n",
       "                       1.9907e-01,  1.8268e-01,  9.5079e-02,  1.1760e-01,  8.8442e-02,\n",
       "                       1.4953e-01,  1.9091e-01,  1.7873e-01,  2.4931e-01,  1.5874e-01,\n",
       "                       1.0555e-01,  1.5210e-02,  3.6189e-01,  1.0533e-01,  2.5612e-01,\n",
       "                       1.6426e-01, -4.5615e-02,  9.2721e-03,  2.3232e-01,  1.4470e-01,\n",
       "                       4.5590e-02,  1.8948e-01,  2.2626e-01,  2.8025e-01, -2.8960e-02,\n",
       "                       1.2323e-01,  1.4175e-01,  1.1727e-01,  1.8036e-01,  8.3211e-02,\n",
       "                       1.1243e-01,  1.7406e-01,  5.6726e-02,  2.6780e-01,  1.7604e-01,\n",
       "                      -1.7495e-02,  1.7527e-01,  1.8880e-01,  1.2011e-01,  2.6620e-01,\n",
       "                       1.0994e-01,  1.9231e-01,  2.0666e-01,  1.6098e-01,  1.7385e-01,\n",
       "                       4.6293e-01,  7.0927e-02,  1.2549e-01,  1.7118e-01,  1.3852e-01,\n",
       "                       1.4326e-01,  1.4524e-01,  1.6987e-01,  9.1069e-02,  1.9097e-01,\n",
       "                       6.2431e-02,  3.6708e-02,  2.2407e-01,  7.6308e-02,  2.8308e-01,\n",
       "                       3.5476e-02,  4.7526e-02,  1.4438e-01,  2.9064e-01,  2.0529e-01,\n",
       "                      -3.0836e-02, -6.0047e-03,  1.4007e-01,  2.7770e-01,  2.3777e-01,\n",
       "                       1.1917e-01,  5.0605e-02,  1.4032e-01,  7.6327e-02,  1.3790e-01,\n",
       "                       3.6192e-02,  6.0212e-02,  1.3967e-01,  2.1955e-02,  3.7496e-02,\n",
       "                       1.1500e-01, -6.0703e-02,  1.5911e-01,  3.3616e-02,  3.9604e-01,\n",
       "                       8.8215e-02,  1.4498e-01,  4.6398e-02,  2.5840e-01,  6.1066e-03,\n",
       "                       4.7153e-02,  1.4959e-01,  2.3258e-01,  1.6175e-01,  1.7071e-01,\n",
       "                       2.3565e-01,  1.8276e-01,  7.3809e-02,  1.5758e-01,  1.6539e-01,\n",
       "                       1.2576e-01,  1.1153e-01,  6.2919e-02,  1.1011e-01,  6.6122e-02,\n",
       "                       5.7688e-02,  2.5967e-01,  3.4814e-02,  1.4548e-01,  2.2956e-01,\n",
       "                       1.6505e-01,  8.3992e-02,  2.4051e-01,  2.4305e-01,  1.8120e-01,\n",
       "                       9.4484e-02,  3.3148e-01,  1.0545e-01,  1.4012e-01, -1.0328e-01,\n",
       "                      -1.3200e-02,  8.7103e-02, -2.1658e-02,  1.4705e-01,  7.5085e-02,\n",
       "                       1.7418e-02,  3.9782e-02,  1.3744e-01,  1.6092e-01,  1.6937e-02,\n",
       "                       4.3111e-02,  6.3435e-02, -9.4086e-04, -3.9714e-02, -1.8333e-01,\n",
       "                       1.7542e-01,  5.1387e-03, -5.9161e-03,  1.0136e-01,  1.4948e-01,\n",
       "                       2.8184e-03,  4.6546e-02, -9.8321e-02, -9.2650e-02,  6.3804e-02,\n",
       "                      -3.4388e-02, -4.2134e-02,  1.1273e-01,  9.9660e-02, -8.4604e-02,\n",
       "                      -3.8775e-02,  9.0703e-02, -1.3117e-02, -3.6303e-02, -8.8143e-02,\n",
       "                      -3.7438e-02, -4.5961e-02,  4.3088e-02, -3.0833e-02, -2.9642e-02,\n",
       "                       1.4103e-01,  1.9069e-01, -9.0503e-02,  7.1301e-03,  1.0018e-01,\n",
       "                       1.1029e-02,  1.1871e-02, -5.3751e-02, -7.5247e-02,  5.4748e-03,\n",
       "                      -2.2366e-02, -5.4552e-02,  1.3074e-01,  3.6344e-03,  1.6621e-01,\n",
       "                      -1.9618e-02,  8.5836e-02,  3.4009e-02,  4.4946e-02,  9.0387e-02,\n",
       "                      -1.8963e-02, -4.2432e-02,  1.3969e-01,  1.6943e-02,  1.1829e-01,\n",
       "                       1.0476e-01,  6.9625e-02,  1.6439e-01,  1.1339e-01, -7.0612e-02,\n",
       "                      -1.2236e-02, -2.2065e-04, -3.2192e-02, -6.8774e-02,  2.7779e-02,\n",
       "                      -3.6142e-02,  4.9161e-02,  7.1650e-02,  1.4081e-01, -2.6260e-02,\n",
       "                      -4.2429e-02,  5.2213e-03, -3.4429e-02,  2.4333e-02,  1.3984e-01,\n",
       "                      -3.7531e-02,  4.1286e-02,  9.8957e-02,  1.8360e-01,  4.7350e-02,\n",
       "                      -6.2812e-02, -1.7021e-02,  1.1726e-01,  1.2023e-01,  9.9192e-02,\n",
       "                      -3.0211e-02,  1.7729e-01,  6.1261e-03,  1.2166e-01, -4.9812e-02,\n",
       "                       3.1416e-02,  5.5178e-02,  1.6496e-01, -1.1113e-01, -4.9385e-02,\n",
       "                       8.0572e-02,  3.5568e-02, -8.3514e-03, -6.9528e-02,  2.9421e-03,\n",
       "                       2.9107e-02, -1.6011e-01, -6.4126e-02, -6.5940e-03,  7.6262e-02,\n",
       "                       1.6359e-01,  1.0193e-02, -1.0427e-01,  9.8290e-02,  5.5285e-02,\n",
       "                       3.2527e-02,  1.1286e-01, -8.4370e-02, -7.8888e-02,  3.9911e-02,\n",
       "                       7.1270e-02, -6.6667e-03,  2.5394e-02, -1.8804e-02,  7.6040e-02,\n",
       "                       2.1557e-01,  2.0722e-02, -1.7838e-02, -3.9934e-02,  8.0230e-02,\n",
       "                       9.9558e-02,  3.8139e-02,  9.4106e-02, -1.2930e-02,  3.8499e-02,\n",
       "                      -1.9081e-02,  1.4148e-01, -4.2979e-02,  5.4085e-02,  2.9921e-02,\n",
       "                       4.6300e-02,  4.6751e-02, -1.3412e-01, -1.7870e-02,  6.5639e-02,\n",
       "                      -8.4061e-03,  2.1253e-03, -6.9743e-02, -9.4325e-02, -3.9199e-02,\n",
       "                      -2.8908e-02, -5.1737e-02,  5.1832e-02,  1.9627e-01,  4.2445e-02,\n",
       "                      -4.1105e-04,  4.4320e-02,  2.4526e-02,  8.8185e-03, -7.8324e-02,\n",
       "                      -1.8962e-03, -1.0265e-02,  1.8213e-03,  2.5891e-03,  2.2933e-02,\n",
       "                      -6.7638e-02, -1.2781e-01,  4.4513e-03, -1.7558e-02, -2.6387e-02,\n",
       "                      -3.8414e-02, -4.0202e-02,  6.4340e-02, -1.0707e-02, -3.6753e-02,\n",
       "                       4.5597e-02,  1.3042e-01, -1.3025e-01, -6.6748e-03,  9.6678e-02,\n",
       "                       2.2753e-02, -3.2497e-02, -7.7419e-02, -9.6488e-02,  5.6638e-02,\n",
       "                       2.4126e-02, -2.6544e-02, -2.1853e-02,  7.1737e-02,  1.1125e-01,\n",
       "                      -8.8704e-02,  7.0949e-02, -1.5132e-01,  2.6891e-02, -2.6322e-02,\n",
       "                       9.9311e-02,  1.0640e-01, -1.1955e-03, -8.3984e-02,  3.6252e-02,\n",
       "                      -6.3938e-03, -6.5663e-02,  7.5189e-02,  1.9549e-02,  5.9326e-02,\n",
       "                      -5.9942e-03, -1.2176e-01,  2.7054e-02,  7.2008e-02,  5.6426e-02,\n",
       "                      -5.1055e-02,  5.2086e-02, -9.2844e-02, -1.4225e-01,  1.9515e-02,\n",
       "                       1.6961e-01,  7.7475e-02, -6.0206e-02,  6.1935e-02,  7.2064e-02,\n",
       "                      -6.2421e-02,  3.1632e-02, -2.3707e-02,  3.6000e-02, -1.2434e-01,\n",
       "                      -2.6668e-02, -6.6683e-02,  5.0742e-03, -1.2093e-01, -1.4999e-02,\n",
       "                      -6.0890e-03,  5.4970e-02, -1.3072e-01,  1.6677e-01, -3.2649e-02,\n",
       "                      -3.8513e-02,  1.4108e-01, -3.3142e-02, -3.3777e-02,  6.3158e-02,\n",
       "                       9.5555e-02, -6.9188e-02,  7.7640e-02,  8.4625e-02, -7.1541e-02,\n",
       "                       9.8594e-02,  1.8485e-01,  2.0288e-02, -6.6499e-02,  2.1203e-01,\n",
       "                       2.7414e-02,  1.0712e-01,  1.0713e-01,  1.1800e-02,  1.4338e-01,\n",
       "                       1.5854e-01,  2.6787e-02,  1.5754e-01, -8.6123e-03,  2.5498e-01,\n",
       "                       3.3423e-01,  2.4813e-02, -2.7253e-02,  4.0052e-02,  8.5543e-02,\n",
       "                       2.0310e-01,  1.8498e-01,  3.2178e-01,  1.3704e-01,  8.3675e-02,\n",
       "                       1.6968e-01,  2.4234e-01,  9.9114e-02,  1.9837e-01,  2.2873e-01,\n",
       "                       4.8738e-02,  7.9687e-02,  4.7344e-01,  2.7786e-01, -1.7069e-02,\n",
       "                       1.2420e-01,  1.9782e-01,  1.1274e-01,  1.0807e-01,  4.9815e-02,\n",
       "                       1.6117e-01,  2.0253e-01,  2.9035e-01,  1.9916e-01,  1.2653e-01,\n",
       "                       1.3261e-01,  1.7273e-01,  3.8686e-02,  1.7882e-01,  2.0506e-02,\n",
       "                       1.2545e-01,  3.2320e-01,  1.7608e-01,  4.4883e-02,  1.8124e-01,\n",
       "                       3.4866e-01,  2.3460e-01,  2.2949e-01,  1.1858e-01,  4.5137e-01,\n",
       "                       2.4007e-01,  1.2835e-01,  2.4281e-01,  2.3921e-01,  2.4321e-01,\n",
       "                       7.8052e-02,  1.3513e-01,  3.6686e-03,  4.0895e-02,  1.2613e-01,\n",
       "                       7.0270e-02,  1.9133e-01,  1.9259e-01,  3.4125e-02,  1.3111e-01,\n",
       "                       5.3217e-03,  4.4122e-02,  2.2813e-01,  2.6372e-01,  6.6260e-02,\n",
       "                       3.8176e-02,  1.4709e-01,  1.3307e-01,  1.2219e-01,  1.1602e-01,\n",
       "                       1.8015e-01,  2.4175e-01,  1.9697e-01,  2.2811e-01,  1.0723e-01,\n",
       "                       1.2372e-01,  7.8467e-02,  6.2001e-02,  2.7733e-01,  2.4238e-01,\n",
       "                      -1.5320e-02,  3.5929e-02,  2.7880e-02,  2.5101e-01,  1.5944e-01,\n",
       "                       4.8447e-02,  1.2102e-01,  9.9527e-02,  1.2114e-01,  1.2913e-01,\n",
       "                       1.6205e-01,  1.3326e-01,  2.4361e-01,  2.1679e-01,  2.7774e-01,\n",
       "                       5.5894e-02,  2.9334e-01,  1.0619e-01,  2.2651e-01,  1.5215e-01,\n",
       "                      -3.8966e-02,  3.0332e-01,  1.2941e-01,  2.7341e-01,  4.5805e-02,\n",
       "                       1.7505e-02,  8.9532e-02, -3.3179e-03,  1.7569e-01,  1.2352e-01,\n",
       "                       9.4000e-02,  2.3234e-01,  2.1692e-01,  1.7385e-01,  3.4684e-01,\n",
       "                       1.3401e-01,  2.6893e-01])),\n",
       "             ('bilstm_oov_context_feature.bias_hh_l0_reverse',\n",
       "              tensor([ 2.8618e-01,  5.3589e-02,  2.5905e-01,  3.6982e-01,  5.7844e-02,\n",
       "                       1.2104e-01,  1.2238e-01,  7.1048e-02, -5.8673e-02,  1.9368e-01,\n",
       "                       2.3798e-01,  2.5003e-01,  2.1025e-01,  1.4777e-01,  1.6432e-01,\n",
       "                       1.0297e-01,  2.3757e-01,  1.8862e-02,  3.2146e-01,  8.3667e-02,\n",
       "                       1.0359e-01,  3.6906e-02,  1.8883e-01,  8.8290e-02,  2.6668e-01,\n",
       "                       2.6692e-01,  4.5305e-02,  4.3608e-02,  2.0494e-01,  4.7062e-02,\n",
       "                       5.5966e-02,  1.0688e-01,  2.2709e-01,  1.4806e-01,  3.9234e-02,\n",
       "                       1.1356e-01,  1.4030e-01, -1.4721e-02,  2.0122e-01,  1.5190e-02,\n",
       "                       1.6487e-01,  1.2258e-01,  1.7260e-01,  1.9614e-01,  1.1418e-01,\n",
       "                      -9.4628e-03,  2.5862e-01,  2.1436e-01,  3.8331e-03,  2.4380e-01,\n",
       "                       3.2569e-02,  2.0689e-01,  1.5824e-01,  9.3401e-02,  2.4435e-01,\n",
       "                       2.9917e-01,  1.5497e-01, -7.4399e-02,  1.0579e-01,  1.2107e-01,\n",
       "                       2.1436e-01,  8.4464e-02,  1.8624e-01,  1.3891e-01,  2.8796e-01,\n",
       "                       5.4862e-02,  6.0316e-02,  1.1897e-01,  1.6797e-01,  2.5331e-01,\n",
       "                       1.2653e-01,  5.9064e-02,  2.6006e-01,  2.2853e-01,  2.1189e-01,\n",
       "                       3.9865e-02,  1.3661e-02,  7.5633e-02,  1.4635e-01,  1.4582e-01,\n",
       "                       1.6757e-01,  1.3025e-01,  3.1172e-01,  1.1531e-01,  1.8904e-01,\n",
       "                       7.0777e-02,  1.6849e-01,  1.9077e-01,  5.6497e-02,  1.7963e-01,\n",
       "                       1.3756e-01,  2.7520e-02,  8.7204e-03,  1.2549e-01,  2.9089e-01,\n",
       "                       1.7947e-01,  9.6242e-02,  1.9401e-02,  1.6822e-01,  3.2493e-03,\n",
       "                       8.1389e-02,  1.1015e-01,  1.5817e-01,  1.1706e-01,  1.9832e-01,\n",
       "                       1.2479e-01,  1.5848e-01,  1.6261e-01,  1.4247e-01,  1.8536e-01,\n",
       "                       1.7161e-01,  2.1815e-01,  5.4782e-02,  2.1469e-01,  1.7396e-01,\n",
       "                       1.1722e-02,  2.2140e-01,  1.4657e-01,  2.6534e-01,  2.1005e-01,\n",
       "                       1.1557e-01,  1.2632e-01,  1.1292e-01,  2.7894e-01,  2.4201e-01,\n",
       "                      -1.0494e-02,  3.2677e-01,  5.9937e-02,  1.1631e-01,  3.9297e-02,\n",
       "                       4.3637e-02,  1.6154e-02,  1.4433e-01,  2.4764e-01,  2.4912e-02,\n",
       "                       1.1693e-01,  2.4728e-02,  4.5181e-02,  8.9802e-02, -2.9172e-02,\n",
       "                       1.2944e-01, -4.2206e-02,  9.7554e-02,  1.1107e-01, -1.5209e-01,\n",
       "                       1.0385e-01, -9.2845e-02,  1.0254e-01,  9.3448e-03, -1.7007e-02,\n",
       "                      -9.9521e-02,  1.3155e-01, -8.6742e-02,  2.3854e-02,  8.8871e-02,\n",
       "                      -1.6268e-01, -3.1389e-02,  6.8429e-02, -1.7389e-02,  1.1059e-02,\n",
       "                       1.0563e-01,  7.4942e-02,  7.3621e-02,  2.7698e-02, -1.3477e-01,\n",
       "                       1.0294e-01, -1.4544e-02, -9.8373e-02,  1.9387e-01, -2.8571e-02,\n",
       "                       1.0541e-01,  8.4996e-02, -1.4863e-03, -8.5429e-02,  7.6694e-02,\n",
       "                       4.2446e-02, -1.0405e-01, -1.2809e-01, -3.5528e-02,  7.8066e-02,\n",
       "                       2.1386e-02, -1.2913e-01,  2.0244e-01, -1.1835e-02,  1.1989e-01,\n",
       "                      -4.0941e-02,  1.4794e-01, -4.5665e-02,  6.1656e-02,  7.0795e-02,\n",
       "                       6.4699e-02, -4.6447e-02,  9.1037e-02, -3.5710e-02,  3.2337e-03,\n",
       "                       8.8526e-02,  1.2527e-01,  4.5124e-02,  9.2248e-02, -3.0091e-03,\n",
       "                       3.7891e-02,  1.3027e-01,  4.2598e-02,  6.3338e-02, -1.3390e-01,\n",
       "                       4.1853e-02,  3.7758e-02,  1.0000e-01,  1.8669e-03,  1.9004e-01,\n",
       "                       1.6927e-02, -5.6131e-02,  2.5618e-02,  4.9930e-02,  9.8091e-02,\n",
       "                      -6.9951e-02,  1.3298e-01,  1.1681e-03, -3.4160e-02,  7.0824e-02,\n",
       "                      -2.8093e-02, -8.6909e-02,  1.4916e-01,  7.7447e-02,  2.7574e-02,\n",
       "                       6.4319e-02,  2.2349e-01,  1.0689e-01,  1.0855e-01,  1.1867e-01,\n",
       "                       1.4451e-01,  6.5111e-03,  9.9282e-02, -6.4320e-02,  1.4594e-02,\n",
       "                      -6.2316e-02, -1.1192e-01,  6.0540e-02, -8.6666e-02, -9.2239e-02,\n",
       "                       1.0405e-01, -5.6594e-02,  8.5512e-02, -9.0128e-02,  4.4304e-02,\n",
       "                       1.5183e-01,  6.9771e-02, -5.4177e-02,  3.6773e-03,  1.0977e-02,\n",
       "                       4.2558e-02,  1.3784e-01, -5.5667e-03, -3.8554e-03,  1.1997e-01,\n",
       "                       6.4970e-02,  5.2278e-02,  5.5029e-02, -2.9365e-02,  7.5679e-03,\n",
       "                       1.5704e-01,  1.2242e-01, -4.1623e-02, -8.2651e-02, -7.8638e-02,\n",
       "                      -8.5280e-02,  7.1489e-02,  7.8270e-02, -6.2465e-03,  1.4955e-02,\n",
       "                      -1.1337e-01, -2.1794e-02,  1.2425e-01, -3.1592e-02, -8.4839e-02,\n",
       "                       2.2799e-02,  6.9072e-02, -2.4244e-02, -4.9174e-02,  2.8673e-02,\n",
       "                       9.9277e-02, -1.7037e-02, -1.5043e-01, -1.1141e-01,  5.9140e-02,\n",
       "                      -8.3967e-02, -1.1273e-02, -5.4128e-02,  1.4827e-01,  1.5951e-01,\n",
       "                       1.9044e-02,  1.6001e-02,  7.3777e-02, -6.0845e-02, -4.7581e-02,\n",
       "                      -3.1374e-02, -7.8201e-02, -5.9734e-02,  3.9985e-02, -7.4840e-02,\n",
       "                       2.3374e-02,  6.1958e-02, -8.6479e-02,  3.4187e-02,  2.1623e-02,\n",
       "                       3.8283e-03, -1.2735e-01,  1.2437e-01,  3.1231e-02,  6.5804e-03,\n",
       "                      -9.1856e-02, -6.6009e-02, -4.9450e-02,  9.6580e-02,  7.7295e-02,\n",
       "                       4.3190e-02, -6.0067e-02, -2.8414e-02, -3.3563e-02,  1.5095e-01,\n",
       "                       7.1108e-02, -2.8973e-02,  2.5018e-02,  5.5390e-02, -6.0220e-03,\n",
       "                       5.3563e-02,  2.6946e-02, -4.6175e-02, -2.6981e-02,  8.5103e-02,\n",
       "                      -2.9119e-02,  1.2197e-02, -2.8127e-02, -1.3251e-01, -1.0460e-02,\n",
       "                       5.5247e-02,  7.1692e-02,  3.7720e-02, -4.7784e-02,  1.2823e-01,\n",
       "                      -6.2142e-02,  1.1013e-03,  1.0142e-01, -4.3667e-02, -3.9508e-02,\n",
       "                      -5.8809e-02,  3.2753e-02, -8.9816e-02,  4.7468e-02, -3.5937e-04,\n",
       "                       1.5403e-01,  1.0657e-01, -1.0908e-02, -2.7086e-02,  1.8286e-02,\n",
       "                       6.9778e-03,  1.9109e-02,  3.2964e-02,  7.5199e-02, -1.5885e-02,\n",
       "                      -1.3556e-02, -2.8195e-02, -5.4646e-02, -3.2459e-02,  1.5366e-01,\n",
       "                      -1.4885e-02,  1.1273e-01, -8.2170e-02,  6.5812e-02, -4.5845e-02,\n",
       "                       8.1303e-02,  1.6654e-02,  4.1610e-02, -9.0813e-02, -3.8260e-02,\n",
       "                       2.9680e-03,  8.3663e-02,  1.2348e-01, -2.4699e-02, -4.3131e-03,\n",
       "                      -8.7404e-02, -1.6216e-02,  3.6916e-02,  8.6311e-02,  2.1968e-01,\n",
       "                       1.4990e-01,  6.7363e-02,  1.1580e-01,  4.9124e-03,  1.4465e-01,\n",
       "                       1.8203e-01,  2.2706e-02,  1.7771e-01, -8.5760e-03,  3.1142e-01,\n",
       "                       2.6197e-01, -2.0875e-02,  8.0473e-02,  1.3209e-01, -4.2487e-02,\n",
       "                       2.8514e-01,  3.1936e-01,  2.5983e-01,  1.2189e-01,  1.6810e-01,\n",
       "                       1.6133e-01,  3.0211e-01,  2.0283e-01,  2.5257e-01,  1.6782e-01,\n",
       "                       6.4791e-02,  9.0864e-02,  3.3142e-01,  2.4707e-01,  9.1374e-02,\n",
       "                       9.7713e-02,  2.8698e-01, -1.9160e-02,  1.6109e-02,  3.9748e-02,\n",
       "                       1.1411e-01,  1.6760e-01,  3.4357e-01,  1.5167e-01,  7.6135e-02,\n",
       "                       1.7247e-01,  2.2626e-01,  1.5350e-01,  1.7890e-01, -2.4193e-02,\n",
       "                       2.2394e-01,  3.8260e-01,  3.8637e-02,  1.4570e-01,  8.0274e-02,\n",
       "                       3.6961e-01,  1.0240e-01,  3.5602e-02,  5.4659e-02,  3.5294e-01,\n",
       "                       2.4809e-01,  1.8054e-01,  2.5756e-01,  3.6127e-02,  1.2198e-01,\n",
       "                       1.9343e-01,  8.0073e-02,  6.8153e-03,  1.2189e-01,  6.9513e-02,\n",
       "                      -2.4199e-02,  1.6958e-01,  1.5102e-01,  2.4550e-01,  1.3447e-01,\n",
       "                       1.1196e-01,  6.0887e-02,  2.0714e-01,  2.8988e-01, -2.9947e-02,\n",
       "                       9.4197e-02,  9.3474e-02,  1.7962e-01,  3.7803e-02,  2.6039e-01,\n",
       "                       1.4020e-01,  3.8941e-01,  1.9703e-01,  3.8145e-01,  1.7217e-01,\n",
       "                       1.7979e-01,  1.8794e-02, -3.8305e-02,  2.6770e-01,  3.4256e-02,\n",
       "                      -3.9665e-02,  6.7777e-03,  1.8630e-02,  3.4048e-01,  7.6481e-02,\n",
       "                       7.1698e-02,  1.9225e-01, -3.4720e-03,  1.4729e-01,  1.3280e-01,\n",
       "                       1.6433e-01,  2.4245e-01,  1.3034e-01,  1.6736e-01,  3.0302e-01,\n",
       "                       8.1521e-02,  1.0302e-01,  2.1409e-01,  1.1201e-01, -2.9224e-02,\n",
       "                       3.7526e-02,  3.5744e-01,  1.9797e-01,  8.0599e-02,  6.0893e-02,\n",
       "                       1.3460e-01,  1.0558e-01, -3.5151e-02,  6.2549e-02,  1.2787e-01,\n",
       "                       7.9537e-02,  2.1485e-01,  1.8250e-01,  1.8081e-01,  1.1419e-01,\n",
       "                       6.8774e-02,  1.8541e-01])),\n",
       "             ('bilstm_right_context_feature.weight_ih_l0',\n",
       "              tensor([[ 0.0947,  0.1841, -0.4124,  ...,  0.2793, -0.0523,  0.0332],\n",
       "                      [ 0.0394, -0.1650, -0.1829,  ..., -0.0349,  0.0453, -0.3063],\n",
       "                      [ 0.4810, -0.1504, -0.2034,  ..., -0.0539,  0.0757, -0.3158],\n",
       "                      ...,\n",
       "                      [-0.3052,  0.1927,  0.2508,  ..., -0.0410,  0.1959,  0.0972],\n",
       "                      [ 0.2205,  0.0731, -0.2913,  ...,  0.2811,  0.1083,  0.2442],\n",
       "                      [ 0.0260, -0.0447,  0.3968,  ..., -0.3468, -0.1042, -0.1572]])),\n",
       "             ('bilstm_right_context_feature.weight_hh_l0',\n",
       "              tensor([[-0.0929,  0.1339, -0.0689,  ...,  0.0607,  0.0309, -0.1035],\n",
       "                      [-0.0360, -0.1827, -0.2148,  ..., -0.2140,  0.0762,  0.1158],\n",
       "                      [ 0.2735, -0.2410,  0.1466,  ..., -0.0354, -0.0675,  0.0043],\n",
       "                      ...,\n",
       "                      [ 0.0845, -0.2280, -0.2671,  ...,  0.1704,  0.1013,  0.0191],\n",
       "                      [-0.0477, -0.0964,  0.0159,  ...,  0.2015,  0.0172,  0.2776],\n",
       "                      [-0.0790, -0.2359, -0.1590,  ..., -0.1795,  0.1936, -0.0137]])),\n",
       "             ('bilstm_right_context_feature.bias_ih_l0',\n",
       "              tensor([-9.3036e-04,  1.9664e-02, -6.8310e-02, -1.5500e-02, -2.7287e-02,\n",
       "                      -1.1263e-01,  8.6817e-02,  1.0820e-02, -5.5289e-02,  6.7783e-03,\n",
       "                      -5.9840e-02, -6.8540e-02, -1.3137e-01, -1.4751e-01, -1.5529e-02,\n",
       "                      -4.8405e-02, -1.2766e-01,  5.6627e-03, -1.6411e-01, -1.0586e-01,\n",
       "                      -2.0349e-03, -7.4291e-02, -8.3110e-02, -1.1502e-01,  3.5419e-02,\n",
       "                      -9.8702e-03, -7.2027e-02, -1.4463e-01, -4.9970e-02,  5.5519e-02,\n",
       "                       7.3607e-03, -8.3512e-02,  6.9605e-02, -1.5498e-01, -7.1399e-02,\n",
       "                      -7.7072e-02, -1.3077e-01, -6.5444e-02, -1.5368e-02,  1.2180e-02,\n",
       "                      -5.6126e-04,  5.4763e-02, -6.0303e-02,  1.4174e-01,  1.1728e-02,\n",
       "                      -8.0429e-02, -5.5391e-02,  8.4548e-02,  3.5180e-02,  1.8562e-01,\n",
       "                       4.7697e-03, -1.0753e-01, -1.6669e-01,  2.2249e-02,  1.7726e-02,\n",
       "                      -3.9980e-02,  8.2925e-02, -7.5624e-02,  1.2352e-02,  1.6561e-01,\n",
       "                      -6.6405e-02, -5.9619e-02,  1.7488e-03,  3.6366e-02, -1.2209e-02,\n",
       "                       9.7663e-04, -7.9112e-02,  9.1988e-03,  2.7543e-02,  1.0627e-01,\n",
       "                      -2.9518e-02, -1.0597e-01, -1.0728e-01,  2.0067e-03,  8.0898e-02,\n",
       "                       4.9389e-02, -1.4253e-01,  3.4840e-02,  1.0951e-01, -1.6396e-01,\n",
       "                      -1.4890e-01, -1.6820e-01, -1.7483e-01, -2.4502e-02, -6.9673e-02,\n",
       "                       1.2605e-01, -6.0020e-02,  4.0953e-02, -9.5191e-03, -5.2198e-02,\n",
       "                       5.2508e-02, -1.4234e-01, -5.6444e-02, -2.7170e-02,  1.4851e-01,\n",
       "                      -6.1445e-02, -5.0218e-02, -4.9700e-02, -9.3432e-03, -1.0850e-01,\n",
       "                      -7.3619e-02, -8.5965e-02, -3.3857e-02, -3.5257e-02,  4.5218e-02,\n",
       "                      -2.3463e-02, -8.9769e-02,  1.0346e-01, -1.1904e-01, -3.4195e-02,\n",
       "                       4.5135e-02,  3.3871e-03, -6.5166e-02, -8.9633e-02, -1.4202e-01,\n",
       "                      -1.7621e-01,  7.8318e-02, -2.4520e-02,  3.1005e-03, -7.2332e-02,\n",
       "                      -4.4064e-02, -8.1910e-02, -1.0441e-01,  3.7346e-02, -1.6865e-01,\n",
       "                      -2.1315e-02, -2.4889e-01,  1.0714e-02,  2.5474e-01, -1.1392e-01,\n",
       "                      -8.7477e-02,  6.8341e-02, -6.9510e-02, -1.2749e-01,  4.8766e-02,\n",
       "                       3.1713e-02, -2.5021e-02, -4.1456e-02, -1.3618e-02, -6.6994e-02,\n",
       "                      -8.1697e-02, -1.3376e-01,  1.4109e-01,  5.0145e-02, -1.5923e-01,\n",
       "                      -1.3075e-01,  4.1509e-02, -2.8428e-02, -1.6073e-01,  9.5592e-02,\n",
       "                      -6.0223e-02, -1.7132e-01, -1.8939e-02, -5.5773e-02, -3.4929e-02,\n",
       "                      -6.1914e-03, -1.6624e-01, -3.1262e-01, -3.9963e-02,  9.4726e-02,\n",
       "                      -1.4793e-01, -1.0713e-01,  7.6965e-02, -5.4711e-02, -1.0275e-01,\n",
       "                      -8.1883e-02, -1.4043e-01, -9.6525e-02,  1.4391e-01,  4.9527e-02,\n",
       "                      -1.2291e-01, -3.2784e-03,  3.6126e-02, -4.3756e-02,  8.9811e-02,\n",
       "                      -1.0551e-01, -7.6826e-02, -9.5777e-02,  6.0146e-02, -1.4670e-01,\n",
       "                       1.3528e-02, -7.0490e-02, -1.7631e-01, -1.2734e-01,  4.1432e-04,\n",
       "                       1.2583e-01, -5.2610e-02, -1.0180e-01,  4.7123e-02, -7.9052e-02,\n",
       "                      -6.8998e-02, -7.2198e-02, -7.7602e-02, -1.3941e-02, -1.6489e-01,\n",
       "                      -1.7721e-01, -1.7562e-03, -1.5005e-02, -2.8998e-02, -1.1479e-01,\n",
       "                      -8.1316e-02, -6.6252e-02,  9.1585e-02, -2.3786e-01,  9.5449e-03,\n",
       "                       5.1759e-03, -1.9673e-01, -1.1333e-01, -6.5203e-02, -8.7984e-02,\n",
       "                      -1.9354e-01, -7.5772e-02,  1.6061e-02, -1.2762e-01,  2.4380e-02,\n",
       "                      -1.2037e-01,  1.1502e-01, -8.2664e-02,  4.8195e-02, -6.8794e-02,\n",
       "                      -1.1653e-02, -8.6828e-02,  1.8783e-02, -6.9517e-02, -3.2821e-02,\n",
       "                      -7.0329e-02,  9.5651e-02, -2.4422e-01, -3.2939e-02,  1.4906e-01,\n",
       "                      -1.1480e-01, -1.3954e-01, -7.7120e-02, -1.0180e-01, -3.3248e-02,\n",
       "                      -1.8279e-01, -1.2604e-01, -8.1705e-02,  1.5120e-02,  6.7071e-02,\n",
       "                       9.7627e-04, -3.1401e-02,  2.3754e-02, -1.4198e-02,  1.2763e-02,\n",
       "                      -4.8409e-02, -7.2847e-02,  3.2240e-02, -1.0303e-02, -2.7859e-02,\n",
       "                      -3.9597e-02, -8.5432e-02, -1.0670e-02, -1.4206e-01, -1.2266e-02,\n",
       "                      -2.0927e-02,  7.5346e-03, -1.4722e-01, -4.6610e-03, -1.1959e-03,\n",
       "                      -7.1238e-02, -1.3390e-02, -9.1599e-02, -8.2229e-02,  2.1955e-02,\n",
       "                      -9.8769e-02,  3.8806e-02,  1.9122e-02,  2.3352e-03,  1.0334e-02,\n",
       "                      -7.4481e-02, -6.3497e-02, -8.3899e-03,  1.6240e-01, -5.7523e-02,\n",
       "                       2.7635e-02,  2.4872e-02,  5.4680e-03, -1.9093e-02, -4.6469e-02,\n",
       "                      -1.2098e-02, -3.4543e-02, -2.4131e-02, -9.4330e-02,  1.1045e-01,\n",
       "                       7.9875e-02,  3.4669e-02,  7.7043e-02,  6.6848e-03,  6.6365e-02,\n",
       "                      -2.6676e-02, -7.6215e-02,  6.1389e-02,  3.5561e-03, -1.9270e-03,\n",
       "                       7.3991e-03,  8.9085e-02,  3.2497e-02,  1.9164e-02, -2.2114e-02,\n",
       "                      -4.6877e-02, -8.0961e-02, -2.1154e-02, -2.3567e-02, -1.5698e-01,\n",
       "                      -2.1651e-02, -9.1532e-03,  3.0014e-02, -2.2288e-02, -5.8992e-03,\n",
       "                      -9.3066e-03,  7.6547e-03,  7.0722e-02,  1.5508e-01, -8.2713e-03,\n",
       "                       9.1377e-02, -4.9768e-02,  5.9367e-02, -5.4595e-02, -1.4610e-02,\n",
       "                       2.5899e-02,  5.9830e-02, -4.9782e-02,  1.6918e-01,  6.5985e-02,\n",
       "                      -4.8695e-02,  2.6670e-02, -1.2555e-02,  5.0029e-02, -4.7910e-02,\n",
       "                      -1.3684e-02, -9.0251e-02, -4.9875e-02,  1.3654e-01, -5.2163e-02,\n",
       "                      -3.9198e-02, -7.0540e-03, -1.6378e-02, -4.6271e-02, -2.6671e-02,\n",
       "                       3.1950e-02,  2.8767e-02, -6.7686e-03, -9.7949e-02, -5.6913e-02,\n",
       "                       7.8416e-02,  3.3511e-02,  3.8017e-02, -2.9243e-02,  5.2845e-02,\n",
       "                      -4.9380e-02, -3.0641e-03, -2.7566e-02,  9.7001e-03, -2.5965e-02,\n",
       "                      -1.8739e-02, -9.1614e-02, -1.7458e-02,  6.9242e-02, -4.5309e-02,\n",
       "                       6.5501e-02, -2.6526e-02,  1.9039e-02, -3.0885e-02, -1.3873e-02,\n",
       "                      -3.7261e-02, -3.1387e-02,  5.6092e-02, -4.9509e-03, -3.1879e-02,\n",
       "                       1.2926e-02,  2.6472e-02, -8.9707e-02, -8.9252e-02, -1.2991e-01,\n",
       "                      -4.1462e-02,  9.4711e-02,  3.3715e-02,  5.0637e-02,  3.6250e-03,\n",
       "                      -3.1371e-02, -1.1300e-02, -1.2920e-02, -5.3456e-03, -3.4158e-02,\n",
       "                      -6.4837e-02, -1.2194e-01, -1.5623e-01, -3.5145e-04, -3.8956e-02,\n",
       "                       3.0077e-04,  4.6212e-02,  8.9057e-02, -5.8994e-03,  2.7701e-03,\n",
       "                      -7.1218e-02, -2.2543e-01, -5.5121e-02,  1.8923e-02,  1.4633e-01,\n",
       "                       1.9084e-02, -8.3940e-02, -2.1916e-01,  1.8057e-02, -4.8985e-02,\n",
       "                      -1.2725e-01, -9.9284e-02, -1.7611e-01, -4.7526e-02,  6.4348e-02,\n",
       "                      -1.1236e-01,  1.0038e-01, -5.3219e-02, -7.0001e-02, -1.4512e-01,\n",
       "                       9.7020e-02, -2.7469e-02,  4.9091e-02, -2.4860e-02, -1.3744e-01,\n",
       "                      -3.6594e-02,  5.6110e-02,  1.9644e-02,  3.6447e-02,  1.0184e-01,\n",
       "                       1.3380e-01, -1.2761e-01,  3.1186e-02,  4.9157e-02, -4.6275e-02,\n",
       "                      -8.0975e-02, -5.0071e-02,  5.8506e-02,  4.2030e-02,  8.1986e-02,\n",
       "                      -7.3904e-02, -2.1248e-01,  2.0709e-02,  1.3722e-01, -6.9980e-02,\n",
       "                       8.8947e-02, -1.1241e-01, -9.3586e-02,  3.0540e-02,  5.3404e-02,\n",
       "                      -2.0719e-01, -5.2636e-02, -7.5134e-04, -1.2749e-01,  7.3765e-02,\n",
       "                       1.4778e-01, -4.1055e-02,  1.0799e-01,  2.1028e-02, -1.9013e-03,\n",
       "                      -1.0769e-01,  3.0446e-02, -6.9406e-02,  1.2615e-03,  1.3534e-01,\n",
       "                       1.1229e-04, -7.0763e-02, -7.7024e-02, -3.0424e-02, -1.4402e-01,\n",
       "                      -1.0052e-01, -1.1388e-01,  5.3445e-02, -2.8929e-02,  1.5839e-01,\n",
       "                       2.8804e-02, -9.9058e-02, -2.5380e-02,  4.3431e-02,  5.4205e-02,\n",
       "                       1.3269e-02, -9.3796e-03,  4.0452e-03, -8.2999e-02, -9.9627e-02,\n",
       "                       2.3087e-02, -1.0527e-01,  6.7822e-02, -1.4348e-01, -1.6897e-01,\n",
       "                       2.1763e-02, -2.3732e-02, -7.0708e-02,  7.2679e-02, -1.1820e-01,\n",
       "                       5.7285e-02,  1.3617e-01, -1.4102e-01,  3.8804e-02,  7.9462e-04,\n",
       "                       6.8424e-02, -7.5590e-02, -8.1176e-02, -1.4499e-01,  9.4042e-03,\n",
       "                      -1.2076e-01, -8.1458e-02,  8.0040e-03, -6.4231e-02,  1.2754e-01,\n",
       "                       6.0905e-03, -4.5671e-02, -3.8448e-02, -1.6755e-01,  5.9665e-02,\n",
       "                      -5.5461e-02,  9.5203e-02])),\n",
       "             ('bilstm_right_context_feature.bias_hh_l0',\n",
       "              tensor([-0.0950,  0.1786, -0.0220, -0.1092, -0.0426, -0.1758,  0.0140,  0.1350,\n",
       "                      -0.0661,  0.0037,  0.0392, -0.1128, -0.0639, -0.0600, -0.0612,  0.0113,\n",
       "                      -0.0872,  0.0718, -0.0634, -0.0861, -0.0966, -0.0542, -0.0371, -0.0646,\n",
       "                      -0.0120, -0.0348, -0.1103, -0.1202, -0.2234, -0.0989,  0.0228, -0.0095,\n",
       "                      -0.0613, -0.1232, -0.1427, -0.0245, -0.0549, -0.0196, -0.0780,  0.0807,\n",
       "                      -0.0333,  0.0946, -0.0252,  0.1225, -0.1088, -0.0332, -0.1205, -0.0600,\n",
       "                       0.0155,  0.1302,  0.0271, -0.2899, -0.1057, -0.0583, -0.0108, -0.1028,\n",
       "                       0.0921, -0.0379, -0.1238,  0.1291, -0.0410, -0.0848, -0.0561,  0.1487,\n",
       "                       0.0014,  0.1370,  0.0720, -0.0360,  0.0299,  0.1718, -0.0655, -0.2395,\n",
       "                      -0.0534,  0.0625,  0.0289,  0.0162,  0.0243,  0.0830,  0.0057, -0.0672,\n",
       "                      -0.1295, -0.1873, -0.0449, -0.1020, -0.0965, -0.0092, -0.1105, -0.0523,\n",
       "                       0.0251,  0.0617,  0.0392, -0.0631, -0.0321, -0.1087,  0.0591, -0.0357,\n",
       "                       0.0483, -0.1312, -0.0790, -0.0860, -0.0374, -0.0641,  0.0172, -0.0280,\n",
       "                       0.0916, -0.0084, -0.1139,  0.0330, -0.0960,  0.0129,  0.0059,  0.1583,\n",
       "                      -0.1043, -0.1413,  0.0359, -0.1105,  0.0413, -0.0188, -0.0060,  0.0423,\n",
       "                      -0.0033,  0.0332, -0.1747, -0.0837, -0.0603, -0.0720, -0.1128,  0.1222,\n",
       "                       0.1311, -0.1170, -0.0499,  0.0313,  0.0299,  0.0225,  0.0454,  0.0822,\n",
       "                       0.0276,  0.1263, -0.2343, -0.0556, -0.1314, -0.2129,  0.0119,  0.1441,\n",
       "                      -0.1008,  0.0835,  0.0107, -0.1324, -0.0134, -0.0891,  0.0365, -0.1812,\n",
       "                      -0.0651, -0.1110, -0.1264, -0.0411, -0.0252, -0.1495,  0.0284,  0.1627,\n",
       "                      -0.1645, -0.1429,  0.0446,  0.0279,  0.1057, -0.0433, -0.2686,  0.0393,\n",
       "                       0.0275, -0.1011, -0.0449,  0.0600,  0.0589, -0.1224, -0.1116, -0.0829,\n",
       "                      -0.0231, -0.0244, -0.0166, -0.0407, -0.0376, -0.0650, -0.0543, -0.1768,\n",
       "                      -0.0038,  0.1053, -0.0274, -0.0405, -0.0984, -0.1002, -0.0429, -0.0513,\n",
       "                      -0.0013, -0.0284, -0.1689, -0.1097, -0.1829, -0.0287,  0.0385, -0.0213,\n",
       "                      -0.2021,  0.0203,  0.0418, -0.0615, -0.0743, -0.0402, -0.1547, -0.0836,\n",
       "                      -0.0472, -0.1027, -0.1752, -0.1215,  0.0036, -0.1035,  0.0476, -0.1111,\n",
       "                       0.1750, -0.1161, -0.0224,  0.0626,  0.0017, -0.1160, -0.0373, -0.0531,\n",
       "                      -0.1488,  0.0297,  0.0736, -0.1489, -0.0673, -0.0377, -0.0545, -0.1810,\n",
       "                       0.0285, -0.0708, -0.1213, -0.1049, -0.0349,  0.0331, -0.0726, -0.0509,\n",
       "                      -0.0484, -0.1329, -0.0457,  0.1217,  0.0600, -0.0631, -0.1197, -0.0999,\n",
       "                       0.0393, -0.1579,  0.0151, -0.0114, -0.1509, -0.1722, -0.1432, -0.0609,\n",
       "                      -0.0253,  0.0127, -0.0208, -0.1312,  0.0483,  0.0211,  0.1592,  0.0531,\n",
       "                       0.0839, -0.0698,  0.0053,  0.1406,  0.0248, -0.0008, -0.1241, -0.1933,\n",
       "                       0.0195, -0.0304, -0.0304,  0.1058,  0.0262, -0.0187, -0.0078,  0.1003,\n",
       "                       0.0200, -0.0472, -0.0093,  0.0010,  0.0793, -0.0200,  0.1377, -0.0256,\n",
       "                      -0.0701,  0.0795,  0.0734, -0.1229, -0.0436, -0.0575,  0.0525,  0.0252,\n",
       "                      -0.0787,  0.0188, -0.0495,  0.0118, -0.0979, -0.0800,  0.0279, -0.0636,\n",
       "                       0.0024,  0.0208, -0.1149,  0.0636, -0.0082, -0.0760, -0.0964, -0.0552,\n",
       "                       0.1026, -0.0715, -0.0573, -0.0820, -0.0249,  0.0029,  0.0473, -0.0530,\n",
       "                      -0.0416,  0.0922, -0.0324, -0.0738,  0.0911, -0.0127,  0.0432,  0.0615,\n",
       "                      -0.0632, -0.0248, -0.0027,  0.0698,  0.0964, -0.0213,  0.0535, -0.0587,\n",
       "                       0.0666, -0.0177, -0.0707,  0.0882, -0.1792,  0.0906,  0.0030,  0.0017,\n",
       "                      -0.0913,  0.0361,  0.0575,  0.0171,  0.1236,  0.0366, -0.0071, -0.0729,\n",
       "                      -0.0475, -0.1394, -0.0420, -0.0862,  0.0019, -0.0718, -0.0491, -0.0391,\n",
       "                      -0.0425,  0.0689, -0.0199,  0.1190,  0.0400,  0.0404, -0.0321, -0.0786,\n",
       "                      -0.0611, -0.0216,  0.0133, -0.0592, -0.0494,  0.0209,  0.0344, -0.0604,\n",
       "                       0.0977,  0.0161,  0.0306,  0.0869,  0.0151, -0.0720, -0.0167, -0.0741,\n",
       "                       0.1488,  0.0433, -0.0235, -0.1137, -0.0184, -0.0849, -0.0189,  0.2071,\n",
       "                       0.0289, -0.0699,  0.0164,  0.0020,  0.0210, -0.1060,  0.0536,  0.0716,\n",
       "                      -0.1113, -0.0238, -0.0172, -0.0470, -0.0179,  0.0822, -0.1038, -0.0754,\n",
       "                      -0.1584,  0.0509, -0.2072,  0.0776, -0.1350, -0.0505,  0.0655,  0.0879,\n",
       "                      -0.0211, -0.0308, -0.0335,  0.0284, -0.0266,  0.0906,  0.0280, -0.0418,\n",
       "                       0.0507,  0.0410, -0.0244,  0.0743, -0.0469, -0.0749, -0.1213, -0.0461,\n",
       "                      -0.0209,  0.1254,  0.1093, -0.0916, -0.1161, -0.1187,  0.0649,  0.0286,\n",
       "                      -0.0673, -0.0507,  0.0065,  0.1251,  0.0610, -0.1392, -0.0603,  0.0230,\n",
       "                       0.0084, -0.0781, -0.0253,  0.0127,  0.0570,  0.0008,  0.0487,  0.0618,\n",
       "                      -0.0157, -0.1565, -0.0074,  0.1538, -0.1124,  0.0838,  0.0510,  0.0521,\n",
       "                      -0.2182, -0.0237, -0.0596,  0.0443, -0.0460,  0.0196, -0.0492, -0.1000,\n",
       "                      -0.0397,  0.0034,  0.1055,  0.0216, -0.1341, -0.0840, -0.0861,  0.0567,\n",
       "                      -0.0531,  0.1149,  0.0913, -0.1476, -0.0625,  0.1064,  0.0403, -0.0560,\n",
       "                       0.0789, -0.0966, -0.0676,  0.2051, -0.0675,  0.0295,  0.0317,  0.0324,\n",
       "                      -0.1174, -0.0637, -0.0289, -0.0445,  0.0363,  0.0146, -0.0831,  0.0470,\n",
       "                       0.1140,  0.0341, -0.0609, -0.0946, -0.1267, -0.0181, -0.0895,  0.0310])),\n",
       "             ('bilstm_right_context_feature.weight_ih_l0_reverse',\n",
       "              tensor([[-0.0648, -0.0375,  0.1903,  ..., -0.2006, -0.0068, -0.1086],\n",
       "                      [-0.1610,  0.1631,  0.1810,  ..., -0.0043,  0.0435,  0.1890],\n",
       "                      [-0.3364, -0.3561, -0.3690,  ..., -0.2215,  0.4142, -0.6521],\n",
       "                      ...,\n",
       "                      [ 0.2282, -0.0999, -0.2733,  ..., -0.2654,  0.0325, -0.2623],\n",
       "                      [-0.0208,  0.0573, -0.2344,  ...,  0.1463,  0.1066,  0.0378],\n",
       "                      [-0.2884,  0.0725, -0.3011,  ...,  0.1958,  0.1264,  0.1455]])),\n",
       "             ('bilstm_right_context_feature.weight_hh_l0_reverse',\n",
       "              tensor([[-0.1885,  0.0649, -0.3153,  ..., -0.1963,  0.2203,  0.1198],\n",
       "                      [ 0.2145, -0.1306,  0.0110,  ...,  0.0740,  0.2001, -0.0298],\n",
       "                      [ 0.0350,  0.0034,  0.1597,  ..., -0.1130, -0.0629,  0.1398],\n",
       "                      ...,\n",
       "                      [-0.1130, -0.0155, -0.0131,  ...,  0.1423, -0.2997, -0.0837],\n",
       "                      [ 0.2235,  0.2777, -0.0271,  ...,  0.1958,  0.2362, -0.0122],\n",
       "                      [ 0.0469, -0.2661,  0.4377,  ..., -0.2025,  0.1683, -0.0236]])),\n",
       "             ('bilstm_right_context_feature.bias_ih_l0_reverse',\n",
       "              tensor([ 1.7182e-01,  1.5138e-02,  9.9048e-02,  1.0224e-02, -1.5662e-02,\n",
       "                       6.8160e-02,  1.0161e-01,  1.8199e-01, -4.5593e-02,  1.6201e-01,\n",
       "                       9.2333e-02,  9.6968e-02,  1.2247e-01,  1.2819e-01, -7.4673e-02,\n",
       "                       6.4749e-02,  2.0572e-01, -4.0162e-03, -4.5326e-02,  2.3498e-02,\n",
       "                       1.8727e-01,  2.7060e-02,  3.7698e-02, -8.9968e-03,  7.9803e-02,\n",
       "                      -1.7342e-01,  3.1219e-02, -2.8174e-02,  2.3311e-02,  1.8866e-02,\n",
       "                       1.5117e-01,  4.6098e-02,  3.6177e-02,  7.3820e-02,  1.8297e-01,\n",
       "                      -3.1376e-02,  7.0510e-02,  1.6260e-01, -8.7908e-04,  9.2470e-02,\n",
       "                       1.8212e-01,  1.9926e-01,  1.2044e-01, -4.1228e-02,  4.6412e-02,\n",
       "                       1.3538e-01,  1.0283e-01,  1.8906e-02,  6.3016e-02,  1.6230e-01,\n",
       "                      -5.2361e-02,  2.1054e-01,  8.6752e-02, -2.3388e-01, -1.2561e-02,\n",
       "                       1.0313e-01,  6.3014e-02, -8.0209e-02, -3.4383e-03, -2.0614e-02,\n",
       "                       1.6100e-01, -4.6901e-02,  1.5303e-01,  1.9413e-01,  1.4712e-01,\n",
       "                       1.1706e-02, -9.9171e-02,  9.8531e-02, -2.8806e-02,  9.0501e-02,\n",
       "                      -2.7167e-02,  2.3923e-02,  8.4771e-02,  9.2117e-02,  1.4054e-01,\n",
       "                      -4.3045e-02, -2.5661e-02,  1.6153e-01, -6.0381e-03,  1.5137e-01,\n",
       "                       5.5349e-02,  4.2260e-02,  1.2966e-01,  2.3516e-02, -2.1228e-02,\n",
       "                      -9.7038e-03, -7.2659e-02,  1.8111e-01,  8.3991e-02,  2.6112e-01,\n",
       "                       2.1140e-01,  7.2174e-02,  1.5816e-02, -7.0801e-02,  7.7243e-03,\n",
       "                       8.3961e-02,  4.2707e-02,  3.0775e-02, -7.3462e-02, -1.3980e-01,\n",
       "                      -2.2738e-02,  1.2051e-01,  6.2395e-02,  2.1360e-02,  2.1516e-02,\n",
       "                       9.7128e-02,  1.2563e-02,  5.5215e-02,  2.5311e-02, -4.1005e-02,\n",
       "                      -9.8142e-02,  1.2165e-01,  3.7743e-02, -8.5540e-02, -1.2708e-01,\n",
       "                       7.8911e-02, -6.6594e-02,  1.1793e-01,  1.7560e-01,  1.2508e-01,\n",
       "                      -7.2723e-03,  2.8094e-02, -2.9805e-02, -1.3921e-02,  5.2849e-02,\n",
       "                       1.3534e-01,  1.8453e-02,  4.2785e-02, -5.0313e-02,  2.8537e-02,\n",
       "                      -1.1631e-01, -7.8882e-02,  4.3388e-03, -2.2951e-01, -1.3014e-01,\n",
       "                      -2.2055e-01, -2.5425e-02, -8.5762e-02, -1.2327e-01, -1.6271e-01,\n",
       "                       2.0027e-02, -1.3321e-01,  1.8206e-02,  1.3925e-02, -6.2893e-03,\n",
       "                       5.3639e-02, -1.0984e-01, -5.4166e-02, -5.4201e-02, -1.5750e-02,\n",
       "                      -1.4697e-01, -6.6507e-02, -5.1677e-02, -1.4084e-01, -5.5124e-02,\n",
       "                       2.8608e-03, -6.5515e-02, -1.3052e-01, -3.7178e-02, -7.6845e-02,\n",
       "                       7.9802e-02, -1.2354e-01, -1.8950e-01, -6.8452e-02,  6.5748e-02,\n",
       "                      -1.4447e-01, -2.1202e-01, -2.9302e-02, -1.2665e-01, -7.4937e-02,\n",
       "                      -3.9174e-02, -4.3720e-02, -5.2453e-02,  2.7520e-02, -1.5473e-01,\n",
       "                      -1.2417e-01, -1.8431e-02, -1.1534e-01, -6.7775e-02, -5.3059e-02,\n",
       "                      -2.3601e-02,  1.4182e-02,  4.4264e-02, -1.4344e-01, -5.1650e-02,\n",
       "                      -9.0764e-02, -1.1880e-01,  1.9767e-02,  6.0194e-02,  4.6122e-02,\n",
       "                       6.3228e-02, -8.5396e-02, -2.2892e-01, -4.2977e-02, -9.4025e-02,\n",
       "                       4.8384e-02, -1.3317e-01, -1.7399e-01, -3.5553e-01, -5.8334e-02,\n",
       "                       1.5195e-02, -3.4254e-02, -1.6106e-01,  3.6597e-02, -4.9296e-02,\n",
       "                       9.9828e-02, -1.5988e-01, -6.7163e-02, -1.8702e-02, -3.4863e-02,\n",
       "                       2.9074e-02,  1.6105e-02, -7.8895e-02, -2.2506e-01, -1.3292e-01,\n",
       "                      -7.0682e-02, -7.3533e-02,  2.7811e-02, -1.8405e-02, -7.8883e-02,\n",
       "                      -9.2645e-02, -1.3876e-01,  1.5311e-02, -1.3513e-01,  1.3659e-04,\n",
       "                      -2.6943e-01, -1.1540e-01,  4.2435e-02, -8.7094e-02, -1.0020e-02,\n",
       "                      -5.5934e-02, -1.0508e-01,  9.5910e-02, -1.2575e-01, -4.8601e-02,\n",
       "                      -5.2902e-02, -1.2380e-01, -1.1555e-01,  7.0348e-02,  4.6084e-02,\n",
       "                      -1.4156e-01, -2.4707e-02,  5.0894e-02, -1.4320e-01, -1.9086e-02,\n",
       "                      -5.1452e-02, -3.6838e-02,  2.2514e-02, -5.5178e-02,  3.7887e-02,\n",
       "                      -2.5446e-02, -2.9342e-02, -9.9863e-04, -1.5298e-01,  5.2889e-02,\n",
       "                       3.0606e-02, -1.6751e-02, -4.2010e-03, -5.9378e-02,  8.2341e-02,\n",
       "                      -1.0236e-01, -2.2842e-02,  3.9672e-02, -9.0304e-02, -7.9807e-03,\n",
       "                       2.2800e-02,  1.7965e-02,  2.2915e-02,  2.4206e-02,  6.6320e-02,\n",
       "                      -4.2281e-02,  5.6601e-02,  8.5267e-02, -1.5166e-02, -6.2051e-02,\n",
       "                       1.7027e-01,  1.9065e-03,  4.3826e-02,  2.0090e-02, -2.9376e-02,\n",
       "                       3.5134e-02,  1.0848e-01, -6.8355e-03,  2.6851e-02,  4.0931e-02,\n",
       "                       1.1810e-02, -4.9629e-02,  1.1075e-01,  7.3580e-03,  6.6749e-02,\n",
       "                      -2.2155e-02,  2.2086e-02,  2.8014e-02,  3.4354e-02, -6.1167e-03,\n",
       "                       4.7733e-02,  7.0509e-02,  8.4668e-02,  2.6542e-02, -1.7369e-02,\n",
       "                      -1.2292e-01,  9.9979e-03, -5.8127e-02,  7.8522e-02, -6.7832e-02,\n",
       "                      -1.4212e-02,  9.1653e-03, -7.4907e-02,  9.5320e-02, -2.2760e-02,\n",
       "                       5.7101e-02, -2.1659e-02,  1.1041e-01,  1.2338e-02,  5.0775e-03,\n",
       "                       1.5502e-04, -9.2760e-02, -9.2190e-02, -3.5359e-02,  7.7299e-02,\n",
       "                      -1.5755e-02, -7.9842e-02,  2.3351e-02, -1.2366e-02, -4.8082e-02,\n",
       "                      -3.3552e-02,  5.2020e-02,  1.1999e-01,  2.7268e-02, -2.0720e-02,\n",
       "                       3.4181e-02, -1.0400e-01,  9.8715e-02, -3.8617e-02, -5.1902e-02,\n",
       "                       5.4526e-02, -1.3673e-02, -3.0030e-02,  8.5788e-02,  1.1100e-02,\n",
       "                      -2.1742e-02, -4.8495e-02,  1.6636e-02, -3.0616e-02,  1.0468e-01,\n",
       "                       4.6045e-02, -1.0924e-01,  6.1608e-03,  1.0689e-01,  3.5374e-02,\n",
       "                      -3.0820e-02, -3.3774e-02,  2.5603e-02, -5.8886e-03,  1.0581e-02,\n",
       "                       1.1399e-01,  4.7029e-02, -7.8226e-02, -3.6940e-04, -4.5166e-02,\n",
       "                      -1.2561e-01,  1.7324e-02, -1.2615e-02, -6.5057e-02,  7.4726e-02,\n",
       "                      -3.3995e-02, -1.3400e-01,  1.3847e-01, -3.0443e-02,  4.5738e-02,\n",
       "                       8.8135e-02,  1.1945e-01, -2.1833e-02,  7.8506e-02,  2.1228e-02,\n",
       "                       7.7577e-02, -3.8960e-02,  1.3400e-01,  6.2347e-02, -4.3094e-02,\n",
       "                       3.4201e-02,  8.9206e-02, -7.1605e-03,  2.3640e-02, -3.9586e-02,\n",
       "                       1.2348e-01,  1.7547e-01,  1.4283e-01, -5.8223e-03,  2.5283e-03,\n",
       "                      -1.0680e-02,  2.2338e-01,  6.0939e-02,  2.2238e-01, -3.5879e-03,\n",
       "                      -1.5012e-02,  1.5040e-01, -5.5742e-02,  4.1413e-02,  9.8310e-02,\n",
       "                       1.5769e-01,  7.7993e-03,  6.2368e-02, -1.2680e-01,  2.5645e-01,\n",
       "                       6.8136e-02,  1.0965e-01, -9.1542e-04, -5.5242e-02, -3.8760e-02,\n",
       "                       3.0995e-02,  1.2272e-01,  1.4382e-01,  6.4331e-03,  1.6406e-01,\n",
       "                       4.5719e-02, -3.2226e-02,  4.2171e-02,  1.5053e-02,  8.0122e-02,\n",
       "                       2.3602e-01,  1.1960e-01,  2.9365e-02,  1.4621e-02,  1.8130e-01,\n",
       "                       1.9971e-01,  2.7720e-01, -7.9317e-02,  6.0334e-02,  8.9303e-02,\n",
       "                       1.7163e-01, -2.0558e-01,  5.5278e-02,  1.6260e-01, -6.4161e-02,\n",
       "                       8.0022e-02, -3.0530e-02, -6.5974e-02,  1.1708e-02,  1.7792e-01,\n",
       "                       3.9052e-02,  5.0871e-02, -2.2443e-02,  3.2260e-02,  8.0599e-02,\n",
       "                      -4.9914e-02,  6.3900e-02,  8.8542e-02,  1.4909e-01,  1.1832e-01,\n",
       "                      -8.1708e-02,  1.8744e-01,  3.4900e-02,  6.7864e-02,  1.2923e-01,\n",
       "                      -1.3560e-01,  5.4612e-02,  7.6278e-02,  1.0958e-01,  9.3824e-02,\n",
       "                      -6.4447e-04,  1.2386e-01, -5.0619e-02, -1.4733e-02,  1.1678e-01,\n",
       "                      -4.9979e-02,  5.0574e-02, -1.6663e-02, -7.9062e-02,  6.9079e-02,\n",
       "                       4.8775e-02,  1.2039e-01,  5.3267e-02,  1.2219e-01,  2.2041e-01,\n",
       "                      -7.7059e-02,  8.7095e-03,  5.8392e-02, -7.3419e-02,  2.1793e-01,\n",
       "                      -7.6737e-03, -4.0137e-02, -1.1874e-01,  5.3468e-03,  1.2679e-02,\n",
       "                       3.1861e-01,  1.5670e-01,  2.0155e-01, -7.5562e-02,  9.3231e-02,\n",
       "                      -2.1040e-02, -3.4772e-02, -8.2458e-02, -5.3102e-02,  1.0896e-01,\n",
       "                       5.0159e-02,  1.4358e-01, -5.8640e-03,  5.9057e-02, -5.4986e-02,\n",
       "                       8.1842e-02,  2.4877e-01,  1.2893e-01,  7.4499e-03,  1.1111e-01,\n",
       "                       8.8942e-02, -1.1270e-01,  4.3361e-02,  1.2829e-01,  1.0678e-01,\n",
       "                       1.5670e-02,  8.3921e-02])),\n",
       "             ('bilstm_right_context_feature.bias_hh_l0_reverse',\n",
       "              tensor([ 1.9623e-01,  1.0180e-01,  1.7576e-01,  6.7299e-02,  1.3910e-01,\n",
       "                       6.7112e-02,  9.8627e-02,  1.7319e-01, -2.0305e-02,  3.7390e-02,\n",
       "                       6.3439e-02,  4.1479e-02,  3.2405e-02, -7.0192e-02, -5.8290e-04,\n",
       "                      -1.6185e-02,  1.8511e-01,  9.2724e-02,  3.3690e-02, -1.0835e-01,\n",
       "                       8.1421e-02, -1.0467e-04,  1.5526e-01, -1.2352e-01,  8.7327e-02,\n",
       "                      -8.2832e-03, -2.5987e-02,  1.0243e-01,  1.3136e-01, -9.8355e-02,\n",
       "                       3.6667e-02,  1.6323e-01, -3.4652e-03, -1.3271e-01,  2.6001e-02,\n",
       "                       3.3882e-02,  1.0965e-01,  8.5290e-02,  1.3889e-01, -6.3626e-02,\n",
       "                       2.0065e-01,  1.8443e-01,  2.1255e-01,  2.5803e-02, -7.5825e-02,\n",
       "                       1.1373e-01, -8.1422e-03, -6.5587e-02,  9.5619e-02,  1.0483e-01,\n",
       "                       3.7183e-02,  6.6046e-02,  1.1910e-01, -6.0049e-02,  1.0928e-01,\n",
       "                       1.0072e-01, -6.3115e-02, -6.7433e-02,  1.4293e-01,  6.8294e-02,\n",
       "                       8.2930e-02, -6.1028e-04,  5.8817e-02,  6.1392e-02,  1.2720e-01,\n",
       "                       1.3085e-01,  4.1393e-02,  1.6486e-01,  3.0791e-03,  8.3630e-02,\n",
       "                       7.4623e-02, -1.7426e-02,  2.9646e-01, -2.2351e-02,  1.6643e-01,\n",
       "                       9.4598e-02, -4.1381e-02,  1.4413e-01,  3.2037e-02,  1.1167e-01,\n",
       "                       1.2099e-02,  2.4605e-02,  7.0931e-02, -1.4103e-03, -7.9692e-02,\n",
       "                       8.5518e-02, -2.6935e-02,  1.6387e-01,  2.8272e-02,  2.6609e-01,\n",
       "                       1.0101e-01, -2.3717e-02,  1.0729e-01, -6.6741e-02, -3.8844e-02,\n",
       "                       7.8404e-02, -1.4962e-02,  1.4790e-02,  8.4884e-02, -2.5281e-02,\n",
       "                       6.5755e-02,  4.5648e-02,  1.4292e-01,  2.7677e-02, -1.3068e-01,\n",
       "                       9.1496e-02,  4.2004e-02, -4.3976e-02,  5.9125e-02, -1.4532e-01,\n",
       "                      -2.2513e-02, -6.2537e-02,  3.0167e-02, -7.1606e-03, -4.3075e-02,\n",
       "                      -4.0346e-02, -9.6206e-02,  1.3659e-01,  9.5728e-02,  1.4555e-01,\n",
       "                       1.6277e-01,  1.1255e-01, -2.2242e-02,  1.0895e-01, -6.4178e-02,\n",
       "                       1.1811e-01,  7.2471e-02,  9.0309e-02, -9.2557e-02,  2.8427e-02,\n",
       "                      -2.7508e-02, -7.4434e-02, -3.0641e-02, -1.7872e-01, -9.0237e-02,\n",
       "                      -2.9514e-01, -4.5820e-02, -1.2155e-01, -1.6030e-01, -7.4835e-02,\n",
       "                      -3.6336e-02, -2.0168e-02, -4.9352e-02, -4.8725e-02, -7.0468e-02,\n",
       "                       6.9406e-02, -2.5641e-02, -6.8087e-02, -9.3536e-02, -6.7689e-02,\n",
       "                      -1.4878e-01, -5.9878e-02, -2.1686e-01, -2.3790e-01,  1.5770e-02,\n",
       "                      -4.8495e-02, -9.8108e-02, -8.4033e-02, -3.8121e-02,  1.8280e-02,\n",
       "                       9.0729e-02,  1.1175e-03, -6.1397e-02, -6.1241e-02, -1.3464e-02,\n",
       "                      -2.7215e-01, -8.6337e-02,  1.8297e-02, -1.2816e-01, -4.5886e-02,\n",
       "                      -1.4331e-01, -3.3527e-02, -1.3119e-02, -3.8859e-02, -1.6905e-01,\n",
       "                      -5.9950e-02,  7.9554e-02, -2.9108e-02, -3.8108e-03, -1.2202e-01,\n",
       "                      -1.6431e-01, -5.2131e-02, -3.5004e-02, -5.3626e-02, -1.4890e-01,\n",
       "                      -5.7749e-02, -1.0471e-01, -2.9741e-02,  2.8842e-02,  7.3166e-02,\n",
       "                      -4.9914e-02, -9.9411e-03, -1.1285e-01,  1.3844e-01, -6.4880e-02,\n",
       "                       1.0451e-01, -5.1527e-02, -5.0636e-02, -1.2800e-01, -9.4886e-02,\n",
       "                      -8.6255e-02,  9.7957e-02, -1.1670e-01,  5.3662e-02, -7.4372e-02,\n",
       "                       2.7671e-02, -1.5803e-01, -1.0860e-01, -9.9019e-02, -8.8280e-02,\n",
       "                       2.0208e-02, -1.7262e-01, -1.8852e-04, -1.5206e-01, -1.2179e-02,\n",
       "                      -7.8352e-02, -2.4452e-02, -4.4652e-02,  6.7334e-02, -2.4123e-01,\n",
       "                      -8.7324e-03, -1.8258e-01,  6.7594e-02, -2.2035e-01,  7.6586e-02,\n",
       "                      -1.4705e-01, -1.1393e-01,  2.2049e-01, -1.8851e-01, -1.1956e-01,\n",
       "                      -8.0554e-02, -1.3467e-01, -2.3450e-02, -9.6847e-02, -2.2362e-01,\n",
       "                      -1.3539e-01,  7.6934e-02, -1.0241e-01, -2.7186e-03, -1.3547e-01,\n",
       "                      -7.0786e-02,  1.5954e-02,  4.9768e-02, -5.7981e-02, -6.0442e-02,\n",
       "                      -5.1737e-02, -1.6235e-01,  4.4955e-02, -3.8192e-02, -9.7617e-02,\n",
       "                      -8.7809e-02, -9.8558e-02, -7.8327e-02, -1.3367e-01,  2.1494e-02,\n",
       "                       7.0880e-02, -9.7291e-02, -7.8231e-03,  6.7886e-03,  6.2030e-02,\n",
       "                       4.7756e-03, -6.8173e-02,  4.3075e-02, -9.2753e-03, -6.6255e-02,\n",
       "                       5.7605e-02,  3.7474e-03,  5.7920e-02, -1.7324e-01, -1.2621e-02,\n",
       "                       5.5655e-02, -1.3118e-01,  4.6698e-02, -3.9485e-03, -2.0989e-01,\n",
       "                       7.0776e-02, -7.9956e-02, -1.2127e-01, -1.3490e-02, -1.1271e-01,\n",
       "                      -9.9694e-02,  5.9456e-03, -6.7655e-02,  3.9199e-02, -3.1204e-02,\n",
       "                      -1.3601e-01,  3.1565e-02, -7.0086e-02,  1.3635e-02, -1.1433e-01,\n",
       "                      -8.0099e-02, -3.4258e-02,  9.4297e-03,  1.1714e-01, -4.9378e-02,\n",
       "                       4.9145e-03,  5.6336e-02, -5.3936e-02,  1.5951e-02, -3.8555e-04,\n",
       "                       6.4826e-02,  2.5647e-02, -7.8134e-02, -9.5230e-04, -1.0917e-01,\n",
       "                      -9.3851e-02, -9.2781e-02,  2.4343e-02,  4.5210e-02,  3.1194e-02,\n",
       "                      -1.2291e-01,  2.2295e-02, -4.1774e-03,  7.3279e-02, -2.4521e-02,\n",
       "                       6.1604e-02,  6.6281e-02, -8.3816e-02, -4.5513e-02, -7.2436e-03,\n",
       "                       7.1965e-02,  7.0500e-02,  5.6925e-02, -7.1522e-03, -1.0616e-01,\n",
       "                       2.7863e-02, -3.6681e-02,  6.6215e-02,  2.4896e-02, -2.7932e-02,\n",
       "                       2.1714e-02,  2.1328e-02,  2.8635e-02, -3.9157e-02, -1.9999e-02,\n",
       "                      -1.6771e-01, -4.9485e-02, -3.5702e-02,  4.8586e-02, -8.4019e-03,\n",
       "                       2.5628e-02, -1.1699e-01, -3.4534e-02,  3.9814e-02,  1.0274e-01,\n",
       "                       2.8662e-02,  1.2521e-01, -6.5688e-03, -3.2278e-02,  4.0212e-02,\n",
       "                      -1.5397e-02, -1.0869e-01,  1.0484e-01,  3.9106e-03,  5.1036e-02,\n",
       "                      -3.5072e-02,  7.4883e-02, -1.6297e-01,  5.4586e-02,  1.0768e-01,\n",
       "                       6.2740e-03,  7.4062e-02, -6.0393e-02, -2.0195e-02, -1.6407e-02,\n",
       "                       4.5354e-02,  3.3014e-02,  1.1024e-02,  3.2172e-02, -7.8834e-02,\n",
       "                      -3.9293e-02,  1.0290e-01, -9.1305e-02, -5.7033e-02, -6.1282e-02,\n",
       "                       6.5669e-02,  2.0706e-02,  4.3905e-02, -4.6776e-03, -1.3745e-01,\n",
       "                      -1.2230e-02,  1.4099e-03, -6.6107e-02, -2.9772e-02,  1.2650e-01,\n",
       "                       1.0272e-01,  2.3717e-01, -1.2411e-02, -3.4084e-02, -2.3365e-02,\n",
       "                      -3.8771e-02,  1.6920e-01, -1.8137e-02,  1.8654e-01, -3.4560e-02,\n",
       "                      -1.6516e-02,  5.1553e-02, -5.7498e-03,  1.1550e-02,  8.4153e-03,\n",
       "                       2.0042e-01,  7.6664e-02,  5.1450e-02, -8.7398e-02,  2.6244e-01,\n",
       "                       2.3001e-02,  4.6508e-02, -7.7592e-02,  1.4763e-01, -9.1461e-02,\n",
       "                       5.3875e-02, -1.2962e-02,  8.1476e-02, -4.5579e-03, -9.2318e-03,\n",
       "                       1.4828e-01,  4.0555e-03, -6.3931e-03,  1.2903e-01,  2.4703e-01,\n",
       "                       2.5501e-01,  1.8171e-01,  8.6711e-02, -6.7395e-02,  2.5672e-01,\n",
       "                       1.4890e-01,  1.4024e-01, -1.7951e-02,  5.2245e-02,  6.0750e-02,\n",
       "                       2.8406e-02, -1.6419e-01,  5.5949e-02,  2.3120e-01, -1.0371e-01,\n",
       "                       5.1572e-02,  2.5788e-02, -1.4866e-01,  4.8121e-02, -6.7161e-02,\n",
       "                      -1.1227e-02,  4.6725e-03,  2.4015e-02,  1.4187e-01,  6.6762e-02,\n",
       "                      -9.5800e-02,  4.9888e-02,  8.0786e-02,  1.4872e-01,  1.4092e-01,\n",
       "                      -2.3982e-02,  1.1622e-01,  5.6867e-02, -1.3395e-01,  6.3905e-02,\n",
       "                      -2.9787e-02,  1.0276e-01,  1.7136e-01,  1.5217e-01,  4.7048e-02,\n",
       "                      -1.1140e-02,  9.9696e-02,  9.4477e-02,  2.3024e-01,  5.5844e-02,\n",
       "                       9.0162e-02, -8.2188e-02, -1.6021e-01, -1.0077e-02, -9.8761e-02,\n",
       "                       3.4006e-02,  1.6957e-01, -3.3131e-02,  2.4325e-01,  1.4726e-01,\n",
       "                       6.3513e-02, -2.8444e-02,  5.6819e-02, -1.2065e-01,  2.2007e-01,\n",
       "                       1.0604e-01,  4.2507e-02,  1.9972e-02,  6.6474e-02, -2.6618e-02,\n",
       "                       1.1456e-01, -6.4520e-03,  6.2825e-02, -1.9934e-02,  9.8686e-02,\n",
       "                       6.3884e-02,  4.8114e-02,  1.4719e-02, -7.5179e-02,  1.9171e-01,\n",
       "                      -5.0796e-02,  1.5800e-01, -1.1938e-01,  2.0050e-02, -1.2764e-01,\n",
       "                       6.7115e-02,  1.3127e-01,  2.1307e-02, -1.1131e-01,  1.4903e-01,\n",
       "                       2.2734e-01,  8.3823e-04, -3.6392e-02,  2.6517e-02,  6.2913e-02,\n",
       "                       7.5758e-02,  6.8243e-02])),\n",
       "             ('fc.0.weight',\n",
       "              tensor([[-0.0287,  0.1227,  0.0376,  ..., -0.1026,  0.2277, -0.0573],\n",
       "                      [-0.1214, -0.2623, -0.0960,  ...,  0.1120, -0.1558,  0.1709],\n",
       "                      [ 0.1262, -0.0390, -0.1127,  ...,  0.1759, -0.0778,  0.3419],\n",
       "                      ...,\n",
       "                      [ 0.1381,  0.0248, -0.0039,  ...,  0.1401,  0.0539,  0.2665],\n",
       "                      [-0.1351,  0.0349,  0.1170,  ..., -0.3100,  0.2449, -0.0292],\n",
       "                      [-0.1243, -0.0615, -0.1682,  ...,  0.1909,  0.0892, -0.0216]])),\n",
       "             ('fc.0.bias',\n",
       "              tensor([-0.0076, -0.2780,  0.0846, -0.0015, -0.1314, -0.1407, -0.1170,  0.0357,\n",
       "                      -0.1480, -0.2121,  0.2266,  0.2304, -0.2201,  0.1613,  0.0977, -0.1968,\n",
       "                      -0.0863,  0.3276, -0.4428,  0.0468,  0.0854,  0.0125, -0.2055, -0.2175,\n",
       "                       0.2120, -0.0484,  0.0650,  0.0943, -0.1517,  0.0144, -0.1066,  0.1651,\n",
       "                       0.0291, -0.0558, -0.1172, -0.0086, -0.0010, -0.1959,  0.3550, -0.2492,\n",
       "                      -0.2606,  0.0583, -0.1989, -0.0224, -0.0908,  0.3912, -0.3104, -0.1033,\n",
       "                      -0.1182,  0.0814, -0.0784, -0.1636,  0.2652, -0.1139,  0.0864, -0.2185,\n",
       "                       0.0658,  0.2976, -0.0023,  0.1433,  0.2611, -0.2902, -0.0405,  0.1843])),\n",
       "             ('oov_embedding.weight',\n",
       "              tensor([[-0.1687, -0.2167, -0.0958,  ..., -0.1007,  0.2994, -0.0065],\n",
       "                      [ 0.0953,  0.0108,  0.2493,  ..., -0.0040,  0.1235,  0.1194],\n",
       "                      [-0.2129, -0.1828,  0.0268,  ...,  0.1875,  0.1639, -0.0034],\n",
       "                      ...,\n",
       "                      [-0.1559,  0.0296, -0.0963,  ..., -0.0425,  0.1391, -0.3235],\n",
       "                      [-0.3495,  0.0113, -0.0789,  ...,  0.0565, -0.1090, -0.0123],\n",
       "                      [ 0.1071,  0.1211,  0.3178,  ...,  0.1979,  0.0883,  0.3254]])),\n",
       "             ('oov_embedding.bias',\n",
       "              tensor([ 0.2545, -0.1988,  0.0130, -0.0236,  0.0319,  0.2058,  0.0382, -0.3326,\n",
       "                      -0.1598,  0.0778,  0.2639,  0.1177,  0.1568, -0.2950, -0.0304, -0.1293,\n",
       "                      -0.3248,  0.0443,  0.0714,  0.1613,  0.0126,  0.0359,  0.0132, -0.1581,\n",
       "                      -0.0946, -0.0947,  0.2202, -0.0063,  0.2726, -0.4059,  0.1262,  0.0221,\n",
       "                      -0.1546, -0.1203,  0.1365,  0.0797,  0.0326,  0.0960, -0.0839,  0.1202,\n",
       "                       0.1444,  0.1067, -0.2546, -0.0703, -0.4328,  0.1202, -0.2061,  0.0390,\n",
       "                      -0.1891,  0.0808, -0.2566,  0.1226,  0.0337,  0.1263,  0.0622,  0.1223,\n",
       "                       0.4176,  0.0471, -0.1429,  0.0896,  0.0909, -0.4120, -0.4110, -0.1860])),\n",
       "             ('prob.0.weight',\n",
       "              tensor([[ 2.9477e-02, -1.0721e-01,  5.0129e-02,  ..., -7.1567e-02,\n",
       "                        2.0688e-01, -6.4468e-02],\n",
       "                      [-1.0221e-01, -2.8140e-02,  2.3314e-01,  ..., -3.5281e-02,\n",
       "                       -1.1491e-02,  7.5149e-02],\n",
       "                      [-2.2829e-01, -3.7146e-01,  2.1333e-01,  ..., -3.5654e-04,\n",
       "                       -2.5221e-01,  8.1463e-02],\n",
       "                      ...,\n",
       "                      [-1.5172e-01, -9.0245e-02,  1.6201e-02,  ..., -4.4147e-01,\n",
       "                       -1.4543e-01, -2.3360e-01],\n",
       "                      [-4.7991e-02, -4.4665e-03, -2.7915e-01,  ...,  2.2337e-01,\n",
       "                       -6.2104e-02, -2.9121e-01],\n",
       "                      [-2.4128e-02,  8.3186e-02, -3.8216e-02,  ..., -3.9175e-02,\n",
       "                       -2.0135e-01,  3.6366e-01]])),\n",
       "             ('prob.0.bias',\n",
       "              tensor([-0.3943, -0.0478, -0.1042,  ...,  0.0095, -0.0832, -0.1610]))])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1616de6-2ec1-4a77-980a-addd6d77d6d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
