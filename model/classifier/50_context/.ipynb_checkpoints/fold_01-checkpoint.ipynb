{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8319205c-12ab-4314-8558-cfae2ca2d1bb",
   "metadata": {},
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41f1e2d8-ccca-4f8b-97e8-4ab8bf6c5886",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import pickle\n",
    "import pytz\n",
    "import torch\n",
    "import timeit\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from copy import deepcopy\n",
    "from datetime import datetime\n",
    "from einops import rearrange\n",
    "from itertools import chain\n",
    "from time import time\n",
    "from torch import nn, optim\n",
    "from torchmetrics.classification import MulticlassAccuracy, MulticlassF1Score, MulticlassConfusionMatrix\n",
    "from torch.optim import lr_scheduler\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from polyglot.mapping import Embedding, CaseExpander, DigitExpander"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3015ead4-c615-4dbc-aa8c-c7e611c3b76e",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecab9839-baf2-480b-a00d-53dc81c66ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hyperparams:\n",
    "     def __init__(\n",
    "        self,\n",
    "        context_size=50,\n",
    "        fold=1,\n",
    "        max_seq_len=82,\n",
    "        input_size=64,\n",
    "        batch_size=32,\n",
    "        num_hidden_layer=1,\n",
    "        hidden_size=128,\n",
    "        dropout=0,\n",
    "        bias=True,\n",
    "        output_size=24,\n",
    "        shuffle=True,\n",
    "        lr=0.005,\n",
    "        batch_first=False,\n",
    "        bidirectional=True,\n",
    "        init_wb_with_kaiming_normal=True,\n",
    "        n_epoch=50,\n",
    "        patience=50,\n",
    "        device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    ):\n",
    "        self.context_size = context_size\n",
    "        self.fold = fold\n",
    "        self.input_size = input_size\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.batch_size = batch_size\n",
    "        self.num_hidden_layer = num_hidden_layer\n",
    "        self.hidden_size = hidden_size\n",
    "        self.dropout = dropout\n",
    "        self.bias = bias\n",
    "        self.output_size = output_size\n",
    "        self.shuffle = shuffle\n",
    "        self.lr = lr\n",
    "        self.batch_first = batch_first\n",
    "        self.bidirectional = bidirectional\n",
    "        self.init_wb_with_kaiming_normal = init_wb_with_kaiming_normal\n",
    "        self.n_epoch = n_epoch\n",
    "        self.patience = patience\n",
    "        self.device = device\n",
    "\n",
    "hyperparams = Hyperparams()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3651614b-b4a1-4968-88a1-ac38e4dc8323",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d70aa1f-c03c-4ec8-b720-0eca1d63020b",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_pos_tag = pd.read_csv(\"../../../datasets/raw/Indonesian_Manually_Tagged_Corpus.tsv\", sep=\"\\t\", header=None, names=[\"token\", \"tag\"], quoting=csv.QUOTE_NONE, skip_blank_lines=False) \n",
    "train = pd.read_csv(f\"../../../datasets/raw/cv/train/train.0{hyperparams.fold}.tsv\", sep=\"\\t\", header=None, names=[\"token\", \"tag\"], quoting=csv.QUOTE_NONE, skip_blank_lines=False)\n",
    "val = pd.read_csv(f\"../../../datasets/raw/cv/val/val.0{hyperparams.fold}.tsv\", sep=\"\\t\", header=None, names=[\"token\", \"tag\"], quoting=csv.QUOTE_NONE, skip_blank_lines=False)\n",
    "test = pd.read_csv(f\"../../../datasets/raw/cv/test/test.0{hyperparams.fold}.tsv\", sep=\"\\t\", header=None, names=[\"token\", \"tag\"], quoting=csv.QUOTE_NONE, skip_blank_lines=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7ce54d-7e46-4d41-aa8e-1dd7f33b8fa4",
   "metadata": {},
   "source": [
    "# Pre-trained Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39c6717c-8302-45dd-acfc-625c92530a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = Embedding.load(\"../../../word_embeddings/polyglot/idn_embeddings.tar.bz2\")\n",
    "embeddings.apply_expansion(DigitExpander)\n",
    "embeddings.apply_expansion(CaseExpander)\n",
    "\n",
    "oov_embeddings = pickle.load(open(f\"../../../logs/comick/{hyperparams.context_size}_contexts/10-11-2022_15-24-28/oov_embedding_dict.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158ed87f-c18d-4a59-a47b-c4e874b951bb",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d29837c-9113-4d5d-b835-351bce316e07",
   "metadata": {},
   "source": [
    "## Add OOV Flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08aeabff-e02c-4d83-bdee-ca428d401eaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "905f415f48eb46feb943bab45712d66c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/266652 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c6a0a959cc748a7bdc2e283c584c260",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/191567 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d254b2b4b6543eb990616e3c924ac51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21461 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f704acecb77b45898f0c5832f753e8a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/53624 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def add_oov_flag(tokens, embeddings):\n",
    "    oov_flags = []\n",
    "    \n",
    "    for token in tqdm(tokens):\n",
    "        try:\n",
    "            if token not in embeddings:\n",
    "                oov_flags.append(True)\n",
    "            else:\n",
    "                oov_flags.append(False)\n",
    "        except:\n",
    "            oov_flags.append(False)\n",
    "        \n",
    "    return pd.DataFrame(oov_flags, columns=[\"is_oov\"])\n",
    "\n",
    "id_pos_tag_oov_flags = add_oov_flag(id_pos_tag[\"token\"].values, embeddings)\n",
    "train_oov_flags = add_oov_flag(train[\"token\"].values, embeddings)\n",
    "val_oov_flags = add_oov_flag(val[\"token\"].values, embeddings)\n",
    "test_oov_flags = add_oov_flag(test[\"token\"].values, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1a6631-74de-483c-b03d-a4176880b8af",
   "metadata": {},
   "source": [
    "## Concate OOV Flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97cddb08-c462-4fd0-b348-44f5464cbb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_pos_tag_df = pd.concat([id_pos_tag, id_pos_tag_oov_flags], axis=1)\n",
    "train_df = pd.concat([train, train_oov_flags], axis=1)\n",
    "val_df = pd.concat([val, val_oov_flags], axis=1)\n",
    "test_df = pd.concat([test, test_oov_flags], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8183be89-5b99-42f8-bedf-8061a990d8b1",
   "metadata": {},
   "source": [
    "## Lowercase OOV Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "441d0127-b999-49e3-ae3d-73d01c5cb9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_pos_tag_df['token'] = np.where(id_pos_tag_df['is_oov'] == True, id_pos_tag_df['token'].str.lower(), id_pos_tag_df['token'])\n",
    "train_df['token'] = np.where(train_df['is_oov'] == True, train_df['token'].str.lower(), train_df['token'])\n",
    "val_df['token'] = np.where(val_df['is_oov'] == True, val_df['token'].str.lower(), val_df['token'])\n",
    "test_df['token'] = np.where(test_df['is_oov'] == True, test_df['token'].str.lower(), test_df['token'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d866169-d378-495d-9af7-c1939feaae40",
   "metadata": {},
   "source": [
    "## Embedding Dict, Index to Token and Token to Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3130fc5d-3e7e-480d-9f47-b5af4b2ce3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = list(id_pos_tag_df[[\"token\", \"tag\", \"is_oov\"]].itertuples(index=False, name=None))\n",
    "\n",
    "def embedding_dict(tokens, embeddings, oov_embeddings):\n",
    "    embedding = {}\n",
    "    \n",
    "    for token in tokens:\n",
    "        if token[0] is not np.nan:\n",
    "            if token[2] == False or token[0] in embeddings:\n",
    "                embedding[token[0]] = embeddings[token[0]]\n",
    "            else:\n",
    "                embedding[token[0]] = oov_embeddings[token[0].lower()]\n",
    "\n",
    "    return embedding\n",
    "\n",
    "embedding_dict = embedding_dict(tokens, embeddings, oov_embeddings)\n",
    "embedding_dict[\"<PAD>\"] = embeddings[\"<PAD>\"]\n",
    "word_embeddings = nn.Embedding.from_pretrained(torch.FloatTensor(np.array(list(embedding_dict.values()))), padding_idx=list(embedding_dict.keys()).index(\"<PAD>\"), freeze=True)\n",
    "\n",
    "idx_to_token = {idx: token for idx, token in enumerate(list(embedding_dict.keys()))}\n",
    "token_to_idx = {token: idx for idx, token in enumerate(list(embedding_dict.keys()))}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab92441-64b9-430e-a8d6-4b4df859cefc",
   "metadata": {},
   "source": [
    "## Token to Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3703497-9ee3-43b9-9705-fcfd2a3f1d94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35358849c07b4615b82afe683541bdc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/266652 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cab1ec17e85b4b0fa03c2fc1a2f20b4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/191567 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d13d8969abb54778bd12f04b4fc430df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/53624 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "428d36ce67b34370b1c553f91fc43eac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21461 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def make_sentence(tokens, max_length_sentence=hyperparams.max_seq_len):\n",
    "    sentence = []\n",
    "    sentences = []\n",
    "\n",
    "    for token in tqdm(tokens):\n",
    "        if token[0] is not np.nan:\n",
    "            sentence.append(token)\n",
    "        else:\n",
    "            sentences.append(sentence[:max_length_sentence])\n",
    "            sentence = []\n",
    "\n",
    "    return sentences\n",
    "\n",
    "all_sentence = make_sentence(list(id_pos_tag_df[[\"token\", \"tag\", \"is_oov\"]].itertuples(index=False, name=None)))\n",
    "train_sentences = make_sentence(list(train_df[[\"token\", \"tag\", \"is_oov\"]].itertuples(index=False, name=None)))\n",
    "val_sentences = make_sentence(list(test_df[[\"token\", \"tag\", \"is_oov\"]].itertuples(index=False, name=None)))\n",
    "test_sentences = make_sentence(list(val_df[[\"token\", \"tag\", \"is_oov\"]].itertuples(index=False, name=None)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220e44ae-dae4-421f-b35e-97e23727e90c",
   "metadata": {},
   "source": [
    "## Word Token, Padding, and Word token to Index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43f0cf3b-695c-4abe-b462-f5aed832efc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "157cb8016ff84d7fb7064f268ef900f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7222 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f18c4abfccb4d878d9294a24f843f5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7222 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f37a0b2e7b6400095d27ac56faf83ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7222 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a10434664284313aa4cb85a8c72f973",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2006 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e1933178efc4f2983e5dc5893d1785b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2006 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b582deaa30404276833ca1307fba330a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2006 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f12e742483041b18905852770a6559b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/802 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe5ad9728a474e8baf7ef05eee5bcabd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/802 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e044cc4a1bf641898e918908782d185a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/802 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize_docs(docs, idx_token):\n",
    "    new_sentence = []\n",
    "    sentences = []\n",
    "    \n",
    "    for sentence in tqdm(docs):\n",
    "        for token in sentence:\n",
    "            new_sentence.append(token[idx_token])\n",
    "        sentences.append(new_sentence)\n",
    "        new_sentence = []\n",
    "\n",
    "    return sentences\n",
    "\n",
    "def padding(docs, max_seq_len=hyperparams.max_seq_len, mode=\"post\", val_pad=\"<PAD>\"):\n",
    "    docs = deepcopy(docs)\n",
    "    doc_with_pad = []\n",
    "    docs_with_pad = []\n",
    "\n",
    "    for doc in tqdm(docs):\n",
    "        if mode == \"pre\":\n",
    "            for _ in range(max_seq_len - len(doc)):\n",
    "                doc.insert(0, val_pad)\n",
    "        elif mode == \"post\":\n",
    "            for _ in range(max_seq_len - len(doc)):\n",
    "                doc.append(val_pad)\n",
    "        else:\n",
    "            return f\"Mode {mode} is not available, use instead 'pre' or 'post'.\"\n",
    "        \n",
    "        docs_with_pad.append(doc)\n",
    "        \n",
    "    return np.array(docs_with_pad)\n",
    "\n",
    "def sent_to_idx(docs, token_to_idx):\n",
    "    new_sentence = []\n",
    "    sentences = []\n",
    "    \n",
    "    for sentence in tqdm(docs):\n",
    "        for token in sentence:\n",
    "            new_sentence.append(token_to_idx[token])\n",
    "        sentences.append(new_sentence)\n",
    "        new_sentence = []\n",
    "\n",
    "    return np.array(sentences)\n",
    "\n",
    "def convert_feature_to_idx(docs, idx_token, token_to_idx, max_seq_len):\n",
    "    sentences = tokenize_docs(docs, idx_token)\n",
    "    sentences_with_pad = padding(sentences, max_seq_len=max_seq_len, mode=\"post\", val_pad=\"<PAD>\")\n",
    "    sentences_to_idx = sent_to_idx(sentences_with_pad, token_to_idx)\n",
    "    \n",
    "    return sentences_to_idx\n",
    "\n",
    "train_sentence_idxs = convert_feature_to_idx(train_sentences, 0, token_to_idx, hyperparams.max_seq_len)\n",
    "val_sentence_idxs = convert_feature_to_idx(val_sentences, 0, token_to_idx, hyperparams.max_seq_len)\n",
    "test_sentence_idxs = convert_feature_to_idx(test_sentences, 0, token_to_idx, hyperparams.max_seq_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c2d150-0276-4ea8-a844-1a06b0b911c6",
   "metadata": {},
   "source": [
    "## Encode Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76c9be34-f098-4b1e-8a4e-d8d06e43e96f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9776f05bc1e446bfb2344d7490991a13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7222 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "489c75f08fa642b9a4c7bcf5b9c21a58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2006 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a072e505cb84bfa89c7e57f69af3b6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/802 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shape   : ((7222, 82), (7222, 82))\n",
      "validation shape : ((2006, 82), (2006, 82))\n",
      "Test shape       : ((802, 82), (802, 82))\n"
     ]
    }
   ],
   "source": [
    "classes = sorted(np.delete(id_pos_tag_df[\"tag\"].unique(), 3))\n",
    "idx_to_label = {idx: label for idx, label in enumerate(classes + [\"<PAD>\"])}\n",
    "label_to_idx = {label: idx for idx, label in enumerate(classes + [\"<PAD>\"])}\n",
    "\n",
    "def encode_class(docs, label_to_idx, seq_len=hyperparams.max_seq_len):\n",
    "    class_idxs = []\n",
    "    classes = []\n",
    "    \n",
    "    for sentence in tqdm(docs):\n",
    "        for token in sentence:\n",
    "            class_idxs.append(label_to_idx[token[1]])\n",
    "            \n",
    "        for _ in range(seq_len - len(sentence)):\n",
    "            class_idxs.append(label_to_idx[\"<PAD>\"])\n",
    "                \n",
    "        classes.append(class_idxs)\n",
    "        class_idxs = []\n",
    "\n",
    "    return np.array(classes)\n",
    "        \n",
    "train_class_idxs = encode_class(train_sentences, label_to_idx)\n",
    "val_class_idxs = encode_class(val_sentences, label_to_idx)\n",
    "test_class_idxs = encode_class(test_sentences, label_to_idx)\n",
    "\n",
    "print(f\"Training shape   : {train_sentence_idxs.shape, train_class_idxs.shape}\")\n",
    "print(f\"validation shape : {val_class_idxs.shape, val_class_idxs.shape}\")\n",
    "print(f\"Test shape       : {test_sentence_idxs.shape, test_class_idxs.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d6d808-0ee8-4979-bcee-43b5020ac96f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Note\n",
    "\n",
    "- Number of sentences = 10030\n",
    "- Train : 72% (7222)\n",
    "- Val   : 8% (802)\n",
    "- Test  : 20% (2006)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33573647-a8e8-474e-9c88-beee03332ec6",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535f0ccc-e2ca-4aa7-b1c3-d782696a3fab",
   "metadata": {},
   "source": [
    "## Feature and Actual Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8927d980-8ee5-4a78-870a-7bef385dbbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature = torch.LongTensor(train_sentence_idxs)\n",
    "val_feature = torch.LongTensor(val_sentence_idxs)\n",
    "test_feature = torch.LongTensor(test_sentence_idxs)\n",
    "\n",
    "train_class = torch.LongTensor(train_class_idxs)\n",
    "val_class = torch.LongTensor(val_class_idxs)\n",
    "test_class = torch.LongTensor(test_class_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "438bf817-b692-48d7-b7ac-3e96f4fcc6e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([7222, 82]), torch.Size([2006, 82]), torch.Size([802, 82]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feature.shape, val_feature.shape, test_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd249179-151f-4197-b90b-3b3cd4bcb15b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([7222, 82]), torch.Size([2006, 82]), torch.Size([802, 82]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_class.shape, val_class.shape, test_class.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c681e53-f708-4c1f-864d-ab93f19412c2",
   "metadata": {},
   "source": [
    "## Tensor Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ae72c8a-6bac-4736-9148-75953831a786",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(train_feature, train_class)\n",
    "val_dataset = TensorDataset(val_feature, val_class)\n",
    "test_dataset = TensorDataset(test_feature, test_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a20687-dcce-432c-bcab-eda007eb35c7",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "454a5731-663c-4776-b855-ae1b6be2cb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=hyperparams.batch_size, shuffle=hyperparams.shuffle)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=hyperparams.batch_size, shuffle=hyperparams.shuffle)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=hyperparams.batch_size, shuffle=hyperparams.shuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1b71ac-f59f-45d3-a06a-54602ded7e95",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a8bc8230-8e64-4f59-b284-da8cced683f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "POSTagger(\n",
       "  (feature): LSTM(64, 128, bidirectional=True)\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=24, bias=True)\n",
       "    (1): Softmax(dim=-1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class POSTagger(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size=hyperparams.input_size,\n",
    "        hidden_size=hyperparams.hidden_size,\n",
    "        dropout=hyperparams.dropout,\n",
    "        bias=hyperparams.bias,\n",
    "        num_layers=hyperparams.num_hidden_layer,\n",
    "        output_size=hyperparams.output_size,\n",
    "        batch_first=hyperparams.batch_first,\n",
    "        bidirectional=hyperparams.bidirectional,\n",
    "        init_wb_with_kaiming_normal=hyperparams.init_wb_with_kaiming_normal\n",
    "    ):\n",
    "        super(POSTagger, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.dropout = dropout\n",
    "        self.bias = bias\n",
    "        self.num_layers = num_layers\n",
    "        self.output_size = output_size\n",
    "        self.batch_first = batch_first\n",
    "        self.bidirectional = bidirectional\n",
    "                \n",
    "        self.feature = nn.LSTM(\n",
    "            input_size = self.input_size,\n",
    "            hidden_size = self.hidden_size,\n",
    "            bias = self.bias,\n",
    "            dropout = self.dropout,\n",
    "            num_layers = self.num_layers,\n",
    "            batch_first = self.batch_first,\n",
    "            bidirectional = self.bidirectional\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(in_features=2 * self.hidden_size if hyperparams.bidirectional else self.hidden_size, out_features=self.output_size, bias=self.bias),\n",
    "            nn.Softmax(dim=-1)\n",
    "        )\n",
    "        \n",
    "        if init_wb_with_kaiming_normal:\n",
    "            self.init_wb()\n",
    "\n",
    "    def init_wb(self):\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, (nn.Linear, nn.LSTM)):\n",
    "                for name, param in module.named_parameters():\n",
    "                    if \"weight\" in name:\n",
    "                        nn.init.kaiming_normal_(param)\n",
    "                    else:\n",
    "                        nn.init.kaiming_normal_(param.reshape(1, -1))\n",
    "        \n",
    "    def forward(self, feature, hidden=None):\n",
    "        output, (hidden, memory) = self.feature(feature, None)\n",
    "        prob = self.classifier(output)\n",
    "\n",
    "        return prob\n",
    "    \n",
    "model = POSTagger().to(hyperparams.device)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d72bd6-f2e6-4f44-8b36-702e5acede59",
   "metadata": {},
   "source": [
    "## Optimizer, Criterion, and Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bfcc4414-fa93-4518-a4bf-872de25c47c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=hyperparams.lr)\n",
    "criterion = nn.CrossEntropyLoss().to(hyperparams.device)\n",
    "train_metric = MulticlassF1Score(average=\"micro\", num_classes=24, mdmc_average=\"global\", multiclass=True, ignore_index=label_to_idx[\"<PAD>\"]).to(hyperparams.device)\n",
    "val_metric = MulticlassF1Score(average=\"micro\", num_classes=24, mdmc_average=\"global\", multiclass=True, ignore_index=label_to_idx[\"<PAD>\"]).to(hyperparams.device)\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", verbose=True, factor=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0591ed5b-e957-43aa-a3d5-4735852fac96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "204824"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(param.numel() for param in model.parameters() if param.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5bdeea-d9c3-41ca-95c0-c2752215f2d8",
   "metadata": {},
   "source": [
    "## Training Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c5d9bdc1-f6c2-41b1-8d3f-e4bfadd2aae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_step(dataloader, model, optimizer, criterion, metric, scheduler=None):\n",
    "    model.train()\n",
    "    \n",
    "    batch_losses = []\n",
    "    batch_metric_scores = []\n",
    "    \n",
    "    for batch, (feature, actual_label) in enumerate(tqdm(dataloader), 1):\n",
    "        # Forward Propagation\n",
    "        feature = rearrange(feature, \"n s -> s n\")\n",
    "        actual_label = rearrange(actual_label, \"n s -> s n\")\n",
    "        embedding = word_embeddings(feature)\n",
    "        \n",
    "        prob = model(\n",
    "            embedding.to(hyperparams.device),\n",
    "            actual_label.to(hyperparams.device)\n",
    "        )\n",
    "        \n",
    "        prob = prob.reshape(-1, prob.shape[-1])\n",
    "        actual_label = actual_label.reshape(-1)\n",
    "\n",
    "        loss = criterion(prob, actual_label.to(hyperparams.device))\n",
    "        metric_score = metric(prob, actual_label.to(hyperparams.device))\n",
    "        metric_score = metric.compute()\n",
    "                \n",
    "        if scheduler is not None:\n",
    "            scheduler.step(loss)\n",
    "        \n",
    "        batch_losses.append(loss.item())\n",
    "        batch_metric_scores.append(metric_score)\n",
    "        \n",
    "        if len(dataloader) < 10:\n",
    "            if batch % 1 == 0 or batch == len(dataloader):\n",
    "                batch_name = \"Batch-\" + str(batch)\n",
    "                print(f\"{batch_name.ljust(9)}: {str(criterion).split('(')[0]}={(loss.item()):.4f} | {str(metric).split('(')[0]}={(metric_score):.4f}\")\n",
    "                with open(f\"../../../logs/classifier/{hyperparams.context_size}_contexts/{root_path}/training_history.txt\", \"a\") as f:\n",
    "                    f.write(f\"{batch_name.ljust(9)}: {str(criterion).split('(')[0]}={(loss.item()):.4f} | {str(metric).split('(')[0]}={(metric_score):.4f}\\n\")\n",
    "        else:\n",
    "            if batch % 15 == 0 or batch == len(dataloader):\n",
    "                batch_name = \"Batch-\" + str(batch)\n",
    "                print(f\"{batch_name.ljust(9)}: {str(criterion).split('(')[0]}={(loss.item()):.4f} | {str(metric).split('(')[0]}={(metric_score):.4f}\")\n",
    "                with open(f\"../../../logs/classifier/{hyperparams.context_size}_contexts/{root_path}/training_history.txt\", \"a\") as f:\n",
    "                    f.write(f\"{batch_name.ljust(9)}: {str(criterion).split('(')[0]}={(loss.item()):.4f} | {str(metric).split('(')[0]}={(metric_score):.4f}\\n\")\n",
    "            \n",
    "        # Backward Propagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    return batch_losses, batch_metric_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659ead5e-da1c-44ec-ac87-48c4891f19cb",
   "metadata": {},
   "source": [
    "## Validation Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0310cd28-75cb-433e-938b-ed4e4989eaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_step(dataloader, model, criterion, metric):\n",
    "    model.eval()\n",
    "    \n",
    "    batch_losses = []\n",
    "    batch_metric_scores = []\n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        for batch, (feature, actual_label) in enumerate(tqdm(dataloader), 1):\n",
    "            # Forward Propagation\n",
    "            feature = rearrange(feature, \"n s -> s n\")\n",
    "            actual_label = rearrange(actual_label, \"n s -> s n\")\n",
    "            embedding = word_embeddings(feature)\n",
    "\n",
    "            prob = model(\n",
    "                embedding.to(hyperparams.device),\n",
    "                actual_label.to(hyperparams.device)\n",
    "            )\n",
    "\n",
    "            prob = prob.reshape(-1, prob.shape[-1])\n",
    "            actual_label = actual_label.reshape(-1)\n",
    "\n",
    "            loss = criterion(prob, actual_label.to(hyperparams.device))\n",
    "            metric_score = metric(prob, actual_label.to(hyperparams.device))\n",
    "            metric_score = metric.compute()\n",
    "\n",
    "            batch_losses.append(loss.item())\n",
    "            batch_metric_scores.append(metric_score)\n",
    "            \n",
    "            if len(dataloader) < 10 and (batch % 1 == 0 or batch == len(dataloader)):\n",
    "                batch_name = \"Batch-\" + str(batch)\n",
    "                print(f\"{batch_name.ljust(9)}: {str(criterion).split('(')[0]}={(loss.item()):.4f} | {str(metric).split('(')[0]}={(metric_score):.4f}\")\n",
    "                with open(f\"../../../logs/classifier/{hyperparams.context_size}_contexts/{root_path}/training_history.txt\", \"a\") as f:\n",
    "                    f.write(f\"{batch_name.ljust(9)}: {str(criterion).split('(')[0]}={(loss.item()):.4f} | {str(metric).split('(')[0]}={(metric_score):.4f}\\n\")\n",
    "            else:\n",
    "                if batch % 15 == 0 or batch == len(dataloader):\n",
    "                    batch_name = \"Batch-\" + str(batch)\n",
    "                    print(f\"{batch_name.ljust(9)}: {str(criterion).split('(')[0]}={(loss.item()):.4f} | {str(metric).split('(')[0]}={(metric_score):.4f}\")\n",
    "                    with open(f\"../../../logs/classifier/{hyperparams.context_size}_contexts/{root_path}/training_history.txt\", \"a\") as f:\n",
    "                        f.write(f\"{batch_name.ljust(9)}: {str(criterion).split('(')[0]}={(loss.item()):.4f} | {str(metric).split('(')[0]}={(metric_score):.4f}\\n\")\n",
    "    \n",
    "    return batch_losses, batch_metric_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97e1189-3368-496b-83ea-a9a98a30826e",
   "metadata": {},
   "source": [
    "## Looping Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d929b35d-23fc-411b-9352-187dbb4ca310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH-1\n",
      "Training Step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37ea590f11c643038a378d2f311295ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/226 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-15 : CrossEntropyLoss=2.4758 | MulticlassF1Score=0.1424\n",
      "Batch-30 : CrossEntropyLoss=2.4761 | MulticlassF1Score=0.1960\n",
      "Batch-45 : CrossEntropyLoss=2.4283 | MulticlassF1Score=0.2436\n",
      "Batch-60 : CrossEntropyLoss=2.4044 | MulticlassF1Score=0.2914\n",
      "Batch-75 : CrossEntropyLoss=2.3775 | MulticlassF1Score=0.3326\n",
      "Batch-90 : CrossEntropyLoss=2.3874 | MulticlassF1Score=0.3651\n",
      "Batch-105: CrossEntropyLoss=2.3861 | MulticlassF1Score=0.3915\n",
      "Batch-120: CrossEntropyLoss=2.3976 | MulticlassF1Score=0.4151\n",
      "Batch-135: CrossEntropyLoss=2.3738 | MulticlassF1Score=0.4346\n",
      "Batch-150: CrossEntropyLoss=2.3900 | MulticlassF1Score=0.4508\n",
      "Batch-165: CrossEntropyLoss=2.3665 | MulticlassF1Score=0.4636\n",
      "Batch-180: CrossEntropyLoss=2.3661 | MulticlassF1Score=0.4752\n",
      "Batch-195: CrossEntropyLoss=2.3655 | MulticlassF1Score=0.4843\n",
      "Batch-210: CrossEntropyLoss=2.3747 | MulticlassF1Score=0.4927\n",
      "Batch-225: CrossEntropyLoss=2.3738 | MulticlassF1Score=0.4992\n",
      "Batch-226: CrossEntropyLoss=2.3737 | MulticlassF1Score=0.4993\n",
      "\n",
      "Validation Step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9773d67fb6249a5bab1621054da62f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-15 : CrossEntropyLoss=2.3679 | MulticlassF1Score=0.5935\n",
      "Batch-30 : CrossEntropyLoss=2.3621 | MulticlassF1Score=0.5943\n",
      "Batch-45 : CrossEntropyLoss=2.3798 | MulticlassF1Score=0.5952\n",
      "Batch-60 : CrossEntropyLoss=2.3838 | MulticlassF1Score=0.5936\n",
      "Batch-63 : CrossEntropyLoss=2.3569 | MulticlassF1Score=0.5938\n",
      "\n",
      "Training   : Mean CrossEntropyLoss = 2.4133 | Mean MulticlassF1Score = 0.3662\n",
      "Validation : Mean CrossEntropyLoss = 2.3732 | Mean MulticlassF1Score = 0.5935\n",
      "================================================================================\n",
      "\n",
      "EPOCH-2\n",
      "Training Step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1c97e4e95c7447a99d8b4cf19acf5ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/226 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-15 : CrossEntropyLoss=2.3367 | MulticlassF1Score=0.6719\n",
      "Batch-30 : CrossEntropyLoss=2.3434 | MulticlassF1Score=0.6885\n",
      "Batch-45 : CrossEntropyLoss=2.3236 | MulticlassF1Score=0.6958\n",
      "Batch-60 : CrossEntropyLoss=2.3468 | MulticlassF1Score=0.6981\n",
      "Batch-75 : CrossEntropyLoss=2.3289 | MulticlassF1Score=0.7030\n",
      "Batch-90 : CrossEntropyLoss=2.3400 | MulticlassF1Score=0.7055\n",
      "Batch-105: CrossEntropyLoss=2.3171 | MulticlassF1Score=0.7068\n",
      "Batch-120: CrossEntropyLoss=2.3166 | MulticlassF1Score=0.7092\n",
      "Batch-135: CrossEntropyLoss=2.3264 | MulticlassF1Score=0.7155\n",
      "Batch-150: CrossEntropyLoss=2.3287 | MulticlassF1Score=0.7210\n",
      "Batch-165: CrossEntropyLoss=2.3219 | MulticlassF1Score=0.7251\n",
      "Batch-180: CrossEntropyLoss=2.3200 | MulticlassF1Score=0.7285\n",
      "Batch-195: CrossEntropyLoss=2.3164 | MulticlassF1Score=0.7318\n",
      "Batch-210: CrossEntropyLoss=2.3093 | MulticlassF1Score=0.7356\n",
      "Batch-225: CrossEntropyLoss=2.3104 | MulticlassF1Score=0.7397\n",
      "Batch-226: CrossEntropyLoss=2.3137 | MulticlassF1Score=0.7398\n",
      "\n",
      "Validation Step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32e530782108489e9e437eeb95d551d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-15 : CrossEntropyLoss=2.3208 | MulticlassF1Score=0.7929\n",
      "Batch-30 : CrossEntropyLoss=2.3129 | MulticlassF1Score=0.7885\n",
      "Batch-45 : CrossEntropyLoss=2.3177 | MulticlassF1Score=0.7900\n",
      "Batch-60 : CrossEntropyLoss=2.3035 | MulticlassF1Score=0.7903\n",
      "Batch-63 : CrossEntropyLoss=2.3326 | MulticlassF1Score=0.7900\n",
      "\n",
      "Yeah 🎉😄! Model improved.\n",
      "\n",
      "Training   : Mean CrossEntropyLoss = 2.3298 | Mean MulticlassF1Score = 0.7080\n",
      "Validation : Mean CrossEntropyLoss = 2.3141 | Mean MulticlassF1Score = 0.7909\n",
      "================================================================================\n",
      "\n",
      "EPOCH-3\n",
      "Training Step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98103a859ffb4ccb945fe6cd2aeb0a44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/226 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-15 : CrossEntropyLoss=2.3037 | MulticlassF1Score=0.7923\n",
      "Batch-30 : CrossEntropyLoss=2.3149 | MulticlassF1Score=0.7884\n",
      "Batch-45 : CrossEntropyLoss=2.3046 | MulticlassF1Score=0.7912\n",
      "Batch-60 : CrossEntropyLoss=2.3065 | MulticlassF1Score=0.7910\n",
      "Batch-75 : CrossEntropyLoss=2.3154 | MulticlassF1Score=0.7905\n",
      "Batch-90 : CrossEntropyLoss=2.3078 | MulticlassF1Score=0.7917\n",
      "Batch-105: CrossEntropyLoss=2.3133 | MulticlassF1Score=0.7930\n",
      "Batch-120: CrossEntropyLoss=2.3162 | MulticlassF1Score=0.7934\n",
      "Batch-135: CrossEntropyLoss=2.3167 | MulticlassF1Score=0.7927\n",
      "Batch-150: CrossEntropyLoss=2.2988 | MulticlassF1Score=0.7926\n",
      "Batch-165: CrossEntropyLoss=2.3061 | MulticlassF1Score=0.7934\n",
      "Batch-180: CrossEntropyLoss=2.3117 | MulticlassF1Score=0.7934\n",
      "Batch-195: CrossEntropyLoss=2.3134 | MulticlassF1Score=0.7936\n",
      "Batch-210: CrossEntropyLoss=2.3127 | MulticlassF1Score=0.7940\n",
      "Batch-225: CrossEntropyLoss=2.3111 | MulticlassF1Score=0.7951\n",
      "Batch-226: CrossEntropyLoss=2.3287 | MulticlassF1Score=0.7951\n",
      "\n",
      "Validation Step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c24d946da6647699e16d01d92f729ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-15 : CrossEntropyLoss=2.3017 | MulticlassF1Score=0.8055\n",
      "Batch-30 : CrossEntropyLoss=2.3031 | MulticlassF1Score=0.8053\n",
      "Batch-45 : CrossEntropyLoss=2.2969 | MulticlassF1Score=0.8063\n",
      "Batch-60 : CrossEntropyLoss=2.3110 | MulticlassF1Score=0.8056\n",
      "Batch-63 : CrossEntropyLoss=2.3053 | MulticlassF1Score=0.8052\n",
      "\n",
      "Yeah 🎉😄! Model improved.\n",
      "\n",
      "Training   : Mean CrossEntropyLoss = 2.3115 | Mean MulticlassF1Score = 0.7918\n",
      "Validation : Mean CrossEntropyLoss = 2.3089 | Mean MulticlassF1Score = 0.8059\n",
      "================================================================================\n",
      "\n",
      "EPOCH-4\n",
      "Training Step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "008ea6be3c1648db8a6792996c1e1329",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/226 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-15 : CrossEntropyLoss=2.3036 | MulticlassF1Score=0.7987\n",
      "Batch-30 : CrossEntropyLoss=2.3082 | MulticlassF1Score=0.8051\n",
      "Batch-45 : CrossEntropyLoss=2.2987 | MulticlassF1Score=0.8062\n",
      "Batch-60 : CrossEntropyLoss=2.3070 | MulticlassF1Score=0.8079\n",
      "Batch-75 : CrossEntropyLoss=2.2972 | MulticlassF1Score=0.8082\n",
      "Batch-90 : CrossEntropyLoss=2.3091 | MulticlassF1Score=0.8086\n",
      "Batch-105: CrossEntropyLoss=2.3005 | MulticlassF1Score=0.8103\n",
      "Batch-120: CrossEntropyLoss=2.3054 | MulticlassF1Score=0.8130\n",
      "Batch-135: CrossEntropyLoss=2.2995 | MulticlassF1Score=0.8138\n",
      "Batch-150: CrossEntropyLoss=2.3098 | MulticlassF1Score=0.8146\n",
      "Batch-165: CrossEntropyLoss=2.3030 | MulticlassF1Score=0.8153\n",
      "Batch-180: CrossEntropyLoss=2.3093 | MulticlassF1Score=0.8160\n",
      "Batch-195: CrossEntropyLoss=2.2954 | MulticlassF1Score=0.8169\n",
      "Batch-210: CrossEntropyLoss=2.3030 | MulticlassF1Score=0.8180\n",
      "Batch-225: CrossEntropyLoss=2.3134 | MulticlassF1Score=0.8182\n",
      "Batch-226: CrossEntropyLoss=2.3012 | MulticlassF1Score=0.8182\n",
      "\n",
      "Validation Step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d57d98ac20c54a96a21d35cf122772fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-15 : CrossEntropyLoss=2.3015 | MulticlassF1Score=0.8258\n",
      "Batch-30 : CrossEntropyLoss=2.3028 | MulticlassF1Score=0.8255\n",
      "Batch-45 : CrossEntropyLoss=2.3009 | MulticlassF1Score=0.8249\n",
      "Batch-60 : CrossEntropyLoss=2.2954 | MulticlassF1Score=0.8259\n",
      "Batch-63 : CrossEntropyLoss=2.2994 | MulticlassF1Score=0.8267\n",
      "\n",
      "Yeah 🎉😄! Model improved.\n",
      "\n",
      "Training   : Mean CrossEntropyLoss = 2.3042 | Mean MulticlassF1Score = 0.8107\n",
      "Validation : Mean CrossEntropyLoss = 2.3019 | Mean MulticlassF1Score = 0.8254\n",
      "================================================================================\n",
      "\n",
      "EPOCH-5\n",
      "Training Step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26f315c4bfb44ae1bed29bfbb90f9b11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/226 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-15 : CrossEntropyLoss=2.3116 | MulticlassF1Score=0.8232\n",
      "Batch-30 : CrossEntropyLoss=2.3034 | MulticlassF1Score=0.8255\n",
      "Batch-45 : CrossEntropyLoss=2.3050 | MulticlassF1Score=0.8278\n",
      "Batch-60 : CrossEntropyLoss=2.3033 | MulticlassF1Score=0.8284\n",
      "Batch-75 : CrossEntropyLoss=2.3015 | MulticlassF1Score=0.8286\n",
      "Batch-90 : CrossEntropyLoss=2.2901 | MulticlassF1Score=0.8290\n",
      "Batch-105: CrossEntropyLoss=2.2909 | MulticlassF1Score=0.8299\n",
      "Batch-120: CrossEntropyLoss=2.2948 | MulticlassF1Score=0.8301\n",
      "Batch-135: CrossEntropyLoss=2.2957 | MulticlassF1Score=0.8298\n",
      "Batch-150: CrossEntropyLoss=2.3067 | MulticlassF1Score=0.8299\n",
      "Batch-165: CrossEntropyLoss=2.3008 | MulticlassF1Score=0.8300\n",
      "Batch-180: CrossEntropyLoss=2.2910 | MulticlassF1Score=0.8300\n",
      "Batch-195: CrossEntropyLoss=2.3051 | MulticlassF1Score=0.8298\n",
      "Batch-210: CrossEntropyLoss=2.2976 | MulticlassF1Score=0.8300\n",
      "Batch-225: CrossEntropyLoss=2.2965 | MulticlassF1Score=0.8300\n",
      "Batch-226: CrossEntropyLoss=2.3024 | MulticlassF1Score=0.8299\n",
      "\n",
      "Validation Step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12745413a93344ba9599eda12d77cad9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-15 : CrossEntropyLoss=2.2943 | MulticlassF1Score=0.8306\n",
      "Batch-30 : CrossEntropyLoss=2.3068 | MulticlassF1Score=0.8260\n",
      "Batch-45 : CrossEntropyLoss=2.3092 | MulticlassF1Score=0.8250\n",
      "Batch-60 : CrossEntropyLoss=2.3012 | MulticlassF1Score=0.8268\n",
      "Batch-63 : CrossEntropyLoss=2.3044 | MulticlassF1Score=0.8269\n",
      "\n",
      "Yeah 🎉😄! Model improved.\n",
      "\n",
      "Training   : Mean CrossEntropyLoss = 2.3004 | Mean MulticlassF1Score = 0.8288\n",
      "Validation : Mean CrossEntropyLoss = 2.3018 | Mean MulticlassF1Score = 0.8270\n",
      "================================================================================\n",
      "\n",
      "EPOCH-6\n",
      "Training Step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb4210a58be44b5cac97b8cbe3764b8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/226 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-15 : CrossEntropyLoss=2.3043 | MulticlassF1Score=0.8258\n",
      "Batch-30 : CrossEntropyLoss=2.3030 | MulticlassF1Score=0.8290\n",
      "Batch-45 : CrossEntropyLoss=2.3149 | MulticlassF1Score=0.8310\n",
      "Batch-60 : CrossEntropyLoss=2.3042 | MulticlassF1Score=0.8308\n",
      "Batch-75 : CrossEntropyLoss=2.3004 | MulticlassF1Score=0.8306\n",
      "Batch-90 : CrossEntropyLoss=2.3078 | MulticlassF1Score=0.8305\n",
      "Batch-105: CrossEntropyLoss=2.3044 | MulticlassF1Score=0.8303\n",
      "Batch-120: CrossEntropyLoss=2.2913 | MulticlassF1Score=0.8311\n",
      "Batch-135: CrossEntropyLoss=2.2973 | MulticlassF1Score=0.8311\n",
      "Batch-150: CrossEntropyLoss=2.3008 | MulticlassF1Score=0.8311\n",
      "Batch-165: CrossEntropyLoss=2.2928 | MulticlassF1Score=0.8314\n",
      "Batch-180: CrossEntropyLoss=2.2963 | MulticlassF1Score=0.8315\n",
      "Batch-195: CrossEntropyLoss=2.2972 | MulticlassF1Score=0.8311\n",
      "Batch-210: CrossEntropyLoss=2.2991 | MulticlassF1Score=0.8313\n",
      "Batch-225: CrossEntropyLoss=2.3002 | MulticlassF1Score=0.8317\n",
      "Batch-226: CrossEntropyLoss=2.2951 | MulticlassF1Score=0.8318\n",
      "\n",
      "Validation Step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2acb27ab45a84529945fd8ace84e9acf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-15 : CrossEntropyLoss=2.2927 | MulticlassF1Score=0.8326\n",
      "Batch-30 : CrossEntropyLoss=2.2892 | MulticlassF1Score=0.8284\n",
      "Batch-45 : CrossEntropyLoss=2.3055 | MulticlassF1Score=0.8277\n",
      "Batch-60 : CrossEntropyLoss=2.2992 | MulticlassF1Score=0.8275\n",
      "Batch-63 : CrossEntropyLoss=2.2990 | MulticlassF1Score=0.8281\n",
      "\n",
      "Yeah 🎉😄! Model improved.\n",
      "\n",
      "Training   : Mean CrossEntropyLoss = 2.2997 | Mean MulticlassF1Score = 0.8302\n",
      "Validation : Mean CrossEntropyLoss = 2.3013 | Mean MulticlassF1Score = 0.8293\n",
      "================================================================================\n",
      "\n",
      "EPOCH-7\n",
      "Training Step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "835b1135550b4457ac47b6833aaa9f2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/226 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-15 : CrossEntropyLoss=2.2940 | MulticlassF1Score=0.8344\n",
      "Batch-30 : CrossEntropyLoss=2.2969 | MulticlassF1Score=0.8326\n",
      "Batch-45 : CrossEntropyLoss=2.3064 | MulticlassF1Score=0.8330\n",
      "Batch-60 : CrossEntropyLoss=2.3016 | MulticlassF1Score=0.8327\n",
      "Batch-75 : CrossEntropyLoss=2.2935 | MulticlassF1Score=0.8328\n",
      "Batch-90 : CrossEntropyLoss=2.2981 | MulticlassF1Score=0.8330\n",
      "Batch-105: CrossEntropyLoss=2.3014 | MulticlassF1Score=0.8329\n",
      "Batch-120: CrossEntropyLoss=2.2981 | MulticlassF1Score=0.8322\n",
      "Batch-135: CrossEntropyLoss=2.3003 | MulticlassF1Score=0.8322\n",
      "Batch-150: CrossEntropyLoss=2.2995 | MulticlassF1Score=0.8329\n",
      "Batch-165: CrossEntropyLoss=2.3037 | MulticlassF1Score=0.8327\n",
      "Batch-180: CrossEntropyLoss=2.2984 | MulticlassF1Score=0.8328\n",
      "Batch-195: CrossEntropyLoss=2.2972 | MulticlassF1Score=0.8326\n",
      "Batch-210: CrossEntropyLoss=2.2939 | MulticlassF1Score=0.8329\n",
      "Batch-225: CrossEntropyLoss=2.3095 | MulticlassF1Score=0.8327\n",
      "Batch-226: CrossEntropyLoss=2.2945 | MulticlassF1Score=0.8328\n",
      "\n",
      "Validation Step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bfdcd666d5c42e6a4eabbb3630f55ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-15 : CrossEntropyLoss=2.2979 | MulticlassF1Score=0.8307\n",
      "Batch-30 : CrossEntropyLoss=2.3035 | MulticlassF1Score=0.8330\n",
      "Batch-45 : CrossEntropyLoss=2.3044 | MulticlassF1Score=0.8315\n",
      "Batch-60 : CrossEntropyLoss=2.3106 | MulticlassF1Score=0.8295\n",
      "Batch-63 : CrossEntropyLoss=2.3058 | MulticlassF1Score=0.8290\n",
      "\n",
      "Yeah 🎉😄! Model improved.\n",
      "\n",
      "Training   : Mean CrossEntropyLoss = 2.2993 | Mean MulticlassF1Score = 0.8327\n",
      "Validation : Mean CrossEntropyLoss = 2.3011 | Mean MulticlassF1Score = 0.8298\n",
      "================================================================================\n",
      "\n",
      "EPOCH-8\n",
      "Training Step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "935a816778ca452bb362d3b0c8518adc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/226 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-15 : CrossEntropyLoss=2.3011 | MulticlassF1Score=0.8247\n",
      "Batch-30 : CrossEntropyLoss=2.2917 | MulticlassF1Score=0.8279\n",
      "Batch-45 : CrossEntropyLoss=2.3013 | MulticlassF1Score=0.8307\n",
      "Batch-60 : CrossEntropyLoss=2.3003 | MulticlassF1Score=0.8305\n",
      "Batch-75 : CrossEntropyLoss=2.2953 | MulticlassF1Score=0.8309\n",
      "Batch-90 : CrossEntropyLoss=2.2941 | MulticlassF1Score=0.8315\n",
      "Batch-105: CrossEntropyLoss=2.3004 | MulticlassF1Score=0.8318\n",
      "Batch-120: CrossEntropyLoss=2.2990 | MulticlassF1Score=0.8323\n",
      "Batch-135: CrossEntropyLoss=2.2961 | MulticlassF1Score=0.8326\n",
      "Batch-150: CrossEntropyLoss=2.3019 | MulticlassF1Score=0.8338\n",
      "Batch-165: CrossEntropyLoss=2.3010 | MulticlassF1Score=0.8341\n",
      "Batch-180: CrossEntropyLoss=2.2956 | MulticlassF1Score=0.8353\n",
      "Batch-195: CrossEntropyLoss=2.2984 | MulticlassF1Score=0.8359\n",
      "Batch-210: CrossEntropyLoss=2.2913 | MulticlassF1Score=0.8364\n",
      "Batch-225: CrossEntropyLoss=2.2966 | MulticlassF1Score=0.8369\n",
      "Batch-226: CrossEntropyLoss=2.2875 | MulticlassF1Score=0.8370\n",
      "\n",
      "Validation Step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73e0386239db430bad0ba35be9bf4b41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-15 : CrossEntropyLoss=2.2957 | MulticlassF1Score=0.8401\n",
      "Batch-30 : CrossEntropyLoss=2.3010 | MulticlassF1Score=0.8364\n",
      "Batch-45 : CrossEntropyLoss=2.2979 | MulticlassF1Score=0.8364\n",
      "Batch-60 : CrossEntropyLoss=2.2897 | MulticlassF1Score=0.8367\n",
      "Batch-63 : CrossEntropyLoss=2.3038 | MulticlassF1Score=0.8364\n",
      "\n",
      "Yeah 🎉😄! Model improved.\n",
      "\n",
      "Training   : Mean CrossEntropyLoss = 2.2979 | Mean MulticlassF1Score = 0.8321\n",
      "Validation : Mean CrossEntropyLoss = 2.2986 | Mean MulticlassF1Score = 0.8380\n",
      "================================================================================\n",
      "\n",
      "EPOCH-9\n",
      "Training Step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88b5ccf90354490ba3f9d11e7209fa08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/226 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-15 : CrossEntropyLoss=2.2967 | MulticlassF1Score=0.8316\n",
      "Batch-30 : CrossEntropyLoss=2.2958 | MulticlassF1Score=0.8414\n",
      "Batch-45 : CrossEntropyLoss=2.3067 | MulticlassF1Score=0.8443\n",
      "Batch-60 : CrossEntropyLoss=2.3011 | MulticlassF1Score=0.8434\n",
      "Batch-75 : CrossEntropyLoss=2.2875 | MulticlassF1Score=0.8439\n",
      "Batch-90 : CrossEntropyLoss=2.2886 | MulticlassF1Score=0.8466\n",
      "Batch-105: CrossEntropyLoss=2.2883 | MulticlassF1Score=0.8498\n",
      "Batch-120: CrossEntropyLoss=2.2949 | MulticlassF1Score=0.8510\n",
      "Batch-135: CrossEntropyLoss=2.2857 | MulticlassF1Score=0.8533\n",
      "Batch-150: CrossEntropyLoss=2.2908 | MulticlassF1Score=0.8548\n",
      "Batch-165: CrossEntropyLoss=2.2969 | MulticlassF1Score=0.8559\n",
      "Batch-180: CrossEntropyLoss=2.2801 | MulticlassF1Score=0.8576\n",
      "Batch-195: CrossEntropyLoss=2.2780 | MulticlassF1Score=0.8586\n",
      "Batch-210: CrossEntropyLoss=2.2923 | MulticlassF1Score=0.8594\n",
      "Batch-225: CrossEntropyLoss=2.2819 | MulticlassF1Score=0.8599\n",
      "Batch-226: CrossEntropyLoss=2.2857 | MulticlassF1Score=0.8599\n",
      "\n",
      "Validation Step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e47bcc7e8afe4aa9a26975af9c39cf90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-15 : CrossEntropyLoss=2.2802 | MulticlassF1Score=0.8712\n",
      "Batch-30 : CrossEntropyLoss=2.2834 | MulticlassF1Score=0.8686\n",
      "Batch-45 : CrossEntropyLoss=2.2957 | MulticlassF1Score=0.8661\n",
      "Batch-60 : CrossEntropyLoss=2.2917 | MulticlassF1Score=0.8654\n",
      "Batch-63 : CrossEntropyLoss=2.2966 | MulticlassF1Score=0.8649\n",
      "\n",
      "Yeah 🎉😄! Model improved.\n",
      "\n",
      "Training   : Mean CrossEntropyLoss = 2.2912 | Mean MulticlassF1Score = 0.8492\n",
      "Validation : Mean CrossEntropyLoss = 2.2899 | Mean MulticlassF1Score = 0.8676\n",
      "================================================================================\n",
      "\n",
      "EPOCH-10\n",
      "Training Step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d906c69364564d48bfa5af5702bf4bbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/226 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-15 : CrossEntropyLoss=2.2939 | MulticlassF1Score=0.8788\n",
      "Batch-30 : CrossEntropyLoss=2.2866 | MulticlassF1Score=0.8732\n",
      "Batch-45 : CrossEntropyLoss=2.2816 | MulticlassF1Score=0.8743\n",
      "Batch-60 : CrossEntropyLoss=2.2883 | MulticlassF1Score=0.8742\n",
      "Batch-75 : CrossEntropyLoss=2.2967 | MulticlassF1Score=0.8755\n",
      "Batch-90 : CrossEntropyLoss=2.2833 | MulticlassF1Score=0.8775\n",
      "Batch-105: CrossEntropyLoss=2.2849 | MulticlassF1Score=0.8792\n",
      "Batch-120: CrossEntropyLoss=2.2819 | MulticlassF1Score=0.8799\n",
      "Batch-135: CrossEntropyLoss=2.2866 | MulticlassF1Score=0.8804\n",
      "Batch-150: CrossEntropyLoss=2.2892 | MulticlassF1Score=0.8812\n",
      "Batch-165: CrossEntropyLoss=2.2784 | MulticlassF1Score=0.8813\n",
      "Batch-180: CrossEntropyLoss=2.2824 | MulticlassF1Score=0.8818\n",
      "Batch-195: CrossEntropyLoss=2.2825 | MulticlassF1Score=0.8825\n",
      "Batch-210: CrossEntropyLoss=2.2784 | MulticlassF1Score=0.8831\n",
      "Batch-225: CrossEntropyLoss=2.2786 | MulticlassF1Score=0.8830\n",
      "Batch-226: CrossEntropyLoss=2.2853 | MulticlassF1Score=0.8830\n",
      "\n",
      "Validation Step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fced2c1e75a0416cb88fe41d38c0ffd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-15 : CrossEntropyLoss=2.2794 | MulticlassF1Score=0.8877\n",
      "Batch-30 : CrossEntropyLoss=2.2872 | MulticlassF1Score=0.8819\n",
      "Batch-45 : CrossEntropyLoss=2.2902 | MulticlassF1Score=0.8832\n",
      "Batch-60 : CrossEntropyLoss=2.2835 | MulticlassF1Score=0.8842\n",
      "Batch-63 : CrossEntropyLoss=2.2876 | MulticlassF1Score=0.8837\n",
      "\n",
      "Yeah 🎉😄! Model improved.\n",
      "\n",
      "Training   : Mean CrossEntropyLoss = 2.2843 | Mean MulticlassF1Score = 0.8792\n",
      "Validation : Mean CrossEntropyLoss = 2.2843 | Mean MulticlassF1Score = 0.8839\n",
      "================================================================================\n",
      "\n",
      "EPOCH-11\n",
      "Training Step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5e385891b9a4c1094295dbbe3b9df2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/226 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-15 : CrossEntropyLoss=2.2862 | MulticlassF1Score=0.8865\n",
      "Batch-30 : CrossEntropyLoss=2.2865 | MulticlassF1Score=0.8876\n",
      "Batch-45 : CrossEntropyLoss=2.2791 | MulticlassF1Score=0.8889\n",
      "Batch-60 : CrossEntropyLoss=2.2796 | MulticlassF1Score=0.8903\n",
      "Batch-75 : CrossEntropyLoss=2.2775 | MulticlassF1Score=0.8907\n",
      "Batch-90 : CrossEntropyLoss=2.2778 | MulticlassF1Score=0.8900\n",
      "Batch-105: CrossEntropyLoss=2.2825 | MulticlassF1Score=0.8904\n",
      "Batch-120: CrossEntropyLoss=2.2837 | MulticlassF1Score=0.8906\n",
      "Batch-135: CrossEntropyLoss=2.2843 | MulticlassF1Score=0.8904\n",
      "Batch-150: CrossEntropyLoss=2.2773 | MulticlassF1Score=0.8902\n",
      "Batch-165: CrossEntropyLoss=2.2816 | MulticlassF1Score=0.8899\n",
      "Batch-180: CrossEntropyLoss=2.2765 | MulticlassF1Score=0.8900\n",
      "Batch-195: CrossEntropyLoss=2.2842 | MulticlassF1Score=0.8901\n",
      "Batch-210: CrossEntropyLoss=2.2771 | MulticlassF1Score=0.8905\n",
      "Batch-225: CrossEntropyLoss=2.2756 | MulticlassF1Score=0.8909\n",
      "Batch-226: CrossEntropyLoss=2.2878 | MulticlassF1Score=0.8908\n",
      "\n",
      "Validation Step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "677ee7ada7ff4065897cf102c2a783a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-15 : CrossEntropyLoss=2.2924 | MulticlassF1Score=0.8835\n",
      "Batch-30 : CrossEntropyLoss=2.2851 | MulticlassF1Score=0.8841\n",
      "Batch-45 : CrossEntropyLoss=2.2867 | MulticlassF1Score=0.8849\n",
      "Batch-60 : CrossEntropyLoss=2.2899 | MulticlassF1Score=0.8849\n",
      "Batch-63 : CrossEntropyLoss=2.2794 | MulticlassF1Score=0.8852\n",
      "\n",
      "Yeah 🎉😄! Model improved.\n",
      "\n",
      "Training   : Mean CrossEntropyLoss = 2.2817 | Mean MulticlassF1Score = 0.8897\n",
      "Validation : Mean CrossEntropyLoss = 2.2837 | Mean MulticlassF1Score = 0.8837\n",
      "================================================================================\n",
      "\n",
      "EPOCH-12\n",
      "Training Step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bebd39e3c3c845839f3ceec79c309b80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/226 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-15 : CrossEntropyLoss=2.2780 | MulticlassF1Score=0.8966\n",
      "Batch-30 : CrossEntropyLoss=2.2836 | MulticlassF1Score=0.8961\n",
      "Batch-45 : CrossEntropyLoss=2.2785 | MulticlassF1Score=0.8945\n",
      "Batch-60 : CrossEntropyLoss=2.2851 | MulticlassF1Score=0.8940\n",
      "Batch-75 : CrossEntropyLoss=2.2785 | MulticlassF1Score=0.8946\n",
      "Batch-90 : CrossEntropyLoss=2.2736 | MulticlassF1Score=0.8943\n",
      "Batch-105: CrossEntropyLoss=2.2807 | MulticlassF1Score=0.8942\n",
      "Batch-120: CrossEntropyLoss=2.2751 | MulticlassF1Score=0.8943\n",
      "Batch-135: CrossEntropyLoss=2.2761 | MulticlassF1Score=0.8945\n",
      "Batch-150: CrossEntropyLoss=2.2812 | MulticlassF1Score=0.8942\n",
      "Batch-165: CrossEntropyLoss=2.2770 | MulticlassF1Score=0.8941\n",
      "Batch-180: CrossEntropyLoss=2.2797 | MulticlassF1Score=0.8938\n",
      "Batch-195: CrossEntropyLoss=2.2864 | MulticlassF1Score=0.8932\n",
      "Batch-210: CrossEntropyLoss=2.2814 | MulticlassF1Score=0.8932\n",
      "Batch-225: CrossEntropyLoss=2.2818 | MulticlassF1Score=0.8932\n",
      "Batch-226: CrossEntropyLoss=2.2815 | MulticlassF1Score=0.8932\n",
      "\n",
      "Validation Step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38c37f7dff43429aa8d44c231a5f5fae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-15 : CrossEntropyLoss=2.2929 | MulticlassF1Score=0.8804\n",
      "Batch-30 : CrossEntropyLoss=2.2833 | MulticlassF1Score=0.8820\n",
      "Batch-45 : CrossEntropyLoss=2.2819 | MulticlassF1Score=0.8842\n",
      "Batch-60 : CrossEntropyLoss=2.2855 | MulticlassF1Score=0.8850\n",
      "Batch-63 : CrossEntropyLoss=2.2855 | MulticlassF1Score=0.8854\n",
      "\n",
      "Yeah 🎉😄! Model improved.\n",
      "\n",
      "Training   : Mean CrossEntropyLoss = 2.2809 | Mean MulticlassF1Score = 0.8947\n",
      "Validation : Mean CrossEntropyLoss = 2.2835 | Mean MulticlassF1Score = 0.8821\n",
      "================================================================================\n",
      "\n",
      "EPOCH-13\n",
      "Training Step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43684d95dd0f4cb18fb9349fab24c683",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/226 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-15 : CrossEntropyLoss=2.2822 | MulticlassF1Score=0.8900\n",
      "Batch-30 : CrossEntropyLoss=2.2918 | MulticlassF1Score=0.8931\n",
      "Batch-45 : CrossEntropyLoss=2.2781 | MulticlassF1Score=0.8945\n",
      "Batch-60 : CrossEntropyLoss=2.2757 | MulticlassF1Score=0.8950\n",
      "Batch-75 : CrossEntropyLoss=2.2763 | MulticlassF1Score=0.8951\n",
      "Batch-90 : CrossEntropyLoss=2.2777 | MulticlassF1Score=0.8951\n",
      "Batch-105: CrossEntropyLoss=2.2820 | MulticlassF1Score=0.8947\n",
      "Batch-120: CrossEntropyLoss=2.2828 | MulticlassF1Score=0.8950\n",
      "Batch-135: CrossEntropyLoss=2.2801 | MulticlassF1Score=0.8949\n",
      "Batch-150: CrossEntropyLoss=2.2855 | MulticlassF1Score=0.8949\n",
      "Batch-165: CrossEntropyLoss=2.2764 | MulticlassF1Score=0.8948\n",
      "Batch-180: CrossEntropyLoss=2.2724 | MulticlassF1Score=0.8959\n",
      "Batch-195: CrossEntropyLoss=2.2766 | MulticlassF1Score=0.8972\n",
      "Batch-210: CrossEntropyLoss=2.2683 | MulticlassF1Score=0.8985\n",
      "Batch-225: CrossEntropyLoss=2.2822 | MulticlassF1Score=0.8996\n",
      "Batch-226: CrossEntropyLoss=2.2736 | MulticlassF1Score=0.8997\n",
      "\n",
      "Validation Step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b76c517781fb44e59d04b02cb7be2ad3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-15 : CrossEntropyLoss=2.2785 | MulticlassF1Score=0.9048\n",
      "Batch-30 : CrossEntropyLoss=2.2808 | MulticlassF1Score=0.9071\n",
      "Batch-45 : CrossEntropyLoss=2.2761 | MulticlassF1Score=0.9083\n",
      "Batch-60 : CrossEntropyLoss=2.2688 | MulticlassF1Score=0.9085\n",
      "Batch-63 : CrossEntropyLoss=2.2728 | MulticlassF1Score=0.9087\n",
      "\n",
      "Yeah 🎉😄! Model improved.\n",
      "\n",
      "Training   : Mean CrossEntropyLoss = 2.2788 | Mean MulticlassF1Score = 0.8954\n",
      "Validation : Mean CrossEntropyLoss = 2.2764 | Mean MulticlassF1Score = 0.9058\n",
      "================================================================================\n",
      "\n",
      "EPOCH-14\n",
      "Training Step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e8b3d17a91c45e385a2a25ecf567602",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/226 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-15 : CrossEntropyLoss=2.2736 | MulticlassF1Score=0.9200\n",
      "Batch-30 : CrossEntropyLoss=2.2748 | MulticlassF1Score=0.9164\n",
      "Batch-45 : CrossEntropyLoss=2.2766 | MulticlassF1Score=0.9162\n",
      "Batch-60 : CrossEntropyLoss=2.2718 | MulticlassF1Score=0.9171\n",
      "Batch-75 : CrossEntropyLoss=2.2762 | MulticlassF1Score=0.9183\n",
      "Batch-90 : CrossEntropyLoss=2.2665 | MulticlassF1Score=0.9192\n",
      "Batch-105: CrossEntropyLoss=2.2681 | MulticlassF1Score=0.9197\n",
      "Batch-120: CrossEntropyLoss=2.2699 | MulticlassF1Score=0.9203\n",
      "Batch-135: CrossEntropyLoss=2.2688 | MulticlassF1Score=0.9204\n",
      "Batch-150: CrossEntropyLoss=2.2755 | MulticlassF1Score=0.9204\n",
      "Batch-165: CrossEntropyLoss=2.2695 | MulticlassF1Score=0.9211\n",
      "Batch-180: CrossEntropyLoss=2.2719 | MulticlassF1Score=0.9211\n",
      "Batch-195: CrossEntropyLoss=2.2684 | MulticlassF1Score=0.9213\n",
      "Batch-210: CrossEntropyLoss=2.2657 | MulticlassF1Score=0.9214\n",
      "Batch-225: CrossEntropyLoss=2.2759 | MulticlassF1Score=0.9215\n",
      "Batch-226: CrossEntropyLoss=2.2661 | MulticlassF1Score=0.9216\n",
      "\n",
      "Validation Step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7295b7b04eb42b586526e7db3944f3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-15 : CrossEntropyLoss=2.2745 | MulticlassF1Score=0.9146\n",
      "Batch-30 : CrossEntropyLoss=2.2717 | MulticlassF1Score=0.9142\n",
      "Batch-45 : CrossEntropyLoss=2.2755 | MulticlassF1Score=0.9139\n",
      "Batch-60 : CrossEntropyLoss=2.2732 | MulticlassF1Score=0.9136\n",
      "Batch-63 : CrossEntropyLoss=2.2712 | MulticlassF1Score=0.9141\n",
      "\n",
      "Yeah 🎉😄! Model improved.\n",
      "\n",
      "Training   : Mean CrossEntropyLoss = 2.2721 | Mean MulticlassF1Score = 0.9197\n",
      "Validation : Mean CrossEntropyLoss = 2.2746 | Mean MulticlassF1Score = 0.9151\n",
      "================================================================================\n",
      "\n",
      "EPOCH-15\n",
      "Training Step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "782b3ecc07fe45be93fee4118e5d14e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/226 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-15 : CrossEntropyLoss=2.2657 | MulticlassF1Score=0.9285\n",
      "Batch-30 : CrossEntropyLoss=2.2697 | MulticlassF1Score=0.9267\n",
      "Batch-45 : CrossEntropyLoss=2.2728 | MulticlassF1Score=0.9252\n",
      "Batch-60 : CrossEntropyLoss=2.2664 | MulticlassF1Score=0.9246\n",
      "Batch-75 : CrossEntropyLoss=2.2746 | MulticlassF1Score=0.9253\n",
      "Batch-90 : CrossEntropyLoss=2.2759 | MulticlassF1Score=0.9254\n",
      "Batch-105: CrossEntropyLoss=2.2700 | MulticlassF1Score=0.9252\n",
      "Batch-120: CrossEntropyLoss=2.2754 | MulticlassF1Score=0.9248\n",
      "Batch-135: CrossEntropyLoss=2.2761 | MulticlassF1Score=0.9244\n",
      "Batch-150: CrossEntropyLoss=2.2694 | MulticlassF1Score=0.9244\n",
      "Batch-165: CrossEntropyLoss=2.2690 | MulticlassF1Score=0.9247\n",
      "Batch-180: CrossEntropyLoss=2.2690 | MulticlassF1Score=0.9245\n",
      "Batch-195: CrossEntropyLoss=2.2712 | MulticlassF1Score=0.9242\n",
      "Batch-210: CrossEntropyLoss=2.2660 | MulticlassF1Score=0.9240\n",
      "Batch-225: CrossEntropyLoss=2.2720 | MulticlassF1Score=0.9244\n",
      "Batch-226: CrossEntropyLoss=2.2712 | MulticlassF1Score=0.9244\n",
      "\n",
      "Validation Step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf13f9ae596148b2b2b2dc129a7fbdc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-15 : CrossEntropyLoss=2.2728 | MulticlassF1Score=0.9136\n",
      "Batch-30 : CrossEntropyLoss=2.2724 | MulticlassF1Score=0.9154\n",
      "Batch-45 : CrossEntropyLoss=2.2796 | MulticlassF1Score=0.9164\n",
      "Batch-60 : CrossEntropyLoss=2.2739 | MulticlassF1Score=0.9159\n",
      "Batch-63 : CrossEntropyLoss=2.2814 | MulticlassF1Score=0.9154\n",
      "\n",
      "Yeah 🎉😄! Model improved.\n",
      "\n",
      "Training   : Mean CrossEntropyLoss = 2.2711 | Mean MulticlassF1Score = 0.9253\n",
      "Validation : Mean CrossEntropyLoss = 2.2742 | Mean MulticlassF1Score = 0.9149\n",
      "================================================================================\n",
      "\n",
      "EPOCH-16\n",
      "Training Step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df33f883290b4c8080fc7a3565761e61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/226 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-15 : CrossEntropyLoss=2.2664 | MulticlassF1Score=0.9259\n",
      "Batch-30 : CrossEntropyLoss=2.2664 | MulticlassF1Score=0.9262\n",
      "Batch-45 : CrossEntropyLoss=2.2664 | MulticlassF1Score=0.9256\n",
      "Batch-60 : CrossEntropyLoss=2.2718 | MulticlassF1Score=0.9269\n",
      "Batch-75 : CrossEntropyLoss=2.2721 | MulticlassF1Score=0.9262\n",
      "Batch-90 : CrossEntropyLoss=2.2777 | MulticlassF1Score=0.9254\n",
      "Batch-105: CrossEntropyLoss=2.2642 | MulticlassF1Score=0.9256\n",
      "Batch-120: CrossEntropyLoss=2.2686 | MulticlassF1Score=0.9256\n",
      "Batch-135: CrossEntropyLoss=2.2716 | MulticlassF1Score=0.9255\n",
      "Batch-150: CrossEntropyLoss=2.2716 | MulticlassF1Score=0.9259\n",
      "Batch-165: CrossEntropyLoss=2.2726 | MulticlassF1Score=0.9259\n",
      "Batch-180: CrossEntropyLoss=2.2720 | MulticlassF1Score=0.9257\n",
      "Batch-195: CrossEntropyLoss=2.2689 | MulticlassF1Score=0.9254\n",
      "Batch-210: CrossEntropyLoss=2.2741 | MulticlassF1Score=0.9258\n",
      "Batch-225: CrossEntropyLoss=2.2648 | MulticlassF1Score=0.9256\n",
      "Batch-226: CrossEntropyLoss=2.2768 | MulticlassF1Score=0.9256\n",
      "\n",
      "Validation Step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbcc66389e5f41bdaeb641910c7b081d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-15 : CrossEntropyLoss=2.2707 | MulticlassF1Score=0.9179\n",
      "Batch-30 : CrossEntropyLoss=2.2797 | MulticlassF1Score=0.9174\n",
      "Batch-45 : CrossEntropyLoss=2.2788 | MulticlassF1Score=0.9170\n",
      "Batch-60 : CrossEntropyLoss=2.2779 | MulticlassF1Score=0.9152\n",
      "Batch-63 : CrossEntropyLoss=2.2755 | MulticlassF1Score=0.9150\n",
      "\n",
      "Yeah 🎉😄! Model improved.\n",
      "\n",
      "Training   : Mean CrossEntropyLoss = 2.2707 | Mean MulticlassF1Score = 0.9257\n",
      "Validation : Mean CrossEntropyLoss = 2.2742 | Mean MulticlassF1Score = 0.9168\n",
      "================================================================================\n",
      "\n",
      "EPOCH-17\n",
      "Training Step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af428384764f45978b6b319711c002fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/226 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-15 : CrossEntropyLoss=2.2677 | MulticlassF1Score=0.9267\n",
      "Batch-30 : CrossEntropyLoss=2.2742 | MulticlassF1Score=0.9248\n",
      "Batch-45 : CrossEntropyLoss=2.2679 | MulticlassF1Score=0.9254\n",
      "Batch-60 : CrossEntropyLoss=2.2635 | MulticlassF1Score=0.9252\n",
      "Batch-75 : CrossEntropyLoss=2.2621 | MulticlassF1Score=0.9253\n",
      "Batch-90 : CrossEntropyLoss=2.2684 | MulticlassF1Score=0.9256\n",
      "Batch-105: CrossEntropyLoss=2.2682 | MulticlassF1Score=0.9256\n",
      "Batch-120: CrossEntropyLoss=2.2725 | MulticlassF1Score=0.9264\n",
      "Batch-135: CrossEntropyLoss=2.2666 | MulticlassF1Score=0.9272\n",
      "Batch-150: CrossEntropyLoss=2.2700 | MulticlassF1Score=0.9267\n",
      "Batch-165: CrossEntropyLoss=2.2646 | MulticlassF1Score=0.9268\n",
      "Batch-180: CrossEntropyLoss=2.2664 | MulticlassF1Score=0.9268\n",
      "Batch-195: CrossEntropyLoss=2.2664 | MulticlassF1Score=0.9267\n",
      "Batch-210: CrossEntropyLoss=2.2693 | MulticlassF1Score=0.9266\n",
      "Batch-225: CrossEntropyLoss=2.2748 | MulticlassF1Score=0.9266\n",
      "Batch-226: CrossEntropyLoss=2.2714 | MulticlassF1Score=0.9266\n",
      "\n",
      "Validation Step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "494d93f1cdbf49b69ffe19350f4c2c31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-15 : CrossEntropyLoss=2.2748 | MulticlassF1Score=0.9135\n",
      "Batch-30 : CrossEntropyLoss=2.2745 | MulticlassF1Score=0.9147\n",
      "Batch-45 : CrossEntropyLoss=2.2726 | MulticlassF1Score=0.9152\n",
      "Batch-60 : CrossEntropyLoss=2.2831 | MulticlassF1Score=0.9151\n",
      "Batch-63 : CrossEntropyLoss=2.2726 | MulticlassF1Score=0.9150\n",
      "\n",
      "Yeah 🎉😄! Model improved.\n",
      "\n",
      "Training   : Mean CrossEntropyLoss = 2.2703 | Mean MulticlassF1Score = 0.9260\n",
      "Validation : Mean CrossEntropyLoss = 2.2742 | Mean MulticlassF1Score = 0.9158\n",
      "================================================================================\n",
      "\n",
      "EPOCH-18\n",
      "Training Step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37029789692a44c89a3704c8d28c9537",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/226 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-15 : CrossEntropyLoss=2.2691 | MulticlassF1Score=0.9275\n",
      "Batch-30 : CrossEntropyLoss=2.2756 | MulticlassF1Score=0.9266\n",
      "Batch-45 : CrossEntropyLoss=2.2694 | MulticlassF1Score=0.9272\n",
      "Batch-60 : CrossEntropyLoss=2.2702 | MulticlassF1Score=0.9268\n",
      "Batch-75 : CrossEntropyLoss=2.2699 | MulticlassF1Score=0.9273\n",
      "Batch-90 : CrossEntropyLoss=2.2689 | MulticlassF1Score=0.9275\n",
      "Batch-105: CrossEntropyLoss=2.2657 | MulticlassF1Score=0.9280\n",
      "Batch-120: CrossEntropyLoss=2.2674 | MulticlassF1Score=0.9275\n",
      "Batch-135: CrossEntropyLoss=2.2689 | MulticlassF1Score=0.9275\n",
      "Batch-150: CrossEntropyLoss=2.2701 | MulticlassF1Score=0.9279\n",
      "Batch-165: CrossEntropyLoss=2.2711 | MulticlassF1Score=0.9284\n",
      "Batch-180: CrossEntropyLoss=2.2638 | MulticlassF1Score=0.9283\n",
      "Batch-195: CrossEntropyLoss=2.2706 | MulticlassF1Score=0.9283\n",
      "Batch-210: CrossEntropyLoss=2.2670 | MulticlassF1Score=0.9287\n",
      "Batch-225: CrossEntropyLoss=2.2706 | MulticlassF1Score=0.9287\n",
      "Batch-226: CrossEntropyLoss=2.2593 | MulticlassF1Score=0.9288\n",
      "\n",
      "Validation Step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "450fdf77f7634f59aeac841e00a24a5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-15 : CrossEntropyLoss=2.2729 | MulticlassF1Score=0.9218\n",
      "Batch-30 : CrossEntropyLoss=2.2688 | MulticlassF1Score=0.9210\n",
      "Batch-45 : CrossEntropyLoss=2.2702 | MulticlassF1Score=0.9192\n",
      "Batch-60 : CrossEntropyLoss=2.2701 | MulticlassF1Score=0.9187\n",
      "Batch-63 : CrossEntropyLoss=2.2679 | MulticlassF1Score=0.9188\n",
      "\n",
      "Yeah 🎉😄! Model improved.\n",
      "\n",
      "Training   : Mean CrossEntropyLoss = 2.2696 | Mean MulticlassF1Score = 0.9279\n",
      "Validation : Mean CrossEntropyLoss = 2.2730 | Mean MulticlassF1Score = 0.9203\n",
      "================================================================================\n",
      "\n",
      "EPOCH-19\n",
      "Training Step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b75d432a54349efa0d9c740a2278953",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/226 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-15 : CrossEntropyLoss=2.2742 | MulticlassF1Score=0.9292\n",
      "Batch-30 : CrossEntropyLoss=2.2638 | MulticlassF1Score=0.9300\n",
      "Batch-45 : CrossEntropyLoss=2.2720 | MulticlassF1Score=0.9329\n",
      "Batch-60 : CrossEntropyLoss=2.2685 | MulticlassF1Score=0.9330\n",
      "Batch-75 : CrossEntropyLoss=2.2734 | MulticlassF1Score=0.9326\n",
      "Batch-90 : CrossEntropyLoss=2.2626 | MulticlassF1Score=0.9321\n",
      "Batch-105: CrossEntropyLoss=2.2700 | MulticlassF1Score=0.9323\n",
      "Batch-120: CrossEntropyLoss=2.2763 | MulticlassF1Score=0.9324\n",
      "Batch-135: CrossEntropyLoss=2.2720 | MulticlassF1Score=0.9324\n",
      "Batch-150: CrossEntropyLoss=2.2657 | MulticlassF1Score=0.9328\n",
      "Batch-165: CrossEntropyLoss=2.2706 | MulticlassF1Score=0.9322\n",
      "Batch-180: CrossEntropyLoss=2.2687 | MulticlassF1Score=0.9320\n",
      "Batch-195: CrossEntropyLoss=2.2689 | MulticlassF1Score=0.9320\n",
      "Batch-210: CrossEntropyLoss=2.2656 | MulticlassF1Score=0.9323\n",
      "Batch-225: CrossEntropyLoss=2.2677 | MulticlassF1Score=0.9322\n",
      "Batch-226: CrossEntropyLoss=2.2726 | MulticlassF1Score=0.9322\n",
      "\n",
      "Validation Step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "300448bcde74432b8be9504d7580c83e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-15 : CrossEntropyLoss=2.2648 | MulticlassF1Score=0.9203\n",
      "Batch-30 : CrossEntropyLoss=2.2730 | MulticlassF1Score=0.9210\n",
      "Batch-45 : CrossEntropyLoss=2.2801 | MulticlassF1Score=0.9217\n",
      "Batch-60 : CrossEntropyLoss=2.2786 | MulticlassF1Score=0.9200\n",
      "Batch-63 : CrossEntropyLoss=2.2713 | MulticlassF1Score=0.9201\n",
      "\n",
      "Yeah 🎉😄! Model improved.\n",
      "\n",
      "Training   : Mean CrossEntropyLoss = 2.2686 | Mean MulticlassF1Score = 0.9323\n",
      "Validation : Mean CrossEntropyLoss = 2.2726 | Mean MulticlassF1Score = 0.9205\n",
      "================================================================================\n",
      "\n",
      "EPOCH-20\n",
      "Training Step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f66019d78ca342e4997ea820797055c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/226 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-15 : CrossEntropyLoss=2.2683 | MulticlassF1Score=0.9362\n",
      "Batch-30 : CrossEntropyLoss=2.2702 | MulticlassF1Score=0.9335\n",
      "Batch-45 : CrossEntropyLoss=2.2690 | MulticlassF1Score=0.9333\n",
      "Batch-60 : CrossEntropyLoss=2.2684 | MulticlassF1Score=0.9330\n",
      "Batch-75 : CrossEntropyLoss=2.2685 | MulticlassF1Score=0.9342\n",
      "Batch-90 : CrossEntropyLoss=2.2697 | MulticlassF1Score=0.9342\n",
      "Batch-105: CrossEntropyLoss=2.2646 | MulticlassF1Score=0.9344\n",
      "Batch-120: CrossEntropyLoss=2.2677 | MulticlassF1Score=0.9342\n",
      "Batch-135: CrossEntropyLoss=2.2666 | MulticlassF1Score=0.9343\n",
      "Batch-150: CrossEntropyLoss=2.2646 | MulticlassF1Score=0.9340\n",
      "Batch-165: CrossEntropyLoss=2.2673 | MulticlassF1Score=0.9335\n",
      "Batch-180: CrossEntropyLoss=2.2661 | MulticlassF1Score=0.9335\n",
      "Batch-195: CrossEntropyLoss=2.2672 | MulticlassF1Score=0.9331\n",
      "Batch-210: CrossEntropyLoss=2.2676 | MulticlassF1Score=0.9330\n",
      "Batch-225: CrossEntropyLoss=2.2603 | MulticlassF1Score=0.9331\n",
      "Batch-226: CrossEntropyLoss=2.2726 | MulticlassF1Score=0.9330\n",
      "\n",
      "Validation Step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82ab0400ce664b7383d1e0876042f4fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-15 : CrossEntropyLoss=2.2697 | MulticlassF1Score=0.9252\n",
      "Batch-30 : CrossEntropyLoss=2.2690 | MulticlassF1Score=0.9242\n",
      "Batch-45 : CrossEntropyLoss=2.2742 | MulticlassF1Score=0.9220\n",
      "Batch-60 : CrossEntropyLoss=2.2756 | MulticlassF1Score=0.9207\n",
      "Batch-63 : CrossEntropyLoss=2.2686 | MulticlassF1Score=0.9207\n",
      "\n",
      "Yeah 🎉😄! Model improved.\n",
      "\n",
      "Training   : Mean CrossEntropyLoss = 2.2682 | Mean MulticlassF1Score = 0.9341\n",
      "Validation : Mean CrossEntropyLoss = 2.2723 | Mean MulticlassF1Score = 0.9236\n",
      "================================================================================\n",
      "\n",
      "EPOCH-21\n",
      "Training Step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef9f4901100c47dd81706ab0ae501e92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/226 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-15 : CrossEntropyLoss=2.2690 | MulticlassF1Score=0.9347\n",
      "Batch-30 : CrossEntropyLoss=2.2694 | MulticlassF1Score=0.9339\n",
      "Batch-45 : CrossEntropyLoss=2.2717 | MulticlassF1Score=0.9329\n",
      "Batch-60 : CrossEntropyLoss=2.2665 | MulticlassF1Score=0.9339\n",
      "Batch-75 : CrossEntropyLoss=2.2729 | MulticlassF1Score=0.9343\n",
      "Batch-90 : CrossEntropyLoss=2.2611 | MulticlassF1Score=0.9347\n",
      "Batch-105: CrossEntropyLoss=2.2668 | MulticlassF1Score=0.9347\n",
      "Batch-120: CrossEntropyLoss=2.2676 | MulticlassF1Score=0.9349\n",
      "Batch-135: CrossEntropyLoss=2.2634 | MulticlassF1Score=0.9352\n",
      "Batch-150: CrossEntropyLoss=2.2628 | MulticlassF1Score=0.9354\n",
      "Batch-165: CrossEntropyLoss=2.2751 | MulticlassF1Score=0.9347\n",
      "Batch-180: CrossEntropyLoss=2.2671 | MulticlassF1Score=0.9350\n",
      "Batch-195: CrossEntropyLoss=2.2725 | MulticlassF1Score=0.9348\n",
      "Batch-210: CrossEntropyLoss=2.2719 | MulticlassF1Score=0.9343\n",
      "Batch-225: CrossEntropyLoss=2.2656 | MulticlassF1Score=0.9343\n",
      "Batch-226: CrossEntropyLoss=2.2689 | MulticlassF1Score=0.9343\n",
      "\n",
      "Validation Step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09fdcb84f1bc4f0ea0d50710868edef6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-15 : CrossEntropyLoss=2.2748 | MulticlassF1Score=0.9234\n",
      "Batch-30 : CrossEntropyLoss=2.2749 | MulticlassF1Score=0.9210\n",
      "Batch-45 : CrossEntropyLoss=2.2710 | MulticlassF1Score=0.9204\n",
      "Batch-60 : CrossEntropyLoss=2.2718 | MulticlassF1Score=0.9207\n",
      "Batch-63 : CrossEntropyLoss=2.2718 | MulticlassF1Score=0.9208\n",
      "\n",
      "Yeah 🎉😄! Model improved.\n",
      "\n",
      "Training   : Mean CrossEntropyLoss = 2.2679 | Mean MulticlassF1Score = 0.9347\n",
      "Validation : Mean CrossEntropyLoss = 2.2722 | Mean MulticlassF1Score = 0.9220\n",
      "================================================================================\n",
      "\n",
      "EPOCH-22\n",
      "Training Step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6f566fa7b90474fb2f601368e3ee0b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/226 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-15 : CrossEntropyLoss=2.2736 | MulticlassF1Score=0.9380\n",
      "Batch-30 : CrossEntropyLoss=2.2693 | MulticlassF1Score=0.9361\n",
      "Batch-45 : CrossEntropyLoss=2.2720 | MulticlassF1Score=0.9350\n",
      "Batch-60 : CrossEntropyLoss=2.2620 | MulticlassF1Score=0.9351\n",
      "Batch-75 : CrossEntropyLoss=2.2721 | MulticlassF1Score=0.9349\n",
      "Batch-90 : CrossEntropyLoss=2.2682 | MulticlassF1Score=0.9346\n",
      "Batch-105: CrossEntropyLoss=2.2678 | MulticlassF1Score=0.9351\n",
      "Batch-120: CrossEntropyLoss=2.2675 | MulticlassF1Score=0.9351\n",
      "Batch-135: CrossEntropyLoss=2.2634 | MulticlassF1Score=0.9355\n",
      "Batch-150: CrossEntropyLoss=2.2690 | MulticlassF1Score=0.9353\n",
      "Batch-165: CrossEntropyLoss=2.2737 | MulticlassF1Score=0.9349\n",
      "Batch-180: CrossEntropyLoss=2.2647 | MulticlassF1Score=0.9353\n",
      "Batch-195: CrossEntropyLoss=2.2688 | MulticlassF1Score=0.9355\n",
      "Batch-210: CrossEntropyLoss=2.2696 | MulticlassF1Score=0.9353\n",
      "Batch-225: CrossEntropyLoss=2.2648 | MulticlassF1Score=0.9353\n",
      "Batch-226: CrossEntropyLoss=2.2693 | MulticlassF1Score=0.9353\n",
      "\n",
      "Validation Step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e189f13e27fd41c18ae6f31b364fa835",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-15 : CrossEntropyLoss=2.2720 | MulticlassF1Score=0.9211\n",
      "Batch-30 : CrossEntropyLoss=2.2750 | MulticlassF1Score=0.9203\n",
      "Batch-45 : CrossEntropyLoss=2.2671 | MulticlassF1Score=0.9221\n",
      "Batch-60 : CrossEntropyLoss=2.2746 | MulticlassF1Score=0.9213\n",
      "Batch-63 : CrossEntropyLoss=2.2673 | MulticlassF1Score=0.9214\n",
      "\n",
      "Yeah 🎉😄! Model improved.\n",
      "\n",
      "Training   : Mean CrossEntropyLoss = 2.2675 | Mean MulticlassF1Score = 0.9354\n",
      "Validation : Mean CrossEntropyLoss = 2.2721 | Mean MulticlassF1Score = 0.9213\n",
      "================================================================================\n",
      "\n",
      "EPOCH-23\n",
      "Training Step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17230d6069dd4141af683b816c10f0ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/226 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-15 : CrossEntropyLoss=2.2655 | MulticlassF1Score=0.9343\n",
      "Batch-30 : CrossEntropyLoss=2.2678 | MulticlassF1Score=0.9361\n",
      "Batch-45 : CrossEntropyLoss=2.2695 | MulticlassF1Score=0.9344\n",
      "Batch-60 : CrossEntropyLoss=2.2663 | MulticlassF1Score=0.9345\n",
      "Batch-75 : CrossEntropyLoss=2.2668 | MulticlassF1Score=0.9355\n",
      "Batch-90 : CrossEntropyLoss=2.2702 | MulticlassF1Score=0.9352\n",
      "Batch-105: CrossEntropyLoss=2.2673 | MulticlassF1Score=0.9354\n",
      "Batch-120: CrossEntropyLoss=2.2630 | MulticlassF1Score=0.9358\n",
      "Batch-135: CrossEntropyLoss=2.2687 | MulticlassF1Score=0.9361\n",
      "Batch-150: CrossEntropyLoss=2.2694 | MulticlassF1Score=0.9359\n",
      "Batch-165: CrossEntropyLoss=2.2647 | MulticlassF1Score=0.9362\n",
      "Batch-180: CrossEntropyLoss=2.2672 | MulticlassF1Score=0.9361\n",
      "Batch-195: CrossEntropyLoss=2.2713 | MulticlassF1Score=0.9357\n",
      "Batch-210: CrossEntropyLoss=2.2672 | MulticlassF1Score=0.9358\n",
      "Batch-225: CrossEntropyLoss=2.2646 | MulticlassF1Score=0.9361\n",
      "Batch-226: CrossEntropyLoss=2.2673 | MulticlassF1Score=0.9361\n",
      "\n",
      "Validation Step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47b801f7fc77416e8b859a813201e59b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-15 : CrossEntropyLoss=2.2769 | MulticlassF1Score=0.9169\n",
      "Batch-30 : CrossEntropyLoss=2.2732 | MulticlassF1Score=0.9198\n",
      "Batch-45 : CrossEntropyLoss=2.2715 | MulticlassF1Score=0.9223\n",
      "Batch-60 : CrossEntropyLoss=2.2722 | MulticlassF1Score=0.9215\n",
      "Batch-63 : CrossEntropyLoss=2.2666 | MulticlassF1Score=0.9217\n",
      "\n",
      "Yeah 🎉😄! Model improved.\n",
      "\n",
      "Training   : Mean CrossEntropyLoss = 2.2673 | Mean MulticlassF1Score = 0.9355\n",
      "Validation : Mean CrossEntropyLoss = 2.2720 | Mean MulticlassF1Score = 0.9210\n",
      "================================================================================\n",
      "\n",
      "EPOCH-24\n",
      "Training Step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b748133aea547c89349f1bf27ee1eca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/226 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-15 : CrossEntropyLoss=2.2630 | MulticlassF1Score=0.9414\n",
      "Batch-30 : CrossEntropyLoss=2.2666 | MulticlassF1Score=0.9384\n",
      "Batch-45 : CrossEntropyLoss=2.2669 | MulticlassF1Score=0.9390\n",
      "Batch-60 : CrossEntropyLoss=2.2648 | MulticlassF1Score=0.9386\n",
      "Batch-75 : CrossEntropyLoss=2.2633 | MulticlassF1Score=0.9382\n",
      "Batch-90 : CrossEntropyLoss=2.2710 | MulticlassF1Score=0.9377\n",
      "Batch-105: CrossEntropyLoss=2.2648 | MulticlassF1Score=0.9376\n",
      "Batch-120: CrossEntropyLoss=2.2674 | MulticlassF1Score=0.9373\n",
      "Batch-135: CrossEntropyLoss=2.2665 | MulticlassF1Score=0.9375\n",
      "Batch-150: CrossEntropyLoss=2.2738 | MulticlassF1Score=0.9371\n",
      "Batch-165: CrossEntropyLoss=2.2686 | MulticlassF1Score=0.9368\n",
      "Batch-180: CrossEntropyLoss=2.2680 | MulticlassF1Score=0.9364\n",
      "Batch-195: CrossEntropyLoss=2.2674 | MulticlassF1Score=0.9367\n",
      "Batch-210: CrossEntropyLoss=2.2674 | MulticlassF1Score=0.9365\n",
      "Batch-225: CrossEntropyLoss=2.2682 | MulticlassF1Score=0.9367\n",
      "Batch-226: CrossEntropyLoss=2.2696 | MulticlassF1Score=0.9367\n",
      "\n",
      "Validation Step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b80f1e86b05148f28b1cec1da72c8756",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-15 : CrossEntropyLoss=2.2770 | MulticlassF1Score=0.9205\n",
      "Batch-30 : CrossEntropyLoss=2.2782 | MulticlassF1Score=0.9209\n",
      "Batch-45 : CrossEntropyLoss=2.2716 | MulticlassF1Score=0.9200\n",
      "Batch-60 : CrossEntropyLoss=2.2697 | MulticlassF1Score=0.9222\n",
      "Batch-63 : CrossEntropyLoss=2.2688 | MulticlassF1Score=0.9221\n",
      "\n",
      "Yeah 🎉😄! Model improved.\n",
      "\n",
      "Training   : Mean CrossEntropyLoss = 2.2671 | Mean MulticlassF1Score = 0.9379\n",
      "Validation : Mean CrossEntropyLoss = 2.2719 | Mean MulticlassF1Score = 0.9203\n",
      "================================================================================\n",
      "\n",
      "EPOCH-25\n",
      "Training Step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1210de73652748d7956ee5c7347b865b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/226 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-15 : CrossEntropyLoss=2.2700 | MulticlassF1Score=0.9364\n",
      "Batch-30 : CrossEntropyLoss=2.2664 | MulticlassF1Score=0.9350\n",
      "Batch-45 : CrossEntropyLoss=2.2653 | MulticlassF1Score=0.9349\n",
      "Batch-60 : CrossEntropyLoss=2.2679 | MulticlassF1Score=0.9363\n",
      "Batch-75 : CrossEntropyLoss=2.2626 | MulticlassF1Score=0.9360\n",
      "Batch-90 : CrossEntropyLoss=2.2683 | MulticlassF1Score=0.9359\n",
      "Batch-105: CrossEntropyLoss=2.2639 | MulticlassF1Score=0.9366\n",
      "Batch-120: CrossEntropyLoss=2.2625 | MulticlassF1Score=0.9369\n",
      "Batch-135: CrossEntropyLoss=2.2652 | MulticlassF1Score=0.9371\n",
      "Batch-150: CrossEntropyLoss=2.2746 | MulticlassF1Score=0.9370\n",
      "Batch-165: CrossEntropyLoss=2.2672 | MulticlassF1Score=0.9370\n",
      "Batch-180: CrossEntropyLoss=2.2630 | MulticlassF1Score=0.9374\n",
      "Batch-195: CrossEntropyLoss=2.2704 | MulticlassF1Score=0.9376\n",
      "Batch-210: CrossEntropyLoss=2.2643 | MulticlassF1Score=0.9379\n",
      "Batch-225: CrossEntropyLoss=2.2697 | MulticlassF1Score=0.9380\n",
      "Batch-226: CrossEntropyLoss=2.2618 | MulticlassF1Score=0.9380\n",
      "\n",
      "Validation Step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e73f69ec4d834eaf81199d9a2f55e0da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-15 : CrossEntropyLoss=2.2688 | MulticlassF1Score=0.9280\n",
      "Batch-30 : CrossEntropyLoss=2.2634 | MulticlassF1Score=0.9261\n",
      "Batch-45 : CrossEntropyLoss=2.2687 | MulticlassF1Score=0.9255\n",
      "Batch-60 : CrossEntropyLoss=2.2707 | MulticlassF1Score=0.9255\n",
      "Batch-63 : CrossEntropyLoss=2.2731 | MulticlassF1Score=0.9255\n",
      "\n",
      "Yeah 🎉😄! Model improved.\n",
      "\n",
      "Training   : Mean CrossEntropyLoss = 2.2667 | Mean MulticlassF1Score = 0.9366\n",
      "Validation : Mean CrossEntropyLoss = 2.2708 | Mean MulticlassF1Score = 0.9263\n",
      "================================================================================\n",
      "\n",
      "EPOCH-26\n",
      "Training Step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18d89c00298747c4930589d13f6413bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/226 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch-15 : CrossEntropyLoss=2.2692 | MulticlassF1Score=0.9395\n",
      "Batch-30 : CrossEntropyLoss=2.2728 | MulticlassF1Score=0.9403\n",
      "Batch-45 : CrossEntropyLoss=2.2679 | MulticlassF1Score=0.9412\n",
      "Batch-60 : CrossEntropyLoss=2.2670 | MulticlassF1Score=0.9421\n",
      "Batch-75 : CrossEntropyLoss=2.2662 | MulticlassF1Score=0.9412\n",
      "Batch-90 : CrossEntropyLoss=2.2631 | MulticlassF1Score=0.9417\n",
      "Batch-105: CrossEntropyLoss=2.2623 | MulticlassF1Score=0.9420\n",
      "Batch-120: CrossEntropyLoss=2.2645 | MulticlassF1Score=0.9420\n",
      "Batch-135: CrossEntropyLoss=2.2688 | MulticlassF1Score=0.9421\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now(pytz.timezone(\"Asia/Ujung_Pandang\"))\n",
    "path_name = now.strftime(\"%m-%d-%Y_%H-%M-%S\")\n",
    "root_path = f\"../../../logs/classifier/{hyperparams.context_size}_contexts/fold_0{hyperparams.fold}/{path_name}\"\n",
    "os.makedirs(root_path)\n",
    "\n",
    "def looping_step(train_dataloader, val_dataloader, model, optimizer, criterion, train_metric, val_metric, n_epoch=hyperparams.n_epoch, patience=hyperparams.patience, monitor=\"loss\"):    \n",
    "    start_time = time()\n",
    "    \n",
    "    epoch_training_losses = []\n",
    "    epoch_training_metric_scores = []\n",
    "    epoch_val_losses = []\n",
    "    epoch_val_metric_scores = []\n",
    "    patience_counter = 0\n",
    "    \n",
    "    # Hyperparameters\n",
    "    with open(f\"{root_path}/training_history.txt\", \"a\") as f:\n",
    "        f.write(f\"HYPERPARAMETERS\\n\")\n",
    "        f.write(f\"{'-' * 80}\\n\")\n",
    "        for name, value in vars(hyperparams).items():\n",
    "            f.write(f\"{name}: {value}\\n\")\n",
    "        \n",
    "        f.write(\"\\n\\nTRAINING PROGRESS\\n\")\n",
    "        f.write(f\"{'-' * 80}\\n\")\n",
    "    \n",
    "    # Training Progress\n",
    "    for epoch in range(1, n_epoch + 1):\n",
    "        print(f\"EPOCH-{epoch}\")\n",
    "        with open(f\"{root_path}/training_history.txt\", \"a\") as f:\n",
    "            f.write(f\"EPOCH-{epoch}\\n\")\n",
    "            f.write(f\"Training Step\\n\")\n",
    "            \n",
    "        # Training Step\n",
    "        print(\"Training Step\")\n",
    "        batch_training_losses, batch_training_metric_scores = training_step(train_dataloader, model, optimizer, criterion, train_metric, scheduler=None)\n",
    "        epoch_training_loss = torch.mean(torch.FloatTensor(batch_training_losses))\n",
    "\n",
    "        epoch_training_loss = torch.mean(torch.FloatTensor(batch_training_losses))\n",
    "        epoch_training_losses.append(epoch_training_loss.item())\n",
    "\n",
    "        epoch_training_metric_score = torch.mean(torch.FloatTensor(batch_training_metric_scores))\n",
    "        epoch_training_metric_scores.append(epoch_training_metric_score.item())\n",
    "        \n",
    "        # Validation Step\n",
    "        with open(f\"{root_path}/training_history.txt\", \"a\") as f:\n",
    "            f.write(f\"\\nValidation Step\\n\")\n",
    "            \n",
    "        print(\"\\nValidation Step\")\n",
    "        batch_val_losses, batch_val_metric_scores = validation_step(val_dataloader, model, criterion, val_metric)\n",
    "        epoch_val_loss = torch.mean(torch.FloatTensor(batch_val_losses))\n",
    "\n",
    "        epoch_val_loss = torch.mean(torch.FloatTensor(batch_val_losses))\n",
    "        epoch_val_losses.append(epoch_val_loss.item())\n",
    "\n",
    "        epoch_val_metric_score = torch.mean(torch.FloatTensor(batch_val_metric_scores))\n",
    "        epoch_val_metric_scores.append(epoch_val_metric_score.item())\n",
    "        \n",
    "        with open(f\"{root_path}/training_history.txt\", \"a\") as f:\n",
    "            if monitor == \"loss\":\n",
    "                if epoch == 1:\n",
    "                    best_state_dict = model.state_dict()\n",
    "                    best_training_loss = epoch_training_loss\n",
    "                    best_training_metric = epoch_training_metric_score\n",
    "                    best_val_loss = epoch_val_loss\n",
    "                    best_val_metric = epoch_val_metric_score\n",
    "                    \n",
    "                    print(f\"\\nTraining   : Mean {str(criterion).split('(')[0]} = {(epoch_training_loss):.4f} | Mean {str(train_metric).split('(')[0]} = {(epoch_training_metric_score):.4f}\")\n",
    "                    print(f\"Validation : Mean {str(criterion).split('(')[0]} = {(epoch_val_loss):.4f} | Mean {str(val_metric).split('(')[0]} = {(epoch_val_metric_score):.4f}\")\n",
    "                    \n",
    "                    f.write(f\"\\nTraining   : Mean {str(criterion).split('(')[0]} = {(epoch_training_loss):.4f} | Mean {str(train_metric).split('(')[0]} = {(epoch_training_metric_score):.4f}\\n\")\n",
    "                    f.write(f\"Validation : Mean {str(criterion).split('(')[0]} = {(epoch_val_loss):.4f} | Mean {str(val_metric).split('(')[0]} = {(epoch_val_metric_score):.4f}\\n\")\n",
    "                elif epoch_training_losses[-1] < epoch_training_losses[-2]:\n",
    "                    best_state_dict = model.state_dict()\n",
    "                    best_training_loss = epoch_training_loss\n",
    "                    best_training_metric = epoch_training_metric_score\n",
    "                    best_val_loss = epoch_val_loss\n",
    "                    best_val_metric = epoch_val_metric_score\n",
    "                    \n",
    "                    print(\"\\nYeah 🎉😄! Model improved.\")\n",
    "                    print(f\"\\nTraining   : Mean {str(criterion).split('(')[0]} = {(epoch_training_loss):.4f} | Mean {str(train_metric).split('(')[0]} = {(epoch_training_metric_score):.4f}\")\n",
    "                    print(f\"Validation : Mean {str(criterion).split('(')[0]} = {(epoch_val_loss):.4f} | Mean {str(val_metric).split('(')[0]} = {(epoch_val_metric_score):.4f}\")\n",
    "                    \n",
    "                    f.write(\"\\nYeah 🎉😄! Model improved.\\n\")\n",
    "                    f.write(f\"\\nTraining   : Mean {str(criterion).split('(')[0]} = {(epoch_training_loss):.4f} | Mean {str(train_metric).split('(')[0]} = {(epoch_training_metric_score):.4f}\\n\")\n",
    "                    f.write(f\"Validation : Mean {str(criterion).split('(')[0]} = {(epoch_val_loss):.4f} | Mean {str(val_metric).split('(')[0]} = {(epoch_val_metric_score):.4f}\\n\")\n",
    "                else:\n",
    "                    patience_counter += 1\n",
    "                    \n",
    "                    print(\"\\nHuft 😥! Model not improved.\")\n",
    "                    print(f\"\\nTraining   : Mean {str(criterion).split('(')[0]} = {(epoch_training_loss):.4f} | Mean {str(train_metric).split('(')[0]} = {(epoch_training_metric_score):.4f}\")\n",
    "                    print(f\"Validation : Mean {str(criterion).split('(')[0]} = {(epoch_val_loss):.4f} | Mean {str(val_metric).split('(')[0]} = {(epoch_val_metric_score):.4f}\")\n",
    "                    print(f\"Patience = {patience_counter}/{patience}❗\")\n",
    "                    \n",
    "                    f.write(\"\\nHuft 😥! Model not improved.\\n\")\n",
    "                    f.write(f\"\\nTraining   : Mean {str(criterion).split('(')[0]} = {(epoch_training_loss):.4f} | Mean {str(train_metric).split('(')[0]} = {(epoch_training_metric_score):.4f}\\n\")\n",
    "                    f.write(f\"Validation : Mean {str(criterion).split('(')[0]} = {(epoch_val_loss):.4f} | Mean {str(val_metric).split('(')[0]} = {(epoch_val_metric_score):.4f}\\n\")\n",
    "                    f.write(f\"Patience = {patience_counter}/{patience}❗\\n\")\n",
    "            else:\n",
    "                if epoch == 1:\n",
    "                    best_state_dict = model.state_dict()\n",
    "                    best_training_loss = epoch_training_loss\n",
    "                    best_training_metric = epoch_training_metric_score\n",
    "                    best_val_loss = epoch_val_loss\n",
    "                    best_val_metric = epoch_val_metric_score\n",
    "                    \n",
    "                    print(f\"\\nTraining   : Mean {str(criterion).split('(')[0]} = {(epoch_training_loss):.4f} | Mean {str(train_metric).split('(')[0]} = {(epoch_training_metric_score):.4f}\")\n",
    "                    print(f\"Validation : Mean {str(criterion).split('(')[0]} = {(epoch_val_loss):.4f} | Mean {str(val_metric).split('(')[0]} = {(epoch_val_metric_score):.4f}\")\n",
    "                    \n",
    "                    f.write(f\"\\nTraining   : Mean {str(criterion).split('(')[0]} = {(epoch_training_loss):.4f} | Mean {str(train_metric).split('(')[0]} = {(epoch_training_metric_score):.4f}\\n\")\n",
    "                    f.write(f\"Validation : Mean {str(criterion).split('(')[0]} = {(epoch_val_loss):.4f} | Mean {str(val_metric).split('(')[0]} = {(epoch_val_metric_score):.4f}\\n\")\n",
    "                elif epoch_training_metric_scores[-1] > epoch_training_metric_scores[-2]:\n",
    "                    best_state_dict = model.state_dict()\n",
    "                    best_training_loss = epoch_training_loss\n",
    "                    best_training_metric = epoch_training_metric_score\n",
    "                    best_val_loss = epoch_val_loss\n",
    "                    best_val_metric = epoch_val_metric_score\n",
    "                    \n",
    "                    print(\"\\nYeah 🎉😄! Model improved.\")\n",
    "                    print(f\"\\nTraining   : Mean {str(criterion).split('(')[0]} = {(epoch_training_loss):.4f} | Mean {str(train_metric).split('(')[0]} = {(epoch_training_metric_score):.4f}\")\n",
    "                    print(f\"Validation : Mean {str(criterion).split('(')[0]} = {(epoch_val_loss):.4f} | Mean {str(val_metric).split('(')[0]} = {(epoch_val_metric_score):.4f}\")\n",
    "                    \n",
    "                    f.write(\"\\nYeah 🎉😄! Model improved.\\n\")\n",
    "                    f.write(f\"\\nTraining   : Mean {str(criterion).split('(')[0]} = {(epoch_training_loss):.4f} | Mean {str(train_metric).split('(')[0]} = {(epoch_training_metric_score):.4f}\\n\")\n",
    "                    f.write(f\"Validation : Mean {str(criterion).split('(')[0]} = {(epoch_val_loss):.4f} | Mean {str(val_metric).split('(')[0]} = {(epoch_val_metric_score):.4f}\\n\")\n",
    "                else:\n",
    "                    patience_counter += 1\n",
    "                    \n",
    "                    print(\"\\nHuft 😥! Model not improved.\")\n",
    "                    print(f\"\\nTraining   : Mean {str(criterion).split('(')[0]} = {(epoch_training_loss):.4f} | Mean {str(train_metric).split('(')[0]} = {(epoch_training_metric_score):.4f}\")\n",
    "                    print(f\"Validation : Mean {str(criterion).split('(')[0]} = {(epoch_val_loss):.4f} | Mean {str(val_metric).split('(')[0]} = {(epoch_val_metric_score):.4f}\")\n",
    "                    print(f\"Patience = {patience_counter}/{patience}❗\\n\")\n",
    "                    \n",
    "                    f.write(\"\\nHuft 😥! Model not improved.\\n\")\n",
    "                    f.write(f\"\\nTraining   : Mean {str(criterion).split('(')[0]} = {(epoch_training_loss):.4f} | Mean {str(train_metric).split('(')[0]} = {(epoch_training_metric_score):.4f}\\n\")\n",
    "                    f.write(f\"Validation : Mean {str(criterion).split('(')[0]} = {(epoch_val_loss):.4f} | Mean {str(val_metric).split('(')[0]} = {(epoch_val_metric_score):.4f}\\n\")\n",
    "                    f.write(f\"Patience = {patience_counter}/{patience}❗\\n\")\n",
    "                    \n",
    "            print(\"=\" * 80, end=\"\\n\\n\")\n",
    "            \n",
    "            f.write(f\"{'=' * 80}\\n\\n\")\n",
    "            \n",
    "            if patience_counter == patience:\n",
    "                print(f\"Early stopping, patience = {patience_counter}/{patience}❗\\n\")\n",
    "                \n",
    "                f.write(f\"Early stopping, patience = {patience_counter}/{patience}❗\\n\")\n",
    "                break\n",
    "        \n",
    "        train_metric.reset()\n",
    "        val_metric.reset()\n",
    "        \n",
    "    finish_time = time()\n",
    "    \n",
    "    # Training plot \n",
    "    fig, (ax_loss, ax_metric_score) = plt.subplots(nrows=1, ncols=2, figsize=(15, 5))\n",
    "\n",
    "    fig.suptitle(f\"Training with context size = {hyperparams.context_size}\")\n",
    "\n",
    "    ax_loss.set_title(\"Loss\")\n",
    "    ax_loss.set_xlabel(\"Epoch\")\n",
    "    ax_loss.set_ylabel(\"Score\")\n",
    "    ax_loss.plot(epoch_training_losses, \"green\", label=\"Training\")\n",
    "    ax_loss.plot(epoch_val_losses, \"orange\", label=\"Validation\")\n",
    "    ax_loss.legend()\n",
    "    ax_loss.grid()\n",
    "\n",
    "    ax_metric_score.set_title(\"F1 Score\")\n",
    "    ax_metric_score.set_xlabel(\"Epoch\")\n",
    "    ax_metric_score.set_ylabel(\"Score\")\n",
    "    ax_metric_score.plot(epoch_training_metric_scores, \"green\", label=\"Training\")\n",
    "    ax_metric_score.plot(epoch_val_metric_scores, \"orange\", label=\"Validation\")\n",
    "    ax_metric_score.legend()\n",
    "    ax_metric_score.grid()\n",
    "\n",
    "    plt.savefig(f\"{root_path}/training_plot.jpg\", dpi=200)                        \n",
    "    \n",
    "    print(\"TRAINING SUMMARY\")\n",
    "    name_best_training_loss = f\"Best {str(criterion).split('(')[0]} training\".ljust(34)\n",
    "    name_best_training_metric = f\"Best {str(train_metric).split('(')[0]} validation\".ljust(34)\n",
    "    name_best_validation_loss = f\"Best {str(criterion).split('(')[0]} training\".ljust(34)\n",
    "    name_best_validation_metric = f\"Best {str(val_metric).split('(')[0]} validation\".ljust(34)\n",
    "    name_training_time = f\"Training duration\".ljust(34)\n",
    "    name_training_date = f\"Training date\".ljust(34)\n",
    "    \n",
    "    print(f\"{name_best_training_loss}: {best_training_loss:.4f}\")\n",
    "    print(f\"{name_best_validation_loss}: {best_val_loss:.4f}\")\n",
    "    print(f\"{name_best_training_metric}: {best_training_metric:.4f}\")\n",
    "    print(f\"{name_best_validation_metric}: {best_val_metric:.4f}\")\n",
    "    print(f\"{name_training_time}: {((finish_time - start_time) / 60):.4f} minutes.\")\n",
    "    print(f\"{name_training_date}: {now}\")\n",
    "    \n",
    "    with open(f\"{root_path}/training_history.txt\", \"a\") as f:\n",
    "        f.write(\"\\nTRAINING SUMMARY\\n\")\n",
    "        f.write(f\"{'-' * 80}\\n\")\n",
    "        f.write(f\"{name_best_training_loss}: {best_training_loss:.4f}\\n\")\n",
    "        f.write(f\"{name_best_validation_loss}: {best_val_loss:.4f}\\n\")\n",
    "        f.write(f\"{name_best_training_metric}: {best_training_metric:.4f}\\n\")\n",
    "        f.write(f\"{name_best_validation_metric}: {best_val_metric:.4f}\\n\")\n",
    "        f.write(f\"{name_training_time}: {((finish_time - start_time) / 60):.4f} minutes.\\n\")\n",
    "        f.write(f\"{name_training_date}: {now}\\n\")\n",
    "    \n",
    "    # Save epoch losses, epoch metric scores, model, state dict, and oov embedding dict\n",
    "    pd.DataFrame({\n",
    "        \"epoch\": list(range(1, hyperparams.n_epoch + 1)),\n",
    "        \"loss\": epoch_training_losses\n",
    "    }).to_csv(f\"{root_path}/training_losses.csv\", index=False)\n",
    "    \n",
    "    pd.DataFrame({\n",
    "        \"epoch\": list(range(1, hyperparams.n_epoch + 1)),\n",
    "        \"f1_score\": epoch_training_metric_scores\n",
    "    }).to_csv(f\"{root_path}/training_metric_scores.csv\", index=False)\n",
    "    \n",
    "    pd.DataFrame({\n",
    "        \"epoch\": list(range(1, hyperparams.n_epoch + 1)),\n",
    "        \"loss\": epoch_val_losses\n",
    "    }).to_csv(f\"{root_path}/val_losses.csv\", index=False)\n",
    "    \n",
    "    pd.DataFrame({\n",
    "        \"epoch\": list(range(1, hyperparams.n_epoch + 1)),\n",
    "        \"f1_score\": epoch_val_metric_scores\n",
    "    }).to_csv(f\"{root_path}/val_metric_scores.csv\", index=False)    \n",
    "    \n",
    "    filename_model_params = f\"{root_path}/model_params.pth\"\n",
    "    torch.save(best_state_dict, filename_model_params)\n",
    "    \n",
    "    return epoch_training_losses, epoch_training_metric_scores, epoch_val_losses, epoch_val_metric_scores\n",
    "\n",
    "epoch_training_losses, epoch_training_metric_scores, epoch_val_losses, epoch_val_metric_scores = looping_step(train_dataloader, val_dataloader, model, optimizer, criterion, train_metric, val_metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c1ab00-060c-492c-b731-b5b78bc10bc0",
   "metadata": {},
   "source": [
    "## End Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1d19df-0c5b-42c0-9619-f3409774cf4b",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa68954-9917-497d-9be1-15bafefe7a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(dataloader, model, criterion, metric):\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        for batch, (feature, actual_label) in enumerate(tqdm(dataloader), 1):\n",
    "            # Forward Propagation\n",
    "            feature = rearrange(feature, \"n s -> s n\")\n",
    "            actual_label = rearrange(actual_label, \"n s -> s n\")\n",
    "            embedding = word_embeddings(feature)\n",
    "\n",
    "            prob = model(\n",
    "                embedding.to(hyperparams.device),\n",
    "                actual_label.to(hyperparams.device)\n",
    "            )\n",
    "\n",
    "            prob = prob.reshape(-1, prob.shape[-1])\n",
    "            actual_label = actual_label.reshape(-1)\n",
    "            pred = rearrange(prob.argmax(dim=1).reshape(feature.shape[0], len(dataloader.dataset)), \"s n -> n s\")\n",
    "\n",
    "            loss = criterion(prob, actual_label.to(hyperparams.device))\n",
    "            metric_score = metric(prob.argmax(dim=1), actual_label.to(hyperparams.device))\n",
    "            metric_score = metric.compute()\n",
    "\n",
    "    return loss, metric_score, pred\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=len(train_dataset))\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=len(val_dataset))\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=len(test_dataset))\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().to(hyperparams.device)\n",
    "metric = MulticlassF1Score(average=\"micro\", num_classes=24, mdmc_average=\"samplewise\", multiclass=True, ignore_index=label_to_idx[\"<PAD>\"]).to(hyperparams.device)\n",
    "train_loss, train_f1_score, train_pred_label = evaluation(train_dataloader, model, criterion, metric)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().to(hyperparams.device)\n",
    "metric = MulticlassF1Score(average=\"micro\", num_classes=24, mdmc_average=\"samplewise\", multiclass=True, ignore_index=label_to_idx[\"<PAD>\"]).to(hyperparams.device)\n",
    "val_loss, val_f1_score, val_pred_label = evaluation(val_dataloader, model, criterion, metric)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().to(hyperparams.device)\n",
    "metric = MulticlassF1Score(average=\"micro\", num_classes=24, mdmc_average=\"samplewise\", multiclass=True, ignore_index=label_to_idx[\"<PAD>\"]).to(hyperparams.device)\n",
    "test_loss, test_f1_score, test_pred_label = evaluation(test_dataloader, model, criterion, metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf283357-3263-43eb-88e0-b3726c41fa47",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_f1_score, val_f1_score, test_f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d776c1-f3d8-48ce-9092-d5919ef6c645",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_f1_score, val_f1_score, test_f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fee85a3-646f-4e0b-8dfa-8b89f3e0a473",
   "metadata": {},
   "source": [
    "## Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8948cb64-711c-4407-bdd6-78bf02161505",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "def viz_evaluation(pred_label, actual_label, title):\n",
    "    plt.figure(figsize=(15, 7), dpi=200)\n",
    "    sns.heatmap(pred_label.detach().cpu() == actual_label, cbar=True, cmap=\"binary_r\")\n",
    "    plt.xlabel(\"Sentence Length\")\n",
    "    plt.ylabel(\"Sentence\")\n",
    "    plt.title(title)\n",
    "    plt.savefig(f\"{root_path}/heatmap_{title.lower()}.jpg\", dpi=200)\n",
    "    plt.show()\n",
    "\n",
    "train_actual_label = train_dataloader.dataset.tensors[1]\n",
    "val_actual_label = val_dataloader.dataset.tensors[1]\n",
    "test_actual_label = test_dataloader.dataset.tensors[1]\n",
    "\n",
    "viz_evaluation(train_pred_label, train_actual_label, f\"Training (F1-Score: {(train_f1_score):.4f})\")\n",
    "viz_evaluation(val_pred_label, val_actual_label, f\"Validation (F1-Score: {(val_f1_score):.4f})\")\n",
    "viz_evaluation(test_pred_label, test_actual_label, f\"Test (F1-Score: {(test_f1_score):.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88a7dca-8191-47cc-a4be-45abd1a9b1d1",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d68452f-f3ad-4899-868b-8aff317e0eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(pred_class, actual_class, title, normalize=None):\n",
    "    conf_mat = MulticlassConfusionMatrix(num_classes=24, normalize=normalize)\n",
    "    plt.figure(figsize=(20, 10), dpi=200)\n",
    "    sns.heatmap(conf_mat(pred_class.detach().cpu(), actual_class), annot=True, fmt=\".2g\", xticklabels=list(label_to_idx.keys()), yticklabels=list(label_to_idx.keys()));\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Actual Class\")\n",
    "    plt.ylabel(\"Predict Class\")\n",
    "    plt.savefig(f\"{root_path}/conf_matrix_{title.lower()}.jpg\", dpi=200)\n",
    "\n",
    "confusion_matrix(train_pred_label, train_actual_label, \"Training\", \"pred\")\n",
    "confusion_matrix(val_pred_label,val_actual_label, \"Validation\", \"pred\")\n",
    "confusion_matrix(test_pred_label, test_actual_label, \"Test\", \"pred\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada17c56-345a-4eba-914a-b093ce956d27",
   "metadata": {},
   "source": [
    "## Prediction Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3467f514-d6a6-46e4-b9bb-295686c5a572",
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_wrong_pred_each_class(pred_class, actual_class):\n",
    "    classes, count_class = actual_class.flatten().unique(return_counts=True)\n",
    "    conf_mat = MulticlassConfusionMatrix(num_classes=24, normalize=\"none\")\n",
    "    correct_pred_count_class = conf_mat(pred_class.detach().cpu(), actual_class).diag()\n",
    "    \n",
    "    correct_pred = {idx_to_label[label.item()]: count.item() for label, count in zip(classes, (correct_pred_count_class))}\n",
    "    wrong_pred = {idx_to_label[label.item()]: count.item() for label, count in zip(classes, (count_class - correct_pred_count_class))}\n",
    "    \n",
    "    return correct_pred, wrong_pred\n",
    "\n",
    "correct_pred, wrong_pred = number_wrong_pred_each_class(train_pred_label, train_actual_label)\n",
    "print(f\"| {'Number class'.ljust(14)} | {'Correct prediction'.ljust(12)} | {'Wrong prediction'.ljust(12)} |\")\n",
    "for (label_correct_pred, count_correct_pred), (label_wrong_pred, count_wrong_pred) in zip(correct_pred.items(), wrong_pred.items()):\n",
    "    print(f\"| {str(label_correct_pred).ljust(6)}: {str(count_correct_pred + count_wrong_pred).ljust(7)}| {label_correct_pred.ljust(6)}: {str(count_correct_pred).ljust(10)} | {label_wrong_pred.ljust(6)}: {str(count_wrong_pred).ljust(8)} |\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc2b172-d261-42d3-b9c3-69f67cd0d622",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_actual_label[308], train_pred_label[308]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925c3a3f-2f10-44f8-b394-bedaf19e2540",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_actual_label[308].detach().cpu() == train_pred_label[308].detach().cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f44bd5-cd73-4184-9078-63d2b5718078",
   "metadata": {},
   "source": [
    "## OOV prediction is correct "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a4df60-901f-49d3-8dfb-b37fab4773be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def oov_flag_token(sentences, max_seq_len=hyperparams.max_seq_len):\n",
    "    sent_copy = deepcopy(sentences)\n",
    "    sent = []\n",
    "    oov_flag = []\n",
    "    \n",
    "    for sentence in tqdm(sent_copy):\n",
    "        for token in sentence:\n",
    "            sent.append(token[2])\n",
    "        \n",
    "        for _ in range(max_seq_len- len(sentence)):\n",
    "            sent.append(False)\n",
    "        \n",
    "        oov_flag.append(sent)\n",
    "        sent = []\n",
    "        \n",
    "    return np.array(oov_flag)\n",
    "\n",
    "train_oov_flag = oov_flag_token(train_sentences, max_seq_len=hyperparams.max_seq_len)\n",
    "val_oov_flag = oov_flag_token(val_sentences, max_seq_len=hyperparams.max_seq_len)\n",
    "test_oov_flag = oov_flag_token(test_sentences, max_seq_len=hyperparams.max_seq_len)\n",
    "\n",
    "def pencentage_oov_pred_correct(pred_oov_flag, oov_flag_tensor):\n",
    "    oov_correct_counter = 0\n",
    "    oov_wrong_counter = 0\n",
    "\n",
    "    for pred, oov_label in tqdm(zip(pred_oov_flag, oov_flag_tensor)):\n",
    "        if pred == True and oov_label == True:\n",
    "            oov_correct_counter += 1\n",
    "        elif pred == False and oov_label == True:\n",
    "            oov_wrong_counter += 1\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "    return oov_correct_counter, oov_wrong_counter\n",
    "\n",
    "train_pred_oov_flag = (train_actual_label == train_pred_label.detach().cpu()).flatten()\n",
    "val_pred_oov_flag = (val_actual_label == val_pred_label.detach().cpu()).flatten()\n",
    "test_pred_oov_flag = (test_actual_label == test_pred_label.detach().cpu()).flatten()\n",
    "train_oov_flag_tensor = torch.tensor(train_oov_flag).flatten()\n",
    "val_oov_flag_tensor = torch.tensor(val_oov_flag).flatten()\n",
    "test_oov_flag_tensor = torch.tensor(test_oov_flag).flatten()\n",
    "\n",
    "train_oov_correct_counter, train_oov_wrong_counter = pencentage_oov_pred_correct(train_pred_oov_flag, train_oov_flag_tensor)\n",
    "val_oov_correct_counter, val_oov_wrong_counter = pencentage_oov_pred_correct(val_pred_oov_flag, val_oov_flag_tensor)\n",
    "test_oov_correct_counter, test_oov_wrong_counter = pencentage_oov_pred_correct(test_pred_oov_flag, test_oov_flag_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e59490d-6b9f-4c4d-833b-28eaf624d445",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_percentage_pred_oov(title, oov_correct_counter, oov_wrong_counter):\n",
    "    print(f\"{title}\")\n",
    "    print(f\"Number OOV token            : {oov_correct_counter + oov_wrong_counter}\")\n",
    "    print(f\"Correct prediction          : {oov_correct_counter}\")\n",
    "    print(f\"Wrong prediction            : {oov_wrong_counter}\")\n",
    "    print(f\"Percentage correct oov pred : {oov_correct_counter / (oov_correct_counter + oov_wrong_counter) * 100}\\n\")\n",
    "    \n",
    "    with open(f\"{root_path}/oov_summary.txt\", \"a\") as f:\n",
    "        f.write(f\"{title}\\n\")\n",
    "        f.write(f\"Number OOV token            : {oov_correct_counter + oov_wrong_counter}\\n\")\n",
    "        f.write(f\"Correct prediction          : {oov_correct_counter}\\n\")\n",
    "        f.write(f\"Wrong prediction            : {oov_wrong_counter}\\n\")\n",
    "        f.write(f\"Percentage correct oov pred : {oov_correct_counter / (oov_correct_counter + oov_wrong_counter) * 100}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cda2e3-0629-4e3c-8459-4324b513ddaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_percentage_pred_oov(\"Training\", train_oov_correct_counter, train_oov_wrong_counter)\n",
    "print_percentage_pred_oov(\"Validation\", val_oov_correct_counter, val_oov_wrong_counter)\n",
    "print_percentage_pred_oov(\"Test\", test_oov_correct_counter, test_oov_wrong_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efce585-5e19-45eb-8781-6818b8369819",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 7))\n",
    "sns.heatmap(train_oov_flag, cmap=plt.cm.binary_r);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97963f81-d9bf-4239-842d-ef30df0dfb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 7))\n",
    "sns.heatmap(val_oov_flag, cmap=plt.cm.binary_r);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3674a992-1715-4d50-892d-bb7df050aeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 7))\n",
    "sns.heatmap(test_oov_flag, cmap=plt.cm.binary_r);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fc95b3-4ee0-4cc1-b7d9-40a3e8150c8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4828bfc-586d-4f3f-999f-cea4c114d2e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
