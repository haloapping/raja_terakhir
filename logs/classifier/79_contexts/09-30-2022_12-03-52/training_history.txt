HYPERPARAMETERS
------------------------------------------------------------
context_size: 79
input_size: 64
batch_size: 32
num_hidden_layer: 1
hidden_size: 128
output_size: 24
shuffle: True
lr: 0.005
batch_first: False
bidirectional: True
init_wb_with_kaiming_normal: True
n_epoch: 20
patience: 100
device: cpu

TRAINING PROGRESS
------------------------------------------------------------
EPOCH-1
Batch-50: CrossEntropyLoss=3.0720 | F1Score=0.3465
Batch-100: CrossEntropyLoss=3.0775 | F1Score=0.3491
Batch-150: CrossEntropyLoss=3.0473 | F1Score=0.3562
Batch-200: CrossEntropyLoss=3.0626 | F1Score=0.3619
Batch-226: CrossEntropyLoss=3.0410 | F1Score=0.3626
Batch-26: CrossEntropyLoss=3.0565 | F1Score=0.3645

Training   : Mean CrossEntropyLoss = 3.0718 | Mean F1Score = 0.3390
Validation : Mean CrossEntropyLoss = 3.0587 | Mean F1Score = 0.3636
============================================================

EPOCH-2
Batch-50: CrossEntropyLoss=3.0625 | F1Score=0.3702
Batch-100: CrossEntropyLoss=3.0722 | F1Score=0.3745
Batch-150: CrossEntropyLoss=3.0559 | F1Score=0.3774
Batch-200: CrossEntropyLoss=3.0550 | F1Score=0.3801
Batch-226: CrossEntropyLoss=3.0149 | F1Score=0.3798
Batch-26: CrossEntropyLoss=2.9964 | F1Score=0.3809

Yeah üéâüòÑ! Model improved.
Training   : Mean CrossEntropyLoss = 3.0584 | Mean F1Score = 0.3756
Validation : Mean CrossEntropyLoss = 3.0539 | Mean F1Score = 0.3812
============================================================

EPOCH-3
Batch-50: CrossEntropyLoss=3.0564 | F1Score=0.4121
Batch-100: CrossEntropyLoss=3.0632 | F1Score=0.4033
Batch-150: CrossEntropyLoss=3.0591 | F1Score=0.3989
Batch-200: CrossEntropyLoss=3.0604 | F1Score=0.3982
Batch-226: CrossEntropyLoss=3.0466 | F1Score=0.3973
Batch-26: CrossEntropyLoss=2.9997 | F1Score=0.3988

Yeah üéâüòÑ! Model improved.
Training   : Mean CrossEntropyLoss = 3.0569 | Mean F1Score = 0.4046
Validation : Mean CrossEntropyLoss = 3.0533 | Mean F1Score = 0.3979
============================================================

EPOCH-4
Batch-50: CrossEntropyLoss=3.0683 | F1Score=0.3969
Batch-100: CrossEntropyLoss=3.0638 | F1Score=0.4014
Batch-150: CrossEntropyLoss=3.0742 | F1Score=0.4026
Batch-200: CrossEntropyLoss=3.0524 | F1Score=0.4019
Batch-226: CrossEntropyLoss=3.0388 | F1Score=0.4005
Batch-26: CrossEntropyLoss=3.0160 | F1Score=0.4024

Yeah üéâüòÑ! Model improved.
Training   : Mean CrossEntropyLoss = 3.0562 | Mean F1Score = 0.3996
Validation : Mean CrossEntropyLoss = 3.0533 | Mean F1Score = 0.4016
============================================================

EPOCH-5
Batch-50: CrossEntropyLoss=3.0498 | F1Score=0.3972
Batch-100: CrossEntropyLoss=3.0481 | F1Score=0.4038
Batch-150: CrossEntropyLoss=3.0580 | F1Score=0.4065
Batch-200: CrossEntropyLoss=3.0730 | F1Score=0.4087
Batch-226: CrossEntropyLoss=3.0318 | F1Score=0.4100
Batch-26: CrossEntropyLoss=2.8643 | F1Score=0.4116

Yeah üéâüòÑ! Model improved.
Training   : Mean CrossEntropyLoss = 3.0556 | Mean F1Score = 0.4019
Validation : Mean CrossEntropyLoss = 3.0468 | Mean F1Score = 0.4106
============================================================

EPOCH-6
Batch-50: CrossEntropyLoss=3.0628 | F1Score=0.4058
Batch-100: CrossEntropyLoss=3.0743 | F1Score=0.4127
Batch-150: CrossEntropyLoss=3.0527 | F1Score=0.4116
Batch-200: CrossEntropyLoss=3.0588 | F1Score=0.4125
Batch-226: CrossEntropyLoss=3.0262 | F1Score=0.4154
Batch-26: CrossEntropyLoss=3.0533 | F1Score=0.4161

Yeah üéâüòÑ! Model improved.
Training   : Mean CrossEntropyLoss = 3.0550 | Mean F1Score = 0.4087
Validation : Mean CrossEntropyLoss = 3.0537 | Mean F1Score = 0.4159
============================================================

EPOCH-7
Batch-50: CrossEntropyLoss=3.0539 | F1Score=0.4185
Batch-100: CrossEntropyLoss=3.0462 | F1Score=0.4224
Batch-150: CrossEntropyLoss=3.0487 | F1Score=0.4220
Batch-200: CrossEntropyLoss=3.0268 | F1Score=0.4226
Batch-226: CrossEntropyLoss=3.0374 | F1Score=0.4224
Batch-26: CrossEntropyLoss=3.0629 | F1Score=0.4232

Yeah üéâüòÑ! Model improved.
Training   : Mean CrossEntropyLoss = 3.0546 | Mean F1Score = 0.4213
Validation : Mean CrossEntropyLoss = 3.0549 | Mean F1Score = 0.4233
============================================================

EPOCH-8
Batch-50: CrossEntropyLoss=3.0539 | F1Score=0.4270
Batch-100: CrossEntropyLoss=3.0550 | F1Score=0.4290
Batch-150: CrossEntropyLoss=3.0489 | F1Score=0.4268
Batch-200: CrossEntropyLoss=3.0633 | F1Score=0.4266
Batch-226: CrossEntropyLoss=3.0272 | F1Score=0.4284
Batch-26: CrossEntropyLoss=2.9496 | F1Score=0.4295

Yeah üéâüòÑ! Model improved.
Training   : Mean CrossEntropyLoss = 3.0545 | Mean F1Score = 0.4282
Validation : Mean CrossEntropyLoss = 3.0491 | Mean F1Score = 0.4296
============================================================

EPOCH-9
Batch-50: CrossEntropyLoss=3.0478 | F1Score=0.4280
Batch-100: CrossEntropyLoss=3.0668 | F1Score=0.4332
Batch-150: CrossEntropyLoss=3.0761 | F1Score=0.4296
Batch-200: CrossEntropyLoss=3.0592 | F1Score=0.4312
Batch-226: CrossEntropyLoss=3.0381 | F1Score=0.4326
Batch-26: CrossEntropyLoss=2.9786 | F1Score=0.4333

Yeah üéâüòÑ! Model improved.
Training   : Mean CrossEntropyLoss = 3.0541 | Mean F1Score = 0.4303
Validation : Mean CrossEntropyLoss = 3.0501 | Mean F1Score = 0.4331
============================================================

EPOCH-10
Batch-50: CrossEntropyLoss=3.0450 | F1Score=0.4455
Batch-100: CrossEntropyLoss=3.0674 | F1Score=0.4315
Batch-150: CrossEntropyLoss=3.0622 | F1Score=0.4314
Batch-200: CrossEntropyLoss=3.0522 | F1Score=0.4333
Batch-226: CrossEntropyLoss=3.0314 | F1Score=0.4346
Batch-26: CrossEntropyLoss=2.9869 | F1Score=0.4356

Yeah üéâüòÑ! Model improved.
Training   : Mean CrossEntropyLoss = 3.0540 | Mean F1Score = 0.4357
Validation : Mean CrossEntropyLoss = 3.0508 | Mean F1Score = 0.4350
============================================================

EPOCH-11
Batch-50: CrossEntropyLoss=3.0566 | F1Score=0.4340
Batch-100: CrossEntropyLoss=3.0374 | F1Score=0.4385
Batch-150: CrossEntropyLoss=3.0320 | F1Score=0.4377
Batch-200: CrossEntropyLoss=3.0564 | F1Score=0.4381
Batch-226: CrossEntropyLoss=3.0098 | F1Score=0.4369
Batch-26: CrossEntropyLoss=3.0595 | F1Score=0.4378

Yeah üéâüòÑ! Model improved.
Training   : Mean CrossEntropyLoss = 3.0539 | Mean F1Score = 0.4402
Validation : Mean CrossEntropyLoss = 3.0535 | Mean F1Score = 0.4381
============================================================

EPOCH-12
Batch-50: CrossEntropyLoss=3.0587 | F1Score=0.4350
Batch-100: CrossEntropyLoss=3.0448 | F1Score=0.4411
Batch-150: CrossEntropyLoss=3.0567 | F1Score=0.4424
Batch-200: CrossEntropyLoss=3.0499 | F1Score=0.4416
Batch-226: CrossEntropyLoss=3.0396 | F1Score=0.4422
Batch-26: CrossEntropyLoss=3.0855 | F1Score=0.4427

Huft üò•! Model not improved.
Training   : Mean CrossEntropyLoss = 3.0540 | Mean F1Score = 0.4406
Validation : Mean CrossEntropyLoss = 3.0545 | Mean F1Score = 0.4429
Patience = 1/100‚ùó
============================================================

EPOCH-13
Batch-50: CrossEntropyLoss=3.0489 | F1Score=0.4437
Batch-100: CrossEntropyLoss=3.0472 | F1Score=0.4438
Batch-150: CrossEntropyLoss=3.0351 | F1Score=0.4424
Batch-200: CrossEntropyLoss=3.0411 | F1Score=0.4451
Batch-226: CrossEntropyLoss=3.0034 | F1Score=0.4434
Batch-26: CrossEntropyLoss=3.0324 | F1Score=0.4440

Yeah üéâüòÑ! Model improved.
Training   : Mean CrossEntropyLoss = 3.0535 | Mean F1Score = 0.4425
Validation : Mean CrossEntropyLoss = 3.0522 | Mean F1Score = 0.4438
============================================================

EPOCH-14
Batch-50: CrossEntropyLoss=3.0545 | F1Score=0.4485
Batch-100: CrossEntropyLoss=3.0621 | F1Score=0.4452
Batch-150: CrossEntropyLoss=3.0548 | F1Score=0.4450
Batch-200: CrossEntropyLoss=3.0504 | F1Score=0.4430
Batch-226: CrossEntropyLoss=3.0114 | F1Score=0.4437
Batch-26: CrossEntropyLoss=2.9438 | F1Score=0.4451

Yeah üéâüòÑ! Model improved.
Training   : Mean CrossEntropyLoss = 3.0534 | Mean F1Score = 0.4461
Validation : Mean CrossEntropyLoss = 3.0490 | Mean F1Score = 0.4447
============================================================

EPOCH-15
Batch-50: CrossEntropyLoss=3.0479 | F1Score=0.4510
Batch-100: CrossEntropyLoss=3.0624 | F1Score=0.4435
Batch-150: CrossEntropyLoss=3.0533 | F1Score=0.4433
Batch-200: CrossEntropyLoss=3.0497 | F1Score=0.4438
Batch-226: CrossEntropyLoss=3.0410 | F1Score=0.4464
Batch-26: CrossEntropyLoss=3.1008 | F1Score=0.4468

Huft üò•! Model not improved.
Training   : Mean CrossEntropyLoss = 3.0537 | Mean F1Score = 0.4484
Validation : Mean CrossEntropyLoss = 3.0544 | Mean F1Score = 0.4464
Patience = 2/100‚ùó
============================================================

EPOCH-16
Batch-50: CrossEntropyLoss=3.0522 | F1Score=0.4486
Batch-100: CrossEntropyLoss=3.0557 | F1Score=0.4504
Batch-150: CrossEntropyLoss=3.0603 | F1Score=0.4476
Batch-200: CrossEntropyLoss=3.0386 | F1Score=0.4489
Batch-226: CrossEntropyLoss=3.0080 | F1Score=0.4497
Batch-26: CrossEntropyLoss=3.0311 | F1Score=0.4514

Yeah üéâüòÑ! Model improved.
Training   : Mean CrossEntropyLoss = 3.0531 | Mean F1Score = 0.4484
Validation : Mean CrossEntropyLoss = 3.0521 | Mean F1Score = 0.4513
============================================================

EPOCH-17
Batch-50: CrossEntropyLoss=3.0612 | F1Score=0.4598
Batch-100: CrossEntropyLoss=3.0453 | F1Score=0.4604
Batch-150: CrossEntropyLoss=3.0676 | F1Score=0.4562
Batch-200: CrossEntropyLoss=3.0565 | F1Score=0.4522
Batch-226: CrossEntropyLoss=3.0487 | F1Score=0.4512
Batch-26: CrossEntropyLoss=3.0330 | F1Score=0.4518

Huft üò•! Model not improved.
Training   : Mean CrossEntropyLoss = 3.0534 | Mean F1Score = 0.4566
Validation : Mean CrossEntropyLoss = 3.0522 | Mean F1Score = 0.4521
Patience = 3/100‚ùó
============================================================

EPOCH-18
Batch-50: CrossEntropyLoss=3.0351 | F1Score=0.4694
Batch-100: CrossEntropyLoss=3.0614 | F1Score=0.4544
Batch-150: CrossEntropyLoss=3.0591 | F1Score=0.4538
Batch-200: CrossEntropyLoss=3.0566 | F1Score=0.4560
Batch-226: CrossEntropyLoss=3.0171 | F1Score=0.4548
Batch-26: CrossEntropyLoss=2.9573 | F1Score=0.4558

Yeah üéâüòÑ! Model improved.
Training   : Mean CrossEntropyLoss = 3.0531 | Mean F1Score = 0.4611
Validation : Mean CrossEntropyLoss = 3.0488 | Mean F1Score = 0.4550
============================================================

EPOCH-19
Batch-50: CrossEntropyLoss=3.0461 | F1Score=0.4503
Batch-100: CrossEntropyLoss=3.0423 | F1Score=0.4513
Batch-150: CrossEntropyLoss=3.0569 | F1Score=0.4536
Batch-200: CrossEntropyLoss=3.0514 | F1Score=0.4554
Batch-226: CrossEntropyLoss=3.0113 | F1Score=0.4571
Batch-26: CrossEntropyLoss=2.9809 | F1Score=0.4570

Yeah üéâüòÑ! Model improved.
Training   : Mean CrossEntropyLoss = 3.0531 | Mean F1Score = 0.4509
Validation : Mean CrossEntropyLoss = 3.0502 | Mean F1Score = 0.4564
============================================================

EPOCH-20
Batch-50: CrossEntropyLoss=3.0446 | F1Score=0.4594
Batch-100: CrossEntropyLoss=3.0586 | F1Score=0.4530
Batch-150: CrossEntropyLoss=3.0594 | F1Score=0.4561
Batch-200: CrossEntropyLoss=3.0445 | F1Score=0.4567
Batch-226: CrossEntropyLoss=3.0201 | F1Score=0.4594
Batch-26: CrossEntropyLoss=3.1518 | F1Score=0.4601

Yeah üéâüòÑ! Model improved.
Training   : Mean CrossEntropyLoss = 3.0527 | Mean F1Score = 0.4577
Validation : Mean CrossEntropyLoss = 3.0556 | Mean F1Score = 0.4599
============================================================


TRAINING SUMMARY
------------------------------------------------------------
Best training CrossEntropyLoss			: 3.0527
Best training F1Score			: 0.4577
Best validation CrossEntropyLoss			: 3.0556
Best validation F1Score			: 0.4599
Training duration		: 17.247 minutes.
Training date			: 2022-09-30 12:03:52.126594+08:00
