EPOCH-1
Batch-50: NLLLoss=4.850069046020508 | F1Score=0.31437501311302185
Batch-100: NLLLoss=4.076752185821533 | F1Score=0.3578124940395355
Batch-150: NLLLoss=3.0721304416656494 | F1Score=0.40166667103767395
Batch-200: NLLLoss=2.454435110092163 | F1Score=0.43187499046325684
Batch-250: NLLLoss=3.0282704830169678 | F1Score=0.4543750286102295
Batch-300: NLLLoss=3.1269445419311523 | F1Score=0.4779166579246521
Batch-350: NLLLoss=3.8457987308502197 | F1Score=0.4952678680419922
Batch-400: NLLLoss=2.8274483680725098 | F1Score=0.5121874809265137
Batch-450: NLLLoss=2.3727686405181885 | F1Score=0.5247916579246521
Batch-500: NLLLoss=1.8678960800170898 | F1Score=0.5375000238418579
Batch-518: NLLLoss=2.8908822536468506 | F1Score=0.5418427586555481

Mean NLLLoss: 3.61639404296875 | Mean F1Score: 0.4396011233329773
===========================================================================

EPOCH-2
Batch-50: NLLLoss=1.3746342658996582 | F1Score=0.6918749809265137
Batch-100: NLLLoss=1.6348791122436523 | F1Score=0.6915624737739563
Batch-150: NLLLoss=2.2847845554351807 | F1Score=0.6931250095367432
Batch-200: NLLLoss=2.1237876415252686 | F1Score=0.6976562738418579
Batch-250: NLLLoss=2.4064762592315674 | F1Score=0.7018749713897705
Batch-300: NLLLoss=2.7860002517700195 | F1Score=0.7073958516120911
Batch-350: NLLLoss=1.825637936592102 | F1Score=0.7119643092155457
Batch-400: NLLLoss=1.4622207880020142 | F1Score=0.7153905630111694
Batch-450: NLLLoss=1.3926361799240112 | F1Score=0.7186805009841919
Batch-500: NLLLoss=1.684211015701294 | F1Score=0.7216874957084656
Batch-518: NLLLoss=2.3933305740356445 | F1Score=0.7225577235221863

Yeah ðŸŽ‰ðŸ˜„! Model improved.
Mean NLLLoss: 1.8895258903503418 | Mean F1Score: 0.7045383453369141
===========================================================================

EPOCH-3
Batch-50: NLLLoss=1.0514910221099854 | F1Score=0.8081250190734863
Batch-100: NLLLoss=0.9198795557022095 | F1Score=0.7943750023841858
Batch-150: NLLLoss=0.7386568784713745 | F1Score=0.7916666865348816
Batch-200: NLLLoss=1.5427154302597046 | F1Score=0.7832812666893005
Batch-250: NLLLoss=1.2860729694366455 | F1Score=0.7806249856948853
Batch-300: NLLLoss=1.0445141792297363 | F1Score=0.7788541913032532
Batch-350: NLLLoss=1.6058205366134644 | F1Score=0.7799999117851257
Batch-400: NLLLoss=1.3499650955200195 | F1Score=0.7799218893051147
Batch-450: NLLLoss=1.2267979383468628 | F1Score=0.7826389074325562
Batch-500: NLLLoss=1.093660831451416 | F1Score=0.7866874933242798
Batch-518: NLLLoss=1.2517352104187012 | F1Score=0.787646472454071

Yeah ðŸŽ‰ðŸ˜„! Model improved.
Mean NLLLoss: 1.1229726076126099 | Mean F1Score: 0.7873852849006653
===========================================================================

EPOCH-4
Batch-50: NLLLoss=0.44505399465560913 | F1Score=0.8737499713897705
Batch-100: NLLLoss=0.44876229763031006 | F1Score=0.8712499737739563
Batch-150: NLLLoss=0.7453041076660156 | F1Score=0.8656250238418579
Batch-200: NLLLoss=0.7602868676185608 | F1Score=0.8635937571525574
Batch-250: NLLLoss=0.5853943228721619 | F1Score=0.8528749942779541
Batch-300: NLLLoss=1.2342746257781982 | F1Score=0.8462499976158142
