EPOCH-1
Batch-50: NLLLoss=5.131376266479492 | F1Score=0.29750001430511475
Batch-100: NLLLoss=4.1774187088012695 | F1Score=0.35218751430511475
Batch-150: NLLLoss=4.070663928985596 | F1Score=0.39041662216186523
Batch-200: NLLLoss=2.8719120025634766 | F1Score=0.41718748211860657
Batch-250: NLLLoss=3.0411574840545654 | F1Score=0.4453750252723694
Batch-300: NLLLoss=3.400233268737793 | F1Score=0.47062501311302185
Batch-350: NLLLoss=3.0907540321350098 | F1Score=0.4881249964237213
Batch-400: NLLLoss=1.7647736072540283 | F1Score=0.5046093463897705
Batch-450: NLLLoss=3.186598062515259 | F1Score=0.5213888883590698
Batch-500: NLLLoss=3.184720277786255 | F1Score=0.5334374904632568
Batch-518: NLLLoss=2.2821576595306396 | F1Score=0.5382200479507446

Mean NLLLoss: 3.6411373615264893 | Mean F1Score: 0.4320591390132904
===========================================================================

EPOCH-2
Batch-50: NLLLoss=1.1830832958221436 | F1Score=0.7018749713897705
Batch-100: NLLLoss=2.643193244934082 | F1Score=0.6937500238418579
Batch-150: NLLLoss=1.508844017982483 | F1Score=0.6899999976158142
Batch-200: NLLLoss=1.5671184062957764 | F1Score=0.6931250095367432
Batch-250: NLLLoss=2.434718370437622 | F1Score=0.6948750019073486
Batch-300: NLLLoss=1.7971487045288086 | F1Score=0.6990625262260437
Batch-350: NLLLoss=2.2011067867279053 | F1Score=0.7072321176528931
Batch-400: NLLLoss=1.360105276107788 | F1Score=0.7089062333106995
Batch-450: NLLLoss=2.4968318939208984 | F1Score=0.7136111855506897
Batch-500: NLLLoss=1.1042062044143677 | F1Score=0.719124972820282
Batch-518: NLLLoss=1.9966078996658325 | F1Score=0.72044438123703

Yeah ðŸŽ‰ðŸ˜„! Model improved.
Mean NLLLoss: 1.8916083574295044 | Mean F1Score: 0.7005807161331177
===========================================================================

EPOCH-3
Batch-50: NLLLoss=0.3054812550544739 | F1Score=0.809374988079071
Batch-100: NLLLoss=1.1265134811401367 | F1Score=0.8037499785423279
Batch-150: NLLLoss=0.4839184284210205 | F1Score=0.7950000166893005
Batch-200: NLLLoss=0.9693862795829773 | F1Score=0.7878124713897705
Batch-250: NLLLoss=0.886881411075592 | F1Score=0.7856249809265137
Batch-300: NLLLoss=1.0683897733688354 | F1Score=0.7833333611488342
Batch-350: NLLLoss=1.0883322954177856 | F1Score=0.782053530216217
Batch-400: NLLLoss=1.0854452848434448 | F1Score=0.7808593511581421
Batch-450: NLLLoss=1.415027141571045 | F1Score=0.7797222137451172
Batch-500: NLLLoss=1.4153151512145996 | F1Score=0.7804999351501465
Batch-518: NLLLoss=1.0598411560058594 | F1Score=0.7800990343093872

Yeah ðŸŽ‰ðŸ˜„! Model improved.
Mean NLLLoss: 1.1501433849334717 | Mean F1Score: 0.7903942465782166
===========================================================================

EPOCH-4
Batch-50: NLLLoss=0.6927880048751831 | F1Score=0.8725000023841858
Batch-100: NLLLoss=1.0010488033294678 | F1Score=0.8725000023841858
Batch-150: NLLLoss=0.30280742049217224 | F1Score=0.8677083849906921
Batch-200: NLLLoss=0.5436969995498657 | F1Score=0.8590624928474426
Batch-250: NLLLoss=0.6921302080154419 | F1Score=0.8523749709129333
Batch-300: NLLLoss=0.6967052221298218 | F1Score=0.848229169845581
Batch-350: NLLLoss=0.3857062757015228 | F1Score=0.845714271068573
Batch-400: NLLLoss=0.9602495431900024 | F1Score=0.8415625095367432
Batch-450: NLLLoss=0.984649658203125 | F1Score=0.8370833396911621
Batch-500: NLLLoss=0.3165869414806366 | F1Score=0.835562527179718
Batch-518: NLLLoss=0.4116024971008301 | F1Score=0.8341987133026123

Yeah ðŸŽ‰ðŸ˜„! Model improved.
Mean NLLLoss: 0.7337779402732849 | Mean F1Score: 0.8538323640823364
===========================================================================

EPOCH-5
Batch-50: NLLLoss=0.12239910662174225 | F1Score=0.8981249928474426
Batch-100: NLLLoss=0.4565892815589905 | F1Score=0.9037500023841858
Batch-150: NLLLoss=0.344551146030426 | F1Score=0.9058333039283752
Batch-200: NLLLoss=0.3617374897003174 | F1Score=0.9056249856948853
Batch-250: NLLLoss=0.3185473382472992 | F1Score=0.9036250114440918
Batch-300: NLLLoss=0.41221722960472107 | F1Score=0.8999999761581421
Batch-350: NLLLoss=0.5432588458061218 | F1Score=0.8965178728103638
Batch-400: NLLLoss=0.9233345985412598 | F1Score=0.8931249976158142
Batch-450: NLLLoss=0.7671688795089722 | F1Score=0.8897222280502319
Batch-500: NLLLoss=0.355207234621048 | F1Score=0.8873124718666077
Batch-518: NLLLoss=0.09348329901695251 | F1Score=0.8870304822921753

Yeah ðŸŽ‰ðŸ˜„! Model improved.
Mean NLLLoss: 0.4519694149494171 | Mean F1Score: 0.8976236581802368
===========================================================================

EPOCH-6
Batch-50: NLLLoss=0.07259436696767807 | F1Score=0.9300000071525574
Batch-100: NLLLoss=0.17343313992023468 | F1Score=0.9303125143051147
Batch-150: NLLLoss=0.3208048641681671 | F1Score=0.9312499761581421
Batch-200: NLLLoss=0.2470739483833313 | F1Score=0.9306250214576721
Batch-250: NLLLoss=0.3726731538772583 | F1Score=0.9269999861717224
Batch-300: NLLLoss=0.1449032425880432 | F1Score=0.9281250238418579
Batch-350: NLLLoss=0.23645129799842834 | F1Score=0.9272321462631226
Batch-400: NLLLoss=0.4756137430667877 | F1Score=0.9246093034744263
Batch-450: NLLLoss=0.7164150476455688 | F1Score=0.9210416674613953
Batch-500: NLLLoss=0.31682297587394714 | F1Score=0.9171249866485596
Batch-518: NLLLoss=0.2876425087451935 | F1Score=0.9157106876373291

Yeah ðŸŽ‰ðŸ˜„! Model improved.
Mean NLLLoss: 0.3305283188819885 | Mean F1Score: 0.9279399514198303
===========================================================================

EPOCH-7
Batch-50: NLLLoss=0.3215222656726837 | F1Score=0.9356250166893005
Batch-100: NLLLoss=0.1104210615158081 | F1Score=0.9387500286102295
Batch-150: NLLLoss=0.16910845041275024 | F1Score=0.940833330154419
Batch-200: NLLLoss=0.24003078043460846 | F1Score=0.9429687261581421
Batch-250: NLLLoss=0.09079261124134064 | F1Score=0.9438750147819519
Batch-300: NLLLoss=0.5163230299949646 | F1Score=0.9443749785423279
Batch-350: NLLLoss=0.2162928730249405 | F1Score=0.9438393115997314
Batch-400: NLLLoss=0.38403937220573425 | F1Score=0.9428906440734863
Batch-450: NLLLoss=0.09020796418190002 | F1Score=0.941736102104187
Batch-500: NLLLoss=0.3699328303337097 | F1Score=0.9388750195503235
Batch-518: NLLLoss=0.04174075648188591 | F1Score=0.938956618309021

Yeah ðŸŽ‰ðŸ˜„! Model improved.
Mean NLLLoss: 0.25404080748558044 | Mean F1Score: 0.9415470957756042
===========================================================================

EPOCH-8
Batch-50: NLLLoss=0.36280298233032227 | F1Score=0.9474999904632568
Batch-100: NLLLoss=0.17585934698581696 | F1Score=0.9409375190734863
Batch-150: NLLLoss=0.038446299731731415 | F1Score=0.9418749809265137
Batch-200: NLLLoss=0.47451168298721313 | F1Score=0.938281238079071
Batch-250: NLLLoss=0.7036401033401489 | F1Score=0.9353749752044678
Batch-300: NLLLoss=0.9764989614486694 | F1Score=0.9337499737739563
Batch-350: NLLLoss=0.2719944715499878 | F1Score=0.932410717010498
Batch-400: NLLLoss=0.2182343453168869 | F1Score=0.9321094155311584
Batch-450: NLLLoss=0.4827726483345032 | F1Score=0.9308333396911621
Batch-500: NLLLoss=0.41404756903648376 | F1Score=0.9303749799728394
Batch-518: NLLLoss=0.010252288542687893 | F1Score=0.93026202917099

Huft ðŸ˜¥! Model not improved.
Mean NLLLoss: 0.29112550616264343 | Mean F1Score: 0.9368988275527954
===========================================================================

EPOCH-9
Batch-50: NLLLoss=0.027297591790556908 | F1Score=0.9412500262260437
Batch-100: NLLLoss=0.38476109504699707 | F1Score=0.9424999952316284
Batch-150: NLLLoss=0.4753588140010834 | F1Score=0.9416666626930237
Batch-200: NLLLoss=0.1251162886619568 | F1Score=0.9392187595367432
Batch-250: NLLLoss=0.426146537065506 | F1Score=0.9404999613761902
Batch-300: NLLLoss=0.33988693356513977 | F1Score=0.9393749833106995
Batch-350: NLLLoss=0.3017370402812958 | F1Score=0.9388392567634583
Batch-400: NLLLoss=0.02172217331826687 | F1Score=0.9399999976158142
Batch-450: NLLLoss=0.15354105830192566 | F1Score=0.9390972256660461
Batch-500: NLLLoss=0.11198900640010834 | F1Score=0.9391250014305115
Batch-518: NLLLoss=0.2297326922416687 | F1Score=0.938956618309021

Yeah ðŸŽ‰ðŸ˜„! Model improved.
Mean NLLLoss: 0.24859574437141418 | Mean F1Score: 0.9404723048210144
===========================================================================

EPOCH-10
Batch-50: NLLLoss=0.05237878859043121 | F1Score=0.9587500095367432
Batch-100: NLLLoss=0.0096970209851861 | F1Score=0.9565624594688416
Batch-150: NLLLoss=0.015689415857195854 | F1Score=0.9558333158493042
Batch-200: NLLLoss=0.07159961014986038 | F1Score=0.9540625214576721
Batch-250: NLLLoss=0.07225024700164795 | F1Score=0.9557499885559082
Batch-300: NLLLoss=0.20699307322502136 | F1Score=0.9526041746139526
Batch-350: NLLLoss=0.4244723618030548 | F1Score=0.9516071677207947
Batch-400: NLLLoss=0.0138070248067379 | F1Score=0.9510937333106995
Batch-450: NLLLoss=0.3575838506221771 | F1Score=0.9488194584846497
Batch-500: NLLLoss=0.33425024151802063 | F1Score=0.9481874704360962
Batch-518: NLLLoss=0.0027860284317284822 | F1Score=0.9475304484367371

Yeah ðŸŽ‰ðŸ˜„! Model improved.
Mean NLLLoss: 0.21816428005695343 | Mean F1Score: 0.9538117051124573
===========================================================================

EPOCH-11
Batch-50: NLLLoss=0.0016495083691552281 | F1Score=0.9674999713897705
Batch-100: NLLLoss=0.03269845247268677 | F1Score=0.9615625143051147
Batch-150: NLLLoss=0.18642503023147583 | F1Score=0.9608333110809326
Batch-200: NLLLoss=0.4866919219493866 | F1Score=0.9595312476158142
Batch-250: NLLLoss=0.07146786898374557 | F1Score=0.9585000276565552
Batch-300: NLLLoss=0.534227192401886 | F1Score=0.9555208086967468
Batch-350: NLLLoss=0.634084165096283 | F1Score=0.9533035755157471
Batch-400: NLLLoss=0.20291858911514282 | F1Score=0.9510937333106995
Batch-450: NLLLoss=0.31479743123054504 | F1Score=0.9481944441795349
Batch-500: NLLLoss=0.20083951950073242 | F1Score=0.945062518119812
Batch-518: NLLLoss=0.3641895651817322 | F1Score=0.9440284967422485

Huft ðŸ˜¥! Model not improved.
Mean NLLLoss: 0.2357463538646698 | Mean F1Score: 0.9562495350837708
===========================================================================

EPOCH-12
Batch-50: NLLLoss=0.0642460361123085 | F1Score=0.9624999761581421
Batch-100: NLLLoss=0.13244695961475372 | F1Score=0.9584375023841858
Batch-150: NLLLoss=0.0363813191652298 | F1Score=0.9552083611488342
Batch-200: NLLLoss=0.07975451648235321 | F1Score=0.9556249976158142
Batch-250: NLLLoss=0.07817947119474411 | F1Score=0.9571250081062317
Batch-300: NLLLoss=0.09214597940444946 | F1Score=0.9581249952316284
Batch-350: NLLLoss=0.005133035592734814 | F1Score=0.9589285850524902
Batch-400: NLLLoss=0.14505687355995178 | F1Score=0.9585937261581421
Batch-450: NLLLoss=0.20591481029987335 | F1Score=0.9582638740539551
Batch-500: NLLLoss=0.20087113976478577 | F1Score=0.9570624828338623
Batch-518: NLLLoss=0.11962805688381195 | F1Score=0.95701003074646

Yeah ðŸŽ‰ðŸ˜„! Model improved.
Mean NLLLoss: 0.17870928347110748 | Mean F1Score: 0.9583476781845093
===========================================================================

EPOCH-13
Batch-50: NLLLoss=0.0036803714465349913 | F1Score=0.9756249785423279
Batch-100: NLLLoss=0.17308375239372253 | F1Score=0.9768750071525574
Batch-150: NLLLoss=0.2257702350616455 | F1Score=0.9739583134651184
Batch-200: NLLLoss=0.0010084786918014288 | F1Score=0.9743750095367432
Batch-250: NLLLoss=0.18116028606891632 | F1Score=0.9745000004768372
Batch-300: NLLLoss=0.005559496581554413 | F1Score=0.973229169845581
Batch-350: NLLLoss=0.0011245941277593374 | F1Score=0.971875011920929
Batch-400: NLLLoss=0.007798437960445881 | F1Score=0.9700000286102295
Batch-450: NLLLoss=0.2842293381690979 | F1Score=0.9686805605888367
Batch-500: NLLLoss=0.19274869561195374 | F1Score=0.965499997138977
Batch-518: NLLLoss=0.12330276519060135 | F1Score=0.9641951322555542

Yeah ðŸŽ‰ðŸ˜„! Model improved.
Mean NLLLoss: 0.16020241379737854 | Mean F1Score: 0.9726496934890747
===========================================================================

EPOCH-14
Batch-50: NLLLoss=0.47124403715133667 | F1Score=0.9543750286102295
Batch-100: NLLLoss=0.17095890641212463 | F1Score=0.956250011920929
Batch-150: NLLLoss=0.1297706514596939 | F1Score=0.9566666483879089
Batch-200: NLLLoss=0.038078512996435165 | F1Score=0.9554687738418579
Batch-250: NLLLoss=0.7360281944274902 | F1Score=0.9547500014305115
Batch-300: NLLLoss=0.08400405943393707 | F1Score=0.95374995470047
Batch-350: NLLLoss=0.2604740262031555 | F1Score=0.9536607265472412
Batch-400: NLLLoss=0.16348938643932343 | F1Score=0.9535937309265137
Batch-450: NLLLoss=0.32011714577674866 | F1Score=0.9509027600288391
Batch-500: NLLLoss=0.5264299511909485 | F1Score=0.950124979019165
Batch-518: NLLLoss=0.16860148310661316 | F1Score=0.9494626522064209

Huft ðŸ˜¥! Model not improved.
Mean NLLLoss: 0.23161180317401886 | Mean F1Score: 0.9540030360221863
===========================================================================

EPOCH-15
Batch-50: NLLLoss=0.09901861101388931 | F1Score=0.9606249928474426
Batch-100: NLLLoss=0.10052303969860077 | F1Score=0.9524999856948853
Batch-150: NLLLoss=0.017863191664218903 | F1Score=0.9495833516120911
Batch-200: NLLLoss=0.788984477519989 | F1Score=0.9490625262260437
Batch-250: NLLLoss=0.21513794362545013 | F1Score=0.9488750100135803
Batch-300: NLLLoss=0.42216211557388306 | F1Score=0.9483333230018616
Batch-350: NLLLoss=0.014769845642149448 | F1Score=0.9455357193946838
Batch-400: NLLLoss=0.4764717221260071 | F1Score=0.9439843893051147
Batch-450: NLLLoss=0.22004370391368866 | F1Score=0.9426388740539551
Batch-500: NLLLoss=0.28534916043281555 | F1Score=0.9417499899864197
Batch-518: NLLLoss=0.009163932874798775 | F1Score=0.9417944550514221

Huft ðŸ˜¥! Model not improved.
Mean NLLLoss: 0.2764764130115509 | Mean F1Score: 0.9496582746505737
===========================================================================


Training duration : 68.935 minutes.
Training date     : 2022-09-20 04:49:02.121423
